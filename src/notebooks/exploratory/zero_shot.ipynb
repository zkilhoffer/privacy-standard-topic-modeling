{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Zero-shot learning trials\n",
    "\n",
    "- By [Zachary Kilhoffer](https://zkilhoffer.github.io/)\n",
    "- Updated 2024-06-17\n",
    "\n",
    "***\n",
    "\n",
    "## Description\n",
    "- The code is part of the pipelines described in: \n",
    "  - Kilhoffer, Z. et al. (2024 in press). \"Cloud Privacy Beyond Legal Compliance: An NLP analysis of certifiable privacy and security standards\".\n",
    "- The paper will be released on 2024-06-28 at the [IEEE Cloud Summit](https://www.ieeecloudsummit.org/2024-program).\n",
    "\n",
    "***\n",
    "\n",
    "- This goal of this exploratory script is to try to match privacy and security controls with helpful and insightful labels. \n",
    "- This code performs zero-shot learning to match (A) our control texts with (B) pre-defined sets of topics.\n",
    "- A nice feature of the zero-shot learning shown is it allows for documents to be matched to multiple categories, assigning probabilities to each.\n",
    "  - That can help you look for conceptual overlaps between topics.\n",
    "\n",
    "***\n",
    "\n",
    "### Input files:\n",
    " - ...\n",
    " - ...\n",
    "\n",
    "### Output files:\n",
    "- ....\n",
    "- ...\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO:\n",
    "Implement Yuanye comments: \n",
    "- strongest contribution is to make comments on how the documents differ based on the analysis. \n",
    "- some documents for engineers moreso, some for managers/data processor/data controller\n",
    "- really go deep in discussing the differences between documents, and how those differences matter for the implementation of privacy.\n",
    "- spend time doing this in the discussion especially, and to an extent the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, warnings, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import openpyxl\n",
    "from transformers import BertTokenizer, BertModel, pipeline\n",
    "\n",
    "from bertopic import BERTopic\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display tweaks\n",
    "pd.set_option(\"display.max_colwidth\", 200)  # how much text is showing within a cell\n",
    "pd.set_option(\"display.max_columns\", False)\n",
    "pd.set_option(\"display.max_rows\", False)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_excel('../data/df_embeddings_publicdomain.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load classification schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c2p2\n",
    "with open(r'F:\\Dropbox\\Documents\\Education\\PhD\\Cisco\\Cloud Certifications Evaluation V2\\Analysis\\cisco_privacy_controls_2023-11-02\\data\\c2p2_criteria.txt', 'r', encoding='utf8') as f:\n",
    "    c2p2 = [x.strip().lower() for x in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extended fipps\n",
    "with open(r'F:\\Dropbox\\Documents\\Education\\PhD\\Cisco\\Cloud Certifications Evaluation V2\\Analysis\\cisco_privacy_controls_2023-11-02\\data\\extended_FIPPs.txt', 'r', encoding='utf8') as f:\n",
    "    fipps_extended = [x.strip() for x in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nist privacy framework\n",
    "with open(r'F:\\Dropbox\\Documents\\Education\\PhD\\Cisco\\Cloud Certifications Evaluation V2\\Analysis\\cisco_privacy_controls_2023-11-02\\data\\nist_privacy_framework.txt', 'r', encoding='utf8') as f:\n",
    "    nist_framework = [x.strip() for x in f.readlines()]\n",
    "\n",
    "# removing control codes like (ID.IM-P), grabbing what's before, after, or both\n",
    "pattern1 = r' \\(([^)]+)\\):[^:]+'\n",
    "nist_framework_name = [re.sub(pattern1, '', x).lower() for x in nist_framework]\n",
    "nist_framework_name = list(set(nist_framework_name))\n",
    "\n",
    "pattern2 = r' \\(([^)]+)\\):[^:]'\n",
    "nist_framework_full = [re.sub(pattern2, ': ', x).lower() for x in nist_framework]\n",
    "\n",
    "pattern3 = r'\\(([^)]+)\\):[^:](.*)'\n",
    "nist_framework_description = [re.search(pattern3, x).group(2).lower() for x in nist_framework]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a random full control\n",
    "def rando_control():\n",
    "    return df['full_control_text'][random.randint(0, df.shape[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bart large mnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing different levels of specificity/detail of NIST framework description\n",
    "\n",
    "candidate_labels = [fipps_extended, c2p2, nist_framework_name]\n",
    "sequence_to_classify = rando_control()\n",
    "print(sequence_to_classify)\n",
    "print('***'*10)\n",
    "\n",
    "for labels in candidate_labels:\n",
    "    temp = classifier(sequence_to_classify, labels)\n",
    "    for x, y in zip(temp['labels'][:5], temp['scores'][:5]):\n",
    "        print(x if len(x) < 50 else x[:50], f'{y:.3}')\n",
    "    print('***'*10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeBERTa-v3-base-mnli-fever-anli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\", model=\"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deberta-v3-base-tasksource-nli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\", model=\"sileod/deberta-v3-base-tasksource-nli\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mDeBERTa-v3-base-mnli-xnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\", model=\"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create small df to test \n",
    "df_smol = df.groupby('document', group_keys=False).apply(lambda x: x.sample(min(len(x), 3)))\n",
    "df_smol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\", model=\"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\")\n",
    "\n",
    "df_smol['zeroshot_fipps_mDeBERTa'] = df_smol['full_control_text'].apply(lambda x: classifier(x, fipps_extended))\n",
    "df_smol['zeroshot_c2p2_mDeBERTa'] = df_smol['full_control_text'].apply(lambda x: classifier(x, c2p2))\n",
    "df_smol['zeroshot_nist_mDeBERTa'] = df_smol['full_control_text'].apply(lambda x: classifier(x, nist_framework_name))\n",
    "\n",
    "from transformers import pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "df_smol['zeroshot_fipps_bart'] = df_smol['full_control_text'].apply(lambda x: classifier(x, fipps_extended))\n",
    "df_smol['zeroshot_c2p2_bart'] = df_smol['full_control_text'].apply(lambda x: classifier(x, c2p2))\n",
    "df_smol['zeroshot_nist_bart'] = df_smol['full_control_text'].apply(lambda x: classifier(x, nist_framework_name))\n",
    "\n",
    "from transformers import pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"sileod/deberta-v3-base-tasksource-nli\")\n",
    "\n",
    "df_smol['zeroshot_fipps_DeBERTa'] = df_smol['full_control_text'].apply(lambda x: classifier(x, fipps_extended))\n",
    "df_smol['zeroshot_c2p2_DeBERTa'] = df_smol['full_control_text'].apply(lambda x: classifier(x, c2p2))\n",
    "df_smol['zeroshot_nist_DeBERTa'] = df_smol['full_control_text'].apply(lambda x: classifier(x, nist_framework_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ciscovenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
