{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Topic Modeling\n",
    "\n",
    "- By [Zachary Kilhoffer](https://zkilhoffer.github.io/)\n",
    "- Updated 2024-06-17\n",
    "\n",
    "***\n",
    "\n",
    "## Description\n",
    "- TODO\n",
    "- This is the main topic modeling script.\n",
    "- This is part of the BERTopic topic modeling pipeline.\n",
    "\n",
    "***\n",
    "\n",
    "### Input files:\n",
    "Data: \n",
    "  \n",
    "  > `/src/data/data-clean-embeddings.csv`\n",
    "\n",
    "Fine-tuned LLM: \n",
    "\n",
    "  > `/src/outputs/fine_tuned_model`\n",
    "\n",
    "***\n",
    "\n",
    "# TODO:\n",
    "- Start by adding sections for what needs to be done. \n",
    "- Ie, topic modeling, show visual of hierarchy and have explanation, merge categories, pass the representative texts to OpenAI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel, pipeline\n",
    "from bertopic import BERTopic\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import openai\n",
    "from bertopic.backend import OpenAIBackend\n",
    "from bertopic.representation import KeyBERTInspired, MaximalMarginalRelevance, OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display tweaks\n",
    "pd.set_option(\"display.max_colwidth\", 200)  # how much text is showing within a cell\n",
    "pd.set_option(\"display.max_columns\", False)\n",
    "pd.set_option(\"display.max_rows\", False)\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv(\n",
    "    \"../data/data-clean-embeddings.csv\",\n",
    "    converters={\"BERTembeddings\": json.loads, \"finetuned_embeddings\": json.loads},\n",
    "    index_col=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>control_code</th>\n",
       "      <th>control_name</th>\n",
       "      <th>document</th>\n",
       "      <th>control_text_corrected</th>\n",
       "      <th>full_control_text</th>\n",
       "      <th>BERTembeddings</th>\n",
       "      <th>finetuned_embeddings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>control_category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>organisation of information security (ois)</th>\n",
       "      <td>OIS-01</td>\n",
       "      <td>information security management system (isms)</td>\n",
       "      <td>c5</td>\n",
       "      <td>Basic criterion: The cloud service provider operates an Information Security Management System (ISMS) in accordance with ISO/IEC 27001. The scope of the ISMS covers the cloud service provider's or...</td>\n",
       "      <td>Organisation of information security (ois). Information security management system (isms). Basic criterion: The cloud service provider operates an Information Security Management System (ISMS) in ...</td>\n",
       "      <td>[-0.23476624488830566, -0.22193537652492523, -0.9937419891357422, 0.36702337861061096, 0.8497382998466492, -0.16401638090610504, -0.6381358504295349, -0.11291695386171341, -0.966692328453064, -0.9...</td>\n",
       "      <td>[0.07736359536647797, 0.3031435012817383, 0.2493477761745453, 0.2686106860637665, -0.08708430826663971, 0.18207691609859467, -0.3521919846534729, 0.13333041965961456, -0.4935278594493866, -0.26271...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>organisation of information security (ois)</th>\n",
       "      <td>OIS-02</td>\n",
       "      <td>information security policy</td>\n",
       "      <td>c5</td>\n",
       "      <td>Basic criterion: The top management of the cloud service provider has adopted an information security policy and communicated it to internal and external employees, as well as cloud customers. The...</td>\n",
       "      <td>Organisation of information security (ois). Information security policy. Basic criterion: The top management of the cloud service provider has adopted an information security policy and communicat...</td>\n",
       "      <td>[-0.6862502098083496, -0.4821060001850128, -0.9979186654090881, 0.6634559631347656, 0.8985686898231506, -0.33475595712661743, 0.11295092105865479, 0.24699804186820984, -0.975180983543396, -0.99998...</td>\n",
       "      <td>[-0.016582056879997253, -0.0244668610394001, 0.07456215471029282, 0.16462843120098114, -0.07647715508937836, 0.17928528785705566, -0.32165899872779846, 0.036916326731443405, -0.4814055860042572, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           control_code  ...                                                                                                                                                                                     finetuned_embeddings\n",
       "control_category                                         ...                                                                                                                                                                                                         \n",
       "organisation of information security (ois)       OIS-01  ...  [0.07736359536647797, 0.3031435012817383, 0.2493477761745453, 0.2686106860637665, -0.08708430826663971, 0.18207691609859467, -0.3521919846534729, 0.13333041965961456, -0.4935278594493866, -0.26271...\n",
       "organisation of information security (ois)       OIS-02  ...  [-0.016582056879997253, -0.0244668610394001, 0.07456215471029282, 0.16462843120098114, -0.07647715508937836, 0.17928528785705566, -0.32165899872779846, 0.036916326731443405, -0.4814055860042572, -...\n",
       "\n",
       "[2 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect data\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main df\n",
    "docs = list(df[\"full_control_text\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out of the box topic modeling\n",
    "- For illustration, you can get pretty good results with BERTopic with very little effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    }
   ],
   "source": [
    "# topic modeling with BERTopic defaults\n",
    "topic_model = BERTopic()\n",
    "topics, probs = topic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>48</td>\n",
       "      <td>-1_media_and_to_or</td>\n",
       "      <td>[media, and, to, or, systems, the, information, of, external, access]</td>\n",
       "      <td>[Media protection. Media use. a. [selection: Restrict; Prohibit] the use of [assignment: organization-defined types of system media] on [assignment: organization-defined systems or system componen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0_the_cloud_of_criterion</td>\n",
       "      <td>[the, cloud, of, criterion, service, and, in, to, for, provider]</td>\n",
       "      <td>[Control and monitoring of service providers and suppliers (sso). Policies and instructions for controlling and monitoring third parties. Basic criterion: Policies and instructions for controlling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>1_configuration_system_software_and</td>\n",
       "      <td>[configuration, system, software, and, components, the, changes, to, management, of]</td>\n",
       "      <td>[Configuration management. Configuration change control. A. Determine and document the types of changes to the system that are configuration-controlled.\\nB. Review proposed configuration-controlle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>2_contingency_alternate_site_planning</td>\n",
       "      <td>[contingency, alternate, site, planning, processing, recovery, sites, plans, plan, telecommunications]</td>\n",
       "      <td>[Contingency planning. Alternate storage site. a. Establish an alternate storage site, including necessary agreements to permit the storage and retrieval of system backup information; and b. Ensur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>3_physical_access_power_environmental</td>\n",
       "      <td>[physical, access, power, environmental, to, wireless, devices, facility, and, or]</td>\n",
       "      <td>[Physical and environmental protection. Monitoring physical access | monitoring physical access to systems. Monitor physical access to the system, in addition to the physical access monitoring of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>4_system_integrity_monitoring_information</td>\n",
       "      <td>[system, integrity, monitoring, information, and, malicious, or, code, organizationdefined, to]</td>\n",
       "      <td>[System and information integrity. System monitoring | system-generated alerts. Alert [assignment: organization-defined personnel or roles] when the following system-generated indications of compr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>5_authentication_authenticators_identification_identity</td>\n",
       "      <td>[authentication, authenticators, identification, identity, users, of, passwords, to, authenticator, and]</td>\n",
       "      <td>[Identification and authentication. Identification and authentication (organizational users). Uniquely identify and authenticate organizational users and associate that unique identification with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>6_audit_records_event_record</td>\n",
       "      <td>[audit, records, event, record, logging, of, information, time, and, accountability]</td>\n",
       "      <td>[Audit and accountability. Response to audit logging process failures. a. Alert (assignment: organization-defined personnel or roles) within (assignment: organization-defined time period) in the e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>7_accounts_account_access_privileged</td>\n",
       "      <td>[accounts, account, access, privileged, or, system, users, of, control, for]</td>\n",
       "      <td>[Access control. Least privilege | privileged accounts. Restrict privileged accounts on the system to [assignment: organization-defined personnel or roles]. Privileged accounts, including super us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>8_incident_response_and_incidents</td>\n",
       "      <td>[incident, response, and, incidents, to, the, information, handling, training, or]</td>\n",
       "      <td>[Incident response. Incident response testing. Test the effectiveness of the incident response capability for the system [assignment: organization-defined frequency] using the following tests: [as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>9_procedures_policy_and_policies</td>\n",
       "      <td>[procedures, policy, and, policies, or, privacy, security, organizationdefined, the, controls]</td>\n",
       "      <td>[Risk assessment. Policy and procedures. A. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]: 1. [Selection (one or more): organization level; mission/bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>10_system_and_privacy_security</td>\n",
       "      <td>[system, and, privacy, security, the, services, development, of, or, design]</td>\n",
       "      <td>[System and services acquisition. System development life cycle. A. Acquire, develop, and manage the system using [assignment: organization-defined system development life cycle] that incorporates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>11_assessment_assessments_vulnerability_monitoring</td>\n",
       "      <td>[assessment, assessments, vulnerability, monitoring, risk, the, to, and, organizations, testing]</td>\n",
       "      <td>[Risk assessment. Risk assessment. A. Conduct a risk assessment, including: 1. identifying threats to and vulnerabilities in the system; 2. determining the likelihood and magnitude of harm from un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>12_boundary_protection_system_communications</td>\n",
       "      <td>[boundary, protection, system, communications, to, traffic, external, and, network, from]</td>\n",
       "      <td>[System and communications protection. Architecture and provisioning for name/address resolution service. Ensure the systems that collectively provide name/address resolution service for an organi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>13_supply_chain_risk_and</td>\n",
       "      <td>[supply, chain, risk, and, or, management, system, scrm, components, the]</td>\n",
       "      <td>[Risk assessment. Risk assessment | supply chain risk assessment. (a) Assess supply chain risks associated with [assignment: organization-defined systems, system components, and system services]; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>14_cryptographic_information_key_protection</td>\n",
       "      <td>[cryptographic, information, key, protection, of, rest, and, cryptography, confidentiality, integrity]</td>\n",
       "      <td>[System and communications protection. Cryptographic key establishment and management. Establish and manage cryptographic keys when cryptography is employed within the system in accordance with th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>15_maintenance_diagnostic_tools_nonlocal</td>\n",
       "      <td>[maintenance, diagnostic, tools, nonlocal, or, personnel, organizational, the, equipment, and]</td>\n",
       "      <td>[Maintenance. Maintenance personnel. a. Establish a process for maintenance personnel authorization and maintain a list of authorized maintenance organizations or personnel. \\nb. Verify that non-e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  ...                                                                                                                                                                                      Representative_Docs\n",
       "0      -1  ...  [Media protection. Media use. a. [selection: Restrict; Prohibit] the use of [assignment: organization-defined types of system media] on [assignment: organization-defined systems or system componen...\n",
       "1       0  ...  [Control and monitoring of service providers and suppliers (sso). Policies and instructions for controlling and monitoring third parties. Basic criterion: Policies and instructions for controlling...\n",
       "2       1  ...  [Configuration management. Configuration change control. A. Determine and document the types of changes to the system that are configuration-controlled.\\nB. Review proposed configuration-controlle...\n",
       "3       2  ...  [Contingency planning. Alternate storage site. a. Establish an alternate storage site, including necessary agreements to permit the storage and retrieval of system backup information; and b. Ensur...\n",
       "4       3  ...  [Physical and environmental protection. Monitoring physical access | monitoring physical access to systems. Monitor physical access to the system, in addition to the physical access monitoring of ...\n",
       "5       4  ...  [System and information integrity. System monitoring | system-generated alerts. Alert [assignment: organization-defined personnel or roles] when the following system-generated indications of compr...\n",
       "6       5  ...  [Identification and authentication. Identification and authentication (organizational users). Uniquely identify and authenticate organizational users and associate that unique identification with ...\n",
       "7       6  ...  [Audit and accountability. Response to audit logging process failures. a. Alert (assignment: organization-defined personnel or roles) within (assignment: organization-defined time period) in the e...\n",
       "8       7  ...  [Access control. Least privilege | privileged accounts. Restrict privileged accounts on the system to [assignment: organization-defined personnel or roles]. Privileged accounts, including super us...\n",
       "9       8  ...  [Incident response. Incident response testing. Test the effectiveness of the incident response capability for the system [assignment: organization-defined frequency] using the following tests: [as...\n",
       "10      9  ...  [Risk assessment. Policy and procedures. A. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]: 1. [Selection (one or more): organization level; mission/bu...\n",
       "11     10  ...  [System and services acquisition. System development life cycle. A. Acquire, develop, and manage the system using [assignment: organization-defined system development life cycle] that incorporates...\n",
       "12     11  ...  [Risk assessment. Risk assessment. A. Conduct a risk assessment, including: 1. identifying threats to and vulnerabilities in the system; 2. determining the likelihood and magnitude of harm from un...\n",
       "13     12  ...  [System and communications protection. Architecture and provisioning for name/address resolution service. Ensure the systems that collectively provide name/address resolution service for an organi...\n",
       "14     13  ...  [Risk assessment. Risk assessment | supply chain risk assessment. (a) Assess supply chain risks associated with [assignment: organization-defined systems, system components, and system services]; ...\n",
       "15     14  ...  [System and communications protection. Cryptographic key establishment and management. Establish and manage cryptographic keys when cryptography is employed within the system in accordance with th...\n",
       "16     15  ...  [Maintenance. Maintenance personnel. a. Establish a process for maintenance personnel authorization and maintain a list of authorized maintenance organizations or personnel. \\nb. Verify that non-e...\n",
       "\n",
       "[17 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show summary of topics\n",
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "text",
         "hovertext": [
          "Awareness and training. Training records. a. Document and monitor information security and privacy training activities, including security and privacy awareness training and specific role-based security and privacy training. \n\nb. Retain individual training records for [assignment: organization-defined time period]. \n\nDocumentation for specialized training may be maintained by individual supervisors at the discretion of the organization. \n\nThe National Archives and Records Administration provides guidance on records retention for federal agencies.",
          "Access control. Remote access | protection of confidentiality and integrity using encryption. Implement cryptographic mechanisms to protect the confidentiality and integrity of remote access sessions. Virtual private networks can be used to protect the confidentiality and integrity of remote access sessions. Transport Layer Security (TLS) is an example of a cryptographic protocol that provides end-to-end communication security over networks and is used for internet communications and online transactions.",
          "Media protection. Media access. Restrict access to [assignment: organization-defined types of digital and/or non-digital media] to [assignment: organization-defined personnel or roles]. System media includes digital and non-digital media. Digital media includes flash drives, diskettes, magnetic tapes, external or removable hard disk drives (e.g., solid state, magnetic), compact discs, and digital versatile discs. Non-digital media includes paper and microfilm. Denying access to patient medical records in a community hospital unless the individuals seeking access to such records are authorized healthcare providers is an example of restricting access to non-digital media. Limiting access to the design specifications stored on compact discs in the media library to individuals on the system development team is an example of restricting access to digital media.",
          "System and communications protection. System time synchronization. Synchronize system clocks within and between systems and system components. Time synchronization of system clocks is essential for the correct execution of many system services, including identification and authentication processes that involve certificates and time-of-day restrictions as part of access control. Denial of service or failure to deny expired credentials may result without properly synchronized clocks within and between systems and system components. Time is commonly expressed in Coordinated Universal Time (UTC), a modern continuation of Greenwich Mean Time (GMT), or local time with an offset from UTC. The granularity of time measurements refers to the degree of synchronization between system clocks and reference clocks, such as clocks synchronizing within hundreds of milliseconds or tens of milliseconds. Organizations may define different time granularities for system components. Time service can be critical to other security capabilities—such as access control and identification and authentication—depending on the nature of the mechanisms used to support the capabilities.",
          "Media protection. Media transport. a. Protect and control [assignment: organization-defined types of system media] during transport outside of controlled areas using [assignment: organization-defined controls]. b. Maintain accountability for system media during transport outside of controlled areas. c. Document activities associated with the transport of system media. d. Restrict the activities associated with the transport of system media to authorized personnel.\n\nSystem media includes digital and non-digital media. Digital media includes flash drives, diskettes, magnetic tapes, external or removable hard disk drives (e.g., solid state and magnetic), compact discs, and digital versatile discs. Non-digital media includes microfilm and paper.\n\nControlled areas are spaces for which organizations provide physical or procedural controls to meet requirements established for protecting information and systems. Controls to protect media during transport include cryptography and locked containers. Cryptographic mechanisms can provide confidentiality and integrity protections depending on the mechanisms implemented.\n\nActivities associated with media transport include releasing media for transport, ensuring that media enters the appropriate transport processes, and the actual transport. Authorized transport and courier personnel may include individuals external to the organization.\n\nMaintaining accountability of media during transport includes restricting transport activities to authorized personnel and tracking and/or obtaining records of transport activities as the media moves through the transportation system to prevent and detect loss, destruction, or tampering.\n\nOrganizations establish documentation requirements for activities associated with the transport of system media in accordance with organizational assessments of risk. Organizations maintain the flexibility to define record-keeping methods for the different types of media transport as part of a system of transport-related records.",
          "Configuration management. Baseline configuration | configure systems and components for high-risk areas. (a) Issue [assignment: organization-defined systems or system components] with [assignment: organization-defined configurations] to individuals traveling to locations that the organization deems to be of significant risk; and (b) apply the following controls to the systems or components when the individuals return from travel: [assignment: organization-defined controls]. When it is known that systems or system components will be in high-risk areas external to the organization, additional controls may be implemented to counter the increased threat in such areas. For example, organizations can take actions for notebook computers used by individuals departing on and returning from travel. Actions include determining the locations that are of concern, defining the required configurations for the components, ensuring that components are configured as intended before travel is initiated, and applying controls to the components after travel is completed. Specially configured notebook computers include computers with sanitized hard drives, limited applications, and more stringent configuration settings. Controls applied to mobile devices upon return from travel include examining the mobile device for signs of physical tampering and purging and reimaging disk drives. Protecting information that resides on mobile devices is addressed in the MP (Media Protection) family.",
          "Access control. Use of external systems | portable storage devices — restricted use. Restrict the use of organization-controlled portable storage devices by authorized individuals on external systems using [assignment: organization-defined restrictions]. \n\nLimits on the use of organization-controlled portable storage devices in external systems include restrictions on how the devices may be used and under what conditions the devices may be used.",
          "System and services acquisition. Developer-provided training. Require the developer of the system, system component, or system service to provide the following training on the correct use and operation of the implemented security and privacy functions, controls, and/or mechanisms: [assignment: organization-defined training]. Developer-provided training applies to external and internal (in-house) developers. Training personnel is essential to ensuring the effectiveness of the controls implemented within organizational systems. Types of training include web-based and computer-based training, classroom-style training, and hands-on training (including micro-training). Organizations can also request training materials from developers to conduct in-house training or offer self-training to organizational personnel. Organizations determine the type of training necessary and may require different types of training for different security and privacy functions, controls, and mechanisms.",
          "Physical and environmental protection. Visitor access records. a. Maintain visitor access records to the facility where the system resides for [assignment: organization- defined time period].\nb. Review visitor access records [assignment: organization-defined frequency].\nc. Report anomalies in visitor access records to [assignment: organization-defined personnel].\n\nVisitor access records include the names and organizations of individuals visiting, visitor signatures, forms of identification, dates of access, entry and departure times, purpose of visits, and the names and organizations of individuals visited. \n\nAccess record reviews determine if access authorizations are current and are still required to support the organizational mission and business functions. Access records are not required for publicly accessible areas.",
          "Security assessment and authorization. Information exchange. a. Approve and manage the exchange of information between the system and other systems using [selection (one or more): interconnection security agreements; information exchange security agreements; memoranda of understanding or agreement; service level agreements; user agreements; nondisclosure agreements; [assignment: organization-defined type of agreement]].\n\nb. Document, as part of each exchange agreement, the interface characteristics, security and privacy requirements, controls, and responsibilities for each system, and the impact level of the information communicated.\n\nc. Review and update the agreements [assignment: organization-defined frequency].\n\nSystem information exchange requirements apply to information exchanges between two or more systems. System information exchanges include connections via leased lines or virtual private networks, connections to internet service providers, database sharing or exchanges of database transaction information, connections and exchanges with cloud services, exchanges via web-based services, or exchanges of files via file transfer protocols, network protocols (e.g., IPv4, IPv6), email, or other organization-to-organization communications.\n\nOrganizations consider the risk related to new or increased threats that may be introduced when systems exchange information with other systems that may have different security and privacy requirements and controls. This includes systems within the same organization and systems that are external to the organization.\n\nA joint authorization of the systems exchanging information, as described in CA-6 (1) or CA-6 (2), may help to communicate and reduce risk. Authorizing officials determine the risk associated with system information exchange and the controls needed for appropriate risk mitigation.\n\nThe types of agreements selected are based on factors such as the impact level of the information being exchanged, the relationship between the organizations exchanging information (e.g., government to government, government to business, business to business, government or business to service provider, government or business to individual), or the level of access to the organizational system by users of the other system.\n\nIf systems that exchange information have the same authorizing official, organizations need not develop agreements. Instead, the interface characteristics between the systems (e.g., how the information is being exchanged, how the information is protected) are described in the respective security and privacy plans.\n\nIf the systems that exchange information have different authorizing officials within the same organization, the organizations can develop agreements or provide the same information that would be provided in the appropriate agreement type from CA-3a in the respective security and privacy plans for the systems.\n\nOrganizations may incorporate agreement information into formal contracts, especially for information exchanges established between federal agencies and nonfederal organizations (including service providers, contractors, system developers, and system integrators). Risk considerations include systems that share the same networks.",
          "Configuration management. Policy and procedures. a. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]: 1. [Selection (one or more): organization level; mission/business process-level; system-level] configuration management policy that: (a) addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance; and (b) is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines; and 2. Procedures to facilitate the implementation of the configuration management policy and the associated configuration management controls. \n\nb. Designate an [assignment: organization-defined official] to manage the development, documentation, and dissemination of the configuration management policy and procedures.\n\nc. Review and update the current configuration management: \n1. Policy [assignment: organization-defined frequency] and following [assignment: organization-defined events].\n2. Procedures [assignment: organization-defined frequency] and following [assignment: organization-defined events].\n\nConfiguration management policy and procedures address the controls in the CM family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of configuration management policy and procedures.\n\nSecurity and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations. Procedures can be established for security and privacy programs, for mission/business processes, and for systems, if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents. \n\nEvents that may precipitate an update to configuration management policy and procedures include, but are not limited to, assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Risk assessment. Criticality analysis. Identify critical system components and functions by performing a criticality analysis for organization-defined systems, system components, or system services at organization-defined decision points in the system development life cycle. Not all system components, functions, or services necessarily require significant protections. For example, criticality analysis is a key tenet of supply chain risk management and informs the prioritization of protection activities.\n\nThe identification of critical system components and functions considers applicable laws, executive orders, regulations, directives, policies, standards, system functionality requirements, system and component interfaces, and system and component dependencies. Systems engineers conduct a functional decomposition of a system to identify mission-critical functions and components.\n\nThe functional decomposition includes the identification of organizational missions supported by the system, decomposition into the specific functions to perform those missions, and traceability to the hardware, software, and firmware components that implement those functions, including when the functions are shared by many components within and external to the system.\n\nThe operational environment of a system or a system component may impact the criticality, including the connections to and dependencies on cyber-physical systems, devices, system-of-systems, and outsourced IT services. System components that allow unmediated access to critical system components or functions are considered critical due to the inherent vulnerabilities that such components create.\n\nComponent and function criticality are assessed in terms of the impact of a component or function failure on the organizational missions that are supported by the system that contains the components and functions. Criticality analysis is performed when an architecture or design is being developed, modified, or upgraded. If such analysis is performed early in the system development life cycle, organizations may be able to modify the system design to reduce the critical nature of these components and functions, such as by adding redundancy or alternate paths into the system design.\n\nCriticality analysis can also influence the protection measures required by development contractors. In addition to criticality analysis for systems, system components, and system services, criticality analysis of information is an important consideration. Such analysis is conducted as part of security categorization in RA-2.",
          "Media protection. Media sanitization | review, approve, track, document, and verify. Review, approve, track, document, and verify media sanitization and disposal actions. Organizations review and approve media to be sanitized to ensure compliance with records retention policies. Tracking and documenting actions include listing personnel who reviewed and approved sanitization and disposal actions, types of media sanitized, files stored on the media, sanitization methods used, date and time of the sanitization actions, personnel who performed the sanitization, verification actions taken and personnel who performed the verification, and the disposal actions taken. Organizations verify that the sanitization of the media was effective prior to disposal.",
          "Access control. Publicly accessible content. A. Designate individuals authorized to make information publicly accessible.\nB. Train authorized individuals to ensure that publicly accessible information does not contain nonpublic information.\nC. Review the proposed content of information prior to posting onto the publicly accessible system to ensure that nonpublic information is not included.\nD. Review the content on the publicly accessible system for nonpublic information [assignment: organization-defined frequency] and remove such information, if discovered.\n\nIn accordance with applicable laws, executive orders, directives, policies, regulations, standards, and guidelines, the public is not authorized to have access to nonpublic information, including information protected under the privacy and proprietary information. \n\nPublicly accessible content addresses systems that are controlled by the organization and accessible to the public, typically without identification or authentication. Posting information on non-organizational systems (e.g., non-organizational public websites, forums, and social media) is covered by organizational policy. \n\nWhile organizations may have individuals who are responsible for developing and implementing policies about the information that can be made publicly accessible, publicly accessible content addresses the management of the individuals who make such information publicly accessible.",
          "Media protection. Media storage. A. Physically control and securely store [assignment: organization-defined types of digital and/or non-digital media] within [assignment: organization-defined controlled areas]. \nB. Protect system media types defined in MP-4A until the media are destroyed or sanitized using approved equipment, techniques, and procedures. System media includes digital and non-digital media. Digital media includes flash drives, diskettes, magnetic tapes, external or removable hard disk drives (e.g., solid state, magnetic), compact discs, and digital versatile discs. Non-digital media includes paper and microfilm. \nPhysically controlling stored media includes conducting inventories, ensuring procedures are in place to allow individuals to check out and return media to the library, and maintaining accountability for stored media. \nSecure storage includes a locked drawer, desk, or cabinet or a controlled media library. The type of media storage is commensurate with the security category or classification of the information on the media. \nControlled areas are spaces that provide physical and procedural controls to meet the requirements established for protecting information and systems. Fewer controls may be needed for media that contains information determined to be in the public domain, publicly releasable, or have limited adverse impacts on organizations, operations, or individuals if accessed by other than authorized personnel. In these situations, physical access controls provide adequate protection.",
          "Access control. Information flow enforcement. Enforce approved authorizations for controlling the flow of information within the system and between connected systems based on [assignment: organization-defined information flow control policies]. Information flow control regulates where information can travel within a system and between systems (in contrast to who is allowed to access the information) and without regard to subsequent accesses to that information. Flow control restrictions include blocking external traffic that claims to be from within the organization, keeping export-controlled information from being transmitted in the clear to the internet, restricting web requests that are not from the internal web proxy server, and limiting information transfers between organizations based on data structures and content. \n\nTransferring information between organizations may require an agreement specifying how the information flow is enforced (see ca-3). Transferring information between systems in different security or privacy domains with different security or privacy policies introduces the risk that such transfers violate one or more domain security or privacy policies. In such situations, information owners/stewards provide guidance at designated policy enforcement points between connected systems. Organizations consider mandating specific architectural solutions to enforce specific security and privacy policies. Enforcement includes prohibiting information transfers between connected systems (i.e., allowing access only), verifying write permissions before accepting information from another security or privacy domain or connected system, employing hardware mechanisms to enforce one-way information flows, and implementing trustworthy regrading mechanisms to reassess security or privacy attributes and labels. Organizations commonly employ information flow control policies and enforcement mechanisms to control the flow of information between designated sources and destinations within systems and between connected systems. Flow control is based on the characteristics of the information and/or the information path. Enforcement occurs, for example, in boundary protection devices that employ rule sets or establish configuration settings that restrict system services, provide a packet-filtering capability based on header information, or provide a message-filtering capability based on message content. \n\nOrganizations also consider the trustworthiness of filtering and/or inspection mechanisms (i.e., hardware, firmware, and software components) that are critical to information flow enforcement. Control enhancements 3 through 32 primarily address cross-domain solution needs that focus on more advanced filtering techniques, in-depth analysis, and stronger flow enforcement mechanisms implemented in cross-domain products, such as high-assurance guards. Such capabilities are generally not available in commercial off-the-shelf products. Information flow enforcement also applies to control plane traffic (e.g., routing and DNS).",
          "Access control. Information flow enforcement | flow control of encrypted information. Prevent encrypted information from bypassing [assignment: organization-defined information flow control mechanisms] by [selection (one or more): decrypting the information; blocking the flow of the encrypted information; terminating communication sessions attempting to pass encrypted information; [assignment: organization-defined procedure or method]]. Flow control mechanisms include content checking, security policy filters, and data type identifiers. The term encryption is extended to cover encoded data not recognized by filtering mechanisms.",
          "Access control. Information sharing. a. Enable authorized users to determine whether access authorizations assigned to a sharing partner match the information's access and use restrictions for [assignment: organization-defined information sharing circumstances where user discretion is required]. \nB. Employ [assignment: organization-defined automated mechanisms or manual processes] to assist users in making information sharing and collaboration decisions. Information sharing applies to information that may be restricted in some manner based on some formal or administrative determination. Examples of such information include contract-sensitive information, classified information related to special access programs or compartments, privileged information, proprietary information, and personally identifiable information. Security and privacy risk assessments, as well as applicable laws, regulations, and policies, can provide useful inputs to these determinations. Depending on the circumstances, sharing partners may be defined at the individual, group, or organizational level. Information may be defined by content, type, security category, or special access program or compartment. Access restrictions may include non-disclosure agreements (NDA). Information flow techniques and security attributes may be used to provide automated assistance to users making sharing and collaboration decisions.",
          "System and information integrity. Memory protection. Implement the following controls to protect the system memory from unauthorized code execution: [assignment: organization-defined controls]. Some adversaries launch attacks with the intent of executing code in non-executable regions of memory or in memory locations that are prohibited. Controls employed to protect memory include data execution prevention and address space layout randomization. Data execution prevention controls can either be hardware-enforced or software-enforced, with hardware enforcement providing the greater strength of mechanism.",
          "Access control. Use of external systems | limits on authorized use. Permit authorized individuals to use an external system to access the system or to process, store, or transmit organization-controlled information only after: (a) verification of the implementation of controls on the external system as specified in the organization's security and privacy policies and security and privacy plans; or (b) retention of approved system connection or processing agreements with the organizational entity hosting the external system. Limiting authorized use recognizes circumstances where individuals using external systems may need to access organizational systems. Organizations need assurance that the external systems contain the necessary controls so as not to compromise, damage, or otherwise harm organizational systems. Verification that the required controls have been implemented can be achieved by external, independent assessments, attestations, or other means, depending on the confidence level required by organizations.",
          "Media protection. Media sanitization | equipment testing. Test sanitization equipment and procedures [assignment: organization-defined frequency] to ensure that the intended sanitization is being achieved. Testing of sanitization equipment and procedures may be conducted by qualified and authorized external entities, including federal agencies or external service providers.",
          "Personnel security. Personnel termination. Upon termination of individual employment: a. Disable system access within [assignment: organization-defined time period]. b. Terminate or revoke any authenticators and credentials associated with the individual. c. Conduct exit interviews that include a discussion of [assignment: organization-defined information security topics]. d. Retrieve all security-related organizational system-related property. e. Retain access to organizational information and systems formerly controlled by the terminated individual. \n\nSystem property includes hardware authentication tokens, system administration technical manuals, keys, identification cards, and building passes. Exit interviews ensure that terminated individuals understand the security constraints imposed by being former employees and that proper accountability is achieved for system-related property. Security topics at exit interviews include reminding individuals of nondisclosure agreements and potential limitations on future employment. Exit interviews may not always be possible for some individuals, including in cases related to the unavailability of supervisors, illnesses, or job abandonment. Exit interviews are important for individuals with security clearances. The timely execution of termination actions is essential for individuals who have been terminated for cause. In certain situations, organizations consider disabling the system accounts of individuals who are being terminated prior to the individuals being notified.",
          "Security assessment and authorization. Authorization. a. Assign a senior official as the authorizing official for the system. \nb. Assign a senior official as the authorizing official for common controls available for inheritance by organizational systems. \nc. Ensure that the authorizing official for the system, before commencing operations: \n   1. Accepts the use of common controls inherited by the system. \n   2. Authorizes the system to operate. \nd. Ensure that the authorizing official for common controls authorizes the use of those controls for inheritance by organizational systems. \ne. Update the authorizations [assignment: organization-defined frequency]. Authorizations are official management decisions by senior officials to authorize the operation of systems, authorize the use of common controls for inheritance by organizational systems, and explicitly accept the risk to organizational operations and assets, individuals, other organizations, and the nation based on the implementation of agreed-upon controls. \nAuthorizing officials provide budgetary oversight for organizational systems and common controls or assume responsibility for the mission and business functions supported by those systems or common controls. The authorization process is a federal responsibility, and therefore, authorizing officials must be federal employees. \nAuthorizing officials are both responsible and accountable for security and privacy risks associated with the operation and use of organizational systems. Nonfederal organizations may have similar processes to authorize systems and senior officials that assume the authorization role and associated responsibilities. \nAuthorizing officials issue ongoing authorizations of systems based on evidence produced from implemented continuous monitoring programs. Robust continuous monitoring programs reduce the need for separate reauthorization processes. Through the employment of comprehensive continuous monitoring processes, the information contained in authorization packages (i.e., security and privacy plans, assessment reports, and plans of action and milestones) is updated on an ongoing basis. This provides authorizing officials, common control providers, and system owners with an up-to-date status of the security and privacy posture of their systems, controls, and operating environments. To reduce the cost of reauthorization, authorizing officials can leverage the results of continuous monitoring processes to the maximum extent possible as the basis for rendering reauthorization decisions.",
          "Physical and environmental protection. Visitor access records | automated records maintenance and review. Maintain and review visitor access records using [assignment: organization-defined automated mechanisms]. Visitor access records may be stored and maintained in a database management system that is accessible by organizational personnel. Automated access to such records facilitates record reviews on a regular basis to determine if access authorizations are current and still required to support organizational mission and business functions.",
          "Planning. Rules of behavior | social media and external site/application usage restrictions. Include in the rules of behavior restrictions on:\n\n(a) Use of social media, social networking sites, and external sites/applications.\n\n(b) Posting organizational information on public websites.\n\n(c) Use of organization-provided identifiers (e.g., email addresses) and authentication secrets (e.g., passwords) for creating accounts on external sites/applications.\n\nSocial media, social networking, and external site/application usage restrictions address rules of behavior related to the use of social media, social networking, and external sites when organizational personnel are using such sites for official duties or in the conduct of official business. It also applies when organizational information is involved in social media and social networking transactions, and when personnel access social media and networking sites from organizational systems.\n\nOrganizations should also address specific rules that prevent unauthorized entities from obtaining non-public organizational information from social media and networking sites, either directly or through inference. Non-public information includes personally identifiable information and system account information.",
          "System and services acquisition. External system services. a. Require that providers of external system services comply with organizational security and privacy requirements and employ the following controls: [assignment: organization-defined controls]. \nb. Define and document organizational oversight and user roles and responsibilities with regard to external system services. \nc. Employ the following processes, methods, and techniques to monitor control compliance by external service providers on an ongoing basis: [assignment: organization-defined processes, methods, and techniques]. \n\nExternal system services are provided by an external provider, and the organization has no direct control over the implementation of the required controls or the assessment of control effectiveness. Organizations establish relationships with external service providers in a variety of ways, including through business partnerships, contracts, interagency agreements, lines of business arrangements, licensing agreements, joint ventures, and supply chain exchanges. \n\nThe responsibility for managing risks from the use of external system services remains with authorizing officials. For services external to organizations, a chain of trust requires that organizations establish and retain a certain level of confidence that each provider in the consumer-provider relationship provides adequate protection for the services rendered. The extent and nature of this chain of trust vary based on relationships between organizations and the external providers. Organizations document the basis for the trust relationships so that the relationships can be monitored. \n\nExternal system services documentation includes government, service providers, end user security roles and responsibilities, and service-level agreements. Service-level agreements define the expectations of performance for implemented controls, describe measurable outcomes, and identify remedies and response requirements for identified instances of noncompliance.",
          "Awareness and training. Literacy training and awareness. a. Provide security and privacy literacy training to system users (including managers, senior executives, and contractors): 1. As part of initial training for new users and [assignment: organization-defined frequency] thereafter; and 2. When required by system changes or following [assignment: organization-defined events]. \nb. Employ the following techniques to increase the security and privacy awareness of system users [assignment: organization-defined awareness techniques]. \nc. Update literacy training and awareness content [assignment: organization-defined frequency] and following [assignment: organization-defined events]. \nd. Incorporate lessons learned from internal or external security incidents or breaches into literacy training and awareness techniques. \n\nOrganizations provide basic and advanced levels of literacy training to system users, including measures to test the knowledge level of users. Organizations determine the content of literacy training and awareness based on specific organizational requirements, the systems to which personnel have authorized access, and work environments (e.g., telework). The content includes an understanding of the need for security and privacy as well as actions by users to maintain security and personal privacy and to respond to suspected incidents. The content addresses the need for operations security and the handling of personally identifiable information. Awareness techniques include displaying posters, offering supplies inscribed with security and privacy reminders, displaying logon screen messages, generating email advisories or notices from organizational officials, and conducting awareness events. \n\nLiteracy training after the initial training described in at-2a.1 is conducted at a minimum frequency consistent with applicable laws, directives, regulations, and policies. Subsequent literacy training may be satisfied by one or more short ad hoc sessions and include topical information on recent attack schemes, changes to organizational security and privacy policies, revised security and privacy expectations, or a subset of topics from the initial training. Updating literacy training and awareness content on a regular basis helps to ensure that the content remains relevant. Events that may precipitate an update to literacy training and awareness content include, but are not limited to, assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines.",
          "Access control. Information flow enforcement | physical or logical separation of information flows. Separate information flows logically or physically using [assignment: organization-defined mechanisms and/or techniques] to accomplish [assignment: organization-defined required separations by types of information]. Enforcing the separation of information flows associated with defined types of data can enhance protection by ensuring that information is not commingled while in transit and by enabling flow control by transmission paths that are not otherwise achievable. Types of separable information include inbound and outbound communications traffic, service requests and responses, and information of differing security impact or classification levels.",
          "Media protection. Media marking. a. Mark system media indicating the distribution limitations, handling caveats, and applicable security markings (if any) of the information; and b. Exempt [assignment: organization-defined types of system media] from marking if the media remain within [assignment: organization-defined controlled areas]. Security marking refers to the application or use of human-readable security attributes. Digital media includes diskettes, magnetic tapes, external or removable hard disk drives (e.g., solid state, magnetic), flash drives, compact discs, and digital versatile discs. Non-digital media includes paper and microfilm. Controlled Unclassified Information (CUI) is defined by the National Archives and Records Administration along with the appropriate safeguarding and dissemination requirements for such information and is codified in 32 CFR 2002. Security markings are generally not required for media that contains information determined by organizations to be in the public domain or to be publicly releasable. Some organizations may require markings for public information indicating that the information is publicly releasable. System media marking reflects applicable laws, executive orders, directives, policies, regulations, standards, and guidelines.",
          "Access control. Permitted actions without identification or authentication. a. Identify [assignment: organization-defined user actions] that can be performed on the system without identification or authentication consistent with organizational mission and business functions. \nB. Document and provide supporting rationale in the security plan for the system, user actions not requiring identification or authentication. \nSpecific user actions may be permitted without identification or authentication if organizations determine that identification and authentication are not required for the specified user actions. \nOrganizations may allow a limited number of user actions without identification or authentication, including when individuals access public websites or other publicly accessible federal systems, when individuals use mobile phones to receive calls, or when facsimiles are received. \nOrganizations identify actions that normally require identification or authentication but may, under certain circumstances, allow identification or authentication mechanisms to be bypassed. \nSuch bypasses may occur, for example, via a software-readable physical switch that commands bypass of the login functionality and is protected from accidental or unmonitored use. \nPermitting actions without identification or authentication does not apply to situations where identification and authentication have already occurred and are not repeated, but rather to situations where identification and authentication have not yet occurred. \nOrganizations may decide that there are no user actions that can be performed on organizational systems without identification and authentication, and therefore, the value for the assignment operation can be none.",
          "Personnel security. External personnel security. a. Establish personnel security requirements, including security roles and responsibilities for external providers.\nb. Require external providers to comply with personnel security policies and procedures established by the organization.\nc. Document personnel security requirements.\nd. Require external providers to notify [assignment: organization-defined personnel or roles] of any personnel transfers or terminations of external personnel who possess organizational credentials and/or badges, or who have system privileges within [assignment: organization-defined time period].\ne. Monitor provider compliance with personnel security requirements.\n\nExternal provider refers to organizations other than the organization operating or acquiring the system. External providers include service bureaus, contractors, and other organizations that provide system development, information technology services, testing or assessment services, outsourced applications, and network/security management. Organizations explicitly include personnel security requirements in acquisition-related documents.\n\nExternal providers may have personnel working at organizational facilities with credentials, badges, or system privileges issued by organizations. Notifications of external personnel changes ensure the appropriate termination of privileges and credentials. Organizations define the transfers and terminations deemed reportable by security-related characteristics that include functions, roles, and the nature of credentials or privileges associated with transferred or terminated individuals.",
          "Media protection. Media sanitization | nondestructive techniques. Apply nondestructive sanitization techniques to portable storage devices prior to connecting such devices to the system under the following circumstances: [assignment: organization-defined circumstances requiring sanitization of portable storage devices]. Portable storage devices include external or removable hard disk drives (e.g., solid-state, magnetic), optical discs, magnetic or optical tapes, flash memory devices, flash memory cards, and other external or removable disks. Portable storage devices can be obtained from untrustworthy sources and contain malicious code that can be inserted into or transferred to organizational systems through USB ports or other entry portals. While scanning storage devices is recommended, sanitization provides additional assurance that such devices are free of malicious code. Organizations consider nondestructive sanitization of portable storage devices when the devices are purchased from manufacturers or vendors prior to initial use or when organizations cannot maintain a positive chain of custody for the devices.",
          "System and information integrity. Spam protection. a. Employ spam protection mechanisms at system entry and exit points to detect and act on unsolicited messages; and b. Update spam protection mechanisms when new releases are available in accordance with organizational configuration management policy and procedures. \n\nSystem entry and exit points include firewalls, remote-access servers, electronic mail servers, web servers, proxy servers, workstations, notebook computers, and mobile devices. Spam can be transported by different means, including email, email attachments, and web accesses. \n\nSpam protection mechanisms include signature definitions.",
          "Security assessment and authorization. Internal system connections. a. Authorize internal connections of [assignment: organization-defined system components or classes of components] to the system.\nb. Document, for each internal connection, the interface characteristics, security and privacy requirements, and the nature of the information communicated.\nc. Terminate internal system connections after [assignment: organization-defined conditions].\nd. Review [assignment: organization-defined frequency] the continued need for each internal connection.\n\nInternal system connections are connections between organizational systems and separate constituent system components. These include connections between components that are part of the same system, as well as components used for system development. Intra-system connections encompass connections with mobile devices, notebook and desktop computers, tablets, printers, copiers, facsimile machines, scanners, sensors, and servers.\n\nInstead of authorizing each internal system connection individually, organizations have the option to authorize internal connections for a class of system components with common characteristics and/or configurations. For example, printers, scanners, and copiers with a specified processing, transmission, and storage capability, or smart phones and tablets with a specific baseline configuration.\n\nThe continued need for an internal system connection should be reviewed from the perspective of whether it provides support for organizational missions or business functions.",
          "System and communications protection. Network disconnect. Terminate the network connection associated with a communications session at the end of the session or after [assignment: organization-defined time period] of inactivity. Network disconnect applies to internal and external networks. Terminating network connections associated with specific communications sessions includes de-allocating TCP/IP address or port pairs at the operating system level and de-allocating the networking assignments at the application level if multiple application sessions are using a single operating system-level network connection. Periods of inactivity may be established by organizations and include time periods by type of network access or for specific network accesses.",
          "Awareness and training. Literacy training and awareness | social engineering and mining. Provide literacy training on recognizing and reporting potential and actual instances of social engineering and social mining. Social engineering is an attempt to trick an individual into revealing information or taking an action that can be used to breach, compromise, or otherwise adversely impact a system. Social engineering includes phishing, pretexting, impersonation, baiting, quid pro quo, thread-jacking, social media exploitation, and tailgating. Social mining is an attempt to gather information about the organization that may be used to support future attacks. Literacy training includes information on how to communicate the concerns of employees and management regarding potential and actual instances of social engineering and data mining through organizational channels based on established policies and procedures.",
          "System and communications protection. Mobile code. a. Define acceptable and unacceptable mobile code and mobile code technologies; and b. Authorize, monitor, and control the use of mobile code within the system. Mobile code includes any program, application, or content that can be transmitted across a network (e.g., embedded in an email, document, or website) and executed on a remote system. Decisions regarding the use of mobile code within organizational systems are based on the potential for the code to cause damage to the systems if used maliciously. Mobile code technologies include Java applets, JavaScript, HTML5, WebGL, and VBScript. Usage restrictions and implementation guidelines apply to both the selection and use of mobile code installed on servers and mobile code downloaded and executed on individual workstations and devices, including notebook computers and smartphones. Mobile code policy and procedures address specific actions taken to prevent the development, acquisition, and introduction of unacceptable mobile code within organizational systems, including requiring mobile code to be digitally signed by a trusted source.",
          "Access control. Use of external systems. a. [Selection (one or more): Establish [assignment: organization-defined terms and conditions]; Identify [assignment: organization-defined controls asserted to be implemented on external systems]], consistent with the trust relationships established with other organizations owning, operating, and/or maintaining external systems, allowing authorized individuals to: 1. access the system from external systems; and 2. process, store, or transmit organization-controlled information using external systems; or b. Prohibit the use of [assignment: organizationally-defined types of external systems]. External systems are systems that are used by but not part of organizational systems, and for which the organization has no direct control over the implementation of required controls or the assessment of control effectiveness. External systems include personally owned systems, components, or devices; privately-owned computing and communications devices in commercial or public facilities; systems owned or controlled by nonfederal organizations; systems managed by contractors; and federal information systems that are not owned by, operated by, or under the direct supervision or authority of the organization. External systems also include systems owned or operated by other components within the same organization and systems within the organization with different authorization boundaries. Organizations have the option to prohibit the use of any type of external system or prohibit the use of specified types of external systems (e.g., prohibit the use of any external system that is not organizationally owned or prohibit the use of personally-owned systems). For some external systems (i.e., systems operated by other organizations), the trust relationships that have been established between those organizations and the originating organization may be such that no explicit terms and conditions are required. Systems within these organizations may not be considered external. These situations occur when, for example, there are pre-existing information exchange agreements (either implicit or explicit) established between organizations or components or when such agreements are specified by applicable laws, executive orders, directives, regulations, policies, or standards. Authorized individuals include organizational personnel, contractors, or other individuals with authorized access to organizational systems and over which organizations have the authority to impose specific rules of behavior regarding system access. Restrictions that organizations impose on authorized individuals need not be uniform, as the restrictions may vary depending on trust relationships between organizations. Therefore, organizations may choose to impose different security restrictions on contractors than on state, local, or tribal governments. External systems used to access public interfaces to organizational systems are outside the scope of AC-20. Organizations establish specific terms and conditions for the use of external systems in accordance with organizational security policies and procedures. At a minimum, terms and conditions address the specific types of applications that can be accessed on organizational systems from external systems and the highest security category of information that can be processed, stored, or transmitted on external systems. If the terms and conditions with the owners of the external systems cannot be established, organizations may impose restrictions on organizational personnel using those external systems.",
          "Media protection. Media use. a. [selection: Restrict; Prohibit] the use of [assignment: organization-defined types of system media] on [assignment: organization-defined systems or system components] using [assignment: organization-defined controls]; and b. Prohibit the use of portable storage devices in organizational systems when such devices have no identifiable owner. System media includes both digital and non-digital media. Digital media includes diskettes, magnetic tapes, flash drives, compact discs, digital versatile discs, and removable hard disk drives. Non-digital media includes paper and microfilm. Media use protections also apply to mobile devices with information storage capabilities. In contrast to MP-2, which restricts user access to media, MP-7 restricts the use of certain types of media on systems. For example, restricting or prohibiting the use of flash drives or external hard disk drives. Organizations use technical and non-technical controls to restrict the use of system media. Organizations may restrict the use of portable storage devices, for example, by using physical cages on workstations to prohibit access to certain external ports or disabling or removing the ability to insert, read, or write to such devices. Organizations may also limit the use of portable storage devices to only approved devices, including devices provided by the organization, devices provided by other approved organizations, and devices that are not personally owned. Finally, organizations may restrict the use of portable storage devices based on the type of device. For example, by prohibiting the use of writable, portable storage devices and implementing this restriction by disabling or removing the capability to write to such devices. Requiring identifiable owners for storage devices reduces the risk of using such devices by allowing organizations to assign responsibility for addressing known vulnerabilities in the devices.",
          "Security assessment and authorization. Information exchange | transfer authorizations. Verify that individuals or systems transferring data between interconnecting systems have the requisite authorizations (i.e., write permissions or privileges) prior to accepting such data. To prevent unauthorized individuals and systems from making information transfers to protected systems, the protected system verifies - via independent means - whether the individual or system attempting to transfer information is authorized to do so. Verification of the authorization to transfer information also applies to control plane traffic (e.g., routing and DNS) and services (e.g., authenticated SMTP relays).",
          "Media protection. Media sanitization. a. Sanitize [assignment: organization-defined system media] prior to disposal, release out of organizational control, or release for reuse using [assignment: organization-defined sanitization techniques and procedures]. b. Employ sanitization mechanisms with the strength and integrity commensurate with the security category or classification of the information. Media sanitization applies to all digital and non-digital system media subject to disposal or reuse, whether or not the media is considered removable. Examples include digital media in scanners, copiers, printers, notebook computers, workstations, network components, mobile devices, and non-digital media (e.g., paper and microfilm). The sanitization process removes information from system media such that the information cannot be retrieved or reconstructed. Sanitization techniques — including clearing, purging, cryptographic erase, de-identification of personally identifiable information, and destruction — prevent the disclosure of information to unauthorized individuals when such media is reused or released for disposal. Organizations determine the appropriate sanitization methods, recognizing that destruction is sometimes necessary when other methods cannot be applied to media requiring sanitization. Organizations use discretion on the employment of approved sanitization techniques and procedures for media that contains information deemed to be in the public domain or publicly releasable or information deemed to have no adverse impact on organizations or individuals if released for reuse or disposal. Sanitization of non-digital media includes destruction, removing a classified appendix from an otherwise unclassified document, or redacting selected sections or words from a document by obscuring the redacted sections or words in a manner equivalent in effectiveness to removing them from the document. NSA standards and policies control the sanitization process for media that contains classified information. NARA policies control the sanitization process for controlled unclassified information.",
          "Access control. Remote access | managed access control points. Route remote accesses through authorized and managed network access control points. Organizations consider the Trusted Internet Connections (TIC) initiative - DHS TIC requirements for external network connections, since limiting the number of access control points for remote access reduces attack surfaces.",
          "Personnel security. Personnel termination | automated actions. Use organization-defined automated mechanisms to notify organization-defined personnel or roles of individual termination actions or disable access to system resources. In organizations with many employees, not all personnel who need to know about termination actions receive the appropriate notifications. Even if such notifications are received, they may not occur in a timely manner. Automated mechanisms can be used to send automatic alerts or notifications to organizational personnel or roles when individuals are terminated. Such automatic alerts or notifications can be conveyed in a variety of ways, including via telephone, electronic mail, text message, or websites. Automated mechanisms can also be employed to quickly and thoroughly disable access to system resources after an employee is terminated.",
          "Awareness and training. Literacy training and awareness | insider threat. Provide literacy training on recognizing and reporting potential indicators of insider threat. Potential indicators and possible precursors of insider threat can include behaviors such as inordinate, long-term job dissatisfaction; attempts to gain access to information not required for job performance; unexplained access to financial resources; bullying or harassment of fellow employees; workplace violence; and other serious violations of policies, procedures, directives, regulations, rules, or practices. Literacy training includes how to communicate the concerns of employees and management regarding potential indicators of insider threat through channels established by the organization and in accordance with established policies and procedures. Organizations may consider tailoring insider threat awareness topics to the role. For example, training for managers may be focused on changes in the behavior of team members, while training for employees may be focused on more general observations.",
          "Access control. Remote access. a. Establish and document usage restrictions, configuration/connection requirements, and implementation guidance for each type of remote access allowed; and b. Authorize each type of remote access to the system prior to allowing such connections. Remote access is access to organizational systems (or processes acting on behalf of users) that communicate through external networks such as the internet. Types of remote access include dial-up, broadband, and wireless. Organizations use encrypted Virtual Private Networks (VPNs) to enhance confidentiality and integrity for remote connections. The use of encrypted VPNs provides sufficient assurance to the organization that it can effectively treat such connections as internal networks if the cryptographic mechanisms used are implemented in accordance with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Still, VPN connections traverse external networks, and the encrypted VPN does not enhance the availability of remote connections. VPNs with encrypted tunnels can also affect the ability to adequately monitor network communications traffic for malicious code. Remote access controls apply to systems other than public web servers or systems designed for public access. Authorization of each remote access type addresses authorization prior to allowing remote access without specifying the specific formats for such authorization. While organizations may use information exchange and system connection security agreements to manage remote access connections to other systems, such agreements are addressed as part of CA-3. Enforcing access restrictions for remote access is addressed via AC-3.",
          "Awareness and training. Role-based training. a. Provide role-based security and privacy training to personnel with the following roles and responsibilities: [assignment: organization-defined roles and responsibilities]. 1. Before authorizing access to the system, information, or performing assigned duties, and [assignment: organization-defined frequency] thereafter. 2. When required by system changes.\nb. Update role-based training content [assignment: organization-defined frequency] and following [assignment: organization-defined events].\nc. Incorporate lessons learned from internal or external security incidents or breaches into role-based training. \nOrganizations determine the content of training based on the assigned roles and responsibilities of individuals as well as the security and privacy requirements of organizations and the systems to which personnel have authorized access, including technical training specifically tailored for assigned duties. Roles that may require role-based training include senior leaders or management officials (e.g., head of agency/chief executive officer, chief information officer, senior accountable official for risk management, senior agency information security officer, senior agency official for privacy), system owners, authorizing officials, system security officers, privacy officers, acquisition and procurement officials, enterprise architects, systems engineers, software developers, systems security engineers, privacy engineers, system, network, and database administrators, auditors, personnel conducting configuration management activities, personnel performing verification and validation activities, personnel with access to system-level software, control assessors, personnel with contingency planning and incident response duties, personnel with privacy management responsibilities, and personnel with access to personally identifiable information. \nComprehensive role-based training addresses management, operational, and technical roles and responsibilities covering physical, personnel, and technical controls. Role-based training also includes policies, procedures, tools, methods, and artifacts for the security and privacy roles defined. Organizations provide the training necessary for individuals to fulfill their responsibilities related to operations and supply chain risk management within the context of organizational security and privacy programs. Role-based training also applies to contractors who provide services to federal agencies. Types of training include web-based and computer-based training, classroom-style training, and hands-on training (including micro-training). Updating role-based training on a regular basis helps to ensure that the content remains relevant and effective. Events that may precipitate an update to role-based training content include, but are not limited to, assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines.",
          "Planning. Rules of behavior. a. Establish and provide to individuals requiring access to the system, the rules that describe their responsibilities and expected behavior for information and system usage, security, and privacy.\nb. Receive a documented acknowledgment from such individuals, indicating that they have read, understand, and agree to abide by the rules of behavior, before authorizing access to information and the system.\nc. Review and update the rules of behavior [assignment: organization-defined frequency].\nd. Require individuals who have acknowledged a previous version of the rules of behavior to read and re-acknowledge [selection (one or more): [assignment: organization-defined frequency]; when the rules are revised or updated].\n\nRules of behavior represent a type of access agreement for organizational users. Other types of access agreements include nondisclosure agreements, conflict-of-interest agreements, and acceptable use agreements (see ps-6). Organizations consider rules of behavior based on individual user roles and responsibilities and differentiate between rules that apply to privileged users and rules that apply to general users. Establishing rules of behavior for some types of non-organizational users, including individuals who receive information from federal systems, is often not feasible given the large number of such users and the limited nature of their interactions with the systems. Rules of behavior for organizational and non-organizational users can also be established in ac-8.\n\nThe related Controls section provides a list of controls that are relevant to organizational rules of behavior. PL-4b, the documented acknowledgment portion of the control, may be satisfied by the literacy training and awareness and role-based training programs conducted by organizations if such training includes rules of behavior. Documented acknowledgments for rules of behavior include electronic or physical signatures and electronic agreement check boxes or radio buttons.",
          "Personnel security. Access agreements. a. Develop and document access agreements for organizational systems.\nb. Review and update the access agreements [assignment: organization-defined frequency].\nc. Verify that individuals requiring access to organizational information and systems:\n1. Sign appropriate access agreements prior to being granted access.\n2. Re-sign access agreements to maintain access to organizational systems when access agreements have been updated or [assignment: organization-defined frequency].\nAccess agreements include nondisclosure agreements, acceptable use agreements, rules of behavior, and conflict-of-interest agreements. Signed access agreements include an acknowledgement that individuals have read, understand, and agree to abide by the constraints associated with organizational systems to which access is authorized. Organizations can use electronic signatures to acknowledge access agreements unless specifically prohibited by organizational policy.",
          null
         ],
         "marker": {
          "color": "#CFD8DC",
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "other",
         "showlegend": false,
         "type": "scattergl",
         "x": [
          6.9297051429748535,
          9.497055053710938,
          8.730731010437012,
          5.6298322677612305,
          8.749242782592773,
          8.520421028137207,
          9.50809097290039,
          6.70720100402832,
          10.361444473266602,
          8.9170503616333,
          7.371421813964844,
          5.8649821281433105,
          8.694890022277832,
          9.059491157531738,
          8.754337310791016,
          9.102180480957031,
          9.215738296508789,
          9.035425186157227,
          8.222555160522461,
          9.302666664123535,
          8.690958023071289,
          8.294661521911621,
          7.696098804473877,
          10.392223358154297,
          8.948695182800293,
          8.981489181518555,
          6.927386283874512,
          9.149283409118652,
          8.756908416748047,
          10.301907539367676,
          8.959879875183105,
          8.722236633300781,
          8.174253463745117,
          8.983004570007324,
          10.084896087646484,
          6.891496658325195,
          9.356770515441895,
          9.150754928588867,
          8.759957313537598,
          9.050106048583984,
          8.699105262756348,
          9.551640510559082,
          8.312801361083984,
          6.920042991638184,
          9.504331588745117,
          6.924756050109863,
          8.74249267578125,
          8.675753593444824,
          8.578715324401855
         ],
         "y": [
          8.326146125793457,
          6.616523742675781,
          10.77978515625,
          5.046572685241699,
          10.798797607421875,
          10.548042297363281,
          7.86856746673584,
          8.519254684448242,
          6.742228031158447,
          7.6232428550720215,
          8.869775772094727,
          8.282207489013672,
          10.769153594970703,
          7.720080852508545,
          10.804288864135742,
          7.568741321563721,
          7.457956790924072,
          7.61209774017334,
          5.335446834564209,
          7.933956623077393,
          10.74777889251709,
          8.504895210266113,
          7.972030162811279,
          6.69284725189209,
          7.821075439453125,
          8.256675720214844,
          8.32809829711914,
          7.51938533782959,
          10.810487747192383,
          7.706716537475586,
          8.29028034210205,
          10.77760124206543,
          5.27606725692749,
          8.287400245666504,
          8.047947883605957,
          8.306585311889648,
          7.095795154571533,
          8.169072151184082,
          10.783156394958496,
          7.582397937774658,
          10.758338928222656,
          6.675093173980713,
          8.451533317565918,
          8.323697090148926,
          6.636931896209717,
          8.329568862915039,
          7.873976707458496,
          7.906736373901367,
          8.274063110351562
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Procurement, development and modification of information systems (dev). Policies for the development/ procurement of information systems. Basic criterion: Policies and instructions with technical and organizational measures for the secure development of the cloud service are documented, communicated and provided in accordance with SP-01. The policies and instructions contain guidelines for the entire lifecycle of the cloud service and are based on recognized standards and methods with regard to the following aspects: security in software development (requirements, design, implementation, testing, and verification); security in software deployment (including continuous delivery); and security in operation (reaction to identified faults and vulnerabilities). \n\nAdditional criterion: In procurement, products are preferred which have been certified according to the \"Common Criteria for Information Technology Security Evaluation\" (short: Common Criteria - CC) according to evaluation assurance level EAL 4. If non-certified products are to be procured instead of available certified products, a risk assessment is carried out in accordance with OIS-07.\n\nSupplementary information about the criterion: The software provision can be carried out, for example, with continuous delivery methods. Accepted standards and methods are, for example: ISO/IEC 27034; and OWASP Secure Software Development Lifecycle (S-SDLC). \n\nComplementary customer criterion notes on continuous auditing feasibility: No. The contents of the policies and instructions for the proper development or procurement of information systems do not change at a high frequency. A continuous audit of this documentation is not practical. Therefore, the integration of these tests into the recurring audit is sufficient.",
          "Physical security (ps). Redundancy model. Basic criterion: The cloud service is provided from two locations that are redundant to each other. The locations meet the security requirements of the cloud service provider (cf. ps-01 security concept) and are located in an adequate distance from each other to achieve operational redundancy. Operational redundancy is designed in a way that ensures the availability requirements specified in the service level agreement are met. The functionality of the redundancy is checked at least annually by suitable tests and exercises (cf. bcm-04 - verification, updating, and testing of business continuity). \n\nAdditional criterion: The cloud service is provided from more than two locations that provide redundancy to each other. The locations are sufficiently far apart to achieve georedundancy. If two locations fail at the same time, at least one third location is still available to prevent a total service failure. The georedundancy is designed in a way that ensures the availability requirements specified in the service level agreement are met. The functionality of the redundancy is checked at least annually by suitable tests and exercises (cf. bcm-04 - verification, updating, and testing of business continuity).\n\nSupplementary information about the criterion: Operational redundancy of the sites to each other, in the sense of the basic requirement, is given if based on the assessment of elementary risks at the site, corresponding distances of the premises and buildings to these risks are maintained. Very extensive events which, due to their extent, could affect several sites of the same redundancy group simultaneously or in a timely manner (e.g. floods, earthquakes) are not considered. A georedundancy of the sites to each other, in the sense of the optional, more far-reaching requirement, is given if a very extensive event at a site under no circumstances affects several sites of the same redundancy group simultaneously or promptly. The BSI publication \"Kriterien für die Standortwahl höchstverfügbarer und georedun-danter Rechenzentren\" provides assistance in this regard.\n\nThere are cloud providers who no longer address the issue of reliability of the cloud service on a physical level through redundancy from two independent locations but through resilience. The cloud service is provided simultaneously from more than two locations. The underlying distributed data center architecture ensures that the failure of a location or components of a location does not violate the defined availability criteria of the cloud service. Such an architecture can represent an alternative fulfillment (cf. chapter 3.4.7) of the criterion. The tests and exercises on functionality required in the criterion also apply analogously to resilient architectures.\n\nComplementary customer criterion: By means of suitable controls, cloud customers ensure that the existing redundancy model of the cloud provider and the evidence for the verification of the model comply with their own requirements for the availability and reliability of the cloud service.\n\nNotes on continuous auditing feasibility: Partially an annual audit of the effectiveness of the redundancy is only partially suitable for a continuous audit. A continuous audit could return the date of the last transaction to bring about redundancy. In addition, it would be possible to document every transaction that contributes to redundancy by means of logs and to evaluate these logs automatically and continuously. In addition, the status of the redundancy could be continuously queried.",
          "Cryptography and key management (cry). Encryption of sensitive data for storage. Basic criterion: The cloud service provider has established procedures and technical safeguards to encrypt cloud customers’ data during storage. The private keys used for encryption are known only to the cloud customer, in accordance with applicable legal and regulatory obligations and requirements. Exceptions follow a specified procedure. The procedures for the use of private keys, including any exceptions, must be contractually agreed with the cloud customer.\n\nAdditional criterion: The private keys used for encryption are known to the customer exclusively and without exception, in accordance with applicable legal and regulatory obligations and requirements.\n\nSupplementary information about the criterion: An exception to the requirement that keys are known only to the cloud customers may be the use of a master key by the cloud service provider. If the cloud service provider establishes a procedure to use a master key, the cloud service provider must perform sample-based checks regarding the suitability and effectiveness of the procedure, on a regular basis. This criterion does not apply to data that cannot be encrypted for the provision of the cloud service for functional reasons.\n\nComplementary customer criterion: Through suitable controls, cloud customers ensure that for parts of the cloud service under their responsibility (e.g., virtual machines within an IaaS solution), their data is encrypted during storage in accordance with the respective protection requirements.\n\nNotes on continuous auditing feasibility: Partially, the encryption of data of cloud customers is configured centrally; therefore, it is only suitable for continuous auditing to a limited extent. Exceptions to the encryption of data, according to a specified procedure, and the coordination of this with cloud customers should be documented and approved. This, too, is only suitable to a limited extent for continuous auditing, as these exceptions are decided on a case-by-case basis and do not occur at a high enough frequency. In a continuous audit, the system status can be queried to determine whether the encryption is active and whether the approved exceptions are being adhered to.",
          "Dealing with investigation requests from government agencies (inq). Informing cloud customers about investigation requests. Basic criterion: The cloud service provider informs the affected cloud customer(s) without undue delay, unless the applicable legal basis on which the government agency is based prohibits this or there are clear indications of illegal actions in connection with the use of the cloud service. \nAdditional criterion: Supplementary information about the criterion. This does not affect other legal or regulatory requirements that require earlier information for cloud customers. \nComplementary customer criterion: Cloud customers ensure through suitable controls that such notifications are received and legally checked according to their own specifications and possibilities. \nNotes on continuous auditing feasibility: Partially for internal process monitoring at the cloud service provider and facilitation of the audit, a continuous audit of the period between receipt of the request and information of the customers is conceivable. However, as this depends on local legal basis, the effort to establish this in the respective regions will be quite high. If a transaction processing system is implemented at the cloud service provider, at least the process in this system can be continuously audited.",
          "Procurement, development and modification of information systems (dev). Safety training and awareness programme regarding continuous software delivery and associated systems, components or tools.. Basic criterion: The cloud service provider provides a training program for regular, target group-oriented security training and awareness for internal and external employees on standards and methods of secure software development and provision, as well as on how to use the tools used for this purpose. The program is regularly reviewed and updated with regard to the applicable policies and instructions, the assigned roles and responsibilities, and the tools used.\n\nAdditional criterion: Supplementary information about the criterion.\n\nComplementary customer criterion: Notes on continuous auditing feasibility.\n\nFeasibility: Yes, the cloud service provider can automatically check the valid policies and instructions, the assigned roles and responsibilities, and the tools used and document the results in logs. These logs can be automatically evaluated by the auditor, and thus, a continuous audit can be carried out.",
          "Identity and access management (idm). Regular review of access rights. Basic criterion: Access rights of internal and external employees of the cloud service provider, as well as system components that play a role in automated authorization processes of the cloud service provider, are reviewed at least once a year to ensure that they still correspond to the actual area of use. The review is carried out by authorized persons from the cloud service provider’s organizational units, who can assess the appropriateness of the assigned access rights based on their knowledge of the task areas of the employees or system components. Identified deviations will be dealt with promptly, but no later than 7 days after their detection, by appropriate modification or withdrawal of the access rights.\n\nAdditional criterion: Privileged access rights are reviewed at least every six months.\n\nSupplementary information about the criterion: Complementary customer criterion notes on continuous auditing feasibility: Yes, the review audit cannot be recorded automatically. A registration of documents used for documentary purposes could take place (e.g., confirmation that the assignment of the access rights has been reviewed). A continuous audit could indicate when this review was last carried out. The cloud service provider must automate the review process (in particular, the confirmation that the review has been performed) so that the auditor can audit the steps to be performed in case deviations are detected.",
          "Asset management (am). Asset inventory. Basic criterion: The cloud service provider has established procedures for inventorying assets. The inventory is performed automatically and/or by the people or teams responsible for the assets to ensure a complete, accurate, valid, and consistent inventory throughout the asset lifecycle. Assets are recorded with the information needed to apply the risk management procedure (cf. OIS-07), including the measures taken to manage these risks throughout the asset lifecycle. Changes to this information are logged.\n\nAdditional criterion: Logging and monitoring applications take into account the information collected on the assets to identify the impact on cloud services and functions in case of events that could lead to a breach of protection objectives. It also supports information provided to affected cloud customers in accordance with contractual agreements.\n\nSupplementary information about the criterion: Assets within the meaning of this criteria area are the objects required for the information security of the cloud service. This includes the creation, processing, storage, transmission, deletion, or destruction of information in the cloud service provider's area of responsibility. Examples of these objects are firewalls, load balancers, web servers, application servers, and database servers. \n\nThese objects consist of hardware and software objects. Hardware objects are physical and virtual infrastructure resources (e.g., servers, storage systems, network components) as well as end devices if the cloud service provider has determined in a risk assessment that they could endanger the information security of the cloud service in the event of loss or unauthorized access (e.g., mobile devices used as security tokens for authentication). Software objects include hypervisors, containers, operating systems, databases, microservices, and programming interfaces (APIs).\n\nThe lifecycle of an asset includes: acquisition, commissioning, maintenance, decommissioning, and disposal.\n\nComplementary customer criterion notes on continuous auditing feasibility: Yes, the cloud service provider must ensure that assets are automatically captured in a database. Automatic capture of physical assets must also be ensured. However, it would be conceivable to automatically capture these assets when logging onto a network for the first time. The creation of virtual assets can be directly linked to the entry into the database. If all assets are recorded automatically, changes to the database can be documented (logs), and these logs can then be continuously evaluated.\n\nIt is important to ensure that the information contained in the inventory and logs is complete. If automated processes are available, the auditor can create an evaluation of the changes in the inventory based on the logs. To check the completeness, the first step would be to query all current assets at the cloud service provider. This asset list could then be compared with the entries in the asset management database.",
          "Compliance (com). Policy for planning and conducting audits. Basic criterion: Policies and instructions for planning and conducting audits are documented, communicated, and made available in accordance with SP-01. They address the following aspects: \n- Restriction to read-only access to system components in accordance with the agreed audit plan and as necessary to perform the activities. \n- Activities that may result in malfunctions to the cloud service or breaches of contractual requirements are performed during scheduled maintenance windows or outside peak periods. \n- Logging and monitoring of activities. \n\nAdditional criterion: The cloud service provider grants its cloud customers contractually guaranteed information and audit rights. \n\nSupplementary information about the criterion: \n- Complementary customer criterion - Cloud customers ensure through suitable controls that appropriate responses are made to malfunctions to the cloud service through such audits. \n- To the extent that contractually guaranteed information and audit rights exist, the cloud customers ensure through suitable controls that these rights are designed and executed in accordance with their own requirements. \n\nNotes on continuous auditing feasibility: \nPartially, a policy can change ad-hoc. However, the continuous audit of policies is only partially feasible as the only attributes that can be tested are the last change date and the status of review or approval, as far as this information is stored in a system. The content of a policy can hardly be tested automatically.",
          "Product safety and security (pss). Error handling and logging mechanisms. Basic criterion: The cloud service provided is equipped with error handling and logging mechanisms. These enable cloud users to obtain security-related information about the security status of the cloud service as well as the data, services, or functions it provides. The information is detailed enough to allow cloud users to check the following aspects, insofar as they are applicable to the cloud service: which data, services, or functions available to the cloud user within the cloud service have been accessed by whom and when (audit logs); malfunctions during the processing of automatic or manual actions; and changes to security-relevant configuration parameters, error handling and logging mechanisms, user authentication, action authorization, cryptography, and communication security. The logged information is protected from unauthorized access and modification and can be deleted by the cloud customer. If the cloud customer is responsible for the activation or type and scope of logging, the cloud service provider must provide appropriate logging capabilities. \n\nAdditional criterion: Cloud users can retrieve security-related information via documented interfaces which are suitable for further processing this information as part of their security information and event management (SIEM). \n\nSupplementary information about the criterion: In the case of a SaaS service for secure data exchange, the terms data, services, or functions would mean, for example, the logging of all read or write accesses to the stored files and their metadata. \n\nComplementary customer criterion: If the cloud service is equipped with error handling and logging mechanisms, cloud customers must activate these and configure them according to defined requirements. The cloud customer must incorporate their own information security management for this purpose. \n\nNotes on continuous auditing feasibility: Yes, the information about the security status of cloud services and further data provided can be read automatically and continuously, as these must be made available to cloud users in digital form. This enables continuous auditing.",
          "Physical security (ps). Protection from fire and smoke. Basic criterion: Premises and buildings related to the cloud service provided are protected from fire and smoke by structural, technical, and organizational measures that meet the security requirements of the cloud service provider (cf. PS-01 security concept). This includes the following aspects:\n\na) Structural measures: Establishment of fire sections with a fire resistance duration of at least 90 minutes for all structural parts.\n\nb) Technical measures: Early fire detection with automatic voltage release. The monitored areas are sufficiently fragmented to ensure that the prevention of the spread of incipient fires is proportionate to the maintenance of the availability of the cloud service provided. This includes an extinguishing system or oxygen reduction and a fire alarm system with reporting to the local fire department.\n\nc) Organizational measures: Regular fire protection inspections to check compliance with fire protection requirements and regular fire protection exercises.\n\nAdditional criterion: The environmental parameters are monitored. When the permitted control range is exceeded, alarm messages are generated and forwarded to the cloud service provider's subject matter experts.\n\nSupplementary information about the criterion: The monitoring of the environmental parameters is addressed in PS-01. When exceeding the allowed control range, alarm messages are generated and forwarded to the responsible cloud service provider. Structural parts include walls, ceilings, floors, doors, ventilation flaps, etc.\n\nComplementary customer criterion notes on continuous auditing feasibility: Yes, continuous testing is possible insofar as the built-in technology for testing the protective measures produces evaluable data, and these are stored in a standardized form. This would allow the security measures to be continuously evaluated by the auditor. If this technology is not fully available and an inspection of the data center is necessary, the possibility of continuous auditing is achievable only to a limited extent.",
          "Operations (ops). Logging and monitoring – concept. Basic criterion: The cloud service provider has established policies and instructions that govern the logging and monitoring of events on system components within its area of responsibility. These policies and instructions are documented, communicated, and provided according to SP-01 with respect to the following aspects: \n- Definition of events that could lead to a violation of the protection goals \n- Specifications for activating, stopping, and pausing the various logs \n- Information regarding the purpose and retention period of the logs \n- Define roles and responsibilities for setting up and monitoring logging \n- Time synchronization of system components \n- Compliance with legal and regulatory frameworks \n\nAdditional criterion: Supplementary information about the criterion legal and regulatory frameworks can define, for example, legal requirements for retention and deletion of data. \n\nComplementary Customer Criterion: Cloud customers ensure, through suitable controls, that appropriate logging and monitoring of events that may affect the security and availability of the cloud service (e.g., administrator activities, system failures, authentication checks, data deletions, etc.) takes place for those layers of the cloud service under their responsibility. \n\nNotes on Continuous Auditing Feasibility: Partially, a policy can change ad-hoc. However, the continuous audit of policies is only partially feasible as the only attributes that can be tested are the last change date and the status of review or approval, as far as this information is stored in a system. The content of a policy can hardly be tested automatically.",
          "Procurement, development and modification of information systems (dev). Approvals for provision in the production environment. Basic criterion: Authorized personnel or system components of the cloud service provider approve changes to the cloud service based on defined criteria (e.g. test results and required approvals) before these are made available to the cloud customers in the production environment. Cloud customers are involved in the release according to contractual requirements.\n\nAdditional criterion: Supplementary information about the criterion, the definitions for criterion dev-03 apply.\n\nComplementary customer criterion: Where changes are to be approved by the cloud customers in accordance with the contractual agreements before they are made available in the production environment, the cloud customers ensure through suitable controls that authorized and qualified personnel receive the information made available, assess the impact on the ISMS framework, and decide on the approval in accordance with the conditions specified by the cloud service provider.\n\nNotes on continuous auditing feasibility: Yes, verification that all tests have been completed, successfully, and approved by an authorized body can be automated by the cloud service provider and documented in logs. These logs can then be evaluated automatically and continuously by the auditor.",
          "Control and monitoring of service providers and suppliers (sso). Directory of service providers and suppliers. Basic criterion: The cloud service provider maintains a directory for controlling and monitoring the service providers and suppliers who contribute services to the delivery of the cloud service. The following information is maintained in the directory: company name, address, locations of data processing and storage, responsible contact person at the service provider/supplier, responsible contact person at the cloud service provider, description of the service, classification based on the risk assessment, beginning of service usage, and proof of compliance with contractually agreed requirements. The information in the list is checked at least annually for completeness, accuracy, and validity.\n\nAdditional criterion: Supplementary information about the criterion. It is not necessary to maintain a single central register in order to fulfill the basic criterion. \n\nComplementary customer criterion: Notes on continuous auditing feasibility. No ad-hoc completeness checks on the specified criteria can safely take place automatically, as can a comparison of changed data with relevant company databases. This can be set up by the cloud service provider. The auditor can then examine deviations as part of the recurring audit. However, due to the frequency and the completeness analysis, a continuous audit is not efficient due to the large effort required.",
          "Organisation of information security (ois). Application of the risk management policy. Basic criterion: The cloud service provider executes the process for handling risks as needed or at least once a year. The following aspects are taken into account when identifying risks, insofar as they are applicable to the cloud service provided and are within the area of responsibility of the cloud service provider: processing, storage, or transmission of data of cloud customers with different protection needs; occurrence of vulnerabilities and malfunctions in technical protective measures for separating shared resources; attacks via access points, including interfaces accessible from public networks; conflicting tasks and areas of responsibility that cannot be separated for organizational or technical reasons; and dependencies on subservice organizations. The analysis, evaluation, and treatment of risks, including the approval of actions and acceptance of residual risks, are reviewed for adequacy at least annually by the risk owners.\n\nAdditional criterion supplementary information about the criterion: This criterion applies only to risks that reside within the area of responsibility of the cloud service provider. Risks that arise for the cloud customer when using the cloud service are not covered by this criterion. When outsourcing activities for the provision of cloud services to subservice organizations, the responsibility for these risks remains with the cloud service provider. Requirements for measures to manage these risks can be found in the criteria area \"Control and monitoring of service providers and suppliers (SSO)\". Shared resources are e.g. networks, RAM, or storage.\n\nComplementary customer criterion notes on continuous auditing feasibility: Partially, the procedure for handling risks must be tested at least once a year and is therefore part of the standard audit cycle. However, the continuous audit of handling risk is only partially feasible as the only attributes that can be tested are the last review date and the status of review or approval, as far as this information is stored in a system. The content of the risks can hardly be tested automatically.\n\n5.2 Security policies and instructions (SP) objective: Provide policies and instructions regarding security requirements and to support business requirements.",
          "Business continuity management (bcm). Top management responsibility. Basic criterion: The top management (or a member of the top management) of the cloud service provider is named as the process owner of business continuity and emergency management. They are responsible for establishing the process within the company as well as ensuring compliance with the guidelines. They must ensure that sufficient resources are made available for an effective process. People in management and other relevant leadership positions demonstrate leadership and commitment to this issue by encouraging employees to actively contribute to the effectiveness of continuity and emergency management.\n\nAdditional criterion: Supplementary information about the criterion\n\nComplementary customer criterion: \n\nNotes on continuous auditing feasibility: No, the responsibilities for continuity and emergency management processes are initially named and rarely changed afterwards. Therefore, a continuous audit is not effective. However, a continuous audit can return the date of the last revision of the guidelines for continuity and emergency management.",
          "Cryptography and key management (cry). Secure key management. Basic criterion: Procedures and technical safeguards for secure key management in the area of responsibility of the cloud service provider include at least the following aspects: \n- Generation of keys for different cryptographic systems and applications \n- Issuing and obtaining public-key certificates \n- Provisioning and activation of the keys \n- Secure storage of keys (separation of key management system from application and middleware level), including description of how authorized users get access \n- Changing or updating cryptographic keys, including policies defining under which conditions and in which manner the changes and/or updates are to be realized \n- Handling of compromised keys \n- Withdrawal and deletion of keys \n- If pre-shared keys are used, the specific provisions relating to the safe use of this procedure are specified separately\n\nAdditional criterion: Supplementary information about the criterion\n  \nKeys should be withdrawn or deleted, e.g. in the event of compromise or employee changes. The cloud service provider protects the keys which are created and inserted into the cloud service by the cloud customers according to the same criteria as the keys created by the cloud service provider.\n\nComplementary customer criterion: Notes on continuous auditing feasibility\n  \nPartially for procedures and technical measures for key management to take into account the required aspects, these aspects must be implemented in the corresponding configuration. These configurations are rarely changed, and only these changes would have to be audited continuously. However, the system status could be reviewed and, in the event of irregularities, indicated and documented.\n\n5.9 Communication security (COS) \n\nObjective: Ensure the protection of information in networks and the corresponding information processing systems.",
          "Operations (ops). Logging and monitoring – availability of the monitoring software. Basic criterion: The cloud service provider monitors the system components for logging and monitoring in its area of responsibility. Failures are automatically and promptly reported to the cloud service provider's responsible departments so that they can assess the failures and take the required action.\n\nAdditional criterion: The system components for logging and monitoring are designed in such a way that the overall functionality is not restricted if individual components fail.\n\nSupplementary information about the criterion:\n\nComplementary customer criterion notes on continuous auditing feasibility: Yes, automatically communicated failures can be tracked in logs. A continuous and automated audit of these failures can be carried out by evaluating these logs.",
          "Product safety and security (pss). Authentication mechanisms. Basic criterion: The cloud service provider provides authentication mechanisms that can enforce strong authentication (e.g., two or more factors) for users, IT components, or applications within the cloud users' area of responsibility. These authentication mechanisms are set up at all access points that allow users, IT components, or applications to interact with the cloud service. For privileged users, IT components, or applications, these authentication mechanisms are enforced.\n\nAdditional criterion: The cloud service offers out-of-band authentication (OOB), in which the factors are transmitted via different channels (e.g., internet and mobile network).\n\nSupplementary information about the criterion: IT components, in the sense of this criterion, are independently usable objects with external interfaces that can be connected with other IT components. Access points, in the sense of this criterion, are those that can be accessed by users, IT components, or applications via networks (for users, for example, the login screen on the publicly accessible website of the cloud service provider). Multi-factor authentication can be performed with cryptographic certificates, smart cards, or tokens, for example.\n\nComplementary customer criterion: Cloud customers ensure, through suitable controls, that the authentication mechanisms offered by the cloud service are used in accordance with the customer's identity and authorization management requirements.\n\nNotes on continuous auditing feasibility: Partially, the implementation of authentication mechanisms for users takes place via configurations that are only adapted at a low frequency. Thus, continuous auditing is only partially effective here. Nevertheless, it is conceivable to monitor the status of the underlying authentication system, but only deviations from target configurations can be checked. Whether these deviations are desired or not must still be recorded in a manual audit.",
          "Business continuity management (bcm). Verification, updating and testing of the business continuity. Basic criterion: The business impact analysis, business continuity plans, and contingency plans are reviewed, updated, and tested on a regular basis (at least annually) or after significant organizational or environmental changes. Tests involve affected customers (tenants) and relevant third parties. The tests are documented, and results are taken into account for future operational continuity measures.\n\nAdditional criterion: In addition to the tests, exercises are also carried out which, among other things, have resulted in scenarios from security incidents that have already occurred in the past.\n\nSupplementary information about the criterion: Tests are primarily conducted at the operational level and are aimed at operational target groups. Tests include, e.g.: test of technical precautionary measures; functional tests; and plan review. Exercises also take place on a tactical and strategic level. These include, e.g.: plan meeting; staff exercise; command post exercise; communication and alerting exercise; simulation of scenarios; and emergency or full exercise. After a completed exercise: review and possible adaptation of the existing alarm plan.\n\nRelevant third parties are, in particular, service providers and suppliers of the cloud service provider who contribute to the provision of the cloud service (cf. basic criteria sso-02 and sso-05).\n\nComplementary customer criterion: Cloud customers ensure through suitable controls that measures to prevent the impact of a cloud service or cloud service provider outage are regularly reviewed, updated, tested, and exercised. The cloud service provider is involved in the tests and exercises in accordance with the contractual agreements. Cloud customers ensure through suitable controls that the results of the cloud service provider's BCM tests and exercises are incorporated into their own BCM and that they are fully appreciated with regard to ensuring the customer's operational continuity. In tests and exercises that involve the customer and therefore require own measures on the customer side, cloud customers ensure that the appropriate measures for coping with the scenario are practiced and tested by means of suitable BCM controls.\n\nNotes on continuous auditing feasibility: Partially implementing the tests of the operational continuity plans in an annual cycle does not make the continuous audit of the entire criterion effective. The effort for both cloud service providers and auditors to automate and continuously test this process would be higher than the results. However, it is possible to continuously audit whether a test was carried out within the required time span. To do this, the cloud service provider must document, in a standardized manner, that and when a test was carried out.\n\n5.15 Compliance (COM)\n\nObjective: Avoid non-compliance with legal, regulatory, self-imposed, or contractual information security and compliance requirements.",
          "Personnel (hr). Responsibilities in the event of termination or change of employment. Basic criterion: Internal and external employees have been informed about the responsibilities arising from employment terms and conditions relating to information security, which will remain in place when their employment is terminated or changed, and for how long. \n\nAdditional criterion: Supplementary information about the criterion: The cloud service provider ensures that the policies and instructions reflect applicable legal and regulatory requirements in accordance with SP-01. \n\nComplementary customer criterion: Notes on continuous auditing feasibility: Yes. As part of a comprehensive, system-based documentation of HR data, it is conceivable that the employee will receive confirmation that he or she has been informed about the required topics. This should be requested again at the end of the employment relationship. If such documentation was available in standardized and digital form, the auditor would be able to check each termination for this confirmation and identify any deviations. This makes continuous verification possible.",
          "Operations (ops). Data backup and recovery – concept. Basic criterion: Policies and instructions for data backup and recovery are documented, communicated, and provided in accordance with SP-01. The following aspects need to be addressed:\n\n- The extent and frequency of data backups and the duration of data retention should align with contractual agreements with cloud customers and the cloud service provider's operational continuity requirements for Recovery Time Objective (RTO) and Recovery Point Objective (RPO).\n- Data should be backed up in an encrypted state-of-the-art form.\n- Access to backed-up data and execution of restores should be performed only by authorized persons.\n- Tests of recovery procedures (cf. OPS-08) should be conducted.\n\nAdditional criterion: Supplementary information about the criterion:\n\n- The data backup concept specifies the type of data backup to be carried out (e.g., type, manner, duration) and identifies any specific data that must be backed up in special cases (e.g., pure use of compute nodes without data storage).\n- Backup procedures should differentiate between backups and snapshots of virtual machines. Snapshots do not replace backups but can be included in the backup strategy to achieve Recovery Point Objectives (RPO) if they are stored outside the original data location.\n- The business requirements of the cloud service provider for the scope, frequency, and duration of data backup should be determined through a business impact analysis (cf. BCM-03) for development and operational processes of the cloud service.\n- If different data backup and recovery procedures exist for data under the responsibility of the cloud customer and the cloud service provider, both variants need to be included in a test according to this criteria catalogue.\n- For procedures to secure the data of the cloud service provider, only the adequacy and implementation of the controls need to be proven, but not their effectiveness.\n- For procedures to secure the data of cloud customers, proof of effectiveness must also be provided.\n\nComplementary customer criterion: Cloud customers need to ensure, through suitable controls, that the contractual agreements made with the cloud service provider regarding the scope, frequency, and duration of data retention meet their business requirements. The business requirements are assessed as part of the business impact analysis (cf. BCM-02).\n\nNotes on continuous auditing feasibility: Partially, a policy can change ad-hoc. However, continuous auditing of policies is only partially feasible as the only attributes that can be tested are the last change date and the status of review or approval, as far as this information is stored in a system. The content of a policy can hardly be tested automatically.",
          "Control and monitoring of service providers and suppliers (sso). Monitoring of compliance with requirements. Basic criterion: The cloud service provider monitors compliance with information security requirements and applicable legal and regulatory requirements in accordance with policies and instructions concerning controlling and monitoring of third parties. Monitoring includes a regular review of the following evidence to the extent that such evidence is to be provided by third parties in accordance with the contractual agreements: reports on the quality of the service provided; certificates of the management systems' compliance with international standards; independent third-party reports on the suitability and operating effectiveness of their service-related internal control systems; and records of the third parties on the handling of vulnerabilities, security incidents, and malfunctions. The frequency of the monitoring corresponds to the classification of the third party based on the risk assessment conducted by the cloud service provider (cf. SSO-02). The results of the monitoring are included in the review of the third party's risk assessment. Identified violations and deviations are subjected to analysis, evaluation, and treatment in accordance with the risk management procedure (cf. OIS-07). \n\nAdditional criterion: The procedures for monitoring compliance with the requirements are supplemented by automatic procedures relating to the following aspects: configuration of system components; performance and availability of system components; response time to malfunctions and security incidents; and recovery time (time until completion of error handling). Identified violations and discrepancies are automatically reported to the responsible personnel or system components of the cloud service provider for prompt assessment and action. \n\nSupplementary information about the criterion: Evidence for the review of the suitability and operating effectiveness of the service-related internal control system includes reports in accordance with ISAE 3402, IDW PS 951, SOC 2, or BSI C5. In the evidence provided by the third parties, the cloud service provider reviews, for example, the following aspects and, if necessary, incorporates the findings into the risk assessment in order to derive and initiate mitigating actions: the scope and the validity respectively the period covered by the evidence; for attestation reports: qualifications of the opinion, included deviations/other observations including management's response and corresponding controls to be implemented and executed by the cloud service provider; disclosed subcontractors incl. any changes among those (e.g. additional subcontractor); and stated security incidents. \n\nComplementary customer criterion: Cloud customers ensure through suitable controls that they stay informed about subservice organizations of their cloud service provider (e.g. on the basis of the information in the C5 attestation report) and decide on the basis of their need for protection of their data processed and stored in the cloud service whether further action should be taken to monitor and check these subservice organizations. \n\nNotes on continuous auditing feasibility: Partially, a continuous audit of some of the required evidence, such as the reviews conducted and their results, can be performed once the cloud service provider documents the associated steps using a tool. However, a review on content-level, such as reviewing the response to risk assessments and violations of service provider requirements, is difficult as it requires a semantic understanding. As a result, at least parts of the criterion are suitable for continuous audit.",
          "Identity and access management (idm). Authentication mechanisms. Basic criterion: System components in the cloud service provider's area of responsibility that are used to provide the cloud service, authenticate users of the cloud service provider's internal and external employees, as well as system components that are involved in the cloud service provider's automated authorization processes. Access to the production environment requires two-factor or multi-factor authentication. Within the production environment, user authentication takes place through passwords, digitally signed certificates, or procedures that achieve at least an equivalent level of security. If digitally signed certificates are used, administration is carried out in accordance with the guideline for key management (cf. cry-01). The password requirements are derived from a risk assessment and documented, communicated, and provided in a password policy according to sp-01. Compliance with the requirements is enforced by the configuration of the system components, as far as technically possible. Additional criterion: Access to the non-production environment requires two-factor or multi-factor authentication. Within the non-production environment, users are authenticated using passwords, digitally signed certificates, or procedures that provide at least an equivalent level of security.\n\nSupplementary information about the criterion: Complementary customer criterion notes on continuous auditing feasibility: Yes, if the implementation is enforced by appropriate system configuration (automated control), the status of the configuration or its last change can be checked regularly.\n\n5.8 Cryptography and Key Management (CRY)\n\nObjective: Ensure appropriate and effective use of cryptography to protect the confidentiality, authenticity, or integrity of information.",
          "Control and monitoring of service providers and suppliers (sso). Policies and instructions for controlling and monitoring third parties. Basic criterion: Policies and instructions for controlling and monitoring third parties (e.g. service providers or suppliers) whose services contribute to the provision of the cloud service are documented, communicated, and provided in accordance with SP-01 with respect to the following aspects:\n\n- Requirements for the assessment of risks resulting from the procurement of third-party services\n- Requirements for the classification of third parties based on the risk assessment by the cloud service provider and the determination of whether the third party is a subcontractor (cf. supplementary information)\n- Information security requirements for the processing, storage, or transmission of information by third parties based on recognized industry standards\n- Information security awareness and training requirements for staff\n- Applicable legal and regulatory requirements\n- Requirements for dealing with vulnerabilities, security incidents, and malfunctions\n- Specifications for the contractual agreement of these requirements\n- Specifications for the monitoring of these requirements\n- Specifications for applying these requirements also to service providers used by the third parties, insofar as the services provided by these service providers also contribute to the provision of the cloud service.\n\nAdditional criterion: Subservice organizations of the cloud service provider are contractually obliged to provide regular reports by independent auditors on the suitability of the design and operating effectiveness of their service-related internal control system. The reports include the complementary subservice organizations that are required, together with the controls of the cloud service provider, to meet the applicable basic criteria of BSI C5 with reasonable assurance. In case no reports can be provided, the cloud service provider agrees to appropriate information and audit rights to assess the suitability and effectiveness of the service-related internal control system, including the complementary controls, by qualified personnel.\n\nSupplementary information about the criterion: Reports by independent auditors on the suitability of the design and operating effectiveness of their service-related internal control system are, for example, attestation reports in accordance with ISAE 3402, IDW PS 951, SOC 2, or BSI C5. Qualified personnel works, for example, in the cloud service provider's internal audit department or is commissioned by the cloud service provider in the form of expert third parties, such as audit firms, and may hold relevant certifications such as \"Certified Internal Auditor (CIA)\". The complementary controls at the subservice provider are necessary in order to, together with the controls of the cloud service provider, fulfill the applicable C5 criteria with reasonable assurance. Applicable legal and regulatory requirements may exist, for example, in the areas of data protection, intellectual property rights, or copyright. If legal or regulatory requirements provide for a regulation deviating from these criteria for the control of subcontractors, these regulations remain unaffected by the C5 criteria.\n\nComplementary customer criterion notes on continuous auditing feasibility: Partially regarding the availability of the documentation, a continuous audit is not practical since the associated processes and steps can be tested in a recurring audit. A continuous audit of whether changes have been made to the policies is possible, provided that these changes are documented by the cloud service provider and can be evaluated. However, an automated audit of the meaningfulness of the changes is difficult to implement. Regarding the proof that a communication/provision has taken place, a continuous audit is considered possible. For this, the cloud service provider would have to realize the notification based on a system (e.g. based on tickets or notes in the respective service provider contract).",
          "Physical security (ps). Surveillance of operational and environmental parameters. Basic criterion: The operating parameters of the technical utilities (cf. PS-06) and the environmental parameters of the premises and buildings related to the cloud service provided are monitored and controlled in accordance with the security requirements of the cloud service provider (cf. PS-01 security concept). When the permitted control range is exceeded, the responsible departments of the cloud provider are automatically informed in order to promptly initiate the necessary measures for return to the control range.\n\nAdditional criterion; supplementary information about the criterion: Operating parameters and environmental parameters of the premises and buildings include, for example, air temperature and humidity, leakage.\n\nComplementary customer criterion: Notes on continuous auditing feasibility: Yes, the monitoring and control of the operating parameters of the technical supply facilities is carried out automatically and documented in a standardized manner, for example, in logs. These logs are then automated by the inspector and can be continuously evaluated.\n\n5.6 Operations (OPS)\n\nObjective: Ensure proper and regular operation, including appropriate measures for planning and monitoring capacity, protection against malware, logging and monitoring events, and dealing with vulnerabilities, malfunctions, and failures.",
          "Operations (ops). Protection against malware – implementation. Basic criterion: System components under the cloud service provider's responsibility that are used to deploy the cloud service in the production environment are configured with malware protection according to the policies and instructions. If protection programs are set up with signature and behavior-based malware detection and removal, these protection programs are updated at least daily.\n\nAdditional criterion: The configuration of the protection mechanisms is monitored automatically. Deviations from the specifications are automatically reported to the subject matter experts so that the deviations are immediately assessed and the necessary measures taken.\n\nSupplementary information about the criterion: Protection against malicious programs can be implemented by operating system-specific protection mechanisms or explicit protection programs (e.g., for signature- and behavior-based detection and removal of malicious programs).\n\nComplementary customer criterion: Cloud customers ensure, through suitable controls, that the layers of the cloud service for which they are responsible have security products in place to detect and remove malware.\n\nNotes on continuous auditing feasibility: Yes, the first step should be to check whether all systems are covered. This should be monitored by continuously checking a tool, including the additions and deletions of entries. In the second step, the log files for the updates of the individual servers and the regular scans should be audited continuously. Identified malware or irregularities should be marked and tracked as part of the continuous scan.",
          "Personnel (hr). Confidentiality agreements. Basic criterion: The non-disclosure or confidentiality agreements to be agreed with internal employees, external service providers, and suppliers of the cloud service provider are based on the requirements identified by the cloud service provider for the protection of confidential information and operational details. The agreements are to be accepted by external service providers and suppliers when the contract is agreed. The agreements must be accepted by internal employees of the cloud service provider before authorization to access data of cloud customers is granted. The requirements must be documented and reviewed at regular intervals (at least annually). If the review shows that the requirements need to be adapted, the non-disclosure or confidentiality agreements are updated. The cloud service provider must inform the internal employees, external service providers, and suppliers and obtain confirmation of the updated confidentiality or non-disclosure agreement.\n\nAdditional criterion: Supplementary information about the criterion in a confidentiality agreement. It should be described: which information must be kept confidential; the period for which this confidentiality agreement applies; what actions must be taken upon termination of this agreement, e.g. destruction or return of data medium; how the ownership of information is regulated; what rules apply to the use and disclosure of confidential information to other partners if necessary; and the consequences of a breach of the agreement. Confidentiality or non-disclosure agreements can be signed by means of an electronic signature, insofar as this is legally binding.\n\nComplementary customer criterion: Notes on continuous auditing feasibility: Yes, the signing of confidentiality agreements with internal employees, external service providers, and suppliers can be standardized and stored digitally. An automated continuous evaluation can then be carried out to check whether all parties have signed such a confidentiality agreement and whether the agreement is up-to-date.\n\n5.4 Asset Management (AM)\n\nObjective: Identify the organization's own assets and ensure an appropriate level of protection throughout their lifecycle.",
          "Portability and interoperability (pi). Contractual agreements for the provision of data. Basic Criterion: In contractual agreements, the following aspects are defined with regard to the termination of the contractual relationship, insofar as these are applicable to the cloud service: type, scope, and format of the data the cloud service provider provides to the cloud customer; definition of the timeframe within which the cloud service provider makes the data available to the cloud customer; definition of the point in time as of which the cloud service provider makes the data inaccessible to the cloud customer and deletes it; and the cloud customers’ responsibilities and obligations to cooperate for the provision of the data. The definitions are based on the needs of subject matter experts of potential customers who assess the suitability of the cloud service with regard to a dependency on the cloud service provider as well as legal and regulatory requirements.\n\nAdditional Criterion: The design of the aspects is based on legal and regulatory requirements in the environment of the cloud service provider. The cloud service provider identifies the requirements regularly, at least once a year, and checks them for actuality and adjusts the contractual agreements accordingly.\n\nSupplementary Information about the Criterion: The type and scope of the data and the responsibilities for its provision depend on the service model of the cloud service or the services and functions provided. In the case of IaaS and PaaS, the cloud customer is generally responsible for extracting and backing up the data that is stored in the cloud service before termination of the contractual relationship (cf. complementary requirement). The cloud service provider’s responsibility is typically limited to the provision of data for the configuration of the infrastructure or platform that the cloud customer has set up within its environment (e.g., configuration of networks, images of virtual machines and containers). With SaaS, the cloud customer typically relies on export functions provided by the cloud service provider. Data created by the cloud customer should be available in the same format as stored in the cloud service. Other data, including relevant log files and metadata, should be available in an applicable standard format, such as CSV, JSON, or XML.\n\nIn Germany, legal requirements for retention can be found, for example, in the German Tax Code (§ 147 AO) and the German Commercial Code (§ 257 HGB). These provide for a retention obligation of six or ten years.\n\nComplementary Customer Criterion: Cloud customers ensure through suitable controls that the data to which they are contractually entitled is requested from the cloud service provider at the end of the contract or accessed via defined interfaces (the type and scope of the data correspond to the contractual agreements that were concluded prior to the use of the cloud service) and that it is stored in accordance with the legal requirements applicable to this data.\n\nNotes on Continuous Auditing Feasibility: No, the cloud service provider should have a standardized template for its contracts. Hence, all contracts are structured according to the same pattern. This template is rarely changed. Therefore, a continuous audit is not practical. Therefore, it is sufficient to test the contracts and the associated template as part of the recurring audit.",
          "Organisation of information security (ois). Risk management policy. Basic criteria: Policies and instructions for risk management procedures are documented, communicated, and provided in accordance with SP-01. The following aspects should be addressed:\n\n- Identification of risks associated with the loss of confidentiality, integrity, availability, and authenticity of information within the scope of the ISMS and assigning risk owners.\n- Analysis of the probability and impact of occurrence and determination of the level of risk.\n- Evaluation of the risk analysis based on defined criteria for risk acceptance and prioritization of handling.\n- Handling of risks through measures, including approval of authorization and acceptance of residual risks by risk owners.\n- Documentation of the activities implemented to enable consistent, valid, and comparable results.\n\nAdditional criterion: Supplementary information about the criterion is that the risk level can be determined by qualitative, semi-quantitative, and quantitative methods (cf. ISO 31010) based on the likelihood and impacts.\n\nComplementary customer criterion: Notes on continuous auditing feasibility: Partially, a policy can change ad-hoc. However, the continuous audit of policies is only partially feasible as the only attributes that can be tested are the last change date and the status of review or approval, as far as this information is stored in a system. The content of a policy can hardly be tested automatically.",
          "Security incident management (sim). Evaluation and learning process. Basic criterion: Mechanisms are in place to measure and monitor the type and scope of security incidents and to report them to support agencies. The information obtained from the evaluation is used to identify recurrent or significant incidents and to identify the need for further protection.\n\nAdditional criterion: Supplementary information about the criterion supporting bodies may be external service providers or government agencies such as the BSI.\n\nComplementary customer criterion: Cloud customers ensure, through suitable controls, that they include into their ISMS the findings and measures related to previous security incidents reported by the cloud service provider. The cloud customers evaluate whether and which supporting measures they might take on their side.\n\nNotes on continuous auditing feasibility: No, the existing mechanisms for measuring the type and scope of security incidents are rarely changed. As a result, continuous auditing is not effective. In addition, in some cases, it can be a manual task carried out by employees to identify recurring incidents or incidents with significant consequences and to develop associated protective measures.\n\n5.14 Business Continuity Management (BCM) Objective: Plan, implement, maintain, and test procedures and measures for business continuity and emergency management.",
          "Business continuity management (bcm). Planning business continuity. Basic criterion: Based on the business impact analysis, a single framework for operational continuity and business plan planning will be implemented, documented, and enforced to ensure that all plans are consistent. Planning is based on established standards, which are documented in a \"Statement of Applicability\". Business continuity plans and contingency plans take the following aspects into account: \n\n- Defined purpose and scope with consideration of the relevant dependencies.\n- Accessibility and comprehensibility of the plans for persons who are to act accordingly.\n- Ownership by at least one designated person responsible for review, updating, and approval.\n- Defined communication channels, roles, and responsibilities, including notification of the customer.\n- Recovery procedures, manual interim solutions, and reference information (taking into account prioritization in the recovery of cloud infrastructure components and services and alignment with customers).\n- Methods for putting the plans into effect.\n- Continuous process improvement.\n- Interfaces to security incident management. \n\nAdditional criterion: \n\nSupplementary information about the criterion: The consistency of plans, according to the basic criterion, must also be maintained when different locations are used.\n\nComplementary customer criterion: \n\nCloud customers ensure through suitable controls that the results of the business impact analysis are sufficiently considered when planning the operational continuity and the business plan in order to provide for the effects of a failure of the cloud service or cloud service provider. \n\nCloud customers ensure through suitable controls that the availability of the cloud service, its recovery time according to the BCM plan, and the data loss of the cloud service are consistent with their own availability requirements and tolerable data loss. \n\nNotes on continuous auditing feasibility: \n\nNo, the introduction of the framework and the business plan based on a business impact analysis is a manual process of the cloud service provider. A continuous audit is not practical. The plans can be tested as part of the recurring audit.",
          "Personnel (hr). Security training and awareness programme. Basic criterion: The cloud service provider operates a target group-oriented security awareness and training program, which is completed by all internal and external employees of the cloud service provider on a regular basis. The program is regularly updated based on changes to policies and instructions and the current threat situation and includes the following aspects: handling system components used to provide the cloud service in the production environment in accordance with applicable policies and procedures; handling cloud customer data in accordance with applicable policies and instructions and applicable legal and regulatory requirements; information about the current threat situation; and correct behavior in the event of security incidents. \n\nAdditional criterion: The learning outcomes achieved through the awareness and training program are measured and evaluated in a target group-oriented manner. The measurements cover quantitative and qualitative aspects. The results are used to improve the awareness and training program. \n\nSupplementary information about the criterion: \n\nComplementary customer criterion: Notes on continuous auditing \n\nFeasibility: Yes, the concept behind the security awareness and training program does not require continuous assessment and is sufficiently covered by the recurring audit. However, the completion of the training can be traced via training portals. For a continuous audit that each employee has completed and, if necessary, repeated the relevant training courses for his role description, a clear system-based definition of the necessary training courses for each role description must be carried out at the cloud service provider. The expected dates which the respective training course is to be completed must also be recorded. The documentation that the training has been completed by the employee and, if necessary, successfully completed with an examination, should take place in the same portal. The auditor then has the option of examining the results of the training courses for employees of the cloud service provider for deviations by automatically and continuously comparing the expected training dates with the actual date on which the employees completed the training.",
          "Communication security (cos). Technical safeguards. Basic criterion: Based on the results of a risk analysis carried out according to ISO-06, the cloud service provider has implemented technical safeguards that are suitable to promptly detect and respond to network-based attacks. These attacks are based on irregular incoming or outgoing traffic patterns and/or distributed denial of service (DDoS) attacks. The corresponding technical protection measures are documented, communicated, and provided in accordance with SP-01. \n\nAdditional criterion: Technical measures ensure that no unknown (physical or virtual) devices join the cloud service provider's (physical or virtual) network. This can be achieved through measures such as MACsec according to IEEE 802.1x:2010. \n\nSupplementary information about the criterion: Network-based attacks can include MAC spoofing and ARP poisoning attacks. \n\nComplementary customer criterion: Cloud customers are responsible for ensuring suitable controls for parts of the cloud service under their responsibility (e.g., virtual machines within an IaaS solution). They should detect and respond to network-based attacks based on anomalous inbound and outbound traffic patterns, such as MAC spoofing, ARP poisoning attacks, and DDoS attacks, in a timely manner. \n\nNotes on continuous auditing feasibility: The technical protective measures are suitable for continuous auditing, but they are rarely changed. However, the data fed into the overall SIEM system and the detection of correlating events are suitable for continuous auditing. This data can be evaluated automatically and continuously, as can the monitoring of correlating events.",
          "Physical security (ps). Protection against interruptions caused by power failures and other such risks. Basic criterion: Measures to prevent the failure of the technical supply facilities required for the operation of system components with which information from cloud customers is processed are documented and set up in accordance with the security requirements of the cloud service provider (cf. PS-01 Security Concept). The following aspects should be considered:\n\n- Operational redundancy (n+1) in power and cooling supply.\n- Use of appropriately sized uninterruptible power supplies (UPS) and emergency power systems (NEA) designed to ensure that all data remains undamaged in the event of a power failure.\n- The functionality of UPS and NEA should be checked at least annually by suitable tests and exercises (cf. BCM-04 – Verification, Updating, and Testing of Business Continuity).\n- Maintenance (servicing, inspection, repair) of the utilities should be conducted in accordance with the manufacturer’s recommendations.\n- Protection of power supply and telecommunications lines against interruption, interference, damage, and eavesdropping.\n- The protection should be checked regularly, but at least every two years, as well as in the case of suspected manipulation by qualified personnel. The following aspects should be considered:\n  - Traces of violent attempts to open closed distributors.\n  - Up-to-dateness of the documentation in the distribution list.\n  - Conformity of the actual wiring and patching with the documentation.\n  - The short-circuits and earthing of unneeded cables are intact.\n  - Absence of impermissible installations and modifications.\n\nAdditional criterion: Uninterruptible power supplies (UPS) and emergency power supplies (NPS) should be designed to meet the availability requirements defined in the Service Level Agreement. The cooling supply should be designed in such a way that the permissible operating and environmental parameters are also ensured on at least five consecutive days with the highest outside temperatures measured to date within a radius of at least 50 km around the locations of the premises and buildings, with a safety margin of 3K (in relation to the outside temperature). The cloud service provider has previously determined the highest outdoor temperatures measured to date (cf. PS-01 Security Concept). The connection to the telecommunications network should have sufficient redundancy to ensure that the failure of a telecommunications network does not impair the security or performance of the cloud service provider.\n\nSupplementary information about the criterion: Measures to prevent the failure of the technical supply facilities include power supply, cooling, fire-fighting technology, telecommunications, security technology, etc. Cloud service providers can ensure that all data remains undamaged in the event of a power failure by shutting down servers following a defined procedure. Power supply and telecommunications lines can be protected against interruption, interference, damage, and eavesdropping by, for example, underground supply via different supply routes.\n\nComplementary customer criterion: Notes on continuous auditing feasibility: Partially, the physical security of premises, as well as failure precautions of the technical supply facilities, should be ensured on-site by an inspection of the data center. Therefore, a continuous examination is achievable only to a limited extent. If the built-in technology for failure prevention produces evaluable log data, this requirement can partly be audited continuously. However, this does not replace an inspection. Otherwise, a continuous inspection can be carried out at least partially by indicating the last inspection date.",
          "Communication security (cos). Security requirements for connections in the cloud service provider’s network. Basic criterion: Specific security requirements are designed, published, and provided for establishing connections within the cloud service provider's network. The security requirements define, for the cloud service provider's area of responsibility, in which cases the security zones are to be separated and in which cases cloud customers are to be logically or physically segregated. They also define which communication relationships and network and application protocols are permitted in each case. Additionally, the security requirements detail how the data traffic for administration and monitoring is segregated from each other on the network level, which internal, cross-location communication is permitted, and which cross-network communication is allowed.\n\nAdditional criterion: Management procedures (cf. OIS-06) and follow-up measures (cf. OPS-18) are defined and tracked. At specified intervals, the business justification for using all services, protocols, and ports is reviewed. \n\nSupplementary information: The review also includes the justifications for compensatory measures for the use of protocols that are considered insecure. Cross-location communication can be realized, for example, for individual regions or data centers via WAN, LAN, VPN, RAS.\n\nComplementary customer criterion: Additional criterion notes on continuous auditing feasibility: No. The required security requirements are centrally documented and rarely changed. Continuous auditing is not practical.",
          "Communication security (cos). Monitoring of connections in the cloud service provider’s network. Basic criterion: A distinction is made between trusted and untrusted networks. Based on a risk assessment, these are separated into different security zones for internal and external network areas (and DMZ, if applicable). Physical and virtualized network environments are designed and configured to restrict and monitor the established connection to trusted or untrusted networks according to the defined security requirements. The entirety of the conception and configuration undertaken to monitor the connections mentioned is assessed in a risk-oriented manner, at least annually, with regard to the resulting security requirements. Identified vulnerabilities and deviations are subject to risk assessment in accordance with the risk supplementary information about the criterion. The review of the security requirements depends on the measures implemented to design the networks. For example, monitoring and reviewing firewall rules or log files for abnormalities, as well as visual inspections of physical network components for changes.\n\nComplementary customer criterion: Cloud customers ensure through suitable controls that the virtual networks within the cloud service for which they are responsible are designed, configured, and documented in accordance with their network security requirements (e.g. logical segmentation of the cloud customer's organizational units).\n\nNotes on continuous auditing feasibility: Yes, if the business justification and the regular review of the monitoring concept are documented in a standardized way, these processes can be evaluated automatically. Thus, a continuous audit can be conducted. The separation of the networks is suitable for continuous auditing as well since the status of the separation can be continuously audited here.",
          "Identity and access management (idm). Privileged access rights. Basic criterion: Privileged access rights for internal and external employees, as well as technical users of the cloud service provider, are assigned and changed in accordance with the policy for managing user accounts and access rights (cf. idm-01) or a separate specific policy. Privileged access rights are personalized, limited in time according to a risk assessment, and assigned as necessary for the execution of tasks (\"need-to-know principle\"). Technical users are assigned to internal or external employees of the cloud service provider. Activities of users with privileged access rights are logged in order to detect any misuse of privileged access in suspicious cases. The logged information is automatically monitored for defined events that may indicate misuse. When such an event is identified, the responsible personnel are automatically informed so that they can promptly assess whether misuse has occurred and take corresponding action. In the event of proven misuse of privileged access rights, disciplinary measures are taken in accordance with hr-04.\n\nAdditional criterion: Supplementary information about the criterion \"privileged access rights\" in the sense of the basic criterion: are those that enable employees of the cloud service provider to perform any of the following activities: read or write access to the cloud customers' data processed, stored, or transmitted in the cloud service, unless such data is encrypted or the encryption can be deactivated for access by the cloud service provider; and changes to the operational and/or security configuration of the system components in the production environment, in particular the starting, stopping, deleting, or deactivating of system components, if this can affect the confidentiality, integrity, or availability of the data of the cloud customers (also indirectly, e.g. by deactivating the logging and monitoring of security-relevant events). Misused privileged access rights can be treated e.g. as a security incident, cf. sim-01.\n\nComplementary customer criterion: Notes on continuous auditing feasibility: partially, the assignment of audit authorizations must be audited manually. This includes the classification as privileged, personalization, and evaluation of the need-to-know principle. The time limit could be read, but the implementation effort would be very high. A continuous audit does not appear to be sensible here. Only the system status could be audited continuously. The automatic triggering of a notification in suspicious cases could be compared with documented measures to handle these cases. However, this entire process must be digitized for this purpose, and the effort involved currently appears to be very high. However, a continuous audit could show the time of the last manual audit.",
          "Operations (ops). Involvement of cloud customers in the event of incidents. Basic criterion: The cloud service provider periodically informs the cloud customer on the status of incidents affecting the cloud customer, or, where appropriate and necessary, involves the customer in the resolution, in a manner consistent with the contractual agreements. As soon as an incident has been resolved from the cloud service provider’s perspective, the cloud customer is informed according to the contractual agreements about the actions taken.\n\nAdditional criterion: Supplementary information about the criterion complementary customer criterion. Cloud customers ensure through suitable controls that they receive notifications from the cloud service provider regarding incidents that affect them, and that these notifications are forwarded in a timely manner to the department responsible for processing them so that appropriate action can be taken.\n\nNotes on continuous auditing feasibility: Yes, a continuous audit is possible if customers are informed about incidents via a standardized communication channel and this is documented (e-mails, logs). The auditor can then evaluate the compiled documentation automatically and continuously. However, it seems more effective to combine the evaluation of the communication of incidents to cloud customers with the evaluation of the elimination of the incidents. As soon as the incidents have been resolved automatically, in the best case, an automatic message is generated and sent to the cloud customer. This message is to be documented. This makes it possible for the auditor to evaluate whether the cloud customer has been properly informed on a regular basis about all incidents affecting them but not beyond.",
          "Control and monitoring of service providers and suppliers (sso). Risk assessment of service providers and suppliers. Basic criterion: Service providers and suppliers of the cloud service provider undergo a risk assessment in accordance with the policies and instructions for the control and monitoring of third parties prior to contributing to the delivery of the cloud service. The adequacy of the risk assessment is reviewed regularly, at least annually, by qualified personnel of the cloud service provider during service usage. The risk assessment includes the identification, analysis, evaluation, handling, and documentation of risks with regard to the following aspects: protection needs regarding the confidentiality, integrity, availability, and authenticity of information processed, stored, or transmitted by the third party; impact of a protection breach on the provision of the cloud service; the cloud service provider's dependence on the service provider or supplier for the scope, complexity, and uniqueness of the service purchased, including the consideration of possible alternatives.\n\nAdditional criterion: Supplementary information about the criterion complementary customer criterion notes on continuous auditing feasibility: No continuous auditing of the risk assessment is not effective, as only its regular execution could be audited automatically, but not the content. In addition, the specified frequency of at least one year is covered by the recurring audit. Risk assessments are rarely carried out dynamically and therefore do not often change during the year.",
          "Operations (ops). Logging and monitoring – access, storage and deletion. Basic criterion: The requirements for the logging and monitoring of events and for the secure handling of metadata are implemented by technically supported procedures with regard to the following restrictions: access only for authorized users and systems; retention for the specified period; and deletion when further retention is no longer necessary for the purpose of collection.\n\nNotes on continuous auditing feasibility: No, a continuous check is only of limited use here, since the primary purpose of checking the handling of metadata is to check the guidelines and the associated configurations of the tools for securing, processing, and deleting metadata. In addition, the contractual basis for the use of metadata may also need to be considered. A continuous audit could include the configuration for deleting or anonymizing the metadata and automatically recording whether the configuration still exists and is implemented correctly. In this case, there would be a partial possibility for continuous auditing.",
          "Cryptography and key management (cry). Encryption of data for transmission (transport encryption). Basic criterion: The cloud service provider has established procedures and technical measures for strong encryption and authentication for the transmission of data of cloud customers over public networks.\n\nAdditional criterion: The cloud service provider has established procedures and technical measures for strong encryption and authentication for the transmission of all data.\n\nSupplementary information about the criterion: When transmitting data with normal protection requirements within the cloud service provider's infrastructure, encryption is not mandatory, provided that the data is not transmitted via public networks. In this case, the non-public environment of the cloud service provider can generally be deemed trusted. The protocols TLS 1.2 and TLS 1.3 are currently regarded as strong, state-of-the-art transport encryptions, in each case in combination with perfect forward secrecy. The specific configuration should comply with the recommendations of the (current) version of the BSI Technical Guideline TR-02102-2 \"Cryptographic Procedures: Recommendations and Key Lengths - Part 2: Use of Transport Layer Security (TLS)\". Generally, the use of wildcard certificates is not considered a secure procedure.\n\nThe basic criterion for the transmission of cloud customers' data relates to, for example, the sending of electronic messages via public networks.\n\nComplementary customer criterion: Cloud customers ensure, through suitable controls for those parts of the cloud service under their responsibility, that their data is transmitted over encrypted connections in accordance with the respective protection requirements.\n\nNotes on continuous auditing feasibility: Partially, the procedures and technical measures for encrypting data during transmission are configured centrally. This configuration rarely changes. Therefore, a continuous audit would not be sensible, as only changes to this configuration would have to be checked. However, the system status can be audited continuously. This also applies to the additional criterion.",
          "Product safety and security (pss). Session management. Basic criterion: To protect confidentiality, availability, integrity, and authenticity during interactions with the cloud service, a suitable session management system is used that at least corresponds to the state-of-the-art and is protected against known attacks. Mechanisms are implemented that invalidate a session after it has been detected as inactive. The inactivity can be detected by time measurement. In this case, the time interval can be configured by the cloud service provider or – if technically possible – by the cloud customer.\n\nAdditional criterion: Supplementary information about the criterion of known attacks includes manipulation, forgery, session takeover, denial of service attacks, enveloping, replay, and null cipher attacks.\n\nComplementary customer criterion: Cloud customers can use appropriate controls to ensure that they are using the session management protection features of the cloud service in accordance with their own ISMS. They also set the time period after which a session becomes invalid according to their own ISMS specifications.\n\nNotes on continuous auditing feasibility: Partially, the use of session management is controlled by configurations. These configurations are changed or adapted at a low frequency, so continuous auditing is only partially effective. Nevertheless, monitoring the status of the underlying authentication system is conceivable, but only deviations from target configurations can be checked. Whether these deviations are normal must still be tested in a manual audit.",
          "Operations (ops). Managing vulnerabilities, malfunctions and errors – penetration tests. Basic criterion: The cloud service provider has penetration tests carried out by qualified internal personnel or external service providers at least once a year. The penetration tests are carried out according to a documented test methodology and include the system components relevant to the provision of the cloud service in the area of responsibility of the cloud service provider, which have been identified as such in a risk analysis. The cloud service provider assesses the severity of the findings made in penetration tests according to defined criteria. For findings with medium or high criticality regarding the confidentiality, integrity, or availability of the cloud service, actions must be taken within defined time windows for prompt remediation or mitigation.\n\nAdditional criterion: The tests are carried out every six months. They must always be performed by independent external auditors. Internal personnel for penetration tests may support the external service providers.\n\nSupplementary information about the criterion: Vulnerabilities should be classified according to damage potential, and a period of time should be specified for the required response. The following classification, according to the BSI publication \"Ein Praxis-Leitfaden für IS-Penetrationstests,\" can serve as an orientation: high: immediate reaction; medium: short-term response; low: medium-term response; and information: long-term response.\n\nComplementary customer criterion: Notes on continuous auditing feasibility: Partially, since penetration tests are carried out annually, a continuous audit is not practical since the effort required to automate the execution of the test is probably greater than the benefit.",
          "Operations (ops). Managing vulnerabilities, malfunctions and errors – concept. Basic criterion: Guidelines and instructions with technical and organizational measures are documented, communicated, and provided in accordance with SP-01 to ensure the timely identification and addressing of vulnerabilities in the system components used to provide the cloud service. These guidelines and instructions contain specifications regarding the following aspects: regular identification of vulnerabilities; assessment of the severity of identified vulnerabilities; prioritization and implementation of actions to promptly remediate or mitigate identified vulnerabilities based on severity and according to defined timelines; and handling of system components for which no measures are initiated for the timely remediation or mitigation of vulnerabilities. \n\nAdditional criterion: Supplementary information about the criterion identified vulnerabilities can be classified according to established metrics such as CVSS or OWASP. The decision not to remediate or mitigate identified vulnerabilities must be made by the cloud service provider based on a risk assessment. If necessary, risk-compensating measures must be taken. \n\nComplementary customer criterion: Cloud customers ensure, through suitable controls, that they check system components in their area of responsibility for vulnerabilities on a regular basis and mitigate these with appropriate measures. \n\nNotes on continuous auditing feasibility: No, a policy can change ad-hoc. However, the continuous audit of policies is only partially feasible as the only attributes that can be tested are the last change date and the status of review or approval, as far as this information is stored in a system. The content of a policy can hardly be tested automatically.",
          "Business continuity management (bcm). Business impact analysis policies and instructions. Basic criteria: Policies and instructions to determine the impact of any malfunction to the cloud service or enterprise are documented, communicated, and made available in accordance with SP-01. The following aspects are considered as minimum: \n\n- Possible scenarios based on a risk analysis \n- Identification of critical products and services \n- Identify dependencies, including processes (including resources required), applications, business partners, and third parties \n- Capture threats to critical products and services \n- Identification of effects resulting from planned and unplanned malfunctions and changes over time \n- Determination of the maximum acceptable duration of malfunctions \n- Identification of restoration priorities \n- Determination of time targets for the resumption of critical products and services within the maximum acceptable time period (RTO) \n- Determination of time targets for the maximum reasonable period during which data can be lost and not recovered (RPO) \n- Estimation of the resources needed for resumption\n\nAdditional criteria: Supplementary information about the criterion scenarios to be considered according to the basic criteria are, for example, the loss of personnel, buildings, infrastructure, and service providers. \n\nComplementary customer criteria: Cloud customers ensure through suitable controls that the scenarios for a failure of the cloud service or the cloud service provider are sufficiently considered in the context of their business impact analysis.\n\nNotes on continuous auditing feasibility: Partially, a policy can change ad-hoc. However, the continuous audit of policies is only partially feasible as the only attributes that can be tested are the last change date and the status of review or approval, as far as this information is stored in a system. The content of a policy can hardly be tested automatically.",
          "Operations (ops). Capacity management – controlling of resources. Basic criterion: Depending on the capabilities of the respective service model, the cloud customer can control and monitor the allocation of the system resources assigned to the customer for administration/use in order to avoid overcrowding of resources and to achieve sufficient performance.\n\nAdditional criterion: Supplementary information about the criterion resources, according to the possibilities of the service model, are, for example, computing capacity; storage capacity; configuration of network properties; application programming interfaces (APIs); and databases.\n\nComplementary customer criterion: Cloud customers ensure through suitable controls that they manage and monitor the system resources in their area of responsibility.\n\nNotes on continuous auditing feasibility: Partially, the existence of tools for controlling resources by the cloud customers themselves is, in itself, a continuous process, which can be continuously checked provided that the cloud service provider can prove the functionality of these tools by means of logs. However, continuously checking this only generates limited value. The functionality of the provided tools can be continuously audited if they are documented and can be evaluated by the cloud service provider.",
          "Procurement, development and modification of information systems (dev). Policies for changes to information systems. Basic criterion: Policies and instructions with technical and organizational safeguards for change management of system components of the cloud service within the scope of software deployment are documented, communicated, and provided according to SP-01. The following aspects should be considered:\n\n1. Criteria for risk assessment, categorization, and prioritization of changes.\n2. Related requirements for the type and scope of testing to be performed and necessary approvals for the development/implementation of the change.\n3. Approvals for releases of changes in the production environment by authorized personnel or system components.\n4. Requirements for the performance and documentation of tests.\n5. Requirements for segregation of duties during development, testing, and release of changes.\n6. Requirements for informing cloud customers about the type and scope of changes and their obligations to cooperate based on contractual agreements.\n7. Requirements for documenting changes in system, operational, and user documentation.\n8. Requirements for the implementation and documentation of emergency changes, maintaining the same level of security as normal changes.\n\nAdditional criterion: Supplementary information about changes in the sense of the basic criterion refers to those that can lead to changes in the configuration, functionality, or security of system components of the cloud service in the production environment. This includes changes to the infrastructure and source code. If individual changes are combined in a new release, update, patch, or comparable software object for software provisioning, this software object is considered a change within the meaning of the basic criterion, but not the individual changes contained therein. Changes to the existing network configuration must also undergo a specified procedure as they are necessary for the effective segregation of cloud customers. Personnel and system components authorized to approve changes must adhere to the requirements for access and access authorizations (cf. IDM-01), following a specified procedure (cf. IDM-02). Relevant information includes descriptions of new functions. The cloud customer's obligations to cooperate may include carrying out certain tests.\n\nComplementary customer criterion: Notes on continuous auditing feasibility: No, the contents of the policies and instructions for managing and modifying system components are not changed at a high frequency. A continuous audit of this documentation is therefore not effective. It is sufficient to integrate these tests into the recurring audit.",
          "Product safety and security (pss). Images for virtual machines and containers. Basic criterion: If cloud customers operate virtual machines or containers with the cloud service, the cloud service provider must ensure the following aspects: The cloud customer can restrict the selection of images of virtual machines or containers according to their specifications so that users of this cloud customer can only launch the images or containers released according to these restrictions. If the cloud service provider provides images of virtual machines or containers to the cloud customer, the cloud service provider must appropriately inform the cloud customer of the changes made to the previous version. In addition, these images provided by the cloud service provider must be hardened according to generally accepted industry standards. \n\nAdditional criterion: At startup and runtime of virtual machine or container images, an integrity check must be performed that detects image manipulations and reports them to the cloud customer. \n\nSupplementary information about the criterion: This criterion is typically not applicable to the SaaS service model. Generally accepted industry standards are, for example, the Security Configuration Benchmark of the Centre for Internet Security (CIS) or the corresponding modules in the BSI IT-Grundschutz-Kompendium. \n\nComplementary customer criterion: Cloud customers must use appropriate controls to ensure that the images of virtual machines or containers they operate with the cloud service comply with their information security management requirements and that the results of the integrity checks at startup and at runtime are processed according to these requirements. \n\nNotes on continuous auditing feasibility: Partially, these functions must be centrally audited at regular intervals but not continuously. Therefore, it is sufficient to integrate this into the recurring audit. With an agent system, it would be possible to continuously query the configurations of the individual virtual machines and thus compare them with the target image. This could also be set up on demand and thus become part of the control that takes over the integrity check.",
          "Portability and interoperability (pi). Documentation and safety of input and output interfaces. Basic criteria: The cloud service can be accessed by other cloud services or IT systems of cloud customers through documented inbound and outbound interfaces. Furthermore, the interfaces are clearly documented for subject matter experts on how they can be used to retrieve the data. Communication takes place through standardized communication protocols that ensure the confidentiality and integrity of the transmitted information, according to its protection requirements. Communication over untrusted networks is encrypted according to CRY-02. The type and scope of the documentation on the interfaces are geared to the needs of the cloud customers' subject matter experts to enable the use of these interfaces. The information is maintained in a way that is applicable for the cloud service's version intended for productive use. \n\nAdditional criteria: Supplementary information about the criterion complementary customer criterion. Cloud customers ensure, through suitable controls, that the provided interfaces (and their security) are adequate for their protection requirements, by means of appropriate checks before the start of use of the cloud service and each time the interfaces are changed. \n\nNotes on continuous auditing feasibility: Partially, the defined input and output interfaces of cloud services are rarely changed. Therefore, it is sufficient for the auditor to test these interfaces, the communication of potential changes, and the associated documentation as part of the recurring audit. In a continuous audit, however, the system status of the interfaces could be queried and evaluated continuously.",
          "Security incident management (sim). Policy for security incident management. Basic Criterion: Policies and instructions with technical and organizational safeguards are documented, communicated, and provided in accordance with SP-01 to ensure a fast, effective, and proper response to all known security incidents. The cloud service provider defines guidelines for the classification, prioritization, and escalation of security incidents and creates interfaces to the incident management and business continuity management. In addition, the cloud service provider has set up a \"Computer Emergency Response Team\" (CERT), which contributes to the coordinated resolution of occurring security incidents. Customers affected by security incidents are informed in a timely and appropriate manner.\n\nAdditional Criterion: There are instructions on how to collect the data of a suspicious system conclusively in the event of a security incident. Additionally, there are analysis plans for typical security incidents and an evaluation methodology to ensure that the collected information does not lose its evidential value in any subsequent legal assessment.\n\nSupplementary Information about the Criterion: Complementary Customer Criterion: Cloud customers ensure, through suitable controls, that they receive notifications from the cloud service provider about security incidents that affect them and that these notifications are forwarded in a timely manner to the responsible departments for handling so that an appropriate response can be triggered.\n\nNotes on Continuous Auditing Feasibility: Partially, a continuous audit of the documented policies and instructions is not effective because they are not subject to high-frequency changes. Thus, the audit of the policies and instructions can be performed in the recurring audit. Similarly, setting up a CERT is not suitable for continuous auditing as it is an organizational body and does not require continuous monitoring. The timely communication of security incidents to affected customers can be covered by a continuous audit approach. In addition, the cloud service provider can document not only the security incidents by means of logs but also that they have been communicated to the customer via email, for example. The fact that there was communication to affected customers for every security incident can thus be evaluated automatically and continuously by the auditor. However, this procedure can be combined with the audit approach of further requirements of security incident management.",
          "Physical security (ps). Physical security and environmental control requirements. Basic criterion: Security requirements for premises and buildings related to the cloud service provided are based on the security objectives of the information security policy, identified protection requirements for the cloud service, and the assessment of risks to physical and environmental security. The security requirements are documented, communicated, and provided in a policy or concept according to SP-01. The security requirements for data centers are based on criteria that comply with established rules of technology. They are suitable for addressing the following risks in accordance with the applicable legal and contractual requirements: faults in planning, unauthorized access, insufficient surveillance, insufficient air conditioning, fire and smoke, water, power failure, and air ventilation and filtration. If the cloud service provider uses premises or buildings operated by third parties to provide the cloud service, the document describes which security requirements the cloud service provider places on these third parties. The appropriate and effective verification of implementation is carried out in accordance with the criteria for controlling and monitoring subcontractors (cf. SSO-01, SSO-02).\n\nAdditional criterion: The security requirements include time constraints for self-sufficient operation in the event of exceptional events (e.g., prolonged power outage, heat waves, low water in cold river water supply) and maximum tolerable utility downtime. The time limits for self-sufficient operation provide for at least 48 hours in the event of a failure of the external power supply. For self-sufficient operation during a heat period, the highest outside temperatures measured to date within a radius of at least 50 km around the locations of the premises and buildings have been determined with a safety margin of 3 K. The security requirements stipulate that the permissible operating and environmental parameters of the cooling supply must also be observed on at least five consecutive days with these outside temperatures, including the safety margin (cf. PS-06 Protection against Failure of the Supply Facilities). If water is taken from a river for air conditioning, it is determined at which water levels and water temperatures the air conditioning can be maintained for how long. The maximum tolerable downtimes of utility facilities are suitable for meeting the availability requirements contained in the service level agreement.\n\nSupplementary information about the criterion: Premises and buildings related to the cloud service provided include data centers and server rooms housing system components used to process cloud customer data and the technical utilities required to operate these system components (e.g., power supply, refrigeration, fire-fighting, telecommunications, security, etc.). Backup or redundancy computer centers. Premises and buildings operated by third parties are e.g., server housing, colocation, IaaS. Premises and buildings in which no data from cloud customers is processed or stored (e.g., offices of the cloud service provider, server rooms with system components for internal development and test systems) are not subject to this criteria area. The recognized rules of technology are defined in relevant standards, e.g., EN 50600 (Facilities and Infrastructures of Data Centers). Incorrect planning can endanger the operational safety and availability of the premises or buildings. This can result from an incorrect assessment of elementary hazards at the site (e.g., air traffic, earthquakes, floods, hazardous substances) as well as an incorrect conception of the bandwidth or energy supply. Time specifications for self-sustaining operation as well as maximum tolerable downtimes of utility facilities are typically collected during the business impact analysis (cf. BCM-02, BCM-03).\n\nComplementary customer criterion notes on continuous auditing feasibility: Partially, a policy can change ad-hoc. However, the continuous audit of policies is only partially feasible as the only attributes that can be tested are the last change date and the status of review or approval, as far as this information is stored in a system. The content of a policy can hardly be tested automatically.",
          "Operations (ops). Data backup and recovery – regular testing. Basic criterion: Restore procedures are tested regularly, at least annually. The tests allow an assessment to be made as to whether the contractual agreements as well as the specifications for the maximum tolerable downtime (Recovery Time Objective, RTO) and the maximum permissible data loss (Recovery Point Objective, RPO) are adhered to (cf. BCM-02). Deviations from the specifications are reported to the responsible personnel or system components so that these can promptly assess the deviations and initiate the necessary actions. \n\nAdditional criterion: At the customer's request, the cloud service provider informs the cloud customer of the results of the recovery tests. Recovery tests are embedded in the cloud service provider's emergency management. \n\nSupplementary information about the criterion: If the data backup is not part of the contract concluded between the cloud service provider and the cloud customer, this criterion is not applicable. The cloud service provider must present this situation transparently in the system description. \n\nComplementary customer criterion notes on continuous auditing feasibility: Partially, if the tests on the restoration procedures are performed at regular intervals, the time of execution and results can be audited automatically. However, the effort of a continuous audit of this criterion is high and the added value limited if the tests are carried out in an annual cycle.",
          "Asset management (am). Acceptable use and safe handling of assets policy. Basic criterion: Policies and instructions for acceptable use and safe handling of assets are documented, communicated, and provided in accordance with SP-01. They address the following aspects of the asset lifecycle as applicable to the asset:\n\n- Approval procedures for acquisition, commissioning, maintenance, decommissioning, and disposal by authorized personnel or system components\n- Inventory\n- Classification and labeling based on the need for protection of the information and measures\n- Measures for the level of protection identified\n- Secure configuration of mechanisms for error handling, logging, encryption, authentication, and authorization\n- Requirements for versions of software and images as well as application of patches\n- Handling of software for which support and security patches are not available anymore\n- Restriction of software installations or use of services\n- Protection against malware\n- Remote deactivation, deletion, or blocking\n- Physical delivery and transport\n- Dealing with incidents and vulnerabilities\n- Complete and irrevocable deletion of the data upon decommissioning\n\nAdditional criterion: Supplementary information about the criterion and complementary customer criterion notes on continuous auditing feasibility:\n\nPartially, a policy can change ad-hoc. However, the continuous audit of policies is only partially feasible as the only attributes that can be tested are the last change date and the status of review or approval, as far as this information is stored in a system. The content of a policy can hardly be tested automatically.",
          "Identity and access management (idm). Confidentiality of authentication information. Basic criterion: The allocation of authentication information to access system components used to provide the cloud service to internal and external users of the cloud provider and system components that are involved in automated authorization processes of the cloud provider is done in an orderly manner that ensures the confidentiality of the information. If passwords are used as authentication information, their confidentiality is ensured by the following procedures, as far as technically possible: \n\n- Users can initially create the password themselves or must change an initial password when logging on to the system component for the first time. \n- An initial password loses its validity after a maximum of 14 days. \n- When creating passwords, compliance with the password specifications (cf. idm-09) is enforced as far as technically possible. \n- The user is informed about changing or resetting the password. \n- The server-side storage takes place using cryptographically strong hash functions. \n- Deviations are evaluated by means of a risk analysis and mitigating measures derived from this are implemented. \n\nAdditional criterion: \nThe users sign a declaration in which they assure that they treat personal (or shared) authentication information confidentially and keep it exclusively for themselves (within the members of the group). \n\nSupplementary information about the criterion: \nArgon2i, for example, is suitable for using a password hash function. Insofar as this is legally binding, declarations can be signed using an electronic signature. \n\nComplementary customer criterion: \nNotes on continuous auditing feasibility: Yes, if the implementation is enforced by appropriate system configuration (automated control), the status or the last change of the configuration can be checked regularly.",
          "Asset management (am). Asset classification and labelling. Basic criterion: Assets are classified and, if possible, labeled. The classification and labeling of an asset reflect the protection needs of the information it processes, stores, or transmits. The need for protection is determined by the individuals or groups responsible for the assets of the cloud service provider, according to a uniform schema. The schema provides levels of protection for the confidentiality, integrity, availability, and authenticity protection objectives. \n\nAdditional criterion: Logging and monitoring applications take the asset protection needs into account in order to inform the responsible stakeholder of events that could lead to a violation of the protection goals, so that the necessary measures are taken with an appropriate priority. Actions for events on assets with a higher level of protection take precedence over events on assets with a lower need for protection. \n\nSupplementary information about the criterion: If the cloud service provider does not make a differentiated classification of the assets, all assets are to be assigned to the highest defined protection requirement. \n\nComplementary customer criterion: Cloud customers can use appropriate controls to ensure that the need for protection of the information that can be processed or stored with the cloud service is adequately determined. Cloud customers can also use appropriate controls to ensure that the information processed or stored with the cloud service is protected against tampering, copying, modifying, redirecting, or deleting in accordance with its protection needs. \n\nNotes on continuous auditing feasibility: Yes, the classification of the assets and the determination of the need for protection should take place during the initial acquisition of the assets. Thus, the classification should also be documented in an asset management tool. The determination of the protection requirement can also be carried out in a standardized form and stored digitally. If there are changes in the classification, these should also be recorded in logs. The auditor can then automatically test whether all assets on the platform are classified and whether the classification was determined using a standardized format. For changes in the classification, it can be automatically reconstructed whether these were also carried out based on the uniform schema. For this purpose, the logs produced can be evaluated as part of a continuous audit. \n\n5.5 Physical Security (PS) \n\nObjective: Prevent unauthorized physical access and protect against theft, damage, loss, and outage of operations.",
          "Operations (ops). Capacity management – planning. Basic criterion: The planning of capacities and resources (personnel and IT resources) follows an established procedure in order to avoid possible capacity bottlenecks. The procedures include forecasting future capacity requirements to identify usage trends and manage system overload. Cloud service providers take appropriate measures to ensure they continue to meet the requirements agreed with cloud customers for the provision of the cloud service in the event of capacity bottlenecks or outages, particularly those related to the dedicated use of system components, in accordance with the respective agreements.\n\nAdditional criterion: The forecasts are considered in accordance with the service level agreement for planning and preparing the provisioning.\n\nSupplementary information about the criterion: For economic reasons, cloud service providers typically strive for high utilization of IT resources (CPU, RAM, storage space, network). In multi-tenant environments, existing resources must still be shared between cloud users (clients) in a way that adheres to service level agreements. Proper planning and monitoring of IT resources are critical to the availability and competitiveness of the cloud service. If the procedures are not documented or are subject to a higher degree of confidentiality as a trade secret of the cloud service provider, the cloud service provider must be able to explain the procedures at least orally within the scope of this audit. Cloud customers must use appropriate controls to ensure that the capacity and resource requirements to be covered by the cloud service provider are planned and reflected in the SLA with the cloud service provider. The requirements can also be reviewed regularly through appropriate controls, and the SLA can be adjusted accordingly.\n\nComplementary customer criterion notes on continuous auditing feasibility: No. An audit of the planning of capacities and resources requires an assessment of the plausibility or meaningfulness of the content. At present, this can hardly be audited automatically and continuously.",
          "Procurement, development and modification of information systems (dev). Version control. Basic criterion: Version control procedures are set up to track dependencies of individual changes and to restore affected system components back to their previous state as a result of errors or identified vulnerabilities. \n\nAdditional criterion: Version control procedures provide appropriate safeguards to ensure that the integrity and availability of cloud customer data is not compromised when system components are restored back to their previous state. \n\nSupplementary information about the criterion: \n\nComplementary customer criterion notes on continuous auditing feasibility: Yes, the procedures for version control of the cloud service provider, and if necessary, resetting to previous states can be automated. This must be documented in logs. An automatic evaluation of these logs makes continuous auditing possible.",
          "Operations (ops). Testing and documentation of known vulnerabilities. Basic criterion: System components in the area of responsibility of the cloud service provider for the provision of the cloud service are automatically checked for known vulnerabilities at least once a month in accordance with the policies for handling vulnerabilities (cf. ops-18). The severity is assessed in accordance with defined criteria, and measures for timely remediation or mitigation are initiated within defined time windows. \n\nAdditional criterion: Available security patches are applied depending on the severity of the vulnerabilities, as determined based on the latest version of the Common Vulnerability Scoring System (CVSS): \n- Critical (CVSS = 9.0 – 10.0): 3 hours.\n- High (CVSS = 7.0 – 8.9): 3 days.\n- Average (CVSS = 4.0 – 6.9): 1 month.\n- Low (CVSS = 0.1 – 3.9): 3 months. \n\nSupplementary information about the criterion: \nIn contrast to penetration tests (cf. ops-20), which are carried out manually and according to an individual scheme, the check for open vulnerabilities is performed automatically, using so-called vulnerability scanners. \n\nComplementary customer criterion: \nCloud customers ensure through suitable controls that system components under their responsibility are regularly checked for vulnerabilities and mitigated by appropriate measures. \n\nNotes on continuous auditing feasibility: \nYes, the periodic check for vulnerabilities and the corresponding results, as well as the analysis and remediation of identified vulnerabilities, are documented by the cloud service provider. An automated and continuous audit of this procedure can be implemented by the auditor by automatically evaluating the documented results.",
          "Personnel (hr). Employment terms and conditions. Basic criterion: The cloud service provider's internal and external employees are required, by the employment terms and conditions, to comply with applicable policies and instructions relating to information security. The information security policy, and the policies and instructions based on it, must be acknowledged by the internal and external personnel in a documented form before access is granted to any cloud customer data or system components under the responsibility of the cloud service provider, used to provide the cloud service in the production environment.\n\nAdditional criterion: Supplementary information about the criterion. The cloud service provider ensures that the policies and instructions reflect applicable legal and regulatory requirements in accordance with SP-01.\n\nComplementary customer criterion: Notes on continuous auditing feasibility. Yes, due to the obligation of employees to comply with certain requirements, a continuous audit is not practical. Compliance with the requirements can be verified as part of a standard audit cycle. A continuous audit of the granting of access, only after acknowledgement of the instructions, is achievable as long as the cloud service provider designs the approval system to document the appropriate data (e.g., date of acknowledgement, which data the employee had access to and when). A clear definition and differentiation of customer data, as well as data in the productive environment, is essential. With the help of this data, the auditor can perform a comparison and detect deviations accordingly. The data could be monitored using an agent on a monitoring system.",
          "Physical security (ps). Perimeter protection. Basic criterion: The structural shell of premises and buildings related to the cloud service provided are physically solid and protected by adequate security measures that meet the security requirements of the cloud service provider (cf. PS-01 Security Concept). The security measures are designed to detect and prevent unauthorized access so that the information security of the cloud service is not compromised. The outer doors, windows, and other construction elements exhibit an appropriate security level and withstand a burglary attempt for at least 10 minutes. The surrounding wall constructions as well as the locking mechanisms meet the associated requirements.\n\nAdditional criterion: The security measures installed at the site include permanently present security personnel (at least 2 individuals), video surveillance, and anti-burglary systems. Supplementary information about the criterion security measures for detecting unauthorized access can be security personnel, video surveillance, or burglar alarm systems. \n\nThe resistance class RC4 according to DIN EN 1627 stipulates that doors, windows, and other components must withstand a break-in attempt for at least 10 minutes. The US standard SD-STD-01.01 Rev.G. is an international equivalent to this standard.\n\nComplementary customer criterion notes on continuous auditing feasibility: \n\nPartially, a continuous inspection of the structural shell of buildings is only partially feasible. Only the protection against unauthorized access can provide evaluable data in the form of access logs that are stored.",
          "Organisation of information security (ois). Interfaces and dependencies. Basic criterion: Interfaces and dependencies between cloud service delivery activities performed by the cloud service provider and activities performed by third parties are documented and communicated. This includes dealing with the following events: vulnerabilities, security incidents, and malfunctions. The type and scope of the documentation is geared towards the information requirements of the subject matter experts of the affected organizations in order to carry out the activities appropriately (e.g., definition of roles and responsibilities in guidelines, description of cooperation obligations in service descriptions and contracts). The communication of changes to the interfaces and dependencies takes place in a timely manner so that the affected organizations and third parties can react appropriately with organizational and technical measures before the changes take effect.\n\nAdditional criterion: Supplementary information about the criterion. The cloud service provider can define and document the interfaces and dependencies described in the basic criterion in guidelines and instructions. For example, cloud customers’ obligations to cooperate should be described in service descriptions and contracts. \n\nThird parties in the sense of this basic criterion are, e.g., cloud customers and sub-service providers.\n\nComplementary customer criterion: Cloud customers ensure through suitable controls that the guidelines and requirements for compliance with the contractual agreements with the cloud service provider (i.e., responsibilities, cooperation obligations, and interfaces for reporting security incidents) are adequately defined, documented, and set up.\n\nNotes on continuous auditing feasibility: No, an automated continuous audit for critical dependencies and interfaces is currently only possible at a high cost to the cloud service provider.",
          "Security incident management (sim). Processing of security incidents. Basic criterion: Subject matter experts of the cloud service provider, together with external security providers where appropriate, classify, prioritize, and perform root-cause analyses for events that could constitute a security incident.\n\nAdditional criterion: The cloud service provider simulates the identification, analysis, and defense of security incidents and attacks at least once a year through appropriate tests and exercises (e.g. red team training).\n\nSupplementary information about the criterion: Complementary customer criterion notes on continuous auditing feasibility: Yes, the cloud service provider documents all security incidents in digital form, which contains information about the classification, prioritization, and root cause analysis of the incidents. The root cause analysis should be standardized to facilitate continuous auditing. An automatic and continuous evaluation of these security incidents can then be carried out by the auditor by excluding the logs or tickets produced and testing whether the security incident has been classified and prioritized and whether these steps have been carried out based on a standardized root cause analysis. The continuous audit thus provides a constant statement as to whether security incidents have been correctly recorded, classified, and subjected to a root cause analysis.",
          "Compliance (com). Internal audits of the information security management system. Basic criterion: Subject matter experts check the compliance of the Information Security Management System at regular intervals, at least annually, with the relevant and applicable legal, regulatory, self-imposed, or contractual requirements (cf. com-01) as well as compliance with the policies and instructions (cf. sp-01) within their scope of responsibility (cf. ois-01) through internal audits. Identified vulnerabilities and deviations are subject to risk assessment in accordance with the risk management procedure (cf. ois-06), and follow-up measures are defined and tracked (cf. ops-18). Additional criterion: Internal audits are supplemented by procedures to automatically monitor applicable requirements of policies and instructions with regard to the following aspects: configuration of system components to provide the cloud service within the cloud service provider's area of responsibility; performance and availability of these system components; response time to malfunctions and security incidents; recovery time (time to completion of error handling). Identified vulnerabilities and deviations are automatically reported to the appropriate cloud service provider's subject matter experts for immediate assessment and action. Cloud customers can view compliance with selected contractual requirements in real-time. Supplementary information about the criterion: Subject matter experts operate, e.g., in the cloud service provider's internal revision department or expert third parties commissioned by the cloud service provider, such as auditing companies, and may hold relevant certifications such as \"Certified Internal Auditor (CIA)\". With regard to ISMS compliance, see Section 9.2 of ISO/IEC 27001. Complementary customer criterion notes on continuous auditing feasibility: Yes, the regular performance of an internal audit of the ISMS can be set up as part of compliance monitoring. For this purpose, the results of the internal audit must be digitally documented, as well as the individual audit steps. A continuous audit of this internal audit is not effective but can only be considered after compliance monitoring has been set up. The continuous audit can then supply the date of the last audit as the output value.",
          "Product safety and security (pss). Guidelines and recommendations for cloud customers. Basic criterion: The cloud service provider provides cloud customers with guidelines and recommendations for the secure use of the cloud service provided. The information contained therein is intended to assist the cloud customer in the secure configuration, installation, and use of the cloud service, to the extent applicable to the cloud service and the responsibility of the cloud user. The type and scope of the information provided will be based on the needs of subject matter experts of the cloud customers who set information security requirements, implement them, or verify the implementation (e.g. IT, compliance, internal audit). The information in the guidelines and recommendations for the secure use of the cloud service addresses the following aspects, where applicable to the cloud service: instructions for secure configuration; information sources on known vulnerabilities and update mechanisms; error handling and logging mechanisms; authentication mechanisms; roles and rights concept including combinations that result in an elevated risk; and services and functions for administration of the cloud service by privileged users. The information is maintained so that it is applicable to the cloud service provided in the version intended for productive use.\n\nAdditional criterion: Supplementary information about the criterion complementary customer criterion cloud customers ensure through suitable controls that the cloud service provider's information is used to derive policies, concepts, and measures for the secure configuration and use (according to their own risk assessment) of the cloud service. Compliance with these policies, concepts, and measures is checked. Changes to the information are promptly assessed for their impact on these documents, and any necessary changes are implemented.\n\nNotes on continuous auditing feasibility: Partially, the provision of information from the cloud service provider to cloud customers can only be audited continuously to a limited extent. For example, the cloud service provider can make the guidelines and recommendations available via its internal customer portal, which makes continuous audit only partially effective. Here, only an audit for completeness and the last modification date is conceivable, although a discussion of the content of the changes is not effective. For this, a semantic evaluation would be necessary.",
          "Personnel (hr). Disciplinary measures. Basic criterion: In the event of violations of policies and instructions or applicable legal and regulatory requirements, actions are taken in accordance with a defined policy that includes the following aspects: verifying whether a violation has occurred; and consideration of the nature and severity of the violation and its impact. The internal and external employees of the cloud service provider are informed about possible disciplinary measures. The use of disciplinary measures is appropriately documented.\n\nAdditional criterion: Supplementary information about the criterion. The cloud service provider ensures that the policies and instructions reflect applicable legal and regulatory requirements in accordance with SP-01.\n\nComplementary customer criterion: Notes on continuous auditing feasibility: No continuous audit is not practical, as the associated processes and steps can be tested once within a recurring audit. A system-based definition of the violations as well as the corresponding regulations does not appear practical, since in this context individual case decisions are often necessary which cannot be covered by predefined algorithms.",
          "Procurement, development and modification of information systems (dev). Testing changes. Basic criterion: Changes to the cloud service are subject to appropriate testing during software development and deployment. The type and scope of the tests correspond to the risk assessment. The tests are carried out by appropriately qualified personnel of the cloud service provider or by automated test procedures that comply with the state-of-the-art. Cloud customers are involved in the tests in accordance with the contractual requirements. The severity of the errors and vulnerabilities identified in the tests, which are relevant for the deployment decision, is determined according to defined criteria and actions for timely remediation or mitigation are initiated. \n\nAdditional criterion: Supplementary information about the criterion. The errors and vulnerabilities identified in tests can be assessed, for example, according to the Common Vulnerability Scoring System (CVSS). \n\nComplementary customer criterion: Where changes are to be tested by the cloud customers in accordance with the contractual agreements prior to deployment in the production environment, the cloud customers ensure through suitable controls that the tests are performed appropriately to identify errors. In particular, this includes timely execution of the tests by qualified personnel in accordance with the conditions specified by the cloud service provider. \n\nNotes on continuous auditing feasibility: Yes, if the tests are carried out automatically, the execution and associated results can be documented in logs. These logs can then be read continuously by the auditor. Measures for the elimination of identified vulnerabilities can also be documented and carried out in a standardized manner, so that continuous auditing is possible.",
          "Procurement, development and modification of information systems (dev). Risk assessment, categorisation and prioritisation of changes. Basic criterion: In accordance with the applicable policies (cf. dev-03), changes are subjected to a risk assessment with regard to potential effects on the system components concerned and are categorized and prioritized accordingly. Additional criterion: In accordance with the contractual agreements, meaningful information about the occasion, time, duration, type, and scope of the change is submitted to authorized bodies of the cloud customer so that they can carry out their own risk assessment before the change is made available in the production environment. Regardless of the contractual agreements, this is done for changes that have the highest risk category based on their risk assessment. Supplementary information about the criterion: Complementary customer criterion notes on continuous auditing feasibility: Yes, the evaluation of changes in releases can be standardized and automated by the cloud service provider. If this evaluation is carried out in standardized and digital form (tickets/logs), an automated evaluation can be carried out by the auditor.",
          "Procurement, development and modification of information systems (dev). Logging of changes. Basic criterion: System components and tools for source code management and software deployment that are used to make changes to system components of the cloud service in the production environment are subject to a role and rights concept, according to IDM-01, and authorization mechanisms. They must be configured in such a way that all changes are logged and can, therefore, be traced back to the individuals or system components executing them.\n\nAdditional criterion: Supplementary information about the criterion complementary customer criterion notes on continuous auditing feasibility: Yes, the changes to the role and rights concept according to IDM-01 are documented in logs by the cloud service provider. Thus, an automatic and continuous evaluation of these logs can be carried out. Irregularities are detected and logged. The auditor can perform a continuous audit by automatically evaluating the logs and logged irregularities.",
          "Asset management (am). Decommissioning of hardware. Basic criterion: The decommissioning of hardware used to operate system components supporting the cloud service production environment, under the responsibility of the cloud service provider, requires approval based on the applicable policies. The decommissioning includes the complete and permanent deletion of the data or proper destruction of the media.\n\nAdditional criterion: Supplementary information about the criterion: The deletion of data or physical destruction of data mediums can take place, for example, according to DIN 66399 or BSI IT-Grundschutz Module Con.6.\n\nComplementary customer criterion: \n\nNotes on continuous auditing feasibility: Yes, the approval of the decommissioning of hardware by authorized personnel or system components must be digitally documented to allow continuous testing. A ticketing system, for example, is suitable for this purpose. Both the instance and the verification of the complete deletion of the data must be stored in the respective ticket. This enables the auditor to check the tickets in an automated procedure. This requires an automated comparison of the authorized instance against a database containing all potential approvers. In addition, the deletion of the data documented in the ticket must be audited automatically. The compliant use of the assets can be ensured via an agent system which checks active assets. The status of this system can then be queried by the auditor for a continuous audit.",
          "Operations (ops). Separation of datasets in the cloud infrastructure. Basic criterion: Cloud customer data stored and processed on shared virtual and physical resources is securely and strictly separated according to a documented approach based on OIS-07 risk analysis to ensure the confidentiality and integrity of this data. \n\nAdditional criterion: Resources in the storage network are segmented by secure zoning (LUN binding and LUN masking). Supplementary information about the criterion shared resources include memory, cores, and storage networks. \n\nTechnical segregation (separation) of the stored and processed data of cloud customers into shared resources can be achieved through firewalls, access lists, tagging, VLANs, virtualization, and measures in the storage network (e.g., LUN binding and LUN masking). \n\nWhere the adequacy and effectiveness of segregation cannot be assessed with reasonable assurance (e.g., due to complex implementation), evidence may also be provided through expert third-party review results (e.g., penetration tests to validate the concept). \n\nThe segregation of transmitted data is subject to control COS-06. \n\nComplementary customer criterion: Cloud customers ensure through suitable controls that the functions provided by the cloud service for segregating shared virtual and physical resources are used in such a way that risks related to segregation are adequately addressed according to the data's protection requirements. \n\nNotes on continuous auditing feasibility: Partially, the segregation according to a documented concept is implemented by means of a configuration that does not change with high frequency. A continuous audit of this configuration could check whether the configuration and thus the segregation of the data is implemented correctly. However, the effort for a continuous audit would be high, and the benefit limited due to the low change rate of the configuration. Thus, a continuous audit would only be of limited use here. If compliance with the measures taken is monitored, this criterion can be audited automatically. It would also be conceivable to continuously audit the actual data segregation. For this purpose, the cloud service provider would have to set up appropriate agents to monitor the data flow between the customer instances (or its absence) on a permanent and documented basis (logs). \n\n5.7 Identity and Access Management (IDM) \n\nObjective: Secure the authorization and authentication of users of the cloud service provider (typically privileged users) to prevent unauthorized access.",
          "Organisation of information security (ois). Segregation of duties. Basic criterion: Conflicting tasks and responsibilities are separated based on an OIS-06 risk assessment to reduce the risk of unauthorized or unintended changes or misuse of cloud customer data processed, stored, or transmitted in the cloud service. The risk assessment covers the following areas, insofar as these are applicable to the provision of the cloud service and are in the area of responsibility of the cloud service provider: \n\nAdministration of rights profiles, approval and assignment of access and access authorizations (cf. IDM-01)\nDevelopment, testing, and release of changes (cf. DEV-01)\nOperation of the system components. \n\nIf separation cannot be established for organizational or technical reasons, measures are in place to monitor the activities in order to detect unauthorized or unintended changes as well as misuse and to take appropriate actions. \n\nAdditional criterion: \n\nSupplementary information about the criterion identified events that may constitute unauthorized or unintentional changes to or misuse of cloud customer data may, for example, be treated as a security incident (cf. SIM-01). \n\nComplementary customer criterion: \n\nNotes on continuous auditing feasibility: \n\nYes, continuous audit is possible, especially in the case of changes to role profiles and responsibilities. This would require an initial check of the defined roles and responsibilities by the cloud service provider. The roles that are added or changed on a monthly basis could then be automated and continuously checked.",
          "Product safety and security (pss). Online register of known vulnerabilities. Basic criteria: The cloud service provider operates or refers to a daily updated online register of known vulnerabilities that affect the cloud service provider and assets provided by the cloud service provider that the cloud customers have to install, provide, or operate themselves under the customers' responsibility. The presentation of the vulnerabilities follows the common vulnerability scoring system (CVSS). The online register is easily accessible to any cloud customer. The information contained therein forms a suitable basis for risk assessment and possible follow-up measures on the part of cloud users. For each vulnerability, it is indicated whether software updates (e.g., patch, update) are available, when they will be rolled out, and whether they will be deployed by the cloud service provider, the cloud customer, or both of them together. \n\nAdditional criteria: Assets provided by the cloud service provider, which must be installed, provided, or operated by cloud users within their area of responsibility, are equipped with automatic update mechanisms. After approval by the respective cloud user, software updates can be rolled out in such a way that they can be distributed to all affected users without human interaction. Supplementary information about the criteria assets provided by the cloud service provider that cloud customers have to install, deploy, or operate themselves in their area of responsibility are, for example, local software clients and apps as well as tools for integrating the cloud service. If the cloud service relies on other cloud services, this registry has to incorporate or refer to the vulnerabilities of those other cloud services in order for this criterion to be met. \n\nComplementary customer criteria: Cloud customers ensure through suitable controls that the information in this register is incorporated sufficiently quickly into their own risk management, evaluated, and if necessary, taken into account in their own area of responsibility. \n\nNotes on continuous auditing feasibility: Yes, a continuous audit includes, above all, whether the information is updated daily. The distribution of software updates must be documented by the cloud service provider (logs). This documentation can then be automatically and continuously evaluated by the auditor to ensure that the software used on assets in the cloud users’ area of responsibility is up-to-date.",
          "Product safety and security (pss). Identification of vulnerabilities of the cloud service. Basic criterion: The cloud service provider applies appropriate measures to check the cloud service for vulnerabilities that might have been integrated into the cloud service during the software development process. The procedures for identifying such vulnerabilities are part of the software development process and, depending on a risk assessment, include the following activities: static application security testing; dynamic application security testing; code reviews by the cloud service provider’s subject matter experts; and obtaining information about confirmed vulnerabilities in software libraries provided by third parties and used in their own cloud service. The severity of identified vulnerabilities is assessed according to defined criteria, and measures are taken to immediately eliminate or mitigate them.\n\nAdditional criterion: The procedures for identifying such vulnerabilities also include annual code reviews or security penetration tests by qualified external third parties.\n\nSupplementary information about the criterion: Known vulnerabilities in externally related system components (e.g., operating systems) used for the development and provision of the cloud service but not going through the cloud service provider’s software development process are the subject of Criteria OPS-23 (Management of vulnerabilities, malfunctions, and errors – open vulnerability assessment).\n\nComplementary customer criterion: Notes on continuous auditing feasibility: Yes, the cloud service provider automatically checks its cloud services for vulnerabilities. This check is documented in a standardized digital form. By auditing this documentation, the auditor verifies whether the cloud service provider has performed a vulnerability scan. In addition, the severity of the identified vulnerabilities can be integrated into this continuous audit if the defined criteria and their application are standardized and machine-readable. The information on identified and/or repaired vulnerabilities can also be transferred directly to the affected customer, increasing transparency.",
          "Security incident management (sim). Duty of the users to report security incidents to a central body. Basic criterion: The cloud service provider informs employees and external business partners of their obligations. If necessary, they agree to, or are contractually obliged to, report all security events that become known to them and are directly related to the cloud service provided by the cloud service provider to a previously designated central office of the cloud service provider promptly. In addition, the cloud service provider communicates that \"false reports\" of events that do not subsequently turn out to be incidents do not have any negative consequences.\n\nAdditional criterion: Supplementary information about the criterion complementary customer criterion cloud customers ensure, through suitable controls, that identified security events which the cloud service provider is required to process are communicated promptly to previously designated responsible personnel. The identification of such security events is supported by suitable controls (cf. complementary criterion for ops-10).\n\nNotes on continuous auditing feasibility: Partially, the cloud service provider should inform its employees and external business partners about their obligations in a standardized and digital format. This obligation usually occurs when the employee joins the company or the business relationship. This enables the auditor to automatically and continuously audit whether all employees and external business partners are notified of their obligations by automatically testing whether the clause, if any, is included in the contract when the contract is signed.",
          "Control and monitoring of service providers and suppliers (sso). Exit strategy for the receipt of benefits. Basic criterion: The cloud service provider has defined and documented exit strategies for the purchase of services where the risk assessment of the service providers and suppliers regarding the scope, complexity, and uniqueness of the purchased service resulted in a very high dependency (cf. supplementary information). Exit strategies are aligned with operational continuity plans and include the following aspects: analysis of the potential costs, impacts, resources, and timing of the transition of a purchased service to an alternative service provider or supplier; definition and allocation of roles, responsibilities, and sufficient resources to perform the activities for a transition; definition of success criteria for the transition; and definition of indicators for monitoring the performance of services, which should initiate the withdrawal from the service if the results are unacceptable. \n\nAdditional criterion: Supplementary information about the criterion - a very high dependency can be assumed in the following situations, in particular: the purchased service is absolutely required for the provision of the cloud service. This situation is given when the cloud service provider provides the cloud service from data centers operated by third parties and provides a SaaS service and uses the IaaS or PaaS of another cloud service provider. The service cannot be obtained within one month from an alternative service provider or supplier, as: it is unique on the market and no other supplier can deliver it; it is strongly individualized by the service provider or supplier and/or the cloud service provider; it cannot be supplied by any other provider in the required quality of service; and it requires specific knowledge that is only/mainly available to the current service provider or supplier and not to the cloud service provider. \n\nComplementary customer criterion: Notes on continuous auditing feasibility - No, the existence of individual exit strategies is not a practical test item for continuous audit. \n\n5.13 Security Incident Management (SIM) \n\nObjective: Ensure a consistent and comprehensive approach to the capture, assessment, communication, and escalation of security incidents.",
          "Communication security (cos). Policies for data transmission. Basic criterion: Policies and instructions with technical and organizational safeguards are documented, communicated, and provided to protect the transmission of data against unauthorized interception, manipulation, copying, modification, redirection, or destruction. These policies and instructions should reference the classification of information (cf. am-06). \nAdditional criterion: A safeguard against unauthorized interception, manipulation, copying, modification, redirection, or destruction of data during transmission is the use of transport encryption according to cry-02. \nComplementary customer criterion: Cloud customers should ensure, through suitable controls, that the transmitted data to the cloud service is protected against tampering, copying, modifying, redirecting, or deleting based on their protection needs. \nNotes on continuous auditing feasibility: It is not feasible to continuously audit policies as they can change ad-hoc. However, the last change date and status of review or approval can be tested if this information is stored in a system. The content of a policy is difficult to test automatically. \n5.10 Portability and Interoperability (PI) \nObjective: Enable the ability to access the cloud service through other cloud services or IT systems of the cloud customers, retrieve the stored data at the end of the contractual relationship, and securely delete it from the cloud service provider.",
          "Procurement, development and modification of information systems (dev). Outsourcing of the development. Basic criterion: In the case of outsourced development of the cloud service (or individual system components), specifications regarding the following aspects are contractually agreed between the cloud service provider and the outsourced development contractor: security in software development (requirements, design, implementation, tests and verifications) in accordance with recognized standards and methods; acceptance testing of the quality of the services provided in accordance with the agreed functional and non-functional requirements; and providing evidence that sufficient verifications have been carried out to rule out the existence of known vulnerabilities.\n\nAdditional criterion: Supplementary information about the criterion outsourced development in the sense of the basic criterion: refers to the development of system components used specifically for the cloud service by a contractor of the cloud service provider. The development takes place according to the processes of the contractor. The purchase of software available on the market as well as the integration of external employees into the processes of the cloud service provider do not constitute outsourcing in the sense of this basic criterion.\n\nComplementary customer criterion: Notes on continuous auditing feasibility: No. An outsourced development of a cloud service provider’s cloud services and the associated contract creation and signing will not be performed with high frequency. Changes in contract structures are also rare. Therefore, a continuous audit in these cases is not effective.",
          "Compliance (com). Identification of applicable legal, regulatory, self-imposed or contractual requirements. Basic criterion: The legal, regulatory, self-imposed, and contractual requirements relevant to the information security of the cloud service, as well as the cloud service provider's procedures for complying with these requirements, are explicitly defined and documented.\n\nAdditional criterion: Supplementary information about the criterion. The cloud service provider's documentation may refer to the following requirements, among others: requirements for the protection of personal data (e.g., EU General Data Protection Regulation); compliance requirements based on contractual obligations with cloud customers (e.g., ISO/IEC 27001, SOC 2, PCI-DSS); generally accepted accounting principles (e.g., in accordance with HGB or IFRS); requirements regarding access to data and auditability of digital documents (e.g., according to GDPDU); and other laws (e.g., according to BSIG or AktG).\n\nComplementary customer criterion: Notes on continuous auditing feasibility. No, a continuous audit of contract specifications, regulations, and their documentation does not seem to be effective. In this case, the test within the recurring audit is sufficient. A continuous audit could assist in giving the date of the last audit of the criteria.",
          "Security policies and instructions (sp). Exceptions from existing policies and instructions. Basic Criterion: Exceptions to the policies and instructions for information security, as well as respective controls, go through the OIS-06 risk management process. This includes the approval of these exceptions and the acceptance of the associated risks by the risk owners. The approvals of exceptions are documented, limited in time, and reviewed for appropriateness at least annually by the risk owners.\n\nAdditional Criterion: Supplementary information about the criterion exceptions, in the sense of the basic criterion, can have organizational or technical causes. For example, an organizational unit may need to deviate from the intended processes and procedures to meet the requirements of a cloud customer. Additionally, a system component may lack technical properties to configure it according to the applicable requirements. Cloud customers can use appropriate controls to ensure that they obtain information from the cloud service provider about deviations from information security policies and instructions. This allows them to assess and appropriately manage the associated risks to their own information security.\n\nComplementary Customer Criterion: Notes on continuous auditing feasibility: Partially, exceptions to policies and instructions are to be reviewed annually. However, the continuous audit of these exceptions is only partially feasible, as the only attributes that can be tested are the last change date and the status or review or approval, as far as this information is stored in a system. The content of an exception can hardly be tested automatically.\n\n5.3 Personnel (HR) Objective: Ensure that employees understand their responsibilities, are aware of their responsibilities with regard to information security, and that the organization's assets are protected in the event of changes in responsibilities or termination.",
          "Product safety and security (pss). Roles and rights concept. Basic criterion: The cloud service provider provides cloud users with a roles and rights concept for managing access rights. It describes rights profiles for the functions provided by the cloud service. The rights profiles are suitable for enabling cloud users to manage access authorizations and permissions in accordance with the principle of least privilege and how it is necessary for the performance of tasks (\"need-to-know principle\") and to implement the principle of functional separation between operational and controlling functions (\"separation of duties\").\n\nAdditional criterion: Supplementary information about the criterion. In IaaS, a role and rights concept would describe, among other things, the rights profiles for the following functions of the cloud service: \n\n- Administration of the states of virtual machines (start, pause, stop) as well as for their migration or monitoring; \n- Management of available images that can be used to create virtual machines; \n- Management of virtual networks (e.g., configuration of virtual routers and switches). \n\nComplementary customer criterion: Cloud customers ensure through suitable controls that: \n\n- The granting of permissions to users in their area of responsibility is subject to authorization; \n- The appropriateness of the assigned authorizations is regularly reviewed and authorizations are adjusted or withdrawn in a timely manner in the event of necessary changes (e.g., employee resignation). \n\nNotes on continuous auditing feasibility: Partially, the existence of a roles and rights concept in the form of a configuration in the system can be monitored. However, it should be noted that, regarding the content of this concept, only deviations from target configurations can be checked. Whether these deviations are desired or not must still be recorded in a manual audit.",
          "Operations (ops). Logging and monitoring – storage of the logging data. Basic criterion: The cloud service provider retains the generated log data and keeps them in an appropriate, unchangeable, and aggregated form, regardless of the source of such data, so that a central, authorized evaluation of the data is possible. Log data is deleted if it is no longer required for the purpose for which they were collected. Between logging servers and the assets to be logged, authentication takes place to protect the integrity and authenticity of the information transmitted and stored. The transfer takes place using state-of-the-art encryption or a dedicated administration network (out-of-band management).\n\nAdditional criterion: The cloud service provider provides customer-specific logging (in terms of scope and duration of retention period) upon the request of the cloud customer. Depending on the protection requirements of the cloud service provider and the technical feasibility, a logical or physical separation of log and customer data is carried out.\n\nSupplementary information about the criterion:\nComplementary customer criterion\nNotes on continuous auditing feasibility: Yes, the storage of logging data at a central location can be documented by logs when the data is saved. The deletion of this data can also be automated and documented by logs. The auditor can then perform an automated and continuous evaluation of these logs.",
          "Operations (ops). Capacity management – monitoring. Basic criterion: Technical and organizational safeguards for the monitoring and provisioning and de-provisioning of cloud services are defined. Thus, the cloud service provider ensures that resources are provided and/or services are rendered according to the contractual agreements and that compliance with the service level agreements is ensured. \n\nAdditional criterion: To monitor capacity and availability, the relevant information is available to the cloud customer in a self-service portal. \n\nSupplementary information about the criterion: Technical and organizational measures typically include the use of monitoring tools with an alarm function when defined threshold values are exceeded, a process for correlating events and an interface to incident management, continuous monitoring of the systems by qualified personnel, and redundancies in the IT systems. \n\nComplementary customer criterion: Cloud customers ensure through suitable controls that the contractual agreements made with the cloud service provider for the provision of resources or services can be monitored. In case of deviations, appropriate controls ensure that the cloud service provider is informed so that the cloud service provider can take appropriate action. \n\nNotes on continuous auditing feasibility: Yes, the part of resource monitoring can be continuously audited by checking capacity forecasts and monitoring the resource management tool. Furthermore, the logs of provisioning and de-provisioning and their impact on resource management can be continuously audited by the changes in resource management.",
          "Operations (ops). Managing vulnerabilities, malfunctions and errors – measurements, analyses and assessments of procedures. Basic criterion: The cloud service provider regularly measures, analyzes, and assesses the procedures with which vulnerabilities and incidents are handled to verify their continued suitability, appropriateness, and effectiveness. Results are evaluated at least quarterly by accountable departments at the cloud service provider to initiate continuous improvement actions and to verify their effectiveness. \n\nAdditional criterion: Supplementary information about the criterion includes common vulnerabilities and exposures (CVE) or similar methods that are suitable for documenting vulnerabilities and incidents. \n\nComplementary customer criterion: Notes on continuous auditing feasibility - Yes, the measurements, analyses, and evaluations are based on data that could be continuously queried in order to verify the plausibility of the results derived from them. The initiation and review of measures for continuous improvement require a manual audit.",
          "Organisation of information security (ois). Information security management system (isms). Basic criterion: The cloud service provider operates an Information Security Management System (ISMS) in accordance with ISO/IEC 27001. The scope of the ISMS covers the cloud service provider's organizational units, locations, and procedures for providing the cloud service. The measures for setting up, implementing, maintaining, and continuously improving the ISMS are documented. The documentation includes: scope of the ISMS (Section 4.3 of ISO/IEC 27001), declaration of applicability (Section 6.1.3), and results of the last management review (Section 9.3).\n\nAdditional criterion: The Information Security Management System (ISMS) has a valid certification according to ISO/IEC 27001 or ISO 27001 based on IT-Grundschutz.\n\nSupplementary information about the criterion: The basic criterion can also be fulfilled without a valid certification of the ISMS according to ISO/IEC 27001 or ISO 27001 based on IT-Grundschutz if the submitted documentation meets the requirements of ISO/IEC 27001.\n\nComplementary customer criterion: Notes on continuous auditing feasibility: Partially, a continuous audit of the ISO 27001 certificate is partially feasible because the existence of a certificate can be continuously verified through the creation date of the certificate and passing an authenticity check. However, the certificate is usually issued for three years, and there will be no dynamic changes as a rule.",
          "Communication security (cos). Networks for administration. Basic criterion: There are separate networks for the administrative management of the infrastructure and for the operation of management consoles. These networks are logically or physically separated from the cloud customer's network and protected from unauthorized access by multi-factor authentication (cf. idm-09). Networks used by the cloud service provider to migrate or create virtual machines are also physically or logically separated from other networks.\n\nAdditional criterion: Supplementary information about the criterion complementary customer criterion notes on continuous auditing feasibility: No, a continuous audit is not practical since infrastructure components and the logical and physical separation of the networks are implemented initially. A continuous audit of these components may require a system status, but it is difficult to test all aspects continuously.",
          "Security policies and instructions (sp). Review and approval of policies and instructions. Basic criterion: Information security policies and instructions are reviewed at least annually for adequacy by the cloud service provider's subject matter experts. The review shall consider at least the following aspects: organizational and technical changes in the procedures for providing the cloud service and legal and regulatory changes in the cloud service provider's environment. Revised policies and instructions are approved before they become effective.\n\nAdditional Criterion:\nSupplementary information about the criterion:\nComplementary customer criterion notes on continuous auditing feasibility:\nPartially, a continuous automated audit of the content changes to policies and instructions is only partially practicable at the current state-of-the-art. A continuous audit of the reviewers' authorization and expertise does not appear to be effective either, as this cannot be linked to specified parameters of an automated evaluation. A continuous examination of this criterion could therefore only consist of returning the date of the last examination.",
          "Identity and access management (idm). Withdraw or adjust access rights as the task area changes. Basic criterion: Access rights are promptly revoked if the job responsibilities of the cloud service provider's internal or external staff or the tasks of system components involved in the cloud service provider's automated authorization processes change. Privileged access rights are adjusted or revoked within 48 hours after the change taking effect. All other access rights are adjusted or revoked within 14 days. After revocation, the procedure for granting user accounts and access rights (cf. idm-02) must be repeated. \n\nAdditional criterion: Supplementary information about the criterion changes in the task area of internal and external employees can be triggered by changes in the employment relationship (e.g., termination, transfer) or in contracts and agreements. For privileged access rights, the definition in idm-06 applies. \n\nComplementary customer criterion: \nNotes on continuous auditing feasibility: Yes, it is necessary to record the changes to the task area in terms of content together with the date of entry into force in order to compare these with the adjustments made to the access rights. A continuous audit seems possible but requires a great deal of effort to implement.",
          "Communication security (cos). Segregation of data traffic in jointly used network environments. Basic criterion: Data traffic of cloud customers in jointly used network environments is segregated on network level according to a documented concept to ensure the confidentiality and integrity of the data transmitted. \nAdditional criterion: In the case of IaaS/PaaS, secure segregation is ensured by physically separated networks or by means of strongly encrypted VLANs. For the definition of strong encryption, the BSI technical guideline TR-02102 must be considered. \nSupplementary information about the criterion: If the suitability and effectiveness of the logical segmentation cannot be assessed with sufficient certainty (e.g. due to a complex implementation), evidence can also be provided based on audit results of expert third parties (e.g. security audits to validate the concept). The segregation of stored and processed data is subject to the criterion OPS-24. After successful authentication via an insecure communication channel (HTTP), a secure communication channel (HTTPS) is to be used. \nWith IaaS/PaaS, secure segregation is ensured by physically separated networks or strong encryption of the networks. For the definition of strong encryption, the BSI technical guideline TR-02102 must be considered (cf. CRY-01). \nIf the cloud service provider does not use shared network environments for cloud customers and instead uses a physical segregation, the basic criterion is not applicable. \nComplementary customer criterion: Through suitable controls, cloud customers ensure that, for parts of the cloud service under their responsibility, virtual networks are designed, configured, and documented in accordance with their network security requirements (e.g. logical segmentation of organizational units). \nNotes on continuous auditing feasibility: No. The logical segregation of cloud customer network traffic at the network level is centrally configured and rarely changed. Thus, a continuous audit is not beneficial since no highly frequented automated query can be performed to support the continuous audit.",
          "Product safety and security (pss). Confidentiality of authentication information. Basic criterion: If passwords are used as authentication information for the cloud service, their confidentiality is ensured by the following procedures: \n- Users can initially create the password themselves or must change an initial password when logging into the cloud service for the first time.\n- An initial password loses its validity after a maximum of 14 days.\n- When creating passwords, compliance with the length and complexity requirements of the cloud service provider (cf. idm-09) or the cloud customer is technically enforced.\n- The user is informed about changing or resetting the password.\n- The server-side storage takes place using state-of-the-art cryptographically strong hash functions in combination with at least 32-bit long salt values.\n\nAdditional criterion: Supplementary information about the criterion: \n- The state-of-the-art regarding cryptographically strong hash functions is described in the current version of the BSI Technical Guideline TR-02102-1 \"Cryptographic Mechanisms: Recommendations and Key Lengths\".\n- In version 2019-01 of this guideline, these were: SHA-256, SHA-512/256, SHA-384, SHA-512; and SHA3-256, SHA3-384, SHA3-512.\n\nComplementary customer criterion: \n- Cloud customers ensure through suitable controls that they use sufficiently secure passwords (cf. idm-09) according to their own assessment and that the risks of unauthorized access associated with their own choice are borne.\n\nNotes on continuous auditing feasibility: \n- No compliance with security policies for password assignment is configured centrally and adjusted at a low frequency.\n- A continuous audit is therefore only of limited use.",
          "Identity and access management (idm). Policy for user accounts and access rights. Basic criterion: A role and rights concept based on the business and security requirements of the cloud service provider, as well as a policy for managing user accounts and access rights for internal and external employees of the cloud service provider, and system components that have a role in automated authorization processes of the cloud service provider, are documented, communicated, and made available. According to SP-01, the following principles are applied: assignment of unique usernames; granting and modifying user accounts and access rights based on the \"least-privilege-principle\" and the \"need-to-know\" principle; segregation of duties between operational and monitoring functions (\"segregation of duties\"); segregation of duties between managing, approving, and assigning user accounts and access rights; approval by authorized individuals or systems for granting or modifying user accounts and access rights before accessing data of the cloud customer or system components used to provision the cloud service; regular review of assigned user accounts and access rights; blocking and removing access accounts in the event of inactivity; time-based or event-driven removal or adjustment of access rights in the event of changes to job responsibilities; two-factor or multi-factor authentication for users with privileged access; and requirements for the approval and documentation of the management of user accounts and access rights. \n\nAdditional criterion: Supplementary information about the criterion and system components in the sense of the basic criterion can be found in the definition in OPS-23. Automated authorization processes in the sense of this basic criterion concern procedures for automated software provisioning (continuous delivery), as well as for automated provisioning and deprovisioning of user accounts and access rights based on approved requests. \n\nComplementary customer criterion: Notes on continuous auditing feasibility: Partially, a policy can change ad-hoc. However, the continuous audit of policies is only partially feasible, as the only attributes that can be tested are the last change date and the status of review or approval, as far as this information is stored in a system. The content of a policy can hardly be tested automatically. The aspects mentioned in the policy can be converted into individual criteria and embedded in a continuous audit. Individual aspects of the policy which can be examined on an ongoing basis include: unique username; segregation of duties; rights profile management (approvals); authorized bodies or individuals; regular review; deactivation due to inactivity; and multi-factor authentication. \n\nApproval and documentation: Individual aspects of the policy which cannot be continuously examined in a practicable manner include: implementation of least-privilege/need-to-know principles; and withdrawal or adjustment of access rights as the task area changes.",
          "Communication security (cos). Cross-network access. Basic criterion: Each network perimeter is controlled by security gateways. The system access authorization for cross-network access is based on a security assessment, considering the requirements of the cloud customers.\n\nAdditional criterion: Each network perimeter is controlled by redundant and highly-available security gateways.\n\nSupplementary information about the criterion: Cross-network access refers to access from one network to another network through a defined network perimeter.\n\nComplementary customer criterion: Cloud customers ensure, through suitable controls, that access to their virtual networks within the cloud service is controlled according to their protection needs. This is achieved by using security gateways on the perimeters of the virtual networks for which they are responsible.\n\nNotes on continuous auditing feasibility: Yes, if the control of the network perimeters is documented (e.g., by logs), these logs can be automatically evaluated. This provides the possibility of a continuous audit for this part of the criterion. If the security evaluation for access authorizations is conducted in a standardized form by the cloud service provider, it can also be automatically evaluated. In such a case, a continuous audit for the second part of the criterion would also be possible.",
          "Operations (ops). Logging and monitoring – configuration. Basic criterion: Access to system components for logging and monitoring in the cloud service provider’s area of responsibility is restricted to authorized users. Changes to the configuration are made in accordance with the applicable policies (cf. dev-03). \n\nAdditional criterion: Access to system components for logging and monitoring in the cloud service provider’s area of responsibility requires two-factor authentication. \n\nSupplementary information about the criterion: \nComplementary customer criterion notes on continuous auditing feasibility: Yes, the continuous audit of this access restriction can be tested by log files of all changes to access rights for the system components for logging and monitoring. Changes can be automatically and continuously audited according to the person’s sense and need for access.",
          "Security incident management (sim). Documentation and reporting of security incidents. Basic criterion: After a security incident has been processed, the solution is documented in accordance with the contractual agreements, and the report is sent to the affected customers for final acknowledgement or, if applicable, as confirmation. \n\nAdditional criterion: The customer can either actively approve solutions, or the solution is automatically approved after a certain period. Information on security incidents or confirmed security breaches is made available to all affected customers. The contract between the cloud service provider and the cloud customer regulates which data is made available to the cloud customer for their own analysis in the event of security incidents. \n\nSupplementary information about the criterion: Complementary customer criterion. Cloud customers ensure through suitable controls that they receive notifications from the cloud service provider about security incidents that affect them and their resolution, and that these notifications are forwarded promptly to the entity responsible for handling them so that an appropriate response can be made. \n\nNotes on continuous auditing feasibility: Yes. In the logs or tickets that document the security incidents (cf. sim-03), the cloud service provider also describes the solution pursued to eliminate the incident. Additionally, the cloud service provider also documents the confirmation to the customer. The auditor can then automatically and continuously read out whether the documented security incidents have been resolved and whether a solution has been documented. The same applies to the communication of the resolution of the incidents to affected customers. If this is not the case, the unresolved security incident can be documented as the output value of the continuous audit.",
          "Identity and access management (idm). Access to cloud customer data. Basic criterion: The cloud customer is informed by the cloud service provider whenever internal or external employees of the cloud service provider read or write to the cloud customer’s data processed, stored, or transmitted in the cloud service or have accessed it without the prior consent of the cloud customer. The information is provided whenever data of the cloud customer is/was not encrypted, the encryption is/was disabled for access, or the contractual agreements do not explicitly exclude such information. The information contains the cause, time, duration, type, and scope of the access. The information is sufficiently detailed to enable subject matter experts of the cloud customer to assess the risks of the access. The information is provided in accordance with the contractual agreements or within 72 hours after the access.\n\nAdditional criterion: Access to the data processed, stored, or transmitted in the cloud service by internal or external employees of the cloud service provider requires the prior consent of an authorized department of the cloud customer, provided that the cloud customer's data is not encrypted, encryption is disabled for access, or contractual agreements do not explicitly exclude such consent. For the consent, the cloud customer's department is provided with meaningful information about the cause, time, duration, type, and scope of the access supporting assessing the risks associated with the access.\n\nSupplementary information about the criterion: Subject matter experts, in the sense of this basic criterion, are personnel from e.g. IT, compliance, or internal audit.\n\nComplementary customer criterion notes on continuous auditing feasibility: Yes, a continuous audit of the notifications carried out only appears practical if the accesses mentioned are also logged and classified automatically. The content of the notifications can only be audited if the content is specified by the cloud service provider according to a specific scheme. Then, a comparison and plausibility check can take place. A continuous audit would test all notifications after they have been received and thus check whether the process has been executed correctly in all cases.",
          "Dealing with investigation requests from government agencies (inq). Limiting access to or disclosure of data in investigation requests. Basic criterion: The cloud service provider's procedures establish access to or disclose data of cloud customers in the context of investigation requests from governmental agencies. These procedures ensure that the agencies only gain access to or insight into the data that is the subject of the investigation request. If clear limitation of the data is not possible, the cloud service provider anonymizes or pseudonymizes the data. This ensures that government agencies can only assign it to those cloud customers who are the subject of the investigation request. \n\nAdditional criterion: Supplementary information about the criterion complementary customer criterion notes on continuous auditing feasibility. Partially, a separate role for the investigator is to be provided (cf. also inq-03). It is conceivable that certain data types for this role may not be visible, pseudonymized or anonymized. Additionally, data of customers that are not part of the investigation may be excluded. However, this requires manual effort in the configuration and assignment of the investigator role. Under these conditions, however, a continuous audit of whether and to what extent the investigator had access to data is conceivable. \n\n5.17 Product Safety and Security (PSS): Objective: Provides up-to-date information on the secure configuration and known vulnerabilities of the cloud service for cloud customers. It also provides appropriate mechanisms for troubleshooting and logging, as well as authentication and authorization of users of cloud customers.",
          "Personnel (hr). Verification of qualification and trustworthiness. Basic criterion: The competency and integrity of all internal and external employees of the cloud service provider with access to cloud customer data or system components under the cloud service provider's responsibility, who are responsible for providing the cloud service in the production environment, shall be verified prior to commencement of employment in accordance with local legislation and regulations by the cloud service provider. To the extent permitted by law, the review will cover the following areas: \n\n- Verification of the person through an identity card. \n- Verification of the CV. \n- Verification of academic titles and degrees. \n- Request for a police clearance certificate for applicants. \n- Certificate of good conduct or national equivalent. \n- Evaluation of the risk of potential blackmail. \n\nAdditional criterion: \nSupplementary information about the criterion: External employees, in the sense of the criteria, are those who perform activities in accordance with the processes and procedures of the cloud service provider. Employees of sub-service providers who perform activities according to their own processes and procedures are not covered by this criterion. The verification of qualification and trustworthiness can be supported by a specialized service provider. Depending on national legislation, national equivalents of the German certificate of good conduct may also be permitted. The assessment of the extent to which a potential employee can be blackmailed can be carried out, for example, by checking their creditworthiness. \n\nComplementary customer criterion notes on continuous auditing feasibility: Partially, continuous auditing is only partially achievable due to complications arising from local deviations in laws and regulations. It would be conceivable to continuously query the process steps stored in the system for each new hire in relation to the specified areas, based on a list of employees maintained in the HR system where new hires are registered. To do this, the cloud service provider would have to go through and document these steps, applying a system-based approach. The auditor could then use an agent or a connected monitoring system to detect any deviations from the standard process.",
          "Operations (ops). Data backup and recovery – storage. Basic criterion: The cloud service provider transfers data to be backed up to a remote location or transports it on backup media to a remote location. If the data backup is transmitted to the remote location via a network, the data backup or the transmission of the data takes place in an encrypted form that corresponds to the state-of-the-art. The distance to the main site is chosen after sufficient consideration of the factors recovery times and impact of disasters on both sites. The physical and environmental security measures at the remote site are at the same level as at the main site.\n\nAdditional criterion:\nSupplementary information about the criterion: If the data backup is not part of the contract concluded between the cloud service provider and the cloud customer, this criterion is not applicable. The cloud service provider must present this situation transparently in the system description.\n\nA remote location can be, for example, another data center of the cloud service provider.\n\nComplementary customer criterion:\nNotes on continuous auditing feasibility: Yes. If the data is transported physically, a continuous audit of this criterion means that the successful storage has been confirmed. In the case of electronic transmission, the log files of the transmission can be continuously evaluated, and the result of this audit can be transmitted.",
          "Organisation of information security (ois). Contact with relevant government agencies and interest groups. Basic criterion: The cloud service provider leverages relevant authorities and interest groups in order to stay informed about current threats and vulnerabilities. The information flows into the procedures for handling risks (cf. OIS-06) and vulnerabilities (cf. OPS-19). \n\nAdditional criterion: If the cloud service is used by public sector organizations in Germany, the cloud service provider leverages contacts with the National IT Situation Centre and the CERT Association of the BSI. \n\nSupplementary information about the criterion: Relevant contacts are, for example, the Federal Office for Information Security (BSI), OWASP Foundation, and CERT networks such as DFN-CERT and TF-CSIRT. \n\nPublic sector organizations in Germany are, for example, authorities and ministries. \n\nComplementary customer criterion notes on continuous auditing feasibility: Yes, a continuous audit of the cloud service provider's contacts with relevant authorities and stakeholders can be achieved by continuously storing relevant information on a monthly basis, such as a list of contacted entities and evidence of receipt of a response. \n\nA continuous flow of information demonstrates a constant connection to relevant authorities and interest groups. Furthermore, the distribution of the information and, if necessary, the documentation of the handling of identified risks and vulnerabilities could be continuously audited for the coverage of this criterion.",
          "Identity and access management (idm). Granting and change of user accounts and access rights. Basic criterion: Specified procedures for granting and modifying user accounts and access rights for internal and external employees of the cloud service provider as well as for system components involved in automated authorization processes of the cloud service provider ensure compliance with the role and rights concept as well as the policy for managing user accounts and access rights.\n\nAdditional criterion: The cloud service provider offers cloud customers a self-service with which they can independently assign and change user accounts and access rights.\n\nSupplementary information about the criterion: Complementary customer criterion notes on continuous auditing feasibility: No. A continuous audit of procedures is strongly dependent on the underlying systematics and automation of the cloud service provider's procedures. This may vary in individual cases, but in general, a continuous audit does not appear to be effective.",
          "Compliance (com). Information on information security performance and management assessment of the isms. Basic criterion: The top management of the cloud service provider is regularly informed about the information security performance within the scope of the ISMS in order to ensure its continued suitability, adequacy, and effectiveness. The information is included in the management review of the ISMS, which is performed at least once a year.\n\nAdditional criterion: Supplementary information about the criterion is that the top management is a natural person or group of people who make final decisions for the institution and are responsible for these. The aspects to be dealt with in the management review of the ISMS are listed in Section 9.3 of ISO/IEC 27001.\n\nComplementary customer criterion: Notes on continuous auditing feasibility - partially, the actual transmission of information to the cloud service provider's management can be logged and automated. However, the testing of the contents of the communication and the fact that these have also been included in the management assessment must still be carried out within the regular audit.\n\n5.16 Dealing with investigation requests from government agencies (INQ)\n\nObjective: Ensure appropriate handling of government investigation requests for legal review, information to cloud customers, and limitation of access to or disclosure of data.",
          "Dealing with investigation requests from government agencies (inq). Legal assessment of investigative inquiries. Basic criterion: Investigation requests from government agencies are subjected to a legal assessment by subject matter experts of the cloud service provider. The assessment determines whether the government agency has an applicable and legally valid legal basis and what further steps need to be taken.\n\nAdditional criterion: Supplementary information about the criterion complementary customer criterion. Cloud customers ensure through suitable controls that the type and scope of government investigation requests and the associated disclosure of their own data has been dealt with in their own risk management and that the use of the cloud service only takes place when this risk has been deemed acceptable.\n\nNotes on continuous auditing feasibility: No. Although a continuous audit of the performance of the assessment and its documentation is conceivable, a continuous audit is not practical. Rather, the criterion aims at the qualification of the auditing personnel as well as the process behind it, which is both subject to manual audit.",
          "Operations (ops). Managing vulnerabilities, malfunctions and errors – system hardening. Basic criterion: System components in the production environment used to provide the cloud service under the cloud service provider's responsibility are hardened according to generally accepted industry standards. The hardening requirements for each system component are documented. If non-modifiable (\"immutable\") images are used, compliance with the hardening specifications as defined in the hardening requirements is checked upon the creation of the images. Configuration and log files regarding the continuous availability of the images are retained.\n\nAdditional criterion: System components in the cloud service provider's area of responsibility are automatically monitored for compliance with hardening specifications. Deviations from the specifications are automatically reported to the appropriate departments of the cloud service provider for immediate assessment and action.\n\nSupplementary information about the criterion: System components in the sense of the basic criterion are objects required for the information security of the cloud service during the creation, processing, storage, transmission, deletion, or destruction of information in the cloud service provider's area of responsibility. For example, firewalls, load balancers, web servers, application servers, and database servers. These system components consist of hardware and software objects. This criterion is limited to software objects such as hypervisors, operating systems, databases, programming interfaces (APIs), images (e.g., for virtual machines and containers), and applications for logging and monitoring security events. The configuration and log files for non-modifiable images include, for example, the configuration of the images used with regard to implemented hardening specifications including version history, and logs for file integrity monitoring of images in productive use. Generally accepted industry standards include, for example, the security configuration benchmark of the \"Centre for Internet Security\" (CIS) or the corresponding modules in the BSI IT-Grundschutz-Kompendium. Compliance with hardening specifications can be monitored with, for example, file integrity monitoring.\n\nComplementary customer criterion: Cloud customers ensure through suitable controls that layers of the cloud service which are under their responsibility are hardened according to generally established and accepted industry standards. The hardening specifications applied are derived from a risk assessment of the planned usage of the cloud service.\n\nNotes on continuous auditing feasibility: Yes, the verification of compliance with the specifications for the hardening of system components can be automatically tested and subsequently documented (logs). The auditor can evaluate these logs automatically and continuously and thus carry out a continuous audit.",
          "Operations (ops). Protection against malware – concept. Basic criterion: Policies and instructions with specifications for protection against malware are documented, communicated, and provided in accordance with SP-01. The following aspects should be considered:\n\n- Use of system-specific protection mechanisms\n- Operating protection programs on system components under the responsibility of the cloud service provider that are used to provide the cloud service in the production environment\n- Operation of protection programs for employees’ terminal equipment \n\nAdditional criterion: The cloud service provider creates regular reports on the checks performed, which are reviewed and analyzed by authorized bodies or committees. \n\nPolicies and instructions should describe the technical measures taken to securely configure and monitor the management console (both the customer’s self-service and the service provider’s cloud administration) to protect it from malware. Updates should be applied at the highest frequency that the vendor(s) contractually offer(s). \n\nSupplementary information about the criterion \"protection programs for employee devices\" can be, for example, server-based protection programs that scan files in attachments on the server or filter network traffic.\n\nComplementary customer criterion notes on continuous auditing feasibility: Partially, a policy can change ad-hoc. However, the continuous audit of policies is only partially feasible, as the only attributes that can be tested are the last change date and the status of review or approval, as far as this information is stored in a system. The content of a policy can hardly be tested automatically.",
          "Communication security (cos). Documentation of the network topology. Basic criterion: The documentation of the logical structure of the network used to provision or operate the cloud service is traceable and up-to-date. This is to avoid administrative errors during live operation and to ensure timely recovery in the event of malfunctions, in accordance with contractual obligations. The documentation should show how the subnets are allocated and how the network is zoned and segmented. Additionally, it should indicate the geographical locations where the cloud customers' data is stored.\n\nAdditional criterion: Supplementary information about the criterion zoning includes segmentation of the subnets with a firewall implemented at the network perimeters.\n\nComplementary customer criterion: Notes on continuous auditing feasibility: No, the documentation of the logical structure of the network is rarely changed and is stored centrally. Therefore, a continuous audit is not effective. However, a continuous audit could provide the date of the last change to the documentation.",
          "Dealing with investigation requests from government agencies (inq). Conditions for access to or disclosure of data in investigation requests. Basic criterion: Access to or disclosure of cloud customer data in connection with government investigation requests is subject to the proviso that the cloud service provider's legal assessment has shown that an applicable and valid legal basis exists and that the investigation request must be granted on that basis.\n\nAdditional criterion:\n\n- Supplementary information about the criterion\n- Complementary customer criterion\n- Notes on continuous auditing feasibility: Yes, to the extent that a separate role is assigned to the investigator in order to gain access to the data. The prerequisites specified in the request can be entered and checked by the system and linked to the assignment of the investigator role. A continuous query can then be made to ensure that the role was only granted if the prerequisites defined by the system were fulfilled. Deviations can be audited manually.",
          "Procurement, development and modification of information systems (dev). Separation of environments. Basic criterion: Production environments are physically or logically separated from test or development environments to prevent unauthorized access to cloud customer data, the spread of malware, or changes to system components. Data contained in the production environments is not used in test or development environments to avoid compromising their confidentiality.\n\nAdditional criterion: Supplementary information about the criterion complementary customer criterion notes on continuous auditing feasibility: Yes, since fundamental changes in test or development environments that would affect the physical or logical separation are rarely made, a continuous audit is not practical. The respective environments must be tested initially and then audited again if changes are made.\n\n5.12 Control and monitoring of service providers and suppliers (SSO) objective: Ensure the protection of information that service providers or suppliers of the cloud service provider (subcontractors) can access and monitor the agreed services and security requirements.",
          "Organisation of information security (ois). Information security policy. Basic criterion: The top management of the cloud service provider has adopted an information security policy and communicated it to internal and external employees, as well as cloud customers. The policy describes the following:\n\n- The importance of information security, based on the requirements of cloud customers in relation to information security.\n- The security objectives and desired security level, based on the business goals and tasks of the cloud service provider.\n- The most important aspects of the security strategy to achieve the set security objectives.\n- The organizational structure for information security in the ISMS application area.\n\nAdditional criterion:\n\nSupplementary information about the criterion: The top management refers to a natural person or group of persons who make the final decisions for the institution and are responsible for those decisions.\n\nComplementary customer criterion:\n\nNotes on continuous auditing feasibility: \nPartially, a policy can change ad-hoc. However, the continuous audit of policies is only partially feasible as the only attributes that can be tested are the last change date and the status of review or approval, as far as this information is stored in a system. The content of a policy can hardly be tested automatically.",
          "Product safety and security (pss). Locations of data processing and storage. Basic criterion: The cloud customer is able to specify the locations (location/country) of the data processing and storage, including data backups, according to the contractually available options. This must be ensured by the cloud architecture.\n\nAdditional criterion: Supplementary information about the criterion. This criterion supplements the general condition BC-01. The cloud architecture must exist in such a way that it enables the technical design of the IT infrastructure to provide the cloud service in accordance with the data location specifications agreed with the customer.\n\nComplementary customer criterion: Cloud customers ensure, through suitable controls, that when selecting service providers and configuring the cloud service, they are informed about the available data processing and storage locations. If there is a choice between different locations, they select those that meet their own requirements. Depending on the use case and especially when using services of a cloud service provider based in another country, cloud customers take the laws applicable to them into account when making their selection (e.g., when processing personal data; compliance with legal retention obligations for business documents, etc.).\n\nNotes on continuous auditing feasibility: Yes, a continuous survey of the location of the data and the country from which the service is provided can be carried out automatically by the cloud service provider. This information can then be made available to the customer, for example, on their dashboard or on request.",
          "Security policies and instructions (sp). Documentation, communication and provision of policies and instructions. Basic criterion: Policies and instructions (including concepts and guidelines) are derived from the information security policy and are documented according to a uniform structure. They are communicated and made available to all internal and external employees of the cloud service provider in an appropriate manner. The policies and instructions are version controlled and approved by the top management of the cloud service provider or an authorized body. The policies and instructions describe at least the following aspects: objectives; scope; roles and responsibilities, including staff qualification requirements and the establishment of substitution rules; roles and dependencies on other organizations (especially cloud customers and sub-service organizations); steps for the execution of the security strategy; and applicable legal and regulatory requirements.\n\nAdditional criterion: Supplementary information about the criterion. The appropriateness of the demand-oriented communication and provision must be assessed against the size and complexity of the cloud service provider's organization and the type of cloud service offered. Possible criteria are: integration of guidelines and instructions in the onboarding of new employees; training and information campaigns when adopting new or revising existing policies and instructions; form of provision.\n\nPolicies and instructions are required for the following basic criteria in which the content is specified in more detail: risk management policy (OIS-06); acceptable use and handling of assets policy (AM-02); security requirements for premises and buildings (PS-01); physical site access control (PS-04); concept for protection against malware (OPS-04); concept for data protection and recovery (OPS-06); concept for logging and monitoring (OPS-10); concept for metadata handling (OPS-11); concept for handling of vulnerabilities, malfunctions, and errors (OPS-18); policy for system and data access authorizations (IDM-01); policy for the use of encryption procedures and key management (CRY-01); policies for data transmission (COS-08); policies for the development/procurement of information systems (DEV-01); policies for changes to information systems (DEV-03); policies and instructions for controlling and monitoring third parties (SSO-01); policy for security incident management (SIM-01); business impact analysis policies and procedures (BCM-02); policy for planning and conducting audits (COM-02).\n\nComplementary customer criterion: Notes on continuous auditing feasibility: partially regarding the uniformity and content of the policies and instructions, there is a need for manual testing, so continuous testing cannot be fully achieved. The communication/provision of policies and instructions can be queried via various registers. Registries for all approved policies and instructions can serve as a basis for reviewing the policies/instructions provided in the usual channels and may be combined with a conditional access check. These requirements must first be met by the cloud service provider. Versioning after approval by authorized personnel can be automatically audited and is therefore suitable for continuous audit.",
          "Operations (ops). Logging and monitoring – identification of events. Basic criterion: The logging data is automatically monitored for events that may violate the protection goals in accordance with the logging and monitoring requirements. This also includes the detection of relationships between events (event correlation). Identified events are automatically reported to the appropriate departments for prompt evaluation and action.\n\nAdditional criterion: Additional information about the criterion. Supplementary information about the criterion.\n\nComplementary customer criterion: Complementary notes on continuous auditing feasibility: Yes, the cloud service provider can automatically test the list of assets critical for monitoring and record this test in logs. The auditor can audit the log files for irregularities automatically and continuously.",
          "Operations (ops). Logging and monitoring – metadata management concept. Basic criterion: Policies and instructions for the secure handling of metadata (usage data) are documented, communicated, and provided according to SP-01 with regard to the following aspects: \n\n- Metadata is collected and used solely for billing, incident management, and security incident management purposes. \n\n- Exclusively anonymous metadata is used to deploy and enhance the cloud service, ensuring that no conclusions can be drawn about the cloud customer or user. \n\n- No commercial use of metadata is allowed. \n\n- Storage of metadata is for a fixed period reasonably related to the purposes of the collection. \n\n- Immediate deletion of metadata is required if the purposes of the collection are fulfilled and further storage is no longer necessary. \n\n- Provision of metadata to cloud customers is done according to contractual agreements. \n\nAdditional criterion: Personal data is automatically removed from the log data before the cloud service provider processes it, to the extent that it is technically possible. The removal should be performed in a way that allows the cloud service provider to continue using the log data for the purpose for which it was collected. \n\nSupplementary information about the criterion: Metadata refers to all data generated by the cloud service provider through the use of its service by the cloud customer, excluding content-related data. This includes login/logout times, IP addresses, customers' GPS location, resources used (network, storage, computer), accessed data, data sharing, and communication details. This data is used for billing purposes, (security) incident management, and can also be utilized for analyzing customer behavior and making decision-making and work processes visible to the cloud service provider, depending on the specific cloud service. The criteria aim to provide a transparent and clear definition of the collection and use of metadata. \n\nIn addition, metadata also refers to data generated when the cloud service provider accesses customer data (e.g., for indexing). \n\nComplementary customer criterion notes on continuous auditing feasibility: Partially, policy changes can occur ad-hoc. However, continuous auditing of policies is only partially feasible, as the only attributes that can be tested are the last change date and the status of review or approval, to the extent that this information is stored in a system. The content of a policy can hardly be tested automatically.",
          "Identity and access management (idm). Locking and withdrawal of user accounts in the event of inactivity or multiple failed logins. Basic criterion: User accounts of internal and external employees of the cloud service provider, as well as for system components involved in automated authorization processes of the cloud service provider, are automatically locked if they have not been used for a period of two months. Approval from authorized personnel or system components is required to unlock these accounts. Locked user accounts are automatically revoked after six months. After revocation, the procedure for granting user accounts and access rights (cf. idm-02) must be repeated. \n\nAdditional criterion: Supplementary information about the criterion locking can result from a longer absence of the employee, for example, due to illness, parental leave, or sabbatical. \n\nComplementary customer criterion: Notes on continuous auditing feasibility: Yes, automated processes can easily be included in the continuous audit. Appropriate evaluation and reporting mechanisms must be used by the cloud service provider. The auditor must use data analyses to detect deviations.",
          "Asset management (am). Commitment to permissible use, safe handling and return of assets. Basic criterion: The cloud service provider's internal and external employees are provably committed to the policies and instructions for acceptable use and safe handling of assets before they can be used. If the cloud service provider has determined in a risk assessment that loss or unauthorized access could compromise the information security of the cloud service, any assets handed over are provably returned upon termination of employment.\n\nAdditional criterion: Physical assets of internal and external employees are managed centrally. Central management enables software, data, and policy distribution, as well as remote deactivation, deletion, or locking.\n\nSupplementary information about the criterion:\nThe basic criterion essentially concerns mobile devices (e.g., notebooks, tablets, smartphones, etc.) where confidential information is stored. Unauthorized access to these devices can be used to obtain privileged access to the cloud service (e.g., if these are used as security tokens for authentication).\n\nComplementary customer criterion notes on continuous auditing feasibility: Yes, the obligation of the employees to follow the policies and instructions can be made in digital form. This can be used to create a monitoring system that documents the non-obligation to employee guidelines in the form of logs. In this case, the auditor can check the exceptions in the form of logs and request evidence of what additional steps the cloud service provider has taken in these cases to minimize the risk. The compliant use of the assets can then be ensured via an agent system that checks active assets. The status of this system can then be queried by the auditor for a continuous audit.",
          "Physical security (ps). Physical site access control. Basic criterion: At access points to premises and buildings related to the cloud service provided, physical access controls are set up in accordance with the cloud service provider's security requirements (cf. PS-01 security concept) to prevent unauthorized access. Access controls are supported by an access control system. The requirements for the access control system are documented, communicated, and provided in a policy or concept in accordance with SP-01 and include the following aspects: \n\n- Specified procedure for the granting and revoking of access authorizations (cf. IDM-02) based on the principle of least authorization (\"least-privilege principle\") and as necessary for the performance of tasks (\"need-to-know principle\").\n- Automatic revocation of access authorizations if they have not been used for a period of 2 months.\n- Automatic withdrawal of access authorizations if they have not been used for a period of 6 months.\n- Two-factor authentication for access to areas hosting system components that process cloud customer information.\n- Visitors and external personnel are tracked individually by the access control during their work in the premises and buildings, identified as such (e.g., by visible wearing of a visitor pass), and supervised during their stay.\n- Existence and nature of access logging that enables the cloud service provider, in the sense of an effectiveness audit, to check whether only defined personnel have entered the premises and buildings related to the cloud service provided.\n\nAdditional criterion: Supplementary information about the criterion complementary customer criterion notes on continuous auditing:\n\nFeasibility: Yes. Access control via an access card system can be documented by the cloud service provider in the form of logs. These logs can be evaluated automatically. In addition, unauthorized access can also be traced through these logs. This can also be evaluated automatically. Therefore, a continuous audit is possible. Insofar as the withdrawal of access authorizations is standardized and documented in the same way, an automated evaluation is also possible here, and thus, a continuous audit can be carried out.",
          "Product safety and security (pss). Authorisation mechanisms. Basic criterion: Access to the functions provided by the cloud service is restricted by access controls (authorization mechanisms) that verify whether users, IT components, or applications are authorized to perform certain actions. The cloud service provider validates the functionality of the authorization mechanisms before new functions are made available to cloud users and in the event of changes to the authorization mechanisms of existing functions (cf. dev-06). The severity of identified vulnerabilities is assessed according to defined criteria based on industry-standard metrics (e.g., Common Vulnerability Scoring System), and measures for timely resolution or mitigation are initiated. Vulnerabilities that have not been fixed are listed in the online register of known vulnerabilities (cf. pss-02).\n\nAdditional criterion: Access controls are attribute-based to enable granular and contextual checks against multiple attributes of a user, IT component, or application (e.g., role, location, authentication method).\n\nSupplementary information about the criterion: Complementary customer criterion notes on continuous auditing feasibility: Yes, the changes to authorization mechanisms and the identification of vulnerabilities are documented in a standardized manner by the cloud service provider. This documentation can be automated and continuously audited. If the elimination of the vulnerabilities and their prioritization also takes place in a standardized form (according to standardized criteria), these points can be integrated into the continuous audit.",
          "Operations (ops). Logging and monitoring – accountability. Basic criterion: The log data generated allows for an unambiguous identification of user accesses at the tenant level to support (forensic) analysis in the event of a security incident. Interfaces are available to conduct forensic analyses and perform backups of infrastructure components and their network communication.\n\nAdditional criterion: Upon request of the cloud customer, the cloud service provider provides the logs relating to the cloud customer in an appropriate form and in a timely manner so that the cloud customer can investigate any incidents relating to them.\n\nSupplementary information about the criterion: Infrastructure components in the sense of this criterion are, for example, fabric controllers, network components, and virtualization servers.\n\nComplementary customer criterion: Cloud customers ensure through suitable controls that unique user IDs are assigned, which allow for a corresponding analysis in the event of a security incident.\n\nNotes on continuous auditing feasibility: No. For the generated logging data to allow unambiguous identification of user accesses at the tenant level, the creation of this data must be configured accordingly. This configuration does not have to be audited continuously but only if it is changed. The interfaces can also be audited initially and then tested again if changes are made.",
          "Product safety and security (pss). Software defined networking. Basic criterion: If the cloud service offers functions for software-defined networking (SDN), the confidentiality of the data of the cloud user is ensured by suitable SDN procedures. The cloud service provider validates the functionality of the SDN functions before providing new SDN features to cloud users or modifying existing SDN features. Identified defects are assessed and corrected in a risk-oriented manner.\n\nAdditional criterion: Supplementary information about the criterion: This criterion is typically not applicable to the SaaS service model. Suitable SDN methods for increasing confidentiality are, for example, L2 overlay networking (tagging) or tunneling/encapsulation.\n\nComplementary customer criterion: Notes on continuous auditing feasibility: Yes. Validation during provision and modification of SDN functions and identification of defects can be documented in a standardized manner by the cloud service provider. This documentation can be audited continuously and automatically by the auditor. The \"marking\" of the data is carried out by a configuration that has to be tested centrally. A continuous audit of all transmitted data packets would not be effective here. The status of the configuration can be continuously audited against a target value, and a content evaluation must be carried out manually.",
          "Asset management (am). Commissioning of hardware. Basic criterion: The cloud service provider has an approval process for the use of hardware to be commissioned, which is used to provide the cloud service in the production environment, in which the risks arising from the commissioning are identified, analyzed and mitigated. Approval is granted after verification of the secure configuration of the mechanisms for error handling, logging, encryption, authentication, and authorization according to the intended use and based on the applicable policies. \n\nAdditional criterion: \n\nSupplementary information about the criterion: The basic criterion applies only to physical hardware objects, such as servers, storage systems, and network components. Virtual hardware and software objects are considered in the criteria areas (ops) and (dev). The approval process typically considers both the basic approval to use the hardware and the final approval of the configured assets. \n\nComplementary customer criterion: \n\nNotes on continuous auditing feasibility: \n\nYes, the approval of the commissioning of hardware by authorized personnel or system components must be digitally documented to allow continuous testing. A ticketing system, for example, is suitable for this purpose. Both the instance and the verification of the configuration must be stored in the respective ticket. This makes it possible for the auditor to check the tickets in an automated procedure. This requires an automated comparison of the authorized instance against a database containing all potential approvers. In addition, the verification of the configuration in the ticket must be audited automatically. The compliant use of the assets can then be ensured via an agent system which checks active assets. The status of this system can then be queried by the auditor for a continuous audit.",
          "Operations (ops). Data backup and recovery – monitoring. Basic criterion: The execution of data backups is monitored by technical and organizational measures. Malfunctions are investigated by qualified staff and rectified promptly to ensure compliance with contractual obligations to cloud customers or the cloud service provider's business requirements regarding the scope and frequency of data backup and the duration of storage.\n\nAdditional criterion: The relevant logs or summarized results are available to the cloud customer in a self-service portal for monitoring the data backup.\n\nSupplementary information about the criterion: If the data backup is not part of the contract concluded between the cloud service provider and the cloud customer, this criterion is not applicable. The cloud service provider must present this situation transparently in the system description.\n\nComplementary customer criterion: Cloud customers ensure, through suitable controls, that the backup of data within their area of responsibility is monitored by technical and organizational measures.\n\nNotes on continuous auditing feasibility: Yes, the execution of different data backups can be performed by continuously auditing the log files and the associated results of the data backup. Any errors in the data backup would be continuously detected and could be explained by appropriate measures and documentation in the audit.",
          "Portability and interoperability (pi). Secure deletion of data. Basic criterion: The cloud service provider's procedures for deleting the cloud customers' data upon termination of the contractual relationship ensure compliance with the contractual agreements (cf. pi-02). The deletion includes data in the cloud customer's environment, metadata, and data stored in the data backups. The deletion procedures prevent recovery by forensic means.\n\nAdditional criterion supplementary information about the criterion suitable methods for data deletion are, e.g., multiple overwriting or deletion of the encryption key.\n\nComplementary customer criterion: Cloud customers ensure through suitable controls that the legal and regulatory framework (e.g., legal requirements for storage and deletion) is identified and that the deletion of their data is initiated accordingly.\n\nNotes on continuous auditing feasibility: Yes, the complete deletion of the data is documented by the cloud service provider using logs. The logs should include which data has been deleted so that it can be tracked whether data has been deleted in the cloud customer's environment, metadata, and data in the backup. The auditor can then perform an automated evaluation of these logs. The auditor can also check the system status of the procedure for deleting the data. The fact that the deletion procedures prevent recovery by forensic means does not have to be audited continuously. The deletion procedures used can be tested as part of the recurring audit.\n\n5.11 Procurement, development, and modification of information systems (dev) objective: Ensure information security in the development cycle of information systems.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "0_the_cloud_of",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "0_the_cloud_of"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          12.61209487915039,
          11.350530624389648,
          10.1273193359375,
          12.547374725341797,
          12.519917488098145,
          12.574275970458984,
          11.758445739746094,
          12.206342697143555,
          11.585917472839355,
          11.286283493041992,
          11.340757369995117,
          12.598247528076172,
          12.493401527404785,
          12.2178955078125,
          13.080283164978027,
          9.983274459838867,
          11.33549690246582,
          11.719461441040039,
          13.0401611328125,
          12.157569885253906,
          11.249679565429688,
          12.47284984588623,
          12.402311325073242,
          12.360152244567871,
          11.309834480285645,
          11.763604164123535,
          12.168978691101074,
          11.593785285949707,
          12.357016563415527,
          13.006009101867676,
          13.100379943847656,
          12.807350158691406,
          10.776132583618164,
          11.284955024719238,
          10.823063850402832,
          10.772852897644043,
          12.508392333984375,
          12.839178085327148,
          12.520747184753418,
          11.306713104248047,
          9.968356132507324,
          11.541462898254395,
          12.215254783630371,
          12.185967445373535,
          13.079465866088867,
          11.48172664642334,
          12.616545677185059,
          11.71066665649414,
          10.88992691040039,
          12.928418159484863,
          11.288612365722656,
          11.26010799407959,
          11.7481107711792,
          12.401991844177246,
          11.795042991638184,
          11.609436988830566,
          12.593241691589355,
          12.173980712890625,
          12.206229209899902,
          11.289299011230469,
          12.222530364990234,
          12.980866432189941,
          12.449604988098145,
          11.67941951751709,
          12.195557594299316,
          12.471941947937012,
          12.64356803894043,
          12.541850090026855,
          11.549662590026855,
          10.833379745483398,
          12.425865173339844,
          12.005106925964355,
          12.112669944763184,
          12.80185317993164,
          12.519947052001953,
          10.864380836486816,
          12.622279167175293,
          12.337766647338867,
          12.271383285522461,
          11.727789878845215,
          11.25572395324707,
          11.491515159606934,
          12.270275115966797,
          12.536192893981934,
          10.774880409240723,
          12.288439750671387,
          12.550219535827637,
          10.806912422180176,
          11.98509407043457,
          12.497084617614746,
          10.721653938293457,
          11.375093460083008,
          12.930607795715332,
          12.449329376220703,
          12.525304794311523,
          12.274088859558105,
          11.252705574035645,
          12.485894203186035,
          12.588923454284668,
          12.521084785461426,
          12.517998695373535,
          11.777544975280762,
          11.82899284362793,
          10.80822467803955,
          12.535360336303711,
          12.563739776611328,
          12.540060997009277,
          11.7863187789917,
          12.166439056396484,
          11.286044120788574,
          11.24831485748291,
          12.55666732788086,
          11.821795463562012,
          10.334457397460938,
          11.72751522064209,
          11.277800559997559,
          10.87472152709961,
          11.715108871459961,
          11.289207458496094,
          11.255742073059082,
          11.930777549743652
         ],
         "y": [
          3.3096847534179688,
          4.599685192108154,
          4.275622844696045,
          2.190213441848755,
          3.11647367477417,
          4.264384746551514,
          2.673846483230591,
          2.6833410263061523,
          3.656461477279663,
          4.70945930480957,
          2.6745691299438477,
          3.193960189819336,
          2.809131383895874,
          2.8948349952697754,
          2.176328659057617,
          4.403184413909912,
          2.69767165184021,
          3.8266820907592773,
          2.216654062271118,
          2.513340950012207,
          2.2228024005889893,
          2.6705257892608643,
          4.386214256286621,
          2.6612515449523926,
          4.661916255950928,
          3.1421267986297607,
          2.5954861640930176,
          2.894683361053467,
          2.741403818130493,
          2.262535333633423,
          2.1577863693237305,
          2.607875347137451,
          3.4807069301605225,
          4.720305919647217,
          3.546035051345825,
          3.48563289642334,
          4.336280822753906,
          2.3419549465179443,
          2.818307638168335,
          2.62223482131958,
          4.409557819366455,
          3.730010509490967,
          3.395427942276001,
          3.3386390209198,
          2.18206524848938,
          2.73864483833313,
          3.3094372749328613,
          3.6804959774017334,
          3.533905506134033,
          2.3406500816345215,
          4.693958282470703,
          2.2167038917541504,
          2.721468210220337,
          4.390715599060059,
          2.6965553760528564,
          2.8319883346557617,
          3.2192864418029785,
          3.4153268337249756,
          2.4362077713012695,
          4.706806659698486,
          2.701385974884033,
          2.295133113861084,
          2.6187069416046143,
          3.7661283016204834,
          2.4630208015441895,
          3.3256423473358154,
          3.3237109184265137,
          3.1624388694763184,
          2.4314568042755127,
          3.505185127258301,
          2.7827258110046387,
          3.585526943206787,
          3.471518039703369,
          2.4059348106384277,
          2.8110897541046143,
          3.486173152923584,
          3.2911159992218018,
          2.597935914993286,
          2.7972378730773926,
          3.752291202545166,
          2.481147527694702,
          2.7619638442993164,
          3.261963367462158,
          2.698275327682495,
          3.4725394248962402,
          2.7855491638183594,
          4.303737163543701,
          3.5402064323425293,
          4.110472202301025,
          4.345030307769775,
          3.4253990650177,
          2.7596936225891113,
          2.3305699825286865,
          4.383719444274902,
          2.208066701889038,
          2.4521751403808594,
          2.2788078784942627,
          2.739886999130249,
          4.238612651824951,
          2.597733974456787,
          2.1944899559020996,
          3.2687995433807373,
          3.0410947799682617,
          3.50301456451416,
          2.212186813354492,
          3.1548731327056885,
          2.7202155590057373,
          2.468959331512451,
          2.7900185585021973,
          2.6651201248168945,
          2.4567601680755615,
          4.292224884033203,
          2.571864366531372,
          6.592462539672852,
          3.7283663749694824,
          2.76078724861145,
          3.510922908782959,
          2.6690633296966553,
          2.2368996143341064,
          2.375734329223633,
          3.1516103744506836
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Configuration management. Configuration settings | respond to unauthorized changes. Take the following actions in response to unauthorized changes to organization-defined configuration settings: alerting designated organizational personnel, restoring established configuration settings, or halting affected system processing in extreme cases.",
          "Configuration management. Impact analyses | separate test environments. Analyze changes to the system in a separate test environment before implementation in an operational environment, looking for security and privacy impacts due to flaws, weaknesses, incompatibility, or intentional malice. A separate test environment requires an environment that is physically or logically separate and distinct from the operational environment. The separation is sufficient to ensure that activities in the test environment do not impact activities in the operational environment and that information in the operational environment is not inadvertently transmitted to the test environment. Separate environments can be achieved by physical or logical means. If physically separate test environments are not implemented, organizations determine the strength of the mechanism required when implementing logical separation.",
          "Configuration management. Impact analyses | verification of controls. After system changes, verify that the impacted controls are implemented correctly, operating as intended, and producing the desired outcome with regard to meeting the security and privacy requirements for the system. Implementation in this context refers to installing changed code in the operational system that may have an impact on security or privacy controls.",
          "Configuration management. Configuration settings | automated management, application, and verification. Manage, apply, and verify configuration settings for [assignment: organization-defined system components] using [assignment: organization-defined automated mechanisms]. Automated tools (e.g., hardening tools, baseline configuration tools) can improve the accuracy, consistency, and availability of configuration settings information. Automation can also provide data aggregation and data correlation capabilities, alerting mechanisms, and dashboards to support risk-based decision-making within the organization.",
          "Configuration management. Configuration settings. A. Establish and document configuration settings for components employed within the system that reflect the most restrictive mode consistent with operational requirements using [assignment: organization-defined common secure configurations].\nB. Implement the configuration settings.\nC. Identify, document, and approve any deviations from established configuration settings for [assignment: organization-defined system components] based on [assignment: organization-defined operational requirements].\nD. Monitor and control changes to the configuration settings in accordance with organizational policies and procedures.\n\nConfiguration settings are the parameters that can be changed in the hardware, software, or firmware components of the system that affect the security and privacy posture or functionality of the system. Information technology products for which configuration settings can be defined include mainframe computers, servers, workstations, operating systems, mobile devices, input/output devices, protocols, and applications. Parameters that impact the security posture of systems include registry settings; account, file, or directory permission settings; and settings for functions, protocols, ports, services, and remote connections. Privacy parameters are parameters impacting the privacy posture of systems, including the parameters required to satisfy other privacy controls. Privacy parameters include settings for access controls, data processing preferences, and processing and retention permissions.\n\nOrganizations establish organization-wide configuration settings and subsequently derive specific configuration settings for systems. The established settings become part of the configuration baseline for the system. Common secure configurations (also known as security configuration checklists, lockdown and hardening guides, and security reference guides) provide recognized, standardized, and established benchmarks that stipulate secure configuration settings for information technology products and platforms as well as instructions for configuring those products or platforms to meet operational requirements. Common secure configurations can be developed by a variety of organizations, including information technology product developers, manufacturers, vendors, federal agencies, consortia, academia, industry, and other organizations in the public and private sectors.\n\nImplementation of a common secure configuration may be mandated at the organization level, mission and business process level, system level, or at a higher level, including by a regulatory agency. Common secure configurations include the United States Government Configuration Baseline (USGCB) and Security Technical Implementation Guides (STIGs), which affect the implementation of CM-6 and other controls such as AC-19 and CM-7. The Security Content Automation Protocol (SCAP) and the defined standards within the protocol provide an effective method to uniquely identify, track, and control configuration settings.",
          "Configuration management. Baseline configuration | automation support for accuracy and currency. Maintain the currency, completeness, accuracy, and availability of the baseline configuration of the system using [assignment: organization-defined automated mechanisms]. Automated mechanisms that help organizations maintain consistent baseline configurations for systems include configuration management tools, hardware, software, firmware inventory tools, and network management tools. Automated tools can be used at the organization level, mission and business process level, or system level on workstations, servers, notebook computers, network components, or mobile devices. Tools can be used to track version numbers on operating systems, applications, types of software installed, and current patch levels. Automation support for accuracy and currency can be satisfied by the implementation of CM-8 (2) for organizations that combine system component inventory and baseline configuration activities.",
          "Planning. Baseline selection. Select a control baseline for the system. Control baselines are predefined sets of controls specifically assembled to address the protection needs of a group, organization, or community of interest. Controls are chosen for baselines to either satisfy mandates imposed by laws, executive orders, directives, regulations, policies, standards, and guidelines or address threats common to all users of the baseline under the assumptions specific to the baseline. Baselines represent a starting point for the protection of individuals' privacy, information, and information systems with subsequent tailoring actions to manage risk in accordance with mission, business, or other constraints (see PL-11). Federal control baselines are provided in SP 800-53b. The selection of a control baseline is determined by the needs of stakeholders. Stakeholder needs consider mission and business requirements as well as mandates imposed by applicable laws, executive orders, directives, policies, regulations, standards, and guidelines. For example, the control baselines in SP 800-53b are based on the requirements from FISMA and privacy. The requirements, along with the NIST standards and guidelines implementing the legislation, direct organizations to select one of the control baselines after reviewing the information types and the information that is processed, stored, and transmitted on the system; analyzing the potential adverse impact of the loss or compromise of the information or system on the organization's operations and assets, individuals, other organizations, or the nation; and considering the results from system and organizational risk assessments. CNSSI 1253 provides guidance on control baselines for national security systems.",
          "Configuration management. Access restrictions for change | privilege limitation for production and operation. (a) Limit privileges to change system components and system-related information within a production or operational environment; and (b) review and reevaluate privileges [assignment: organization-defined frequency]. In many organizations, systems support multiple mission and business functions. Limiting privileges to change system components with respect to operational systems is necessary because changes to a system component may have far-reaching effects on mission and business processes supported by the system. The relationships between systems and mission/business processes are, in some cases, unknown to developers. System-related information includes operational procedures.",
          "Configuration management. Least functionality | prevent program execution. Prevent program execution in accordance with [selection (one or more): [assignment: organization-defined policies, rules of behavior, and/or access agreements regarding software program usage and restrictions]; rules authorizing the terms and conditions of software program usage]. Prevention of program execution addresses organizational policies, rules of behavior, and/or access agreements that restrict software usage and the terms and conditions imposed by the developer or manufacturer, including software licensing and copyrights. Restrictions include prohibiting auto-execute features, restricting roles allowed to approve program execution, permitting or prohibiting specific software programs, or restricting the number of program instances executed at the same time.",
          "Configuration management. Least functionality | periodic review. (A) Review the system [assignment: organization-defined frequency] to identify unnecessary and/or nonsecure functions, ports, protocols, software, and services; and (B) disable or remove [assignment: organization-defined functions, ports, protocols, software, and services within the system deemed to be unnecessary and/or nonsecure]. Organizations review functions, ports, protocols, and services provided by systems or system components to determine the functions and services that are candidates for elimination. Such reviews are especially important during transition periods from older technologies to newer technologies (e.g., transition from IPv4 to IPv6). These technology transitions may require implementing the older and newer technologies simultaneously during the transition period and returning to minimum essential functions, ports, protocols, and services at the earliest opportunity. Organizations can either decide the relative security of the function, port, protocol, and/or service or base the security decision on the assessment of other entities. Insecure protocols include Bluetooth, FTP, and peer-to-peer networking.",
          "Configuration management. Software usage restrictions. a. Use software and associated documentation in accordance with contract agreements and copyright laws. \nb. Track the use of software and associated documentation protected by quantity licenses to control copying and distribution. \nc. Control and document the use of peer-to-peer file sharing technology to ensure that this capability is not used for the unauthorized distribution, display, performance, or reproduction of copyrighted work. \n\nSoftware license tracking can be accomplished by manual or automated methods, depending on organizational needs. Examples of contract agreements include software license agreements and non-disclosure agreements.",
          "Configuration management. Signed components. Prevent the installation of [assignment: organization-defined software and firmware components] without verification that the component has been digitally signed using a certificate that is recognized and approved by the organization. Software and firmware components should not be installed unless signed with recognized and approved certificates. These components include software and firmware version updates, patches, service packs, device drivers, and basic input/output system updates. Organizations can identify applicable software and firmware components by type, specific items, or a combination of both. Digital signatures and organizational verification of such signatures are methods of code authentication.",
          "Configuration management. Configuration change control | cryptography management. Ensure that cryptographic mechanisms used to provide the following controls are under configuration management: [assignment: organization-defined controls]. The controls referenced in the control enhancement refer to security and privacy controls from the control catalog. Regardless of the cryptographic mechanisms employed, processes and procedures are in place to manage those mechanisms. For example, if system components use certificates for identification and authentication, a process is implemented to address the expiration of those certificates.",
          "Configuration management. Least functionality. a. Configure the system to provide only [assignment: organization-defined mission essential capabilities]. \nb. Prohibit or restrict the use of the following functions, ports, protocols, software, and/or services: [assignment: organization-defined prohibited or restricted functions, system ports, protocols, software, and/or services].\n\nSystems provide a wide variety of functions and services. Some of the functions and services routinely provided by default may not be necessary to support essential organizational missions, functions, or operations. Additionally, it is sometimes convenient to provide multiple services from a single system component, but doing so increases risk over limiting the services provided by that single component.\n\nWhere feasible, organizations limit component functionality to a single function per component. Organizations consider removing unused or unnecessary software and disabling unused or unnecessary physical and logical ports and protocols to prevent unauthorized connection of components, transfer of information, and tunneling. Organizations employ network scanning tools, intrusion detection and prevention systems, and end-point protection technologies, such as firewalls and host-based intrusion detection systems, to identify and prevent the use of prohibited functions, protocols, ports, and services.\n\nLeast functionality can also be achieved as part of the fundamental design and development of the system (see SA-8, SC-2, and SC-3).",
          "Configuration management. Baseline configuration. a. Develop, document, and maintain under configuration control a current baseline configuration of the system. \n\nb. Review and update the baseline configuration of the system as follows:\n1. [Assignment: organization-defined frequency].\n2. When required due to [Assignment: organization-defined circumstances].\n3. When system components are installed or upgraded.\n\nBaseline configurations for systems and system components include connectivity, operational, and communications aspects of systems. Baseline configurations are documented, formally reviewed, and agreed-upon specifications for systems or configuration items within those systems. Baseline configurations serve as a basis for future builds, releases, or changes to systems and include security and privacy control implementations, operational procedures, information about system components, network topology, and logical placement of components in the system architecture. \n\nMaintaining baseline configurations requires creating new baselines as organizational systems change over time. Baseline configurations of systems reflect the current enterprise architecture.",
          "Configuration management. Configuration change control. A. Determine and document the types of changes to the system that are configuration-controlled.\nB. Review proposed configuration-controlled changes to the system and approve or disapprove such changes with explicit consideration for security and privacy impact analyses.\nC. Document configuration change decisions associated with the system.\nD. Implement approved configuration-controlled changes to the system.\nE. Retain records of configuration-controlled changes to the system for [assignment: organization-defined time period].\nF. Monitor and review activities associated with configuration-controlled changes to the system.\nG. Coordinate and provide oversight for configuration change control activities through [assignment: organization-defined configuration change control element] that convenes [selection (one or more): [assignment: organization-defined frequency]; when [assignment: organization-defined configuration change conditions]].\n\nConfiguration change control for organizational systems involves the systematic proposal, justification, implementation, testing, review, and disposition of system changes, including system upgrades and modifications. Configuration change control includes changes to baseline configurations, configuration items of systems, operational procedures, configuration settings for system components, remediate vulnerabilities, and unscheduled or unauthorized changes. Processes for managing configuration changes to systems include configuration control boards or change advisory boards that review and approve proposed changes. For changes that impact privacy risk, the senior agency official for privacy updates privacy impact assessments and system of records notices. For new systems or major upgrades, organizations consider including representatives from the development organizations on the configuration control boards or change advisory boards. Auditing of changes includes activities before and after changes are made to systems and the auditing activities required to implement such changes. See also SA-10.",
          "Configuration management. Access restrictions for change | automated access enforcement and audit records. (a) Enforce access restrictions using organization-defined automated mechanisms. \n(b) Automatically generate audit records of the enforcement actions. \nOrganizations log system accesses associated with applying configuration changes to ensure that configuration change control is implemented and to support after-the-fact actions should organizations discover any unauthorized changes.",
          "Configuration management. Access restrictions for change. Define, document, approve, and enforce physical and logical access restrictions associated with changes to the system. Changes to the hardware, software, or firmware components of systems or the operational procedures related to the system can potentially have significant effects on the security of the systems or individuals' privacy. Therefore, organizations permit only qualified and authorized individuals to access systems for purposes of initiating changes. Access restrictions include physical and logical access controls (see AC-3 and PE-3), software libraries, workflow automation, media libraries, abstract layers (i.e., changes implemented into external interfaces rather than directly into systems), and change windows (i.e., changes occur only during specified times).",
          "Configuration management. Configuration change control | testing, validation, and documentation of changes. Test, validate, and document changes to the system before finalizing the implementation of the changes. Changes to systems include modifications to hardware, software, or firmware components and configuration settings defined in CM-6. Organizations ensure that testing does not interfere with system operations that support organizational mission and business functions. Individuals or groups conducting tests understand security and privacy policies and procedures, system security and privacy policies and procedures, and the health, safety, and environmental risks associated with specific facilities or processes. Operational systems may need to be taken offline, or replicated to the extent feasible, before testing can be conducted. If systems must be taken offline for testing, the tests are scheduled to occur during planned system outages whenever possible. If the testing cannot be conducted on operational systems, organizations employ compensating controls.",
          "Configuration management. Configuration management plan. Develop, document, and implement a configuration management plan for the system that:\n\na. Addresses roles, responsibilities, and configuration management processes and procedures.\nb. Establishes a process for identifying configuration items throughout the system development life cycle and for managing the configuration of the configuration items.\nc. Defines the configuration items for the system and places the configuration items under configuration management.\nd. Is reviewed and approved by [assignment: organization-defined personnel or roles].\ne. Protects the configuration management plan from unauthorized disclosure and modification.\n\nConfiguration management activities occur throughout the system development life cycle. As such, there are developmental configuration management activities (e.g., the control of code and software libraries) and operational configuration management activities (e.g., control of installed components and how the components are configured). Configuration management plans satisfy the requirements in configuration management policies while being tailored to individual systems.\n\nConfiguration management plans define processes and procedures for how configuration management is used to support system development life cycle activities. Configuration management plans are generated during the development and acquisition stage of the system development life cycle. The plans describe how to advance changes through change management processes, update configuration settings and baselines, maintain component inventories, control development, test, and operational environments, and develop, release, and update key documents.\n\nOrganizations can employ templates to help ensure the consistent and timely development and implementation of configuration management plans. Templates can represent a configuration management plan for the organization with subsets of the plan implemented on a system by system basis.\n\nConfiguration management approval processes include the designation of key stakeholders responsible for reviewing and approving proposed changes to systems and personnel who conduct security and privacy impact analyses prior to the implementation of changes to the systems.\n\nConfiguration items are the system components, such as the hardware, software, firmware, and documentation to be configuration-managed. As systems continue through the system development life cycle, new configuration items may be identified, and some existing configuration items may no longer need to be under configuration control.",
          "Configuration management. Impact analyses. Analyze changes to the system to determine potential security and privacy impacts prior to change implementation. Organizational personnel with security or privacy responsibilities conduct impact analyses. Individuals conducting impact analyses possess the necessary skills and technical expertise to analyze the changes to systems as well as the security or privacy ramifications.\n\nImpact analyses include:\n- Reviewing security and privacy plans, policies, and procedures to understand control requirements.\n- Reviewing system design documentation and operational procedures to understand control implementation and how specific system changes might affect the controls.\n- Reviewing the impact of changes on organizational supply chain partners with stakeholders.\n- Determining how potential changes to a system create new risks to the privacy of individuals and the ability of implemented controls to mitigate those risks.\n\nImpact analyses also include risk assessments to understand the impact of the changes and determine if additional controls are required.",
          "Configuration management. Baseline configuration | retention of previous configurations. Retain [assignment: organization-defined number] of previous versions of baseline configurations of the system to support rollback. Retaining previous versions of baseline configurations to support rollback includes hardware, software, firmware, configuration files, configuration records, and associated documentation.",
          "Configuration management. Configuration change control | security and privacy representatives. Require organization-defined security and privacy representatives to be members of the organization-defined configuration change control element. Information security and privacy representatives include system security officers, senior agency information security officers, senior agency officials for privacy, or system privacy officers. Representation by personnel with information security and privacy expertise is important because changes to system configurations can have unintended side effects, some of which may be security- or privacy-relevant. Detecting such changes early in the process can help avoid unintended, negative consequences that could ultimately affect the security and privacy posture of systems. The configuration change control element referred to in the second organization-defined parameter reflects the change control elements defined by organizations in CM-3g.",
          "Configuration management. System component inventory | updates during installation and removal. Update the inventory of system components as part of component installations, removals, and system updates. Organizations can improve the accuracy, completeness, and consistency of system component inventories if the inventories are updated as part of component installations or removals or during general system updates. If inventories are not updated at these key times, there is a greater likelihood that the information will not be appropriately captured and documented. System updates include hardware, software, and firmware components.",
          "Configuration management. Least functionality | authorized software — allow-by-exception. (a) Identify [assignment: organization-defined software programs authorized to execute on the system]. \n(b) Employ a deny-all, permit-by-exception policy to allow the execution of authorized software programs on the system. \n(c) Review and update the list of authorized software programs [assignment: organization-defined frequency]. Authorized software programs can be limited to specific versions or from a specific source. \nTo facilitate a comprehensive authorized software process and increase the strength of protection for attacks that bypass application-level authorized software, software programs may be decomposed into and monitored at different levels of detail. These levels include applications, application programming interfaces, application modules, scripts, system processes, system services, kernel functions, registries, drivers, and dynamic link libraries. \nThe concept of permitting the execution of authorized software may also be applied to user actions, system ports and protocols, IP addresses/ranges, websites, and MAC addresses. Organizations consider verifying the integrity of authorized software programs using digital signatures, cryptographic checksums, or hash functions. Verification of authorized software can occur either prior to execution or at system startup. The identification of authorized URLs for websites is addressed in CA-3 (5) and SC-7.",
          "Configuration management. Configuration change control | automated documentation, notification, and prohibition of changes. Use [assignment: organization-defined automated mechanisms] to:\n(a) document proposed changes to the system.\n(b) notify [assignment: organization-defined approval authorities] of proposed changes to the system and request change approval.\n(c) highlight proposed changes to the system that have not been approved or disapproved within [assignment: organization-defined time period].\n(d) prohibit changes to the system until designated approvals are received.\n(e) document all changes to the system.\n(f) notify [assignment: organization-defined personnel] when approved changes to the system are completed.\nNone.",
          "Configuration management. User-installed software. a. Establish [assignment: organization-defined policies] governing the installation of software by users. \nb. Enforce software installation policies through the following methods: [assignment: organization-defined methods]. \nc. Monitor policy compliance [assignment: organization-defined frequency]. \n\nIf provided the necessary privileges, users can install software in organizational systems. To maintain control over the software installed, organizations identify permitted and prohibited actions regarding software installation. \n\nPermitted software installations include updates and security patches to existing software and downloading new applications from organization-approved app stores. Prohibited software installations include software with unknown or suspect pedigrees or software that organizations consider potentially malicious. \n\nPolicies selected for governing user-installed software are organization-developed or provided by some external entity. Policy enforcement methods can include procedural methods and automated methods.",
          "System and services acquisition. Developer configuration management. Require the developer of the system, system component, or system service to: \na. Perform configuration management during system, component, or service [selection (one or more): design; development; implementation; operation; disposal]. \nb. Document, manage, and control the integrity of changes to [assignment: organization-defined configuration items under configuration management]. \nc. Implement only organization-approved changes to the system, component, or service. \nd. Document approved changes to the system, component, or service and the potential security and privacy impacts of such changes. \ne. Track security flaws and flaw resolution with the system, component, or service and report findings to [assignment: organization-defined personnel]. \n\nOrganizations consider the quality and completeness of configuration management activities conducted by developers as direct evidence of applying effective security controls. \n\nControls include protecting the master copies of material used to generate security-relevant portions of the system hardware, software, and firmware from unauthorized modification or destruction. \n\nMaintaining the integrity of changes to the system, system component, or system service requires strict configuration control throughout the system development life cycle to track authorized changes and prevent unauthorized changes. \n\nThe configuration items that are placed under configuration management include the formal model, the functional, high-level, and low-level design specifications, other design data, implementation documentation, source code and hardware schematics, the current running version of the object code, tools for comparing new versions of security-relevant hardware descriptions and source code with previous versions, and test fixtures and documentation. \n\nDepending on the mission and business needs of organizations and the nature of the contractual relationships in place, developers may provide configuration management support during the operations and maintenance stage of the system development life cycle.",
          "Configuration management. Information location | automated tools to support information location. Use automated tools to identify organization-defined information by information type on organization-defined system components to ensure controls are in place to protect organizational information and individual privacy. The use of automated tools helps to increase the effectiveness and efficiency of the information location capability implemented within the system. Automation also helps organizations manage the data produced during information location activities and share such information across the organization. The output of automated information location tools can be used to guide and inform system architecture and design decisions.",
          "Configuration management. System component inventory. a. Develop and document an inventory of system components that: 1. accurately reflects the system; 2. includes all components within the system; 3. does not include duplicate accounting of components or components assigned to any other system; 4. is at the level of granularity deemed necessary for tracking and reporting; and 5. includes the following information to achieve system component accountability: [Assignment: organization-defined information deemed necessary to achieve effective system component accountability]. And b. Review and update the system component inventory [Assignment: organization-defined frequency]. \n\nSystem components are discrete, identifiable information technology assets that include hardware, software, and firmware. Organizations may choose to implement centralized system component inventories that include components from all organizational systems. In such situations, organizations ensure that the inventories include system-specific information required for component accountability. The information necessary for effective accountability of system components includes the system name, software owners, software version numbers, hardware inventory specifications, software license information, and for networked components, the machine names and network addresses across all implemented protocols (e.g., IPv4, IPv6). \n\nInventory specifications include date of receipt, cost, model, serial number, manufacturer, supplier information, component type, and physical location. Preventing duplicate accounting of system components addresses the lack of accountability that occurs when component ownership and system association is not known, especially in large or complex connected systems. Effective prevention of duplicate accounting of system components necessitates use of a unique identifier for each component. \n\nFor software inventory, centrally managed software that is accessed via other systems is addressed as a component of the system on which it is installed and managed. Software installed on multiple organizational systems and managed at the system level is addressed for each individual system and may appear more than once in a centralized component inventory, necessitating a system association for each software instance in the centralized inventory to avoid duplicate accounting of components. \n\nScanning systems implementing multiple network protocols (e.g., IPv4 and IPv6) can result in duplicate components being identified in different address spaces. The implementation of CM-8 (7) can help to eliminate duplicate accounting of components.",
          "Configuration management. System component inventory | automated maintenance. Maintain the currency, completeness, accuracy, and availability of the inventory of system components using [assignment: organization-defined automated mechanisms]. Organizations maintain system inventories to the extent feasible. For example, virtual machines can be difficult to monitor because such machines are not visible to the network when not in use. In such cases, organizations maintain as up-to-date, complete, and accurate an inventory as is deemed reasonable. Automated maintenance can be achieved by the implementation of CM-2 (2) for organizations that combine system component inventory and baseline configuration activities.",
          "Planning. Baseline tailoring. Tailor the selected control baseline by applying specified tailoring actions. The concept of tailoring allows organizations to specialize or customize a set of baseline controls by applying a defined set of tailoring actions. Tailoring actions facilitate such specialization and customization by allowing organizations to develop security and privacy plans that reflect their specific mission and business functions, the environments where their systems operate, the threats and vulnerabilities that can affect their systems, and any other conditions or situations that can impact their mission or business success. Tailoring guidance is provided in SP 800-53b. Tailoring a control baseline is accomplished by identifying and designating common controls, applying scoping considerations, selecting compensating controls, assigning values to control parameters, supplementing the control baseline with additional controls as needed, and providing information for control implementation. The general tailoring actions in SP 800-53b can be supplemented with additional actions based on the needs of organizations. Tailoring actions can be applied to the baselines in SP 800-53b in accordance with the security and privacy requirements from FISMA, privacy, and OMB A-130. Alternatively, other communities of interest adopting different control baselines can apply the tailoring actions in SP 800-53b to specialize or customize the controls that represent the specific needs and concerns of those entities.",
          "Configuration management. System component inventory | automated unauthorized component detection. (A) Detect the presence of unauthorized hardware, software, and firmware components within the system using [assignment: organization-defined automated mechanisms]. [Assignment: Organization-defined frequency].\n\n(B) Take the following actions when unauthorized components are detected: [Selection (one or more): disable network access by such components; isolate the components; notify [assignment: organization-defined personnel or roles]].\n\nAutomated unauthorized component detection is applied in addition to monitoring for unauthorized remote connections and mobile devices. Monitoring for unauthorized system components may be accomplished on an ongoing basis or by periodic scanning of systems for that purpose. Automated mechanisms may also be used to prevent the connection of unauthorized components (see CM-7 (9)). Automated mechanisms can be implemented in systems or in separate system components.\n\nWhen acquiring and implementing automated mechanisms, organizations consider whether such mechanisms depend on the ability of the system component to support an agent or supplicant in order to be detected since some types of components do not have or cannot support agents (e.g., IoT devices, sensors).\n\nIsolation can be achieved, for example, by placing unauthorized system components in separate domains or subnets or quarantining such components. This type of component isolation is commonly referred to as sandboxing.",
          "System and services acquisition. Unsupported system components. a. Replace system components when support for the components is no longer available from the developer, vendor, or manufacturer; or b. Provide the following options for alternative sources for continued support for unsupported components [selection (one or more): in-house support; [assignment: organization-defined support from external providers]]. Support for system components includes software patches, firmware updates, replacement parts, and maintenance contracts. An example of unsupported components includes when vendors no longer provide critical software patches or product updates, which can result in an opportunity for adversaries to exploit weaknesses in the installed components. Exceptions to replacing unsupported system components include systems that provide critical mission or business capabilities where newer technologies are not available or where the systems are so isolated that installing replacement components is not an option. Alternative sources for support address the need to provide continued support for system components that are no longer supported by the original manufacturers, developers, or vendors when such components remain essential to organizational mission and business functions. If necessary, organizations can establish in-house support by developing customized patches for critical software components or, alternatively, obtain the services of external providers who provide ongoing support for the designated unsupported components through contractual relationships. Such contractual relationships can include open-source software value-added vendors. The increased risk of using unsupported system components can be mitigated, for example, by prohibiting the connection of such components to public or uncontrolled networks, or implementing other forms of isolation.",
          "Configuration management. Information location. A. Identify and document the location of [assignment: organization-defined information] and the specific system components on which the information is processed and stored.\nB. Identify and document the users who have access to the system and system components where the information is processed and stored.\nC. Document changes to the location (i.e., system or system components) where the information is processed and stored.\n\nInformation location addresses the need to understand where information is being processed and stored. Information location includes identifying where specific information types and information reside in system components and how information is being processed so that information flow can be understood and adequate protection and policy management provided for such information and system components. The security category of the information is also a factor in determining the controls necessary to protect the information and the system component where the information resides (see FIPS 199). The location of the information and system components is also a factor in the architecture and design of the system (see SA-4, SA-8, SA-17).",
          "Configuration management. System component inventory | accountability information. Include in the system component inventory information a means for identifying, by name, position, or role, the individuals responsible and accountable for administering those components. Identifying the individuals who are responsible and accountable for administering system components ensures that the assigned components are properly administered. Additionally, it allows organizations to contact those individuals if any action is required, such as when the component is determined to be the source of a breach, needs to be recalled or replaced, or needs to be relocated.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "1_configuration_system_software",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "1_configuration_system_software"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          6.873507499694824,
          6.795992374420166,
          6.768842697143555,
          6.696443557739258,
          6.704583168029785,
          6.536135673522949,
          7.242346286773682,
          6.726673126220703,
          6.645346164703369,
          6.543788909912109,
          6.651296615600586,
          6.22971248626709,
          6.834941864013672,
          6.391942501068115,
          6.63139533996582,
          6.851820945739746,
          6.779938220977783,
          6.841670513153076,
          6.828857421875,
          6.711049556732178,
          6.840367317199707,
          6.634093284606934,
          6.909734725952148,
          6.2380828857421875,
          6.595800399780273,
          6.868269443511963,
          6.6049089431762695,
          6.521332740783691,
          6.62550163269043,
          6.283181667327881,
          6.351938724517822,
          7.2003254890441895,
          6.271563529968262,
          6.205075263977051,
          6.589561939239502,
          6.240755558013916,
          6.646299362182617
         ],
         "y": [
          9.838255882263184,
          9.84045124053955,
          9.849384307861328,
          9.758678436279297,
          9.747742652893066,
          9.740609169006348,
          8.995332717895508,
          10.217211723327637,
          10.363746643066406,
          10.037446975708008,
          10.325568199157715,
          9.812007904052734,
          9.924562454223633,
          10.081565856933594,
          9.628533363342285,
          9.87860107421875,
          10.176371574401855,
          10.280973434448242,
          9.919111251831055,
          9.701737403869629,
          9.845455169677734,
          9.668880462646484,
          9.937694549560547,
          9.765447616577148,
          10.347707748413086,
          9.872992515563965,
          10.376206398010254,
          9.566951751708984,
          9.755755424499512,
          9.783458709716797,
          9.73924732208252,
          9.139458656311035,
          9.877632141113281,
          9.64071273803711,
          9.72435474395752,
          9.7955904006958,
          9.859874725341797
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Contingency planning. Alternate storage site | recovery time and recovery point objectives. Configure the alternate storage site to facilitate recovery operations in accordance with recovery time and recovery point objectives. Organizations establish recovery time and recovery point objectives as part of contingency planning. Configuration of the alternate storage site includes physical facilities and the systems supporting recovery operations that ensure accessibility and correct execution.",
          "Contingency planning. System backup | separate storage for critical information. Store backup copies of [assignment: organization-defined critical system software and other security-related information] in a separate facility or in a fire-rated container that is not collocated with the operational system. Separate storage for critical information applies to all critical information regardless of the type of backup storage media. Critical system software includes operating systems, middleware, cryptographic key management systems, and intrusion detection systems. Security-related information includes inventories of system hardware, software, and firmware components. Alternate storage sites, including geographically distributed architectures, serve as separate storage facilities for organizations. Organizations may provide separate storage by implementing automated backup processes at alternative storage sites (e.g., data centers). The General Services Administration (GSA) establishes standards and specifications for security and fire-rated containers.",
          "Contingency planning. Contingency plan testing. a. Test the contingency plan for the system [assignment: organization-defined frequency] using the following tests to determine the effectiveness of the plan and the readiness to execute the plan: [assignment: organization-defined tests]. \nb. Review the contingency plan test results. \nc. Initiate corrective actions if needed. \n\nMethods for testing contingency plans to determine the effectiveness of the plans and identify potential weaknesses include checklists, walk-through, and tabletop exercises, simulations (parallel or full interrupt), and comprehensive exercises. Organizations conduct testing based on the requirements in contingency plans and include a determination of the effects on organizational operations, assets, and individuals due to contingency operations. Organizations have flexibility and discretion in the breadth, depth, and timelines of corrective actions.",
          "Contingency planning. Contingency training. A. Provide contingency training to system users consistent with assigned roles and responsibilities. \n\n1. Within the organization-defined time period of assuming a contingency role or responsibility. \n2. When required by system changes. \n3. Organization-defined frequency thereafter. \n\nB. Review and update contingency training content. \nOrganization-defined frequency and following organization-defined events. \n\nContingency training provided by organizations is linked to the assigned roles and responsibilities of organizational personnel to ensure the appropriate content and level of detail is included. For example, some individuals may only need to know when and where to report for duty during contingency operations and if normal duties are affected. System administrators may require additional training on how to establish systems at alternate processing and storage sites. Organizational officials may receive more specific training on how to conduct mission-essential functions in designated off-site locations and how to establish communications with other governmental entities for purposes of coordination on contingency-related activities. \n\nTraining for contingency roles or responsibilities reflects the specific continuity requirements in the contingency plan. Events that may precipitate an update to contingency training content include, but are not limited to, contingency plan testing or an actual contingency (lessons learned), assessment or audit findings, security incidents or breaches, or changes in laws, executive orders, directives, regulations, policies, standards, and guidelines. \n\nAt the discretion of the organization, participation in a contingency plan test or exercise, including lessons learned sessions subsequent to the test or exercise, may satisfy contingency plan training requirements.",
          "Contingency planning. Alternate processing site. a. Establish an alternate processing site, including necessary agreements to permit the transfer and resumption of [assignment: organization-defined system operations] for essential mission and business functions within [assignment: organization-defined time period consistent with recovery time and recovery point objectives], when the primary processing capabilities are unavailable. \nb. Make available at the alternate processing site, the equipment and supplies required to transfer and resume operations or put contracts in place to support delivery to the site within the organization-defined time period for transfer and resumption. \nc. Provide controls at the alternate processing site that are equivalent to those at the primary site. \n\nAlternate processing sites are geographically distinct from primary processing sites and provide processing capability if the primary processing site is not available. The alternate processing capability may be addressed using a physical processing site or other alternatives, such as failover to a cloud-based service provider or other internally or externally provided processing service. Geographically distributed architectures that support contingency requirements may also be considered alternate processing sites. \n\nControls that are covered by alternate processing site agreements include the environmental conditions at alternate sites, access rules, physical and environmental protection requirements, and the coordination for the transfer and assignment of personnel. Requirements are allocated to alternate processing sites that reflect the requirements in contingency plans to maintain essential mission and business functions despite disruption, compromise, or failure in organizational systems.",
          "Contingency planning. Contingency training | simulated events. Incorporate simulated events into contingency training to facilitate effective response by personnel in crisis situations. The use of simulated events creates an environment for personnel to experience actual threat events, including cyber-attacks that disable websites, ransomware attacks that encrypt organizational data on servers, hurricanes that damage or destroy organizational facilities, or hardware or software failures.",
          "Contingency planning. Contingency plan testing | coordinate with related plans. Coordinate contingency plan testing with organizational elements responsible for related plans. Plans related to contingency planning for organizational systems include:\n\n1. Business continuity plans\n2. Disaster recovery plans\n3. Continuity of operations plans\n4. Crisis communications plans\n5. Critical infrastructure plans\n6. Cyber incident response plans\n7. Occupant emergency plans \n\nCoordination of contingency plan testing does not require organizations to create organizational elements to handle related plans or to align such elements with specific plans. However, it does require that if such organizational elements are responsible for related plans, organizations coordinate with those elements.",
          "Contingency planning. Contingency plan | continue mission and business functions. Plan for the continuance of [selection: all; essential] mission and business functions with minimal or no loss of operational continuity and sustain that continuity until full system restoration at primary processing and/or storage sites. Organizations may choose to conduct the contingency planning activities to continue mission and business functions as part of business continuity planning or business impact analyses. Primary processing and/or storage sites defined by organizations as part of contingency planning may change depending on the circumstances associated with the contingency.",
          "Contingency planning. Contingency plan testing | alternate processing site. Test the contingency plan at the alternate processing site: (a) to familiarize contingency personnel with the facility and available resources; and (b) to evaluate the capabilities of the alternate processing site to support contingency operations. Conditions at the alternate processing site may be significantly different than the conditions at the primary site. Having the opportunity to visit the alternate site and experience the actual capabilities available at the site can provide valuable information on potential vulnerabilities that could affect essential organizational mission and business functions. The on-site visit can also provide an opportunity to refine the contingency plan to address the vulnerabilities discovered during testing.",
          "Contingency planning. Alternate storage site | accessibility. Identify potential accessibility problems to the alternate storage site in the event of an area-wide disruption or disaster and outline explicit mitigation actions. Area-wide disruptions refer to those types of disruptions that are broad in geographic scope, with such determinations made by organizations based on organizational assessments of risk.\n\nExplicit mitigation actions include duplicating backup information at other alternate storage sites if access problems occur at originally designated alternate sites. Additionally, planning for physical access to retrieve backup information is necessary if electronic accessibility to the alternate site is disrupted.",
          "Contingency planning. Contingency plan | coordinate with related plans. Coordinate contingency plan development with organizational elements responsible for related plans. Plans that are related to contingency plans include:\n- Business continuity plans\n- Disaster recovery plans\n- Critical infrastructure plans\n- Continuity of operations plans\n- Crisis communications plans\n- Insider threat implementation plans\n- Data breach response plans\n- Cyber incident response plans\n- Breach response plans\n- Occupant emergency plans.",
          "Contingency planning. Alternate processing site | accessibility. Identify potential accessibility problems to alternate processing sites in the event of an area-wide disruption or disaster and outline explicit mitigation actions. Area-wide disruptions refer to those types of disruptions that are broad in geographic scope, with such determinations made by organizations based on organizational assessments of risk.",
          "Contingency planning. Contingency plan | identify critical assets. Identify critical system assets supporting [SELECTION: all; essential] mission and business functions. Organizations may choose to identify critical assets as part of a criticality analysis, business continuity planning, or business impact analyses. Organizations identify critical system assets so that additional controls can be employed (beyond the controls routinely implemented) to help ensure that organizational mission and business functions can continue to be conducted during contingency operations. The identification of critical information assets also facilitates the prioritization of organizational resources. Critical system assets include technical and operational aspects. Technical aspects include system components, information technology services, information technology products, and mechanisms. Operational aspects include procedures (i.e., manually executed operations) and personnel (i.e., individuals operating technical controls and/or executing manual procedures). Organizational program protection plans can assist in identifying critical assets. If critical assets are resident within or supported by external service providers, organizations consider implementing CP-2 (7) as a control enhancement.",
          "Contingency planning. System recovery and reconstitution | restore within time period. Provide the capability to restore system components within [assignment: organization-defined restoration time periods] from configuration-controlled and integrity-protected information representing a known, operational state for the components. Restoration of system components includes reimaging, which restores the components to known, operational states.",
          "Physical and environmental protection. Alternate work site. a. Determine and document the [assignment: organization-defined alternate work sites] allowed for use by employees. \nb. Employ the following controls at alternate work sites: [assignment: organization-defined controls]. \nc. Assess the effectiveness of controls at alternate work sites. \nd. Provide a means for employees to communicate with information security and privacy personnel in case of incidents. \n\nAlternate work sites include government facilities or the private residences of employees. While distinct from alternative processing sites, alternate work sites can provide readily available alternate locations during contingency operations. Organizations can define different sets of controls for specific alternate work sites or types of sites depending on the work-related activities conducted at the sites. Implementing and assessing the effectiveness of organization-defined controls and providing a means to communicate incidents at alternate work sites support the contingency planning activities of organizations.",
          "Contingency planning. Alternate processing site | separation from primary site. Identify an alternate processing site that is sufficiently separated from the primary processing site to reduce susceptibility to the same threats. Threats that affect alternate processing sites are defined in organizational assessments of risk and include natural disasters, structural failures, hostile attacks, and errors of omission or commission. Organizations determine what is considered a sufficient degree of separation between primary and alternate processing sites based on the types of threats that are of concern. For threats such as hostile attacks, the degree of separation between sites is less relevant.",
          "Contingency planning. Alternate processing site | preparation for use. Prepare the alternate processing site so that the site can serve as the operational site supporting essential mission and business functions. Site preparation includes establishing configuration settings for systems at the alternate processing site consistent with the requirements for such settings at the primary site and ensuring that essential supplies and logistical considerations are in place.",
          "Contingency planning. Telecommunications services | single points of failure. Obtain alternate telecommunications services to reduce the likelihood of sharing a single point of failure with primary telecommunications services. In certain circumstances, telecommunications service providers or services may share the same physical lines, which increases the vulnerability of a single failure point. It is important to have provider transparency for the actual physical transmission capability for telecommunication services.",
          "Contingency planning. Telecommunications services | separation of primary and alternate providers. Obtain alternate telecommunications services from providers that are separated from primary service providers to reduce susceptibility to the same threats. Threats that affect telecommunications services are defined in organizational assessments of risk and include natural disasters, structural failures, cyber or physical attacks, and errors of omission or commission. Organizations can reduce common susceptibilities by minimizing shared infrastructure among telecommunications service providers and achieving sufficient geographic separation between services. Organizations may consider using a single service provider in situations where the service provider can provide alternate telecommunications services that meet the separation needs addressed in the risk assessment.",
          "Contingency planning. Contingency plan | resume mission and business functions. Plan for the resumption of [selection: all; essential] mission and business functions within [assignment: organization-defined time period] of contingency plan activation. Organizations may choose to conduct contingency planning activities to resume mission and business functions as part of business continuity planning or as part of business impact analyses. Organizations prioritize the resumption of mission and business functions. The time period for resuming mission and business functions may be dependent on the severity and extent of the disruptions to the system and its supporting infrastructure.",
          "Contingency planning. System backup | testing for reliability and integrity. Test backup information [assignment: organization-defined frequency] to verify media reliability and information integrity. Organizations need assurance that backup information can be reliably retrieved. Reliability pertains to the systems and system components where the backup information is stored, the operations used to retrieve the information, and the integrity of the information being retrieved. Independent and specialized tests can be used for each of the aspects of reliability. For example, decrypting and transporting (or transmitting) a random sample of backup files from the alternate storage or backup site and comparing the information to the same information at the primary processing site can provide such assurance.",
          "Contingency planning. Alternate storage site. a. Establish an alternate storage site, including necessary agreements to permit the storage and retrieval of system backup information; and b. Ensure that the alternate storage site provides controls equivalent to those of the primary site. Alternate storage sites are geographically distinct from primary storage sites and maintain duplicate copies of information and data if the primary storage site is not available. Similarly, alternate processing sites provide processing capability if the primary processing site is not available. Geographically distributed architectures that support contingency requirements may be considered as alternate storage sites. Items covered by alternate storage site agreements include environmental conditions at the alternate sites, access rules for systems and facilities, physical and environmental protection requirements, and coordination of delivery and retrieval of backup media. Alternate storage sites reflect the requirements in contingency plans so that organizations can maintain essential mission and business functions despite compromise, failure, or disruption in organizational systems.",
          "Contingency planning. Alternate storage site | separation from primary site. Identify an alternate storage site that is sufficiently separated from the primary storage site to reduce susceptibility to the same threats. Threats that affect alternate storage sites are defined in organizational risk assessments and include natural disasters, structural failures, hostile attacks, and errors of omission or commission. Organizations determine what is considered a sufficient degree of separation between primary and alternate storage sites based on the types of threats that are of concern. For threats such as hostile attacks, the degree of separation between sites is less relevant.",
          "Contingency planning. Telecommunications services. Establish alternate telecommunications services, including necessary agreements to permit the resumption of [assignment: organization-defined system operations] for essential mission and business functions within [assignment: organization-defined time period], when the primary telecommunications capabilities are unavailable at either the primary or alternate processing or storage sites. \n\nTelecommunications services (for data and voice) for primary and alternate processing and storage sites are in scope for CP-8. Alternate telecommunications services reflect the continuity requirements in contingency plans to maintain essential mission and business functions despite the loss of primary telecommunications services. \n\nOrganizations may specify different time periods for primary or alternate sites. Alternate telecommunications services include additional organizational or commercial ground-based circuits or lines, network-based approaches to telecommunications, or the use of satellites. Organizations consider factors such as availability, quality of service, and access when entering into alternate telecommunications agreements.",
          "Contingency planning. System backup | transfer to alternate storage site. Transfer system backup information to the alternate storage site. [Assignment: Organization-defined time period and transfer rate consistent with the recovery time and recovery point objectives.] System backup information can be transferred to alternate storage sites either electronically or by the physical shipment of storage media.",
          "Contingency planning. System backup | test restoration using sampling. Use a sample of backup information in the restoration of selected system functions as part of contingency plan testing. Organizations need assurance that system functions can be restored correctly and can support established organizational missions. \n\nTo ensure that the selected system functions are thoroughly exercised during contingency plan testing, a sample of backup information is retrieved to determine whether the functions are operating as intended. \n\nOrganizations can determine the sample size for the functions and backup information based on the level of assurance needed.",
          "Contingency planning. Telecommunications services | priority of service provisions. (a) Develop primary and alternate telecommunications service agreements that contain priority-of-service provisions in accordance with availability requirements (including recovery time objectives). (b) Request telecommunications service priority for all telecommunications services used for national security emergency preparedness if the primary and/or alternate telecommunications services are provided by a common carrier. Organizations should consider the potential mission or business impact in situations where telecommunications service providers are servicing other organizations with similar priority of service provisions.\n\nTelecommunications Service Priority (TSP) is a Federal Communications Commission (FCC) program that directs telecommunications service providers (e.g., wireline and wireless phone companies) to give preferential treatment to users enrolled in the program when they need to add new lines or have their lines restored following a disruption of service, regardless of the cause. The FCC sets the rules and policies for the TSP program, and the Department of Homeland Security manages the TSP program. The TSP program is always in effect and not contingent on a major disaster or attack taking place. Federal sponsorship is required to enroll in the TSP program.",
          "Contingency planning. Contingency plan | capacity planning. Conduct capacity planning so that necessary capacity for information processing, telecommunications, and environmental support exists during contingency operations. Capacity planning is needed because different threats can result in a reduction of the available processing, telecommunications, and support services intended to support essential mission and business functions. Organizations anticipate degraded operations during contingency operations and factor the degradation into capacity planning. For capacity planning, environmental support refers to any environmental factor for which the organization determines that it needs to provide support in a contingency situation, even if in a degraded state. Such determinations are based on an organizational assessment of risk, system categorization (impact level), and organizational risk tolerance.",
          "Contingency planning. Contingency plan. A. Develop a contingency plan for the system that:\n1. Identifies essential mission and business functions and associated contingency requirements.\n2. Provides recovery objectives, restoration priorities, and metrics.\n3. Addresses contingency roles, responsibilities, assigned individuals with contact information.\n4. Addresses maintaining essential mission and business functions despite a system disruption, compromise, or failure.\n5. Addresses eventual, full system restoration without deterioration of the controls originally planned and implemented.\n6. Addresses the sharing of contingency information.\n7. Is reviewed and approved by [Assignment: organization-defined personnel or roles].\n\nB. Distribute copies of the contingency plan to [Assignment: organization-defined key contingency personnel (identified by name and/or by role) and organizational elements].\n\nC. Coordinate contingency planning activities with incident handling activities.\n\nD. Review the contingency plan for the system [Assignment: organization-defined frequency].\n\nE. Update the contingency plan to address changes to the organization, system, or environment of operation and problems encountered during contingency plan implementation, execution, or testing.\n\nF. Communicate contingency plan changes to [Assignment: organization-defined key contingency personnel (identified by name and/or by role) and organizational elements].\n\nG. Incorporate lessons learned from contingency plan testing, training, or actual contingency activities into contingency testing and training.\n\nH. Protect the contingency plan from unauthorized disclosure and modification.\n\nContingency planning for systems is part of an overall program for achieving continuity of operations for organizational mission and business functions. Contingency planning addresses system restoration and implementation of alternative mission or business processes when systems are compromised or breached. Contingency planning is considered throughout the system development life cycle and is a fundamental part of the system design. Systems can be designed for redundancy, to provide backup capabilities, and for resilience. \n\nContingency plans reflect the degree of restoration required for organizational systems since not all systems need to fully recover to achieve the level of continuity of operations desired. System recovery objectives reflect applicable laws, executive orders, directives, regulations, policies, standards, guidelines, organizational risk tolerance, and system impact level. Actions addressed in contingency plans include orderly system degradation, system shutdown, fallback to a manual mode, alternate information flows, and operating in modes reserved for when systems are under attack. \n\nBy coordinating contingency planning with incident handling activities, organizations ensure that the necessary planning activities are in place and activated in the event of an incident. Organizations consider whether continuity of operations during an incident conflicts with the capability to automatically disable the system, as specified in IR-4 (5). Incident response planning is part of contingency planning for organizations and is addressed in the IR (incident response) family.",
          "Contingency planning. System recovery and reconstitution. Provide for the recovery and reconstitution of the system to a known state within [assignment: organization-defined time period consistent with recovery time and recovery point objectives] after a disruption, compromise, or failure. Recovery is executing contingency plan activities to restore organizational mission and business functions. Reconstitution takes place following recovery and includes activities for returning systems to fully operational states. Recovery and reconstitution operations reflect mission and business priorities; recovery point, recovery time, and reconstitution objectives; and organizational metrics consistent with contingency plan requirements. Reconstitution includes the deactivation of interim system capabilities that may have been needed during recovery operations. Reconstitution also includes assessments of fully restored system capabilities, reestablishment of continuous monitoring activities, system reauthorization (if required), and activities to prepare the system and organization for future disruptions, breaches, compromises, or failures. Recovery and reconstitution capabilities can include automated mechanisms and manual procedures. Organizations establish recovery time and recovery point objectives as part of contingency planning.",
          "Contingency planning. Alternate processing site | priority of service. Develop alternate processing site agreements that contain priority-of-service provisions in accordance with availability requirements (including recovery time objectives). Priority of service agreements refer to negotiated agreements with service providers that ensure organizations receive priority treatment consistent with their availability requirements and the availability of information resources for logical alternate processing and/or at the physical alternate processing site. Organizations establish recovery time objectives as part of contingency planning.",
          "Contingency planning. System recovery and reconstitution | transaction recovery. Implement transaction recovery for systems that are transaction-based. Transaction-based systems include database management systems and transaction processing systems. Mechanisms supporting transaction recovery include transaction rollback and transaction journaling.",
          "Contingency planning. Telecommunications services | provider contingency plan. (a) Require primary and alternate telecommunications service providers to have contingency plans. \n(b) Review provider contingency plans to ensure that the plans meet organizational contingency requirements. \n(c) Obtain evidence of contingency testing and training by providers [assignment: organization-defined frequency]. Reviews of provider contingency plans consider the proprietary nature of such plans. In some situations, a summary of provider contingency plans may be sufficient evidence for organizations to satisfy the review requirement. Telecommunications service providers may also participate in ongoing disaster recovery exercises in coordination with the Department of Homeland Security and state and local governments. Organizations may use these types of activities to satisfy evidentiary requirements related to service provider contingency plan reviews, testing, and training.",
          "Contingency planning. System backup. a. Conduct backups of user-level information contained in [assignment: organization-defined system components] [assignment: organization-defined frequency consistent with recovery time and recovery point objectives].\nb. Conduct backups of system-level information contained in the system [assignment: organization-defined frequency consistent with recovery time and recovery point objectives].\nc. Conduct backups of system documentation, including security- and privacy-related documentation [assignment: organization-defined frequency consistent with recovery time and recovery point objectives].\nd. Protect the confidentiality, integrity, and availability of backup information. System-level information includes system state information, operating system software, middleware, application software, and licenses. User-level information includes information other than system-level information. Mechanisms employed to protect the integrity of system backups include digital signatures and cryptographic hashes. Protection of system backup information while in transit is addressed by mp-5 and sc-8. System backups reflect the requirements in contingency plans as well as other organizational requirements for backing up information. Organizations may be subject to laws, executive orders, directives, regulations, or policies with requirements regarding specific categories of information (e.g., personal health information). Organizational personnel consult with the senior agency official for privacy and legal counsel regarding such requirements.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "2_contingency_alternate_site",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "2_contingency_alternate_site"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          3.6814703941345215,
          3.884962558746338,
          3.1726253032684326,
          3.111062526702881,
          3.4910073280334473,
          3.098470449447632,
          3.1378085613250732,
          3.2828195095062256,
          3.327982187271118,
          3.6020052433013916,
          3.165253162384033,
          3.49115252494812,
          3.3439383506774902,
          3.592747449874878,
          3.607041835784912,
          3.4848573207855225,
          3.454744577407837,
          3.1872804164886475,
          3.1958911418914795,
          3.2710533142089844,
          3.8891522884368896,
          3.6493465900421143,
          3.5618348121643066,
          3.1931746006011963,
          3.729557514190674,
          3.6671481132507324,
          3.1817739009857178,
          3.236361265182495,
          3.246959924697876,
          3.518369436264038,
          3.434476852416992,
          3.554508686065674,
          3.1301329135894775,
          3.8698151111602783,
          3.42490553855896
         ],
         "y": [
          0.6451022028923035,
          0.7684427499771118,
          0.952076256275177,
          1.0311858654022217,
          0.5343798995018005,
          1.0031260251998901,
          0.8993411064147949,
          0.870299756526947,
          0.6265866160392761,
          0.478844553232193,
          0.9581590890884399,
          0.4613823890686035,
          1.2287132740020752,
          0.8093135952949524,
          0.4244471788406372,
          0.481460839509964,
          0.5302476286888123,
          0.606696605682373,
          0.6086909770965576,
          1.0166233777999878,
          0.8892938494682312,
          0.5682787895202637,
          0.44627365469932556,
          0.6188663244247437,
          0.637231707572937,
          0.9017760157585144,
          0.6238880157470703,
          0.8756324648857117,
          1.0551990270614624,
          0.8733108639717102,
          0.5712961554527283,
          0.8447997570037842,
          0.8171409368515015,
          0.8718617558479309,
          0.7508814930915833
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Physical and environmental protection. Location of system components. Position system components within the facility to minimize potential damage from physical and environmental hazards, such as floods, fires, tornadoes, earthquakes, hurricanes, terrorism, vandalism, an electromagnetic pulse, electrical interference, and other forms of incoming electromagnetic radiation. Also, consider the location of entry points where unauthorized individuals may be near systems, even if they are not granted access. Such proximity can increase the risk of unauthorized access to organizational communications using wireless packet sniffers or microphones, or unauthorized disclosure of information.",
          "Physical and environmental protection. Fire protection. Employ and maintain fire detection and suppression systems that are supported by an independent energy source. The provision of fire detection and suppression systems applies primarily to organizational facilities that contain concentrations of system resources, including data centers, server rooms, and mainframe computer rooms. Fire detection and suppression systems that may require an independent energy source include sprinkler systems and smoke detectors. An independent energy source is an energy source, such as a microgrid, that is separate or can be separated from the energy sources providing power for the other parts of the facility.",
          "Physical and environmental protection. Access control for output devices. Control physical access to output from [assignment: organization-defined output devices] to prevent unauthorized individuals from obtaining the output. Controlling physical access to output devices includes placing output devices in locked rooms or other secured areas with keypad or card reader access controls and allowing access to authorized individuals only. Also, placing output devices in locations that can be monitored by personnel, installing monitor or screen filters, and using headphones. Examples of output devices include monitors, printers, scanners, audio devices, facsimile machines, and copiers.",
          "Physical and environmental protection. Fire protection | detection systems — automatic activation and notification. Employ fire detection systems that activate automatically and notify [organization-defined personnel or roles] and [organization-defined emergency responders] in the event of a fire. Organizations can identify personnel, roles, and emergency responders. If individuals on the notification list need access authorizations or clearances (e.g., to enter facilities where access is restricted due to the classification or impact level of information within the facility), organizations can include them. Notification mechanisms may require independent energy sources to ensure that the notification capability is not adversely affected by the fire.",
          "Physical and environmental protection. Physical access authorizations. a. Develop, approve, and maintain a list of individuals with authorized access to the facility where the system resides. \nb. Issue authorization credentials for facility access. \nc. Review the access list detailing authorized facility access by individuals [assignment: organization-defined frequency]. \nd. Remove individuals from the facility access list when access is no longer required. \nPhysical access authorizations apply to employees and visitors. Individuals with permanent physical access authorization credentials are not considered visitors. Authorization credentials include ID badges, identification cards, and smart cards. Organizations determine the strength of authorization credentials needed consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Physical access authorizations may not be necessary to access certain areas within facilities that are designated as publicly accessible.",
          "Access control. Access enforcement. Enforce approved authorizations for logical access to information and system resources in accordance with applicable access control policies. Access control policies control access between active entities or subjects (i.e., users or processes acting on behalf of users) and passive entities or objects (i.e., devices, files, records, domains) in organizational systems. In addition to enforcing authorized access at the system level and recognizing that systems can host many applications and services in support of mission and business functions, access enforcement mechanisms can also be employed at the application and service level to provide increased information security and privacy. In contrast to logical access controls that are implemented within the system, physical access controls are addressed by the controls in the Physical and Environmental Protection (PE) family.",
          "Physical and environmental protection. Delivery and removal. a. Authorize and control [assignment: organization-defined types of system components] entering and exiting the facility; and b. Maintain records of the system components. Enforcing authorizations for entry and exit of system components may require restricting access to delivery areas and isolating the areas from the system and media libraries.",
          "Access control. Wireless access | disable wireless networking. Disable, when not intended for use, wireless networking capabilities embedded within system components prior to issuance and deployment. Wireless networking capabilities that are embedded within system components represent a significant potential vulnerability that can be exploited by adversaries. Disabling wireless capabilities when not needed for essential organizational missions or functions can reduce susceptibility to threats by adversaries involving wireless technologies.",
          "Physical and environmental protection. Access control for transmission. Control physical access to [assignment: organization-defined system distribution and transmission lines] within organizational facilities using [assignment: organization-defined security controls]. Security controls applied to system distribution and transmission lines prevent accidental damage, disruption, and physical tampering. Such controls may also be necessary to prevent eavesdropping or modification of unencrypted transmissions. Security controls used to control physical access to system distribution and transmission lines include disconnected or locked spare jacks, locked wiring closets, protection of cabling by conduit or cable trays, and wiretapping sensors.",
          "Physical and environmental protection. Physical access control. A. Enforce physical access authorizations at [assignment: organization-defined entry and exit points to the facility where the system resides] by:\n\n1. Verifying individual access authorizations before granting access to the facility.\n2. Controlling ingress and egress to the facility using [selection (one or more): [assignment: organization-defined physical access control systems or devices] or guards].\n\nB. Maintain physical access audit logs for [assignment: organization-defined entry or exit points].\n\nC. Control access to areas within the facility designated as publicly accessible by implementing the following controls: [assignment: organization-defined physical access controls].\n\nD. Escort visitors and control visitor activity [assignment: organization-defined circumstances requiring visitor escorts and control of visitor activity].\n\nE. Secure keys, combinations, and other physical access devices.\n\nF. Inventory [assignment: organization-defined physical access devices] every [assignment: organization-defined frequency].\n\nG. Change combinations and keys [assignment: organization-defined frequency] and/or when keys are lost, combinations are compromised, or when individuals possessing the keys or combinations are transferred or terminated.\n\nPhysical access control applies to employees and visitors. Individuals with permanent physical access authorizations are not considered visitors.\n\nPhysical access controls for publicly accessible areas may include physical access control logs/records, guards, or physical access devices and barriers to prevent movement from publicly accessible areas to non-public areas.\n\nOrganizations determine the types of guards needed, including professional security staff, system users, or administrative staff. Physical access devices include keys, locks, combinations, biometric readers, and card readers.\n\nPhysical access control systems comply with applicable laws, executive orders, directives, policies, regulations, standards, and guidelines. Organizations have flexibility in the types of audit logs employed. Audit logs can be procedural, automated, or some combination thereof.\n\nPhysical access points can include facility access points, interior access points to systems that require supplemental access controls, or both. Components of systems may be in areas designated as publicly accessible with organizations controlling access to the components.",
          "Physical and environmental protection. Emergency power. Provide an uninterruptible power supply to facilitate an orderly shutdown of the system or transition of the system to long-term alternate power in the event of a primary power source loss. An uninterruptible power supply (UPS) is an electrical system or mechanism that provides emergency power when there is a failure of the main power source. A UPS is typically used to protect computers, data centers, telecommunication equipment, or other electrical equipment where an unexpected power disruption could cause injuries, fatalities, serious mission or business disruption, or loss of data or information. A UPS differs from an emergency power system or backup generator in that the UPS provides near-instantaneous protection from unanticipated power interruptions from the main power source by providing energy stored in batteries, supercapacitors, or flywheels. The battery duration of a UPS is relatively short but provides sufficient time to start a standby power source, such as a backup generator, or properly shut down the system.",
          "Access control. Wireless access | authentication and encryption. Protect wireless access to the system using authentication of users and encryption. Wireless networking capabilities represent a significant potential vulnerability that can be exploited by adversaries. To protect systems with wireless access points, strong authentication of users and devices, along with strong encryption, can reduce susceptibility to threats by adversaries involving wireless technologies.",
          "Access control. Device lock | pattern-hiding displays. Conceal, via the device lock, information previously visible on the display with a publicly viewable image. The pattern-hiding display can include static or dynamic images, such as patterns used with screen savers, photographic images, solid colors, clock, battery life indicator, or a blank screen. Controlled unclassified information is not displayed.",
          "Physical and environmental protection. Emergency power | alternate power supply — minimal operational capability. Provide an alternate power supply for the system that is activated [selection: manually; automatically] and that can maintain minimally required operational capability in the event of an extended loss of the primary power source. Provision of an alternate power supply with minimal operating capability can be satisfied by accessing a secondary commercial power supply or other external power supply.",
          "Physical and environmental protection. Monitoring physical access. a. Monitor physical access to the facility where the system resides to detect and respond to physical security incidents. \nb. Review physical access logs [assignment: organization-defined frequency] and upon occurrence of [assignment: organization-defined events or potential indications of events].\nc. Coordinate results of reviews and investigations with the organizational incident response capability.\n\nPhysical access monitoring includes publicly accessible areas within organizational facilities. Examples of physical access monitoring include the employment of guards, video surveillance equipment (i.e., cameras), and sensor devices. \n\nReviewing physical access logs can help identify suspicious activity, anomalous events, or potential threats. The reviews can be supported by audit logging controls, such as AU-2, if the access logs are part of an automated system.\n\nOrganizational incident response capabilities include investigations of physical security incidents and responses to the incidents. Incidents include security violations or suspicious physical access activities. Suspicious physical access activities include accesses outside of normal work hours, repeated accesses to areas not normally accessed, accesses for unusual lengths of time, and out-of-sequence accesses.",
          "Physical and environmental protection. Fire protection | suppression systems — automatic activation and notification. (a) Employ fire suppression systems that activate automatically and notify [assignment: organization-defined personnel or roles] and [assignment: organization-defined emergency responders]. (b) Employ an automatic fire suppression capability when the facility is not staffed on a continuous basis. Organizations can identify specific personnel, roles, and emergency responders if individuals on the notification list need to have appropriate access authorizations and/or clearances (e.g., to enter facilities where access is restricted due to the impact level or classification of information within the facility). Notification mechanisms may require independent energy sources to ensure that the notification capability is not adversely affected by the fire.",
          "Physical and environmental protection. Monitoring physical access | intrusion alarms and surveillance equipment. Monitor physical access to the facility where the system resides using physical intrusion alarms and surveillance equipment. Physical intrusion alarms can be employed to alert security personnel when unauthorized access to the facility is attempted. Alarm systems work in conjunction with physical barriers, physical access control systems, and security guards by triggering a response when these other forms of security have been compromised or breached. Physical intrusion alarms can include different types of sensor devices, such as motion sensors, contact sensors, and broken glass sensors. Surveillance equipment includes video cameras installed at strategic locations throughout the facility.",
          "Access control. Wireless access. a. Establish configuration requirements, connection requirements, and implementation guidance for each type of wireless access; and b. Authorize each type of wireless access to the system prior to allowing such connections. Wireless technologies include microwave, packet radio (ultra-high frequency or very high frequency), 802.11x, and Bluetooth. Wireless networks use authentication protocols that provide authenticator protection and mutual authentication.",
          "Physical and environmental protection. Environmental controls. a. Maintain [selection (one or more): temperature; humidity; pressure; radiation; [assignment: organization-defined environmental control]] levels within the facility where the system resides at [assignment: organization-defined acceptable levels]. \n\nb. Monitor environmental control levels [assignment: organization-defined frequency]. \n\nThe provision of environmental controls applies primarily to organizational facilities that contain concentrations of system resources (e.g., data centers, mainframe computer rooms, and server rooms). Insufficient environmental controls, especially in very harsh environments, can have a significant adverse impact on the availability of systems and system components that are needed to support organizational mission and business functions.",
          "Access control. Access control for mobile devices | full device or container-based encryption. Employ full-device encryption or container-based encryption to protect the confidentiality and integrity of information on organization-defined mobile devices. Container-based encryption provides a more fine-grained approach to data and information encryption on mobile devices, including encrypting selected data structures such as files, records, or fields.",
          "Physical and environmental protection. Monitoring physical access | monitoring physical access to systems. Monitor physical access to the system, in addition to the physical access monitoring of the facility, at [assignment: organization-defined physical spaces containing one or more components of the system]. Monitoring physical access to systems provides additional monitoring for those areas within facilities where there is a concentration of system components, including server rooms, media storage areas, and communications centers. Physical access monitoring can be coordinated with intrusion detection systems and system monitoring capabilities to provide comprehensive and integrated threat coverage for the organization.",
          "Physical and environmental protection. Emergency shutoff. a. Provide the capability of shutting off power to [assignment: organization-defined system or individual system components] in emergency situations. \nb. Place emergency shutoff switches or devices in [assignment: organization-defined location by system or system component] to facilitate access for authorized personnel. \nc. Protect emergency power shutoff capability from unauthorized activation. \n\nEmergency power shutoff primarily applies to organizational facilities that contain concentrations of system resources, including data centers, mainframe computer rooms, server rooms, and areas with computer-controlled machinery.",
          "Access control. Access control for mobile devices. A. Establish configuration requirements, connection requirements, and implementation guidance for organization-controlled mobile devices, to include when such devices are outside of controlled areas. \nB. Authorize the connection of mobile devices to organizational systems.\n\nA mobile device is a computing device that has a small form factor such that it can easily be carried by a single individual. It is designed to operate without a physical connection, possesses local, non-removable or removable data storage, and includes a self-contained power source. Mobile device functionality may also include voice communication capabilities, on-board sensors that allow the device to capture information, and/or built-in features for synchronizing local data with remote locations. Examples include smartphones and tablets. Mobile devices are typically associated with a single individual. The processing, storage, and transmission capability of the mobile device may be comparable to or merely a subset of notebook/desktop systems, depending on the nature and intended purpose of the device.\n\nProtection and control of mobile devices are behavior or policy-based and require users to take physical action to protect and control such devices when outside of controlled areas. Controlled areas are spaces for which organizations provide physical or procedural controls to meet the requirements established for protecting information and systems. Due to the large variety of mobile devices with different characteristics and capabilities, organizational restrictions may vary for the different classes or types of such devices.\n\nUsage restrictions and specific implementation guidance for mobile devices include:\n- Configuration management\n- Device identification and authentication\n- Implementation of mandatory protective software\n- Scanning devices for malicious code\n- Updating virus protection software\n- Scanning for critical software updates and patches\n- Conducting primary operating system (and possibly other resident software) integrity checks\n- Disabling unnecessary hardware\n\nUsage restrictions and authorization to connect may vary among organizational systems. For example, the organization may authorize the connection of mobile devices to its network and impose a set of usage restrictions, while a system owner may withhold authorization for mobile device connection to specific applications or impose additional usage restrictions before allowing mobile device connections to a system.\n\nAdequate security for mobile devices goes beyond the requirements specified in AC-19. Many safeguards for mobile devices are reflected in other controls. AC-20 addresses mobile devices that are not organization-controlled.",
          "Physical and environmental protection. Water damage protection. Protect the system from damage resulting from water leakage by providing master shutoff or isolation valves that are accessible, working properly, and known to key personnel. The provision of water damage protection primarily applies to organizational facilities that contain concentrations of system resources, including data centers, server rooms, and mainframe computer rooms. Isolation valves can be employed in addition to or in lieu of master shutoff valves to shut off water supplies in specific areas of concern without affecting the entire organization.",
          "Physical and environmental protection. Emergency lighting. Employ and maintain automatic emergency lighting for the system that activates in the event of a power outage or disruption and that covers emergency exits and evacuation routes within the facility. The provision of emergency lighting applies primarily to organizational facilities that contain concentrations of system resources, including data centers, server rooms, and mainframe computer rooms. Emergency lighting provisions for the system are described in the contingency plan for the organization. If emergency lighting for the system fails or cannot be provided, organizations should consider alternate processing sites for power-related contingencies.",
          "Physical and environmental protection. Power equipment and cabling. Protect power equipment and power cabling for the system from damage and destruction. Organizations determine the types of protection necessary for the power equipment and cabling employed at different locations that are both internal and external to organizational facilities and environments of operation. Types of power equipment and cabling include internal cabling and uninterruptible power sources in offices or data centers, generators and power cabling outside of buildings, and power sources for self-contained components such as satellites, vehicles, and other deployable systems.",
          "Physical and environmental protection. Physical access control | system access. Enforce physical access authorizations to the system, in addition to the physical access controls for the facility at [assignment: organization-defined physical spaces containing one or more components of the system]. Control of physical access to the system provides additional physical security for those areas within facilities where there is a concentration of system components.",
          "Access control. Wireless access | restrict configurations by users. Identify and explicitly authorize users allowed to independently configure wireless networking capabilities. Organizational authorizations to allow selected users to configure wireless networking capabilities are enforced, in part, by the access enforcement mechanisms employed within organizational systems.",
          "Physical and environmental protection. Environmental controls | monitoring with alarms and notifications. Employ environmental control monitoring that provides an alarm or notification of changes potentially harmful to personnel or equipment to [assignment: organization-defined personnel or roles]. The alarm or notification may be an audible alarm or a visual message in real-time to personnel or roles defined by the organization. Such alarms and notifications can help minimize harm to individuals and damage to organizational assets by facilitating a timely incident response.",
          "Physical and environmental protection. Water damage protection | automation support. Detect the presence of water near the system and alert [assignment: organization-defined personnel or roles] using [assignment: organization-defined automated mechanisms]. Automated mechanisms include notification systems, water detection sensors, and alarms.",
          "Access control. Device lock. a. Prevent further access to the system by [selection (one or more): initiating a device lock after [assignment: organization-defined time period] of inactivity; requiring the user to initiate a device lock before leaving the system unattended]. \nb. Retain the device lock until the user reestablishes access using established identification and authentication procedures. Device locks are temporary actions taken to prevent logical access to organizational systems when users stop work and move away from the immediate vicinity of those systems but do not want to log out because of the temporary nature of their absences. Device locks can be implemented at the operating system level or at the application level. A proximity lock may be used to initiate the device lock (e.g., via a Bluetooth-enabled device or dongle). User-initiated device locking is behavior or policy-based and, as such, requires users to take physical action to initiate the device lock. Device locks are not an acceptable substitute for logging out of systems, such as when organizations require users to log out at the end of workdays.",
          "Access control. Wireless access | antennas and transmission power levels. Select radio antennas and calibrate transmission power levels to reduce the probability that signals from wireless access points can be received outside of organization-controlled boundaries. Actions that may be taken to limit unauthorized use of wireless communications outside of organization-controlled boundaries include reducing the power of wireless transmissions so that the transmissions are less likely to emit a signal that can be captured outside of the physical perimeters of the organization, employing measures such as emissions security to control wireless emanations, and using directional or beamforming antennas that reduce the likelihood that unintended receivers will be able to intercept signals. Prior to taking such mitigating actions, organizations can conduct periodic wireless surveys to understand the radio frequency profile of organizational systems as well as other systems that may be operating in the area.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "3_physical_access_power",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "3_physical_access_power"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          10.550553321838379,
          10.792082786560059,
          10.484566688537598,
          10.786334991455078,
          10.383496284484863,
          10.250733375549316,
          10.504451751708984,
          9.877123832702637,
          10.492623329162598,
          10.391519546508789,
          10.892863273620605,
          9.83757495880127,
          10.096207618713379,
          10.890002250671387,
          10.621920585632324,
          10.813769340515137,
          10.608710289001465,
          9.867995262145996,
          10.575613021850586,
          9.781608581542969,
          10.601738929748535,
          10.853404998779297,
          9.766535758972168,
          10.755914688110352,
          10.821419715881348,
          10.562376976013184,
          10.43588924407959,
          9.88339900970459,
          10.696276664733887,
          10.743061065673828,
          10.182195663452148,
          9.872307777404785,
          10.427321434020996
         ],
         "y": [
          6.313799858093262,
          5.923996925354004,
          6.39670467376709,
          5.931136608123779,
          6.6882195472717285,
          6.882971286773682,
          6.419083118438721,
          7.303140640258789,
          6.390567779541016,
          6.606625080108643,
          5.746498107910156,
          7.302889823913574,
          7.725436210632324,
          5.75759220123291,
          6.273679256439209,
          5.886056900024414,
          6.262327671051025,
          7.3047776222229,
          6.2737627029418945,
          7.3827433586120605,
          6.321268081665039,
          5.828517436981201,
          7.59547233581543,
          6.012856960296631,
          5.847224712371826,
          6.295423984527588,
          6.484553813934326,
          7.340434551239014,
          6.099854469299316,
          6.024733543395996,
          7.887632369995117,
          7.3020100593566895,
          6.556624889373779
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "System and information integrity. System monitoring | system-generated alerts. Alert [assignment: organization-defined personnel or roles] when the following system-generated indications of compromise or potential compromise occur: [assignment: organization-defined compromise indicators]. Alerts may be generated from a variety of sources, including audit records or inputs from malicious code protection mechanisms, intrusion detection or prevention mechanisms, or boundary protection devices such as firewalls, gateways, and routers. Alerts can be automated and may be transmitted telephonically, by electronic mail messages, or by text messaging. Organizational personnel on the alert notification list can include system administrators, mission or business owners, system owners, information owners/stewards, senior agency information security officers, senior agency officials for privacy, system security officers, or privacy officers. In contrast to alerts generated by the system, alerts generated by organizations in SI-4 (12) focus on information sources external to the system, such as suspicious activity reports and reports on potential insider threats.",
          "System and information integrity. Information input validation. Check the validity of the following information inputs: [assignment: organization-defined information inputs to the system]. Checking the valid syntax and semantics of system inputs - including character set, length, numerical range, and acceptable values - verifies that inputs match specified definitions for format and content. For example, if the organization specifies that numerical values between 1-100 are the only acceptable inputs for a field in a given application, inputs of 387, abc, or %k% are invalid inputs and are not accepted as input to the system. Valid inputs are likely to vary from field to field within a software application. Applications typically follow well-defined protocols that use structured messages (i.e., commands or queries) to communicate between software modules or system components. Structured messages can contain raw or unstructured data interspersed with metadata or control information. If software applications use attacker-supplied inputs to construct structured messages without properly encoding such messages, then the attacker could insert malicious commands or special characters that can cause the data to be interpreted as control information or metadata. Consequently, the module or component that receives the corrupted output will perform the wrong operations or otherwise interpret the data incorrectly. Prescreening inputs prior to passing them to interpreters prevents the content from being unintentionally interpreted as commands. Input validation ensures accurate and correct inputs and prevents attacks such as cross-site scripting and a variety of injection attacks.",
          "System and information integrity. Spam protection | automatic updates. Automatically update spam protection mechanisms [assignment: organization-defined frequency]. Using automated mechanisms to update spam protection mechanisms helps to ensure that updates occur on a regular basis and provide the latest content and protection capabilities.",
          "System and information integrity. System monitoring | risk for individuals. Implement organization-defined additional monitoring of individuals who have been identified by organization-defined sources as posing an increased level of risk. Indications of increased risk from individuals can be obtained from different sources, including personnel records, intelligence agencies, law enforcement organizations, and other sources. The monitoring of individuals is coordinated with the management, legal, security, privacy, and human resource officials who conduct such monitoring. Monitoring is conducted in accordance with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines.",
          "System and information integrity. System monitoring | wireless intrusion detection. Employ a wireless intrusion detection system to identify rogue wireless devices and to detect attack attempts and potential compromises or breaches to the system. Wireless signals may radiate beyond organizational facilities. Organizations proactively search for unauthorized wireless connections, including the conduct of thorough scans for unauthorized wireless access points. Wireless scans are not limited to those areas within facilities containing systems but also include areas outside of facilities to verify that unauthorized wireless access points are not connected to organizational systems.",
          "System and information integrity. Security and privacy function verification. a. Verify the correct operation of [assignment: organization-defined security and privacy functions]. \nb. Perform the verification of the functions specified in si-6a. [Selection (one or more): [assignment: organization-defined system transitional states]; upon command by a user with appropriate privilege; [assignment: organization-defined frequency]].\nc. Alert [assignment: organization-defined personnel or roles] to failed security and privacy verification tests.\nd. [Selection (one or more): Shut the system down; restart the system; [assignment: organization-defined alternative action(s)]] when anomalies are discovered.\n\nTransitional states for systems include system startup, restart, shutdown, and abort. System notifications include hardware indicator lights, electronic alerts to system administrators, and messages to local computer consoles.\n\nIn contrast to security function verification, privacy function verification ensures that privacy functions operate as expected and are approved by the senior agency official for privacy or that privacy attributes are applied or used as expected.",
          "System and information integrity. System monitoring | inbound and outbound communications traffic. (A) Determine criteria for unusual or unauthorized activities or conditions for inbound and outbound communications traffic.\n(B) Monitor inbound and outbound communications traffic [Assignment: organization-defined frequency] for [Assignment: organization-defined unusual or unauthorized activities or conditions].\n\nUnusual or unauthorized activities or conditions related to system inbound and outbound communications traffic include internal traffic that indicates the presence of malicious code or unauthorized use of legitimate code or credentials within organizational systems or propagating among system components, signaling to external systems, and the unauthorized exporting of information. Evidence of malicious code or unauthorized use of legitimate code or credentials is used to identify potentially compromised systems or system components.",
          "System and communications protection. Fail in known state. Failures to achieve a organization-defined known system state for the following failures on the indicated components while preserving organization-defined system state information in failure: (list of organization-defined types of system failures on organization-defined system components). Failure in a known state addresses security concerns in accordance with the mission and business needs of organizations. Failure in a known state prevents the loss of confidentiality, integrity, or availability of information in the event of failures of organizational systems or system components. Failure in a known safe state helps to prevent systems from failing to a state that may cause injury to individuals or destruction to property. Preserving system state information facilitates system restart and return to the operational mode with less disruption of mission and business processes.",
          "System and information integrity. Security alerts, advisories, and directives. a. Receive system security alerts, advisories, and directives from [assignment: organization-defined external organizations] on an ongoing basis. \nb. Generate internal security alerts, advisories, and directives as deemed necessary. \nc. Disseminate security alerts, advisories, and directives to: [selection (one or more): [assignment: organization-defined personnel or roles]; [assignment: organization-defined elements within the organization]; [assignment: organization-defined external organizations]]. \nd. Implement security directives in accordance with established time frames, or notify the issuing organization of the degree of noncompliance. \n\nThe Cybersecurity and Infrastructure Security Agency (CISA) generates security alerts and advisories to maintain situational awareness throughout the federal government. Security directives are issued by OMB or other designated organizations with the responsibility and authority to issue such directives. Compliance with security directives is essential due to the critical nature of many of these directives and the potential (immediate) adverse effects on organizational operations and assets, individuals, other organizations, and the nation should the directives not be implemented in a timely manner. \n\nExternal organizations include supply chain partners, external mission or business partners, external service providers, and other peer or supporting organizations.",
          "System and information integrity. Flaw remediation. a. Identify, report, and correct system flaws.\nb. Test software and firmware updates related to flaw remediation for effectiveness and potential side effects before installation.\nc. Install security-relevant software and firmware updates within [assignment: organization-defined time period] of the release of the updates.\nd. Incorporate flaw remediation into the organizational configuration management process.\n\nThe need to remediate system flaws applies to all types of software and firmware. Organizations identify systems affected by software flaws, including potential vulnerabilities resulting from those flaws, and report this information to designated organizational personnel with information security and privacy responsibilities.\n\nSecurity-relevant updates include patches, service packs, and malicious code signatures. Organizations also address flaws discovered during assessments, continuous monitoring, incident response activities, and system error handling.\n\nBy incorporating flaw remediation into configuration management processes, required remediation actions can be tracked and verified. Organization-defined time periods for updating security-relevant software and firmware may vary based on a variety of risk factors, including the security category of the system, the criticality of the update (i.e., severity of the vulnerability related to the discovered flaw), the organizational risk tolerance, the mission supported by the system, or the threat environment.\n\nSome types of flaw remediation may require more testing than other types. Organizations determine the type of testing needed for the specific type of flaw remediation activity under consideration and the types of changes that are to be configuration-managed. \n\nIn some situations, organizations may determine that the testing of software or firmware updates is not necessary or practical, such as when implementing simple malicious code signature updates. In testing decisions, organizations consider whether security-relevant software or firmware updates are obtained from authorized sources with appropriate digital signatures.",
          "System and information integrity. System monitoring | privileged users. Implement the following additional monitoring of privileged users: [assignment: organization-defined additional monitoring]. Privileged users have access to more sensitive information, including security-related information, than the general user population. Access to such information means that privileged users can potentially do greater damage to systems and organizations than non-privileged users. Therefore, implementing additional monitoring on privileged users helps to ensure that organizations can identify malicious activity at the earliest possible time and take appropriate actions.",
          "System and information integrity. System monitoring | automated tools and mechanisms for real-time analysis. Employ automated tools and mechanisms to support near real-time analysis of events. Automated tools and mechanisms include host-based, network-based, transport-based, or storage-based event monitoring tools and mechanisms or security information and event management (SIEM) technologies that provide real-time analysis of alerts and notifications generated by organizational systems. Automated monitoring techniques can create unintended privacy risks because automated controls may connect to external or otherwise unrelated systems. The matching of records between these systems may create linkages with unintended consequences. Organizations assess and document these risks in their Privacy Impact Assessment and make determinations that are in alignment with their privacy program plan.",
          "System and information integrity. System monitoring | correlate monitoring information. Correlating information from monitoring tools and mechanisms employed throughout the system is crucial. Doing so can provide a more comprehensive view of system activity. It allows for the identification of attack patterns that may otherwise go unnoticed. To achieve this, it is important to understand the capabilities and limitations of diverse monitoring tools and mechanisms. By maximizing the use of the information generated by these tools, organizations can develop, operate, and maintain effective monitoring programs. This correlation of monitoring information becomes even more critical during technology transitions, such as the shift from IPv4 to IPv6 network protocols.",
          "System and information integrity. System monitoring | analyze communications traffic anomalies. Analyze outbound communications traffic at the external interfaces to the system and selected (organization-defined interior points within the system) to discover anomalies. Organization-defined interior points include subnetworks and subsystems. Anomalies within organizational systems include large file transfers, long-time persistent connections, attempts to access information from unexpected locations, the use of unusual protocols and ports, the use of unmonitored network protocols (e.g., IPv6 usage during IPv4 transition), and attempted communications with suspected malicious external addresses.",
          "System and information integrity. Flaw remediation | automated flaw remediation status. Determine if system components have applicable security-relevant software and firmware updates installed using [assignment: organization-defined automated mechanisms]. [Assignment: Organization-defined frequency]. Automated mechanisms can track and determine the status of known flaws for system components.",
          "System and information integrity. System monitoring | system-wide intrusion detection system. Connect and configure individual intrusion detection tools into a system-wide intrusion detection system. Linking individual intrusion detection tools into a system-wide intrusion detection system provides additional coverage and effective detection capabilities. The information contained in one intrusion detection tool can be shared widely across the organization, making the system-wide detection capability more robust and powerful.",
          "System and information integrity. System monitoring. A. Monitor the system to detect:\n1. Attacks and indicators of potential attacks in accordance with the following monitoring objectives: [Assignment: organization-defined monitoring objectives].\n2. Unauthorized local, network, and remote connections.\n\nB. Identify unauthorized use of the system through the following techniques and methods: [Assignment: organization-defined techniques and methods].\n\nC. Invoke internal monitoring capabilities or deploy monitoring devices:\n1. Strategically within the system to collect organization-determined essential information.\n2. At ad hoc locations within the system to track specific types of transactions of interest to the organization.\n\nD. Analyze detected events and anomalies.\n\nE. Adjust the level of system monitoring activity when there is a change in risk to organizational operations and assets, individuals, other organizations, or the nation.\n\nF. Obtain a legal opinion regarding system monitoring activities.\n\nG. Provide [Assignment: organization-defined system monitoring information] to [Assignment: organization-defined personnel or roles] [Selection (one or more): as needed; [Assignment: organization-defined frequency]].\n\nSystem monitoring includes external and internal monitoring. External monitoring includes the observation of events occurring at external interfaces to the system. Internal monitoring includes the observation of events occurring within the system. Organizations monitor systems by observing audit activities in real-time or by observing other system aspects such as access patterns, characteristics of access, and other actions. The monitoring objectives guide and inform the determination of the events.\n\nSystem monitoring capabilities are achieved through a variety of tools and techniques, including intrusion detection and prevention systems, malicious code protection software, scanning tools, audit record monitoring software, and network monitoring software. Depending on the security architecture, the distribution and configuration of monitoring devices may impact throughput at key internal and external boundaries as well as at other locations across a network due to the introduction of network throughput latency. If throughput management is needed, such devices are strategically located and deployed as part of an established organization-wide security architecture. Strategic locations for monitoring devices include selected perimeter locations and near key servers and server farms that support critical applications. Monitoring devices are typically employed at the managed interfaces associated with controls SC-7 and AC-17.\n\nThe information collected is a function of the organizational monitoring objectives and the capability of systems to support such objectives. Specific types of transactions of interest include Hypertext Transfer Protocol (HTTP) traffic that bypasses HTTP proxies. System monitoring is an integral part of organizational continuous monitoring and incident response programs, and output from system monitoring serves as input to those programs.\n\nSystem monitoring requirements, including the need for specific types of system monitoring, may be referenced in other controls (e.g., AC-2g, AC-2 (7), AC-2 (12) (a), AC-17 (1), AU-13, AU-13 (1), AU-13 (2), CM-3f, CM-6d, MA-3a, MA-4a, SC-5 (3) (b), SC-7a, SC-7 (24) (b), SC-18b, SC-43b). Adjustments to levels of system monitoring are based on law enforcement information, intelligence information, or other sources of information.\n\nThe legality of system monitoring activities is based on applicable laws, executive orders, directives, regulations, policies, standards, and guidelines.",
          "System and information integrity. Software, firmware, and information integrity | automated response to integrity violations. Automatically [selection: shut the system down; restart the system; implement [assignment: organization-defined controls]] when integrity violations are discovered. Organizations may define different integrity checking responses by type of information, specific information, or a combination of both. Types of information include firmware, software, and user data. Specific information includes boot firmware for certain types of machines. The automatic implementation of controls within organizational systems includes reversing the changes, halting the system, or triggering audit alerts when unauthorized modifications to critical security files occur.",
          "System and information integrity. System monitoring | host-based devices. Implement the following host-based monitoring mechanisms at [assignment: organization-defined system components]: [assignment: organization-defined host-based monitoring mechanisms]. Host-based monitoring collects information about the host (or system in which it resides). System components in which host-based monitoring can be implemented include servers, notebook computers, and mobile devices. Organizations may consider employing host-based monitoring mechanisms from multiple product developers or vendors.",
          "System and information integrity. Error handling. a. Generate error messages that provide information necessary for corrective actions without revealing information that could be exploited, and \nb. Reveal error messages only to organization-defined personnel or roles. Organizations should consider the structure and content of error messages. The extent to which systems can handle error conditions is guided and informed by organizational policy and operational requirements. Exploitable information includes stack traces and implementation details. Erroneous logon attempts with passwords mistakenly entered as the username, mission or business information that can be derived from, if not stated explicitly by, the information recorded, and personally identifiable information such as account numbers, social security numbers, and credit card numbers. Error messages may also provide a covert channel for transmitting information.",
          "System and information integrity. System monitoring | automated organization-generated alerts. Alert [assignment: organization-defined personnel or roles] using [assignment: organization-defined automated mechanisms] when the following indications of inappropriate or unusual activities with security or privacy implications occur: [assignment: organization-defined activities that trigger alerts]. Organizational personnel on the system alert notification list include system administrators, mission or business owners, system owners, senior agency information security officer, senior agency official for privacy, system security officers, or privacy officers. Automated organization-generated alerts are the security alerts generated by organizations and transmitted using automated means. The sources for organization-generated alerts are focused on other entities such as suspicious activity reports and reports on potential insider threats. In contrast to alerts generated by the organization, alerts generated by the system in SI-4 (5) focus on information sources that are internal to the systems, such as audit records.",
          "System and information integrity. Software, firmware, and information integrity | automated notifications of integrity violations. Employ automated tools that provide notification to [assignment: organization-defined personnel or roles] upon discovering discrepancies during integrity verification. The employment of automated tools to report system and information integrity violations and to notify organizational personnel in a timely manner is essential to effective risk response. Personnel with an interest in system and information integrity violations include mission and business owners, system owners, senior agency information security official, senior agency official for privacy, system administrators, software developers, systems integrators, information security officers, and privacy officers.",
          "System and information integrity. Software, firmware, and information integrity | integration of detection and response. Incorporate the detection of the following unauthorized changes into the organizational incident response capability: [assignment: organization-defined security-relevant changes to the system]. Integrating detection and response helps to ensure that detected events are tracked, monitored, corrected, and available for historical purposes. Maintaining historical records is important for being able to identify and discern adversary actions over an extended time period and for possible legal actions. Security-relevant changes include unauthorized changes to established configuration settings or the unauthorized elevation of system privileges.",
          "System and information integrity. System monitoring | visibility of encrypted communications. Make provisions so that [assignment: organization-defined encrypted communications traffic] is visible to [assignment: organization-defined system monitoring tools and mechanisms]. Organizations balance the need to encrypt communications traffic to protect data confidentiality with the need to maintain visibility into such traffic from a monitoring perspective. Organizations determine whether the visibility requirement applies to internal encrypted traffic, encrypted traffic intended for external destinations, or a subset of the traffic types.",
          "System and information integrity. System monitoring | unauthorized network services. (a) Detect network services that have not been authorized or approved by [assignment: organization-defined authorization or approval processes]; and (b) [selection (one or more): audit; alert [assignment: organization-defined personnel or roles]] when detected. Unauthorized or unapproved network services include services in service-oriented architectures that lack organizational verification or validation and may therefore be unreliable or serve as malicious rogues for valid services.",
          "System and information integrity. Flaw remediation | time to remediate flaws and benchmarks for corrective actions. (a) Measure the time between flaw identification and flaw remediation. \n(b) Establish the following benchmarks for taking corrective actions: [assignment: organization-defined benchmarks]. \n\nOrganizations determine the average time it takes to correct system flaws after they have been identified. Subsequently, they establish organizational benchmarks (i.e., time frames) for taking corrective actions. Benchmarks can be determined based on the type of flaw or the severity of the potential vulnerability, especially if the flaw can be exploited.",
          "System and information integrity. Security alerts, advisories, and directives | automated alerts and advisories. Broadcast security alert and advisory information throughout the organization using organization-defined automated mechanisms. The significant number of changes to organizational systems and environments of operation requires the dissemination of security-related information to a variety of organizational entities that have a direct interest in the success of the organizational mission and business functions. Based on information provided by security alerts and advisories, changes may be required at one or more of the three levels related to the management of risk, including the governance level, mission and business process level, and the information system level.",
          "System and information integrity. Software, firmware, and information integrity | integrity checks. Perform an integrity check of organization-defined software, firmware, and information at startup. At organization-defined transitional states or security-relevant events, perform an integrity check. Perform an integrity check at organization-defined frequency. Security-relevant events include the identification of new threats to which organizational systems are susceptible and the installation of new hardware, software, or firmware. Transitional states include system startup, restart, shutdown, and abort.",
          "System and information integrity. Malicious code protection. A. Implement [selection (one or more): signature-based; non-signature-based] malicious code protection mechanisms at system entry and exit points to detect and eradicate malicious code. \nB. Automatically update malicious code protection mechanisms as new releases are available in accordance with organizational configuration management policy and procedures. \nC. Configure malicious code protection mechanisms to: \n1. Perform periodic scans of the system [assignment: organization-defined frequency] and real-time scans of files from external sources at [selection (one or more): endpoint; network entry and exit points] as the files are downloaded, opened, or executed in accordance with organizational policy. \n2. [selection (one or more): block malicious code; quarantine malicious code; take [assignment: organization-defined action]]; and send an alert to [assignment: organization-defined personnel or roles] in response to malicious code detection. \nD. Address the receipt of false positives during malicious code detection and eradication and the resulting potential impact on the availability of the system. \n\nSystem entry and exit points include firewalls, remote access servers, workstations, electronic mail servers, web servers, proxy servers, notebook computers, and mobile devices. \n\nMalicious code includes viruses, worms, trojan horses, and spyware. Malicious code can also be encoded in various formats contained within compressed or hidden files or hidden in files using techniques such as steganography. Malicious code can be inserted into systems in a variety of ways, including by electronic mail, the world-wide web, and portable storage devices. Malicious code insertions occur through the exploitation of system vulnerabilities. \n\nA variety of technologies and methods exist to limit or eliminate the effects of malicious code. Malicious code protection mechanisms include both signature- and non-signature-based technologies. Non-signature-based detection mechanisms include artificial intelligence techniques that use heuristics to detect, analyze, and describe the characteristics or behavior of malicious code and to provide controls against such code for which signatures do not yet exist or for which existing signatures may not be effective. Malicious code for which active signatures do not yet exist or may be ineffective includes polymorphic malicious code (i.e., code that changes signatures when it replicates). Non-signature-based mechanisms also include reputation-based technologies. \n\nIn addition to the above technologies, pervasive configuration management, comprehensive software integrity controls, and anti-exploitation software may be effective in preventing the execution of unauthorized code. Malicious code may be present in commercial off-the-shelf software as well as custom-built software and could include logic bombs, backdoors, and other types of attacks that could affect organizational mission and business functions. \n\nIn situations where malicious code cannot be detected by detection methods or technologies, organizations rely on other types of controls, including secure coding practices, configuration management and control, trusted procurement processes, and monitoring practices to ensure that software does not perform functions other than the functions intended. \n\nOrganizations may determine that, in response to the detection of malicious code, different actions may be warranted. For example, organizations can define actions in response to malicious code detection during periodic scans, the detection of malicious downloads, or the detection of maliciousness when attempting to open or execute files.",
          "System and information integrity. System monitoring | analyze traffic and covert exfiltration. Analyze outbound communications traffic at external interfaces to the system and at the following interior points to detect covert exfiltration of information: [assignment: organization-defined interior points within the system]. Organization-defined interior points include subnetworks and subsystems. Covert means that can be used to exfiltrate information include steganography.",
          "System and information integrity. Software, firmware, and information integrity. a. Employ integrity verification tools to detect unauthorized changes to the following software, firmware, and information: [assignment: organization-defined software, firmware, and information]. \nb. Take the following actions when unauthorized changes to the software, firmware, and information are detected: [assignment: organization-defined actions]. Unauthorized changes to software, firmware, and information can occur due to errors or malicious activity. Software includes operating systems (with key internal components such as kernels or drivers), middleware, and applications. Firmware interfaces include Unified Extensible Firmware Interface (UEFI) and Basic Input/Output System (BIOS). Information includes personally identifiable information and metadata that contains security and privacy attributes associated with information. Integrity checking mechanisms, including parity checks, cyclical redundancy checks, cryptographic hashes, and associated tools, can automatically monitor the integrity of systems and hosted applications.",
          "System and information integrity. Software, firmware, and information integrity | code authentication. Implement cryptographic mechanisms to authenticate the following software or firmware components prior to installation: [assignment: organization-defined software or firmware components]. Cryptographic authentication includes verifying that software or firmware components have been digitally signed using certificates recognized and approved by organizations. Code signing is an effective method to protect against malicious code. Organizations that employ cryptographic mechanisms also consider cryptographic key management solutions.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "4_system_integrity_monitoring",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "4_system_integrity_monitoring"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          7.076810359954834,
          7.477659225463867,
          7.9650187492370605,
          6.962697505950928,
          6.697235107421875,
          7.316573619842529,
          6.651315212249756,
          7.590707302093506,
          7.114659786224365,
          7.416479587554932,
          6.81449556350708,
          7.078733444213867,
          6.7013959884643555,
          6.668591499328613,
          7.441189289093018,
          6.733031749725342,
          6.766519546508789,
          7.482058048248291,
          6.756096839904785,
          7.467713832855225,
          7.113202095031738,
          7.429328441619873,
          7.411501884460449,
          6.631280422210693,
          6.65991735458374,
          7.423799991607666,
          7.122522830963135,
          7.467753887176514,
          8.001606941223145,
          6.678895950317383,
          7.4556684494018555,
          7.488464832305908,
          7.15821647644043
         ],
         "y": [
          5.9837775230407715,
          5.435802936553955,
          5.3405890464782715,
          5.902277946472168,
          5.7618727684021,
          5.653935432434082,
          5.674053192138672,
          5.465771198272705,
          6.123036861419678,
          5.370394706726074,
          5.812732696533203,
          5.970407485961914,
          5.698208332061768,
          5.690629959106445,
          5.410129547119141,
          5.74354362487793,
          5.703808784484863,
          5.415208339691162,
          5.6317620277404785,
          5.426608562469482,
          5.9940266609191895,
          5.451301097869873,
          5.41339111328125,
          5.638301372528076,
          5.6737260818481445,
          5.389643669128418,
          6.095227241516113,
          5.420010089874268,
          5.342708587646484,
          5.69356632232666,
          5.4224724769592285,
          5.419065952301025,
          5.630249500274658
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Identification and authentication. Cryptographic module authentication. Implement mechanisms for authentication to a cryptographic module that meet the requirements of applicable laws, executive orders, directives, policies, regulations, standards, and guidelines for such authentication. Authentication mechanisms may be required within a cryptographic module to authenticate an operator accessing the module and to verify that the operator is authorized to assume the requested role and perform services within that role.",
          "Identification and authentication. Identification and authentication (non-organizational users). Uniquely identify and authenticate non-organizational users or processes acting on behalf of non-organizational users. Non-organizational users include system users other than organizational users explicitly covered by IA-2. Non-organizational users are uniquely identified and authenticated for accesses other than those explicitly identified and documented in AC-14. Identification and authentication of non-organizational users accessing federal systems may be required to protect federal, proprietary, or privacy-related information (with exceptions noted for national security systems).\n\nOrganizations consider many factors – including security, privacy, scalability, and practicality – when balancing the need to ensure ease of use for access to federal information and systems with the need to protect and adequately mitigate risk.",
          "Identification and authentication. Authenticator management | password-based authentication. For password-based authentication: \n\n(a) Maintain a list of commonly-used, expected, or compromised passwords and update the list [assignment: organization-defined frequency] and when organizational passwords are suspected to have been compromised directly or indirectly. \n(b) Verify, when users create or update passwords, that the passwords are not found on the list of commonly-used, expected, or compromised passwords in ia-5 (1) (a). \n(c) Transmit passwords only over cryptographically-protected channels. \n(d) Store passwords using an approved salted key derivation function, preferably using a keyed hash. \n(e) Require immediate selection of a new password upon account recovery. \n(f) Allow user selection of long passwords and passphrases, including spaces and all printable characters. \n(g) Employ automated tools to assist the user in selecting strong password authenticators. \n(h) Enforce the following composition and complexity rules [assignment: organization-defined composition and complexity rules].\n\nPassword-based authentication applies to passwords regardless of whether they are used in single-factor or multi-factor authentication. Long passwords or passphrases are preferable over shorter passwords. Enforced composition rules provide marginal security benefits while decreasing usability. However, organizations may choose to establish certain rules for password generation (e.g., minimum character length for long passwords) under certain circumstances and can enforce this requirement in ia-5 (1) (h).\n\nAccount recovery can occur, for example, in situations when a password is forgotten. Cryptographically protected passwords include salted one-way cryptographic hashes of passwords. The list of commonly used, compromised, or expected passwords includes passwords obtained from previous breach corpuses, dictionary words, and repetitive or sequential characters. The list includes context-specific words, such as the name of the service, username, and derivatives thereof.",
          "Identification and authentication. Identification and authentication (organizational users) | multi-factor authentication to privileged accounts. Implement multi-factor authentication for access to privileged accounts. Multi-factor authentication requires the use of two or more different factors to achieve authentication. The authentication factors are defined as follows: something you know (e.g., a personal identification number [PIN]), something you have (e.g., a physical authenticator such as a cryptographic private key), or something you are (e.g., a biometric). \n\nMulti-factor authentication solutions that feature physical authenticators include hardware authenticators that provide time-based or challenge-response outputs and smart cards such as the U.S. government Personal Identity Verification (PIV) card or the Department of Defense (DoD) Common Access Card (CAC). In addition to authenticating users at the system level (i.e., at logon), organizations may employ authentication mechanisms at the application level, at their discretion, to provide increased security.\n\nRegardless of the type of access (i.e., local, network, remote), privileged accounts are authenticated using multi-factor options appropriate for the level of risk. Organizations can add additional security measures, such as additional or more rigorous authentication mechanisms, for specific types of access.",
          "Identification and authentication. Identification and authentication (non-organizational users) | acceptance of piv credentials from other agencies. Accept and electronically verify Personal Identity Verification (PIV)-compliant credentials from other federal agencies. Acceptance of PIV credentials from other federal agencies applies to both logical and physical access control systems. PIV credentials are those credentials issued by federal agencies that conform to FIPS Publication 201 and supporting guidelines. The adequacy and reliability of PIV card issuers are addressed and authorized using SP 800-79-2.",
          "Identification and authentication. Identity proofing. a. Identity proof users that require accounts for logical access to systems, based on appropriate identity assurance level requirements as specified in applicable standards and guidelines. \nb. Resolve user identities to a unique individual. \nc. Collect, validate, and verify identity evidence. \n\nIdentity proofing is the process of collecting, validating, and verifying a user’s identity information for the purposes of establishing credentials for accessing a system. Identity proofing is intended to mitigate threats to the registration of users and the establishment of their accounts. \n\nStandards and guidelines specifying identity assurance levels for identity proofing include SP 800-63-3 and SP 800-63a. Organizations may be subject to laws, executive orders, directives, regulations, or policies that address the collection of identity evidence. \n\nOrganizational personnel consult with the senior agency official for privacy and legal counsel regarding such requirements.",
          "Identification and authentication. Re-authentication. Require users to re-authenticate when [assignment: organization-defined circumstances or situations requiring re-authentication]. In addition to the re-authentication requirements associated with device locks, organizations may require re-authentication of individuals in certain situations, including when roles, authenticators, or credentials change, when security categories of systems change, when the execution of privileged functions occurs, after a fixed time period, or periodically.",
          "Identification and authentication. Authenticator management. Manage system authenticators by:\n\na. Verifying, as part of the initial authenticator distribution, the identity of the individual, group, role, service, or device receiving the authenticator.\n\nb. Establishing initial authenticator content for any authenticators issued by the organization.\n\nc. Ensuring that authenticators have sufficient strength of mechanism for their intended use.\n\nd. Establishing and implementing administrative procedures for initial authenticator distribution, for lost or compromised or damaged authenticators, and for revoking authenticators.\n\ne. Changing default authenticators prior to first use.\n\nf. Changing or refreshing authenticators [assignment: organization-defined time period by authenticator type] or when [assignment: organization-defined events] occur.\n\ng. Protecting authenticator content from unauthorized disclosure and modification.\n\nh. Requiring individuals to take, and having devices implement, specific controls to protect authenticators.\n\ni. Changing authenticators for group or role accounts when membership to those accounts changes.\n\nAuthenticators include passwords, cryptographic devices, biometrics, certificates, one-time password devices, and ID badges. Device authenticators include certificates and passwords.\n\nInitial authenticator content is the actual content of the authenticator (e.g., the initial password). In contrast, the requirements for authenticator content contain specific criteria or characteristics (e.g., minimum password length).\n\nDevelopers may deliver system components with factory default authentication credentials (i.e., passwords) to allow for initial installation and configuration. Default authentication credentials are often well-known, easily discoverable, and present a significant risk.\n\nThe requirement to protect individual authenticators may be implemented via control PL-4 or PS-6 for authenticators in the possession of individuals and by controls AC-3, AC-6, and SC-28 for authenticators stored in organizational systems, including passwords stored in hashed or encrypted formats or files containing encrypted or hashed passwords accessible with administrator privileges.\n\nSystems support authenticator management by organization-defined settings and restrictions for various authenticator characteristics (e.g., minimum password length, validation time window for time synchronous one-time tokens, and number of allowed rejections during the verification stage of biometric authentication).\n\nActions can be taken to safeguard individual authenticators, including maintaining possession of authenticators, not sharing authenticators with others, and immediately reporting lost, stolen, or compromised authenticators.\n\nAuthenticator management includes issuing and revoking authenticators for temporary access when no longer needed.",
          "Identification and authentication. Device identification and authentication. Uniquely identify and authenticate [assignment: organization-defined devices and/or types of devices] before establishing a [selection (one or more): local; remote; network] connection. Devices that require unique device-to-device identification and authentication are defined by type, device, or a combination of type and device. Organization-defined device types include devices that are not owned by the organization. Systems use shared known information (e.g., media access control [MAC], Transmission Control Protocol/Internet Protocol [TCP/IP] addresses) for device identification or organizational authentication solutions (e.g., Institute of Electrical and Electronics Engineers (IEEE) 802.1X and Extensible Authentication Protocol [EAP], RADIUS server with EAP-Transport Layer Security [TLS] authentication, Kerberos) to identify and authenticate devices on local and wide area networks. Organizations determine the required strength of authentication mechanisms based on the security categories of systems and mission or business requirements. Because of the challenges of implementing device authentication on a large scale, organizations can restrict the application of the control to a limited number/type of devices based on mission or business needs.",
          "Identification and authentication. Identification and authentication (organizational users) | access to accounts —separate device. Implement multi-factor authentication for [selection (one or more): local; network; remote] access to [selection (one or more): privileged accounts; non-privileged accounts]. Ensure that: \n(a) one of the factors is provided by a device separate from the system gaining access; and \n(b) the device meets [assignment: organization-defined strength of mechanism requirements]. \n\nThe purpose of requiring a device that is separate from the system to which the user is attempting to gain access for one of the factors during multi-factor authentication is to reduce the likelihood of compromising authenticators or credentials stored on the system. Adversaries may be able to compromise such authenticators or credentials and subsequently impersonate authorized users. Implementing one of the factors on a separate device (e.g., a hardware token) provides a greater strength of mechanism and an increased level of assurance in the authentication process.",
          "Identification and authentication. Identification and authentication (non-organizational users) | use of defined profiles. Conform to the following profiles for identity management. [Assignment: Organization-defined identity management profiles.] Organizations define profiles for identity management based on open identity management standards. To ensure that open identity management standards are viable, robust, reliable, sustainable, and interoperable as documented, the federal government assesses and scopes the standards and technology implementations against applicable laws, executive orders, directives, policies, regulations, standards, and guidelines.",
          "Identification and authentication. Identification and authentication (organizational users) | individual authentication with group authentication. When shared accounts or authenticators are employed, require users to be individually authenticated before granting access to the shared accounts or resources. Individual authentication prior to shared group authentication mitigates the risk of using group accounts or authenticators.",
          "Identification and authentication. Identifier management. Manage system identifiers by: a. receiving authorization from [assignment: organization-defined personnel or roles] to assign an individual, group, role, service, or device identifier; b. selecting an identifier that identifies an individual, group, role, service, or device; c. assigning the identifier to the intended individual, group, role, service, or device; and d. preventing reuse of identifiers for [assignment: organization-defined time period]. Common device identifiers include Media Access Control (MAC) addresses, Internet Protocol (IP) addresses, or device-unique token identifiers. The management of individual identifiers is not applicable to shared system accounts. Typically, individual identifiers are the usernames of the system accounts assigned to those individuals. In such instances, the account management activities of AC-2 use account names provided by IA-4. Identifier management also addresses individual identifiers not necessarily associated with system accounts. Preventing the reuse of identifiers implies preventing the assignment of previously used individual, group, role, service, or device identifiers to different individuals, groups, roles, services, or devices.",
          "Identification and authentication. Identification and authentication (organizational users) | access to accounts — replay resistant. Implement replay-resistant authentication mechanisms for access to privileged accounts and non-privileged accounts. Authentication processes resist replay attacks if it is impractical to achieve successful authentications by replaying previous authentication messages. Replay-resistant techniques include protocols that use nonces or challenges such as time synchronous or cryptographic authenticators.",
          "Identification and authentication. Identification and authentication (organizational users). Uniquely identify and authenticate organizational users and associate that unique identification with processes acting on behalf of those users. Organizations can satisfy the identification and authentication requirements by complying with the requirements in HSPD 12. Organizational users include employees or individuals who organizations consider to have an equivalent status to employees (e.g., contractors and guest researchers). \n\nUnique identification and authentication of users applies to all accesses other than those that are explicitly identified in AC-14 and that occur through the authorized use of group authenticators without individual authentication. Since processes execute on behalf of groups and roles, organizations may require unique identification of individuals in group accounts or for detailed accountability of individual activity. \n\nOrganizations employ passwords, physical authenticators, or biometrics to authenticate user identities or, in the case of multi-factor authentication, some combination thereof. Access to organizational systems is defined as either local access or network access. Local access is any access to organizational systems by users or processes acting on behalf of users, where access is obtained through direct connections without the use of networks. \n\nNetwork access is access to organizational systems by users (or processes acting on behalf of users) where access is obtained through network connections (i.e., nonlocal accesses). Remote access is a type of network access that involves communication through external networks. Internal networks include local area networks and wide area networks. \n\nThe use of encrypted virtual private networks for network connections between organization-controlled endpoints and non-organization-controlled endpoints may be treated as internal networks with respect to protecting the confidentiality and integrity of information traversing the network. Identification and authentication requirements for non-organizational users are described in IA-8.",
          "Identification and authentication. Authenticator management | no embedded unencrypted static authenticators. Ensure that unencrypted static authenticators are not embedded in applications or other forms of static storage. In addition to applications, other forms of static storage include access scripts and function keys. Organizations should exercise caution when determining whether embedded or stored authenticators are in encrypted or unencrypted form. If authenticators are used in the manner stored, then those representations are considered unencrypted authenticators.",
          "Identification and authentication. Identity proofing | in-person validation and verification. Require that the validation and verification of identity evidence be conducted in person, before a designated registration authority. In-person proofing reduces the likelihood of fraudulent credentials being issued because it requires the physical presence of individuals, the presentation of physical identity documents, and actual face-to-face interactions with designated registration authorities.",
          "Identification and authentication. Identification and authentication (organizational users) | multi-factor authentication to non-privileged accounts. Implement multi-factor authentication for access to non-privileged accounts. Multi-factor authentication requires the use of two or more different factors to achieve authentication. The authentication factors are defined as follows: something you know (e.g., a personal identification number [PIN]), something you have (e.g., a physical authenticator such as a cryptographic private key), or something you are (e.g., a biometric). \n\nMulti-factor authentication solutions that feature physical authenticators include hardware authenticators that provide time-based or challenge-response outputs and smart cards such as the U.S. government personal identity verification card or the DoD common access card. \n\nIn addition to authenticating users at the system level, organizations may also employ authentication mechanisms at the application level, at their discretion, to provide increased information security. Regardless of the type of access (i.e., local, network, remote), non-privileged accounts are authenticated using multi-factor options appropriate for the level of risk. \n\nOrganizations can provide additional security measures, such as additional or more rigorous authentication mechanisms, for specific types of access.",
          "Identification and authentication. Identification and authentication (organizational users) | acceptance of piv credentials. Accept and electronically verify personal identity verification-compliant credentials. Acceptance of personal identity verification (PIV)-compliant credentials applies to organizations implementing logical access control and physical access control systems. PIV-compliant credentials are those credentials issued by federal agencies that conform to FIPS Publication 201 and supporting guidance documents. The adequacy and reliability of PIV card issuers are authorized using SP 800-79-2. Acceptance of PIV-compliant credentials includes derived PIV credentials, the use of which is addressed in SP 800-166. The DoD Common Access Card (CAC) is an example of a PIV credential.",
          "Identification and authentication. Identity proofing | identity evidence validation and verification. Require that the presented identity evidence be validated and verified through [assignment: organizational defined methods of validation and verification]. Validation and verification of identity evidence increases the assurance that accounts and identifiers are being established for the correct user and authenticators are being bound to that user. Validation refers to the process of confirming that the evidence is genuine and authentic, and the data contained in the evidence is correct, current, and related to an individual. Verification confirms and establishes a linkage between the claimed identity and the actual existence of the user presenting the evidence. Acceptable methods for validating and verifying identity evidence are consistent with the risks to the systems, roles, and privileges associated with the user's account.",
          "Identification and authentication. Identity proofing | identity evidence. Require evidence of individual identification be presented to the registration authority. Identity evidence, such as documentary evidence or a combination of documents and biometrics, reduces the likelihood of individuals using fraudulent identification to establish an identity or, at least, increases the work factor of potential adversaries. The forms of acceptable evidence are consistent with the risks to the systems, roles, and privileges associated with the user's account.",
          "System and services acquisition. Acquisition process | use of approved piv products. Employ only information technology products on the FIPS 201-approved products list for Personal Identity Verification (PIV) capability implemented within organizational systems. Products on the FIPS 201-approved products list meet NIST requirements for Personal Identity Verification (PIV) of federal employees and contractors. PIV cards are used for multi-factor authentication in systems and organizations.",
          "Identification and authentication. Identity proofing | address confirmation. Require that a [selection: registration code. Notice of proofing] be delivered through an out-of-band channel to verify the user's address (physical or digital) of record. To make it more difficult for adversaries to pose as legitimate users during the identity proofing process, organizations can use out-of-band methods to ensure that the individual associated with an address of record is the same individual that participated in the registration. Confirmation can take the form of a temporary enrollment code or a notice of proofing. The delivery address for these artifacts is obtained from records and not self-asserted by the user. The address can include a physical or digital address. A home address is an example of a physical address. Email addresses and telephone numbers are examples of digital addresses.",
          "Identification and authentication. Identification and authentication (non-organizational users) | acceptance of external authenticators. (a) Accept only external authenticators that are NIST-compliant; and (b) document and maintain a list of accepted external authenticators. Acceptance of only NIST-compliant external authenticators applies to organizational systems that are accessible to the public (e.g., public-facing websites). External authenticators are issued by nonfederal government entities and are compliant with SP 800-63b. Approved external authenticators meet or exceed the minimum federal government-wide technical, security, privacy, and organizational maturity requirements. Meeting or exceeding federal requirements allows federal government relying parties to trust external authenticators in connection with an authentication transaction at a specified authenticator assurance level.",
          "Identification and authentication. Authenticator management | expiration of cached authenticators. Prohibit the use of cached authenticators after [assignment: organization-defined time period]. Cached authenticators are used to authenticate to the local machine when the network is not available. If cached authentication information is out of date, the validity of the authentication information may be questionable.",
          "Identification and authentication. Identifier management | identify user status. Manage individual identifiers by uniquely identifying each individual as [assignment: organization-defined characteristic identifying individual status]. Characteristics that identify the status of individuals include contractors, foreign nationals, and non-organizational users. Identifying the status of individuals by these characteristics provides additional information about the people with whom organizational personnel are communicating. For example, it might be useful for a government employee to know that one of the individuals on an email message is a contractor.",
          "Identification and authentication. Authenticator management | public key-based authentication. (a) For public key-based authentication: (1) Enforce authorized access to the corresponding private key. (2) Map the authenticated identity to the account of the individual or group. (b) When Public Key Infrastructure (PKI) is used: (1) Validate certificates by constructing and verifying a certification path to an accepted trust anchor, including checking certificate status information. (2) Implement a local cache of revocation data to support path discovery and validation. Public key cryptography is a valid authentication mechanism for individuals, machines, and devices. For PKI solutions, status information for certification paths includes certificate revocation lists or certificate status protocol responses. For PIV cards, certificate validation involves the construction and verification of a certification path to the Common Policy root trust anchor, which includes certificate policy processing. Implementing a local cache of revocation data to support path discovery and validation also supports system availability in situations where organizations are unable to access revocation information via the network.",
          "Identification and authentication. Authenticator management | multiple system accounts. Implement [assignment: organization-defined security controls] to manage the risk of compromise due to individuals having accounts on multiple systems. When individuals have accounts on multiple systems and use the same authenticators, such as passwords, there is the risk that a compromise of one account may lead to the compromise of other accounts. Alternative approaches include having different authenticators (passwords) on all systems, employing a single sign-on or federation mechanism, or using some form of one-time passwords on all systems. Organizations can also use rules of behavior (see PL-4) and access agreements (see PS-6) to mitigate the risk of multiple system accounts.",
          "Identification and authentication. Authenticator management | protection of authenticators. Protect authenticators commensurate with the security category of the information to which the use of the authenticator permits access. For systems that contain multiple security categories of information without reliable physical or logical separation between categories, authenticators used to grant access to the systems are protected commensurate with the highest security category of information on the systems. Security categories of information are determined as part of the security categorization process.",
          "Identification and authentication. Authentication feedback. Obscure feedback of authentication information during the authentication process to protect the information from possible exploitation and use by unauthorized individuals. Authentication feedback from systems does not provide information that would allow unauthorized individuals to compromise authentication mechanisms. For some types of systems, such as desktops or notebooks with relatively large monitors, the threat (referred to as shoulder surfing) may be significant. For other types of systems, such as mobile devices with small displays, the threat may be less significant and is balanced against the increased likelihood of typographic input errors due to small keyboards. Thus, the means for obscuring authentication feedback is selected accordingly. Obscuring authentication feedback includes displaying asterisks when users type passwords into input devices or displaying feedback for a very limited time before obscuring it.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "5_authentication_authenticators_identification",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "5_authentication_authenticators_identification"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          13.164084434509277,
          13.053675651550293,
          13.132752418518066,
          12.98142147064209,
          12.744034767150879,
          13.653072357177734,
          13.184417724609375,
          13.160953521728516,
          13.163723945617676,
          13.01538372039795,
          13.527701377868652,
          13.287931442260742,
          13.15934944152832,
          13.093514442443848,
          13.024532318115234,
          13.142048835754395,
          13.66096019744873,
          12.980181694030762,
          12.750957489013672,
          13.664682388305664,
          13.661665916442871,
          12.719656944274902,
          13.684085845947266,
          12.954119682312012,
          13.2295560836792,
          13.36887264251709,
          12.681921005249023,
          13.11526107788086,
          13.126317024230957,
          13.045221328735352,
          13.17106819152832
         ],
         "y": [
          7.967392444610596,
          7.8265814781188965,
          7.508352279663086,
          7.643668174743652,
          7.658997058868408,
          7.987189769744873,
          7.970428466796875,
          7.933171272277832,
          7.924027919769287,
          7.732532024383545,
          7.939675807952881,
          7.945073127746582,
          7.84925651550293,
          7.833795547485352,
          7.791179656982422,
          7.908177375793457,
          7.988901138305664,
          7.739692211151123,
          7.640779495239258,
          7.997108459472656,
          7.99107027053833,
          7.656018257141113,
          7.996335506439209,
          7.703572750091553,
          8.015486717224121,
          7.897645950317383,
          7.652913570404053,
          7.800801753997803,
          7.892439842224121,
          7.802734375,
          7.8398332595825195
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Audit and accountability. Audit log storage capacity. Allocate audit log storage capacity to accommodate [assignment: organization-defined audit log retention requirements]. Organizations consider the types of audit logging to be performed and the audit log processing requirements when allocating audit log storage capacity. Allocating sufficient audit log storage capacity reduces the likelihood of such capacity being exceeded and resulting in the potential loss or reduction of audit logging capability.",
          "Audit and accountability. Audit record review, analysis, and reporting. a. Review and analyze system audit records [assignment: organization-defined frequency] for indications of [assignment: organization-defined inappropriate or unusual activity] and the potential impact of the inappropriate or unusual activity. \nb. Report findings to [assignment: organization-defined personnel or roles]. \nc. Adjust the level of audit record review, analysis, and reporting within the system when there is a change in risk based on law enforcement information, intelligence information, or other credible sources of information.\n\nAudit record review, analysis, and reporting covers information security- and privacy-related logging performed by organizations, including logging that results from the monitoring of account usage, remote access, wireless connectivity, mobile device connection, configuration settings, system component inventory, use of maintenance tools and non-local maintenance, physical access, temperature and humidity, equipment delivery and removal, communications at system interfaces, and use of mobile code or voice over internet protocol (VoIP). Findings can be reported to organizational entities that include the incident response team, help desk, and security or privacy offices. If organizations are prohibited from reviewing and analyzing audit records or unable to conduct such activities, the review or analysis may be carried out by other organizations granted such authority. The frequency, scope, and/or depth of the audit record review, analysis, and reporting may be adjusted to meet organizational needs based on new information received.",
          "Audit and accountability. Content of audit records | additional audit information. Generate audit records containing the following additional information: [assignment: organization-defined additional information]. The ability to add information generated in audit records is dependent on system functionality to configure the audit record content. Organizations may consider additional information in audit records, including, but not limited to, access control or flow control rules invoked, and individual identities of group account users. Organizations may also consider limiting additional audit record information to only information that is explicitly needed for audit requirements. This facilitates the use of audit trails and audit logs by not including information in audit records that could potentially be misleading, make it more difficult to locate information of interest, or increase the risk to individuals' privacy.",
          "Audit and accountability. Audit record retention. Retain audit records for [assignment: organization-defined time period consistent with records retention policy] to provide support for after-the-fact investigations of incidents and to meet regulatory and organizational information retention requirements. Organizations retain audit records until it is determined that the records are no longer needed for administrative, legal, audit, or other operational purposes. This includes the retention and availability of audit records relative to Freedom of Information Act (FOIA) requests, subpoenas, and law enforcement actions. Organizations develop standard categories of audit records relative to such types of actions and standard response processes for each type of action. The National Archives and Records Administration (NARA) General Records Schedules provide federal policy on records retention.",
          "Audit and accountability. Non-repudiation. Provide irrefutable evidence that an individual (or process acting on behalf of an individual) has performed [assignment: organization-defined actions to be covered by non-repudiation]. Types of individual actions covered by non-repudiation include creating information, sending and receiving messages, and approving information. Non-repudiation protects against claims by authors of not having authored certain documents, senders of not having transmitted messages, receivers of not having received messages, and signatories of not having signed documents. Non-repudiation services can be used to determine if information originated from an individual or if an individual took specific actions (e.g., sending an email, signing a contract, approving a procurement request, or receiving specific information). Organizations obtain non-repudiation services by employing various techniques or mechanisms, including digital signatures and digital message receipts.",
          "Audit and accountability. Time stamps. a. Use internal system clocks to generate time stamps for audit records; and b. Record time stamps for audit records that meet [assignment: organization-defined granularity of time measurement] and that use Coordinated Universal Time, have a fixed local time offset from Coordinated Universal Time, or that include the local time offset as part of the time stamp. Time stamps generated by the system include date and time. Time is commonly expressed in Coordinated Universal Time (UTC), a modern continuation of Greenwich Mean Time (GMT), or local time with an offset from UTC. Granularity of time measurements refers to the degree of synchronization between system clocks and reference clocks (e.g., clocks synchronizing within hundreds of milliseconds or tens of milliseconds). Organizations may define different time granularities for different system components. Time service can be critical to other security capabilities such as access control and identification and authentication, depending on the nature of the mechanisms used to support those capabilities.",
          "Audit and accountability. Audit record review, analysis, and reporting | automated process integration. Integrate audit record review, analysis, and reporting processes using [assignment: organization-defined automated mechanisms]. Organizational processes that benefit from integrated audit record review, analysis, and reporting include incident response, continuous monitoring, contingency planning, investigation, and response to suspicious activities, and Inspector General audits.",
          "Audit and accountability. Response to audit logging process failures | real-time alerts. Provide an alert within [assignment: organization-defined real-time period] to [assignment: organization-defined personnel, roles, and/or locations] when the following audit failure events occur: [assignment: organization-defined audit logging failure events requiring real-time alerts]. Alerts provide organizations with urgent messages. Real-time alerts provide these messages at information technology speed (i.e., the time from event detection to alert occurs in seconds or less).",
          "Audit and accountability. Audit record review, analysis, and reporting | correlate audit record repositories. Analyze and correlate audit records across different repositories to gain organization-wide situational awareness. Organization-wide situational awareness includes awareness across all three levels of risk management (i.e., organizational level, mission/business process level, and information system level) and supports cross-organization awareness.",
          "Audit and accountability. Protection of audit information | cryptographic protection. Implement cryptographic mechanisms to protect the integrity of audit information and audit tools. Cryptographic mechanisms used for protecting the integrity of audit information include signed hash functions using asymmetric cryptography. This enables the distribution of the public key to verify the hash information while maintaining the confidentiality of the secret key used to generate the hash.",
          "Audit and accountability. Audit record generation. a. Provide audit record generation capability for the event types the system is capable of auditing as defined in au-2a on [assignment: organization-defined system components].\nb. Allow [assignment: organization-defined personnel or roles] to select the event types that are to be logged by specific components of the system.\nc. Generate audit records for the event types defined in au-2c that include the audit record content defined in au-3. Audit records can be generated from many different system components. The event types specified in au-2d are the event types for which audit logs are to be generated and are a subset of all event types for which the system can generate audit records.",
          "Audit and accountability. Event logging. a. Identify the types of events that the system is capable of logging in support of the audit function: [Assignment: organization-defined event types that the system is capable of logging]. \nb. Coordinate the event logging function with other organizational entities requiring audit-related information to guide and inform the selection criteria for events to be logged. \nc. Specify the following event types for logging within the system: [Assignment: organization-defined event types (subset of the event types defined in AU-2a.) along with the frequency of (or situation requiring) logging for each identified event type]. \nd. Provide a rationale for why the event types selected for logging are deemed to be adequate to support after-the-fact investigations of incidents. \ne. Review and update the event types selected for logging [Assignment: organization-defined frequency].\n\nAn event is an observable occurrence in a system. The types of events that require logging are those events that are significant and relevant to the security of systems and the privacy of individuals. Event logging also supports specific monitoring and auditing needs. Event types include password changes, failed logons or failed accesses related to systems, security or privacy attribute changes, administrative privilege usage, PIV credential usage, data action changes, query parameters, or external credential usage. \n\nIn determining the set of event types that require logging, organizations consider the monitoring and auditing appropriate for each of the controls to be implemented. For completeness, event logging includes all protocols that are operational and supported by the system. To balance monitoring and auditing requirements with other system needs, event logging requires identifying the subset of event types that are logged at a given point in time. \n\nFor example, organizations may determine that systems need the capability to log every file access successful and unsuccessful, but not activate that capability except for specific circumstances due to the potential burden on system performance. The types of events that organizations desire to be logged may change. Reviewing and updating the set of logged events is necessary to help ensure that the events remain relevant and continue to support the needs of the organization. \n\nOrganizations consider how the types of logging events can reveal information about individuals that may give rise to privacy risk and how best to mitigate such risks. For example, there is the potential to reveal personally identifiable information in the audit trail, especially if the logging event is based on patterns or time of usage. Event logging requirements, including the need to log specific event types, may be referenced in other controls and control enhancements. These include AC-2(4), AC-3(10), AC-6(9), AC-17(1), CM-3f, CM-5(1), IA-3(3)(b), MA-4(1), MP-4(2), PE-3, PM-21, PT-7, RA-8, SC-7(9), SC-7(15), SI-3(8), SI-4(22), SI-7(8), and SI-10(1). \n\nOrganizations include event types that are required by applicable laws, executive orders, directives, policies, regulations, standards, and guidelines. Audit records can be generated at various levels, including at the packet level as information traverses the network. Selecting the appropriate level of event logging is an important part of a monitoring and auditing capability and can identify the root causes of problems. When defining event types, organizations consider the logging necessary to cover related event types, such as the steps in distributed, transaction-based processes, and the actions that occur in service-oriented architectures.",
          "Audit and accountability. Protection of audit information | access by subset of privileged users. Authorize access to management of audit logging functionality to only [assignment: organization-defined subset of privileged users or roles]. Individuals or roles with privileged access to a system and who are also the subject of an audit by that system may affect the reliability of the audit information by inhibiting audit activities or modifying audit records. Requiring privileged access to be further defined between audit-related privileges and other privileges limits the number of users or roles with audit-related privileges.",
          "Audit and accountability. Audit record review, analysis, and reporting | permitted actions. Specify the permitted actions for each [selection (one or more): system process; role; user] associated with the review, analysis, and reporting of audit record information. Organizations specify permitted actions for system processes, roles, and users associated with the review, analysis, and reporting of audit records through system account management activities. Specifying permitted actions on audit record information is a way to enforce the principle of least privilege. Permitted actions are enforced by the system and include read, write, execute, append, and delete.",
          "Audit and accountability. Protection of audit information. A. Protect audit information and audit logging tools from unauthorized access, modification, and deletion.\nB. Alert [assignment: organization-defined personnel or roles] upon detection of unauthorized access, modification, or deletion of audit information.\nAudit information includes all information needed to successfully audit system activity, such as audit records, audit log settings, audit reports, and personally identifiable information. Audit logging tools are those programs and devices used to conduct system audit and logging activities.\nProtection of audit information focuses on technical protection and limits the ability to access and execute audit logging tools to authorized individuals. Physical protection of audit information is addressed by both media protection controls and physical and environmental protection controls.",
          "Audit and accountability. Response to audit logging process failures. a. Alert (assignment: organization-defined personnel or roles) within (assignment: organization-defined time period) in the event of an audit logging process failure. B. Take the following additional actions: (assignment: organization-defined additional actions). Audit logging process failures include software and hardware errors, failures in audit log capturing mechanisms, and reaching or exceeding audit log storage capacity. Organization-defined actions include overwriting the oldest audit records, shutting down the system, and stopping the generation of audit records. Organizations may choose to define additional actions for audit logging process failures based on the type of failure, the location of the failure, the severity of the failure, or a combination of such factors. When the audit logging process failure is related to storage, the response is carried out for the audit log storage repository (i.e., the distinct system component where the audit logs are stored), the system on which the audit logs reside, the total audit log storage capacity of the organization (i.e., all audit log storage repositories combined), or all three. Organizations may decide to take no additional actions after alerting designated roles or personnel.",
          "Audit and accountability. Audit record reduction and report generation | automatic processing. Provide and implement the capability to process, sort, and search audit records for events of interest based on the following content: [assignment: organization-defined fields within audit records]. \n\nEvents of interest can be identified by the content of audit records, including system resources involved, information objects accessed, identities of individuals, event types, event locations, event dates and times, internet protocol addresses involved, or event success or failure. \n\nOrganizations may define event criteria to any degree of granularity required, such as locations selectable by a general networking location or by specific system component.",
          "Audit and accountability. Response to audit logging process failures | storage capacity warning. Provide a warning to organization-defined personnel, roles, and/or locations within the organization-defined time period, when the allocated audit log storage volume reaches the organization-defined percentage of the repository's maximum audit log storage capacity. Please note that organizations may have multiple audit log storage repositories distributed across multiple system components. Each repository may have different storage volume capacities.",
          "Audit and accountability. Audit record review, analysis, and reporting | central review and analysis. Provide and implement the capability to centrally review and analyze audit records from multiple components within the system. Automated mechanisms for centralized reviews and analyses include Security Information and Event Management (SIEM) products.",
          "Audit and accountability. Audit record review, analysis, and reporting | correlation with physical monitoring. Correlate information from audit records with information obtained from monitoring physical access to further enhance the ability to identify suspicious, inappropriate, unusual, or malevolent activity. The correlation of physical audit record information and the audit records from systems may assist organizations in identifying suspicious behavior or supporting evidence of such behavior. For example, the correlation of an individual's identity for logical access to certain systems with the additional physical security information that the individual was present at the facility when the logical access occurred may be useful in investigations.",
          "Audit and accountability. Audit record reduction and report generation. Provide and implement an audit record reduction and report generation capability that: \n\na. Supports on-demand audit record review, analysis, and reporting requirements, as well as after-the-fact investigations of incidents. \n\nb. Does not alter the original content or time ordering of audit records. \n\nAudit record reduction is a process that manipulates collected audit log information and organizes it into a summary format that is more meaningful to analysts. \n\nAudit record reduction and report generation capabilities do not always emanate from the same system or the same organizational entities that conduct audit logging activities. \n\nThe audit record reduction capability includes modern data mining techniques with advanced data filters to identify anomalous behavior in audit records. \n\nThe report generation capability provided by the system can generate customizable reports. \n\nTime ordering of audit records can be an issue if the granularity of the timestamp in the record is insufficient.",
          "Audit and accountability. Audit record generation | changes by authorized individuals. Provide and implement the capability for (assignment: organization-defined individuals or roles) to change the logging to be performed on (assignment: organization-defined system components) based on (assignment: organization-defined selectable event criteria) within (assignment: organization-defined time thresholds). Permitting authorized individuals to make changes to system logging enables organizations to extend or limit logging as necessary to meet organizational requirements. Logging that is limited to conserve system resources may be extended (either temporarily or permanently) to address certain threat situations. In addition, logging may be limited to a specific set of event types to facilitate audit reduction, analysis, and reporting. Organizations can establish time thresholds in which logging actions are changed (e.g., near real-time, within minutes, or within hours).",
          "Audit and accountability. Audit record generation | system-wide and time-correlated audit trail. Compile audit records from [assignment: organization-defined system components] into a system-wide (logical or physical) audit trail that is time-correlated to within [assignment: organization-defined level of tolerance for the relationship between time stamps of individual records in the audit trail]. Audit trails are time-correlated if the time stamps in the individual audit records can be reliably related to the time stamps in other audit records to achieve a time ordering of the records within organizational tolerances.",
          "System and information integrity. Information management and retention. Manage and retain information within the system and information output from the system in accordance with applicable laws, executive orders, directives, regulations, policies, standards, guidelines, and operational requirements. Information management and retention requirements cover the full life cycle of information, in some cases extending beyond system disposal. Information to be retained may also include policies, procedures, plans, reports, data output from control implementation, and other types of administrative information.\n\nThe National Archives and Records Administration (NARA) provides federal policy and guidance on records retention and schedules. If organizations have a records management office, consider coordinating with records management personnel. Records produced from the output of implemented controls that may require management and retention include, but are not limited to: all XX-1, AC-6 (9), AT-4, AU-12, CA-2, CA-3, CA-5, CA-6, CA-7, CA-8, CA-9, CM-2, CM-3, CM-4, CM-6, CM-8, CM-9, CM-12, CM-13, CP-2, IR-6, IR-8, MA-2, MA-4, PE-2, PE-8, PE-16, PE-17, PL-2, PL-4, PL-7, PL-8, PM-5, PM-8, PM-9, PM-18, PM-21, PM-27, PM-28, PM-30, PM-31, PS-2, PS-6, PS-7, PT-2, PT-3, PT-7, RA-2, RA-3, RA-5, RA-8, SA-4, SA-5, SA-8, SA-10, SI-4, SR-2, SR-4, SR-8.",
          "Audit and accountability. Audit record review, analysis, and reporting | integrated analysis of audit records. Integrate analysis of audit records with analysis of [selection (one or more): vulnerability scanning information; performance data; system monitoring information; [assignment: organization-defined data/information collected from other sources]] to further enhance the ability to identify inappropriate or unusual activity. Integrated analysis of audit records does not require vulnerability scanning, the generation of performance data, or system monitoring. Rather, integrated analysis requires that the analysis of information generated by scanning, monitoring, or other data collection activities is integrated with the analysis of audit record information. Security information and event management tools can facilitate audit record aggregation or consolidation from multiple system components, as well as audit record correlation and analysis. The use of standardized audit record analysis scripts developed by organizations (with localized script adjustments, as necessary) provides more cost-effective approaches for analyzing audit record information collected. The correlation of audit record information with vulnerability scanning information is important in determining the veracity of vulnerability scans of the system and in correlating attack detection events with scanning results. Correlation with performance data can uncover denial-of-service attacks or other types of attacks that result in the unauthorized use of resources. Correlation with system monitoring information can assist in uncovering attacks and in better relating audit information to operational situations.",
          "Audit and accountability. Content of audit records. Ensure that audit records contain information that establishes the following: a. What type of event occurred; b. When the event occurred; c. Where the event occurred; d. Source of the event; e. Outcome of the event; and f. Identity of any individuals, subjects, or objects/entities associated with the event. Audit record content that may be necessary to support the auditing function includes event descriptions (item a), timestamps (item b), source and destination addresses (item c), user or process identifiers (items d and f), success or fail indications (item e), and filenames involved (items a, c, e, and f). Event outcomes include indicators of event success or failure and event-specific results, such as the system security and privacy posture after the event occurred. Organizations consider how audit records can reveal information about individuals that may give rise to privacy risks and how best to mitigate such risks. For example, there is the potential to reveal personally identifiable information in the audit trail, especially if the trail records inputs or is based on patterns or time of usage.",
          "System and communications protection. System time synchronization | synchronization with authoritative time source. (a) Compare the internal system clocks. [Assignment: organization-defined frequency].  \n(b) Synchronize the internal system clocks to the authoritative time source when the time difference is greater than [Assignment: organization-defined time period]. \n\nSynchronization of internal system clocks with an authoritative source provides uniformity of timestamps for systems with multiple system clocks and systems connected over a network.",
          "Audit and accountability. Protection of audit information | store on separate physical systems or components. Store audit records [assignment: organization-defined frequency] in a repository that is part of a physically different system or system component than the system or component being audited. Storing audit records in a repository separate from the audited system or system component helps to ensure that a compromise of the system being audited does not also result in a compromise of the audit records. Storing audit records on separate physical systems or components also preserves the confidentiality and integrity of audit records and facilitates the management of audit records as an organization-wide activity. Storing audit records on separate systems or components applies to initial generation as well as backup or long-term storage of audit records.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "6_audit_records_event",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "6_audit_records_event"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          4.931520938873291,
          4.855185508728027,
          5.035846710205078,
          5.2505598068237305,
          4.9116668701171875,
          5.450466156005859,
          4.951424598693848,
          5.002443790435791,
          4.955416679382324,
          4.899066925048828,
          5.09051513671875,
          5.082194805145264,
          4.932385444641113,
          4.87315034866333,
          4.8453450202941895,
          4.9574809074401855,
          5.089404106140137,
          4.915191650390625,
          4.940916538238525,
          4.891366481781006,
          5.121891021728516,
          5.164924144744873,
          5.207260608673096,
          5.327419757843018,
          4.994454860687256,
          5.060105323791504,
          5.701361656188965,
          5.029520034790039,
          5.052445888519287
         ],
         "y": [
          4.875643253326416,
          5.2601318359375,
          5.119688510894775,
          5.132400989532471,
          5.066133499145508,
          5.033058166503906,
          5.265555381774902,
          4.884923934936523,
          5.275346755981445,
          5.053358554840088,
          4.985750198364258,
          4.918324947357178,
          5.067086696624756,
          5.136500358581543,
          5.089169979095459,
          4.889775276184082,
          5.157365798950195,
          4.856871604919434,
          5.27979040145874,
          5.369841575622559,
          5.057036876678467,
          4.936367034912109,
          5.037981986999512,
          5.188048362731934,
          5.3904218673706055,
          5.055188179016113,
          5.071725845336914,
          5.009905815124512,
          5.087978363037109
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Access control. Account management | inactivity logout. Require that users log out when [assignment: organization-defined time period of expected inactivity or description of when to log out]. Inactivity logout is behavior- or policy-based and requires users to take physical action to log out when they are expecting inactivity longer than the defined period. Automatic enforcement of inactivity logout is addressed by AC-11.",
          "Access control. Least privilege. Employ the principle of least privilege, allowing only authorized accesses for users (or processes acting on behalf of users) that are necessary to accomplish assigned organizational tasks. Organizations employ least privilege for specific duties and systems. The principle of least privilege is also applied to system processes, ensuring that the processes have access to systems and operate at privilege levels no higher than necessary to accomplish organizational missions or business functions. Organizations consider the creation of additional processes, roles, and accounts as necessary to achieve least privilege. Organizations apply least privilege to the development, implementation, and operation of organizational systems.",
          "Access control. Least privilege | privilege levels for code execution. Prevent the following software from executing at higher privilege levels than users executing the software: [assignment: organization-defined software]. In certain situations, software applications or programs need to execute with elevated privileges to perform required functions. However, depending on the software functionality and configuration, if the privileges required for execution are at a higher level than the privileges assigned to organizational users invoking such applications or programs, those users may indirectly be provided with greater privileges than assigned.",
          "Access control. Account management. a. Define and document the types of accounts allowed and specifically prohibited for use within the system. \nb. Assign account managers. \nc. Require [assignment: organization-defined prerequisites and criteria] for group and role membership. \nd. Specify: 1. Authorized users of the system. 2. Group and role membership. 3. Access authorizations (i.e., privileges) and [assignment: organization-defined attributes (as required)] for each account. \ne. Require approvals by [assignment: organization-defined personnel or roles] for requests to create accounts. \nf. Create, enable, modify, disable, and remove accounts in accordance with [assignment: organization-defined policy, procedures, prerequisites, and criteria]. \ng. Monitor the use of accounts. \nh. Notify account managers and [assignment: organization-defined personnel or roles] within: 1. [assignment: organization-defined time period] when accounts are no longer required. 2. [assignment: organization-defined time period] when users are terminated or transferred. 3. [assignment: organization-defined time period] when system usage or need-to-know changes for an individual. \ni. Authorize access to the system based on: 1. A valid access authorization. 2. Intended system usage. 3. [assignment: organization-defined attributes (as required)]. \nj. Review accounts for compliance with account management requirements [assignment: organization-defined frequency]. \nk. Establish and implement a process for changing shared or group account authenticators (if deployed) when individuals are removed from the group. \nl. Align account management processes with personnel termination and transfer processes. \n\nExamples of system account types include individual, shared, group, system, guest, anonymous, emergency, developer, temporary, and service. Identification of authorized system users and the specification of access privileges reflect the requirements in other controls in the security plan. Users requiring administrative privileges on system accounts receive additional scrutiny by organizational personnel responsible for approving such accounts and privileged access, including system owner, mission or business owner, senior agency information security officer, or senior agency official for privacy. \n\nTypes of accounts that organizations may wish to prohibit due to increased risk include shared, group, emergency, anonymous, temporary, and guest accounts. Where access involves personally identifiable information, security programs collaborate with the senior agency official for privacy to establish the specific conditions for group and role membership, specify authorized users, group and role membership, and access authorizations for each account, and create, adjust, or remove system accounts in accordance with organizational policies. Policies can include such information as account expiration dates or other factors that trigger the disabling of accounts. Organizations may choose to define access privileges or other attributes by account, type of account, or a combination of the two. Examples of other attributes required for authorizing access include restrictions on time of day, day of week, and point of origin. In defining other system account attributes, organizations consider system-related requirements and mission/business requirements. Failure to consider these factors could affect system availability. \n\nTemporary and emergency accounts are intended for short-term use. Organizations establish temporary accounts as part of normal account activation procedures when there is a need for short-term accounts without the demand for immediacy in account activation. Organizations establish emergency accounts in response to crisis situations and with the need for rapid account activation. Therefore, emergency account activation may bypass normal account authorization processes. Emergency and temporary accounts are not to be confused with infrequently used accounts, including local logon accounts used for special tasks or when network resources are unavailable (may also be known as accounts of last resort). Such accounts remain available and are not subject to automatic disabling or removal dates. Conditions for disabling or deactivating accounts include when shared/group, emergency, or temporary accounts are no longer required and when individuals are transferred or terminated. Changing shared/group authenticators when members leave the group is intended to ensure that former group members do not retain access to the shared or group account. Some types of system accounts may require specialized training.",
          "Access control. Least privilege | authorize access to security functions. Authorize access for an organization-defined individuals or roles to:\n(a) organization-defined security functions (deployed in hardware, software, and firmware).\n(b) organization-defined security-relevant information.\n\nSecurity functions include establishing system accounts, configuring access authorizations (i.e., permissions, privileges), configuring settings for events to be audited, and establishing intrusion detection parameters. \n\nSecurity-relevant information includes filtering rules for routers or firewalls, configuration parameters for security services, cryptographic key management information, and access control lists.\n\nAuthorized personnel include security administrators, system administrators, system security officers, system programmers, and other privileged users.",
          "Access control. Concurrent session control. Limit the number of concurrent sessions for each organization-defined account and/or account type to the organization-defined number. Organizations may define the maximum number of concurrent sessions for system accounts globally, by account type, by account, or any combination thereof. For example, organizations may limit the number of concurrent sessions for system administrators or other individuals working in particularly sensitive domains or mission-critical applications. Concurrent session control addresses concurrent sessions for system accounts. It does not, however, address concurrent sessions by single users via multiple system accounts.",
          "Access control. Account management | privileged user accounts. (a) Establish and administer privileged user accounts in accordance with [selection: a role-based access scheme; an attribute-based access scheme]. \n(b) Monitor privileged role or attribute assignments. \n(c) Monitor changes to roles or attributes. \n(d) Revoke access when privileged role or attribute assignments are no longer appropriate. \n\nPrivileged roles are organization-defined roles assigned to individuals that allow those individuals to perform certain security-relevant functions that ordinary users are not authorized to perform. Privileged roles include key management, account management, database administration, system and network administration, and web administration. \n\nA role-based access scheme organizes permitted system access and privileges into roles. In contrast, an attribute-based access scheme specifies allowed system access and privileges based on attributes.",
          "Access control. System use notification. a. Display [assignment: organization-defined system use notification message or banner] to users before granting access to the system that provides privacy and security notices consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines, and state that users are accessing a U.S. government system. System usage may be monitored, recorded, and subject to audit. Unauthorized use of the system is prohibited and subject to criminal and civil penalties. Use of the system indicates consent to monitoring and recording.\n\nb. Retain the notification message or banner on the screen until users acknowledge the usage conditions and take explicit actions to log on to or further access the system.\n\nc. For publicly accessible systems:\n\n1. Display system use information [assignment: organization-defined conditions] before granting further access to the publicly accessible system.\n\n2. Display references, if any, to monitoring, recording, or auditing that are consistent with privacy accommodations for such systems that generally prohibit those activities.\n\n3. Include a description of the authorized uses of the system.\n\nSystem use notifications can be implemented using messages or warning banners displayed before individuals log in to systems. System use notifications are used only for access via logon interfaces with human users. Notifications are not required when human interfaces do not exist.\n\nBased on an assessment of risk, organizations consider whether or not a secondary system use notification is needed to access applications or other system resources after the initial network logon.\n\nOrganizations consider system use notification messages or banners displayed in multiple languages based on organizational needs and the demographics of system users. Organizations consult with the privacy office for input regarding privacy messaging and the Office of the General Counsel or organizational equivalent for legal review and approval of warning banner content.",
          "Access control. Account management | usage conditions. Enforce [assignment: organization-defined circumstances and/or usage conditions] for [assignment: organization-defined system accounts]. Specifying and enforcing usage conditions helps to enforce the principle of least privilege, increase user accountability, and enable effective account monitoring. Account monitoring includes alerts generated if the account is used in violation of organizational parameters. Organizations can describe specific conditions or circumstances under which system accounts can be used, such as by restricting usage to certain days of the week, time of day, or specific durations of time.",
          "Access control. Remote access | privileged commands and access. (a) Authorize the execution of privileged commands and access to security-relevant information via remote access only in a format that provides accessible evidence and for the following needs: [assignment: organization-defined needs]. \n\n(b) Document the rationale for remote access in the security plan for the system. Remote access to systems represents a significant potential vulnerability that can be exploited by adversaries. As such, restricting the execution of privileged commands and access to security-relevant information via remote access reduces the exposure of the organization and the susceptibility to threats by adversaries to the remote access capability.",
          "Access control. Least privilege | privileged accounts. Restrict privileged accounts on the system to [assignment: organization-defined personnel or roles]. Privileged accounts, including super user accounts, are typically described as a system administrator for various types of commercial off-the-shelf operating systems. Restricting privileged accounts to specific personnel or roles prevents day-to-day users from accessing privileged information or privileged functions. Organizations may differentiate in the application of restricting privileged accounts between allowed privileges for local accounts and for domain accounts, provided that they retain the ability to control system configurations for key parameters and as otherwise necessary to sufficiently mitigate risk.",
          "Access control. Least privilege | prohibit non-privileged users from executing privileged functions. Prevent non-privileged users from executing privileged functions. Privileged functions include disabling, circumventing, or altering implemented security or privacy controls, establishing system accounts, performing system integrity checks, and administering cryptographic key management activities. Non-privileged users are individuals who do not possess appropriate authorizations. Privileged functions that require protection from non-privileged users include circumventing intrusion detection and prevention mechanisms or malicious code protection mechanisms. Preventing non-privileged users from executing privileged functions is enforced by AC-3.",
          "Access control. Least privilege | non-privileged access for nonsecurity functions. Require that users of system accounts (or roles) with access to [assignment: organization-defined security functions or security-relevant information] use non-privileged accounts or roles when accessing non-security functions. Requiring the use of non-privileged accounts when accessing non-security functions limits exposure when operating from within privileged accounts or roles. The inclusion of roles addresses situations where organizations implement access control policies, such as role-based access control, and where a change of role provides the same degree of assurance in the change of access authorizations for the user and the processes acting on behalf of the user as would be provided by a change between a privileged and non-privileged account.",
          "Access control. Unsuccessful logon attempts. a. Enforce a limit of [assignment: organization-defined number] consecutive invalid logon attempts by a user during a [assignment: organization-defined time period]. \nb. Automatically [selection (one or more): lock the account or node for an [assignment: organization-defined time period]; lock the account or node until released by an administrator; delay next logon prompt per [assignment: organization-defined delay algorithm]; notify system administrator; take other [assignment: organization-defined action]] when the maximum number of unsuccessful attempts is exceeded. The need to limit unsuccessful logon attempts and take subsequent action when the maximum number of attempts is exceeded applies regardless of whether the logon occurs via a local or network connection. Due to the potential for denial of service, automatic lockouts initiated by systems are usually temporary and automatically release after a predetermined, organization-defined time period. If a delay algorithm is selected, organizations may employ different algorithms for different components of the system based on the capabilities of those components. Responses to unsuccessful logon attempts may be implemented at the operating system and the application levels. Organization-defined actions that may be taken when the number of allowed consecutive invalid logon attempts is exceeded include prompting the user to answer a secret question in addition to the username and password, invoking a lockdown mode with limited user capabilities (instead of full lockout), allowing users to only logon from specified internet protocol (IP) addresses, requiring a captcha to prevent automated attacks, or applying user profiles such as location, time of day, IP address, device, or media access control (MAC) address. If automatic system lockout or execution of a delay algorithm is not implemented in support of the availability objective, organizations consider a combination of other actions to help prevent brute force attacks. In addition to the above, organizations can prompt users to respond to a secret question before the number of allowed unsuccessful logon attempts is exceeded. Automatically unlocking an account after a specified period of time is generally not permitted. However, exceptions may be required based on operational mission or need.",
          "Access control. Account management | disable accounts. Disable accounts within [assignment: organization-defined time period] when the accounts: (a) have expired; (b) are no longer associated with a user or individual; (c) are in violation of organizational policy; or (d) have been inactive for [assignment: organization-defined time period]. Disabling expired, inactive, or otherwise anomalous accounts supports the concepts of least privilege and least functionality, which reduce the attack surface of the system.",
          "Access control. Account management | automated system account management. Support the management of system accounts using [assignment: organization-defined automated mechanisms]. Automated system account management includes using automated mechanisms to create, enable, modify, disable, and remove accounts. Notify account managers when an account is created, enabled, modified, disabled, or removed, or when users are terminated or transferred. Monitor system account usage. Report atypical system account usage. Automated mechanisms can include internal system functions and email, telephonic, and text messaging notifications.",
          "Access control. Session termination. Automatically terminate a user session after [assignment: organization-defined conditions or trigger events requiring session disconnect]. Session termination addresses the termination of user-initiated logical sessions. In contrast to SC-10, which addresses the termination of network connections associated with communications sessions (i.e., network disconnect). A logical session (for local, network, and remote access) is initiated whenever a user (or process acting on behalf of a user) accesses an organizational system. Such user sessions can be terminated without terminating network sessions. Session termination ends all processes associated with a user's logical session, except for those processes that are specifically created by the user (i.e., session owner) to continue after the session is terminated. Conditions or trigger events that require automatic termination of the session include organization-defined periods of user inactivity, targeted responses to certain types of incidents, or time-of-day restrictions on system use.",
          "Access control. Least privilege | log use of privileged functions. Log the execution of privileged functions. The misuse of privileged functions, either intentionally or unintentionally, by authorized users or by unauthorized external entities that have compromised system accounts, is a serious and ongoing concern and can have significant adverse impacts on organizations. Logging and analyzing the use of privileged functions is one way to detect such misuse and, in doing so, help mitigate the risk from insider threats and the advanced persistent threat.",
          "Access control. Account management | account monitoring for atypical usage. (a) Monitor system accounts for [assignment: organization-defined atypical usage]; and (b) report atypical usage of system accounts to [assignment: organization-defined personnel or roles]. Atypical usage includes accessing systems at certain times of the day or from locations that are not consistent with the normal usage patterns of individuals. Monitoring for atypical usage may reveal rogue behavior by individuals or an attack in progress. Account monitoring may inadvertently create privacy risks since data collected to identify atypical usage may reveal previously unknown information about the behavior of individuals. Organizations assess and document privacy risks from monitoring accounts for atypical usage in their privacy impact assessment and make determinations that are in alignment with their privacy program plan.",
          "Access control. Account management | automated temporary and emergency account management. Automatically remove temporary and emergency accounts after an organization-defined time period for each type of account. Management of temporary and emergency accounts includes the removal or disabling of such accounts automatically after a predefined time period, rather than at the convenience of the system administrator. Automatic removal or disabling of accounts provides a more consistent implementation.",
          "Access control. Remote access | monitoring and control. Employ automated mechanisms to monitor and control remote access methods. Monitoring and control of remote access methods allows organizations to detect attacks and help ensure compliance with remote access policies by auditing the connection activities of remote users on a variety of system components, including servers, notebook computers, workstations, smartphones, and tablets. Audit logging for remote access is enforced by AU-2. Audit events are defined in AU-2a.",
          "Access control. Account management | automated audit actions. Automatically audit account creation, modification, enabling, disabling, and removal actions. Account management audit records are defined in accordance with AU-2 and reviewed, analyzed, and reported in accordance with AU-6.",
          "Access control. Least privilege | network access to privileged commands. Authorize network access to [assignment: organization-defined privileged commands] only for [assignment: organization-defined compelling operational needs] and document the rationale for such access in the security plan for the system. Network access is any access across a network connection, in lieu of local access (i.e., the user being physically present at the device).",
          "Access control. Least privilege | review of user privileges. (a) Review [assignment: organization-defined frequency] the privileges assigned to [assignment: organization-defined roles or classes of users] to validate the need for such privileges; and (b) reassign or remove privileges, if necessary, to correctly reflect organizational mission and business needs. The need for certain assigned user privileges may change over time to reflect changes in organizational mission and business functions, environments of operation, technologies, or threats. A periodic review of assigned user privileges is necessary to determine if the rationale for assigning such privileges remains valid. If the need cannot be revalidated, organizations take appropriate corrective actions.",
          "Access control. Separation of duties. A. Identify and document [Assignment: organization-defined duties of individuals requiring separation]. \n\nB. Define system access authorizations to support separation of duties. Separation of duties addresses the potential for abuse of authorized privileges and helps to reduce the risk of malevolent activity without collusion. Separation of duties includes dividing mission or business functions and support functions among different individuals or roles. It also involves conducting system support functions with different individuals and ensuring that security personnel who administer access control functions do not also administer audit functions. \n\nBecause separation of duty violations can span systems and application domains, organizations consider the entirety of systems and system components when developing policy on separation of duties. Separation of duties is enforced through the account management activities in AC-2, access control mechanisms in AC-3, and identity management activities in IA-2, IA-4, and IA-12.",
          "Access control. Account management | restrictions on use of shared and group accounts. Only permit the use of shared and group accounts that meet [assignment: organization-defined conditions for establishing shared and group accounts]. Before permitting the use of shared or group accounts, organizations should consider the increased risk due to the lack of accountability associated with such accounts.",
          "Access control. Account management | disable accounts for high-risk individuals. Disable accounts of individuals within [assignment: organization-defined time period] of discovery of [assignment: organization-defined significant risks]. Users who pose a significant security and/or privacy risk include individuals for whom reliable evidence indicates either the intention to use authorized access to systems to cause harm or through whom adversaries will cause harm. Such harm includes adverse impacts to organizational operations, organizational assets, individuals, other organizations, or the nation. Close coordination among system administrators, legal staff, human resource managers, and authorizing officials is essential when disabling system accounts for high-risk individuals.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "7_accounts_account_access",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "7_accounts_account_access"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          10.405245780944824,
          10.910877227783203,
          10.956954002380371,
          10.629828453063965,
          10.840470314025879,
          10.569558143615723,
          10.809977531433105,
          10.33342456817627,
          10.575305938720703,
          10.763470649719238,
          10.93657398223877,
          10.973372459411621,
          10.949816703796387,
          10.437422752380371,
          10.595816612243652,
          10.55905532836914,
          10.181450843811035,
          10.97986888885498,
          10.636542320251465,
          10.545097351074219,
          10.621137619018555,
          10.515215873718262,
          10.84862995147705,
          10.890503883361816,
          10.74092960357666,
          10.630117416381836,
          10.655725479125977,
          10.684905052185059
         ],
         "y": [
          8.2554349899292,
          7.873643398284912,
          7.804348945617676,
          8.288491249084473,
          7.84928035736084,
          8.303176879882812,
          7.945314884185791,
          8.007633209228516,
          8.277168273925781,
          7.677014350891113,
          7.905255317687988,
          7.776422023773193,
          7.863417148590088,
          8.21798324584961,
          8.306267738342285,
          8.307162284851074,
          8.193868637084961,
          7.7756757736206055,
          8.369584083557129,
          8.336893081665039,
          7.479113578796387,
          8.353453636169434,
          7.782434463500977,
          7.853076457977295,
          7.810394763946533,
          8.299558639526367,
          8.327230453491211,
          8.045899391174316
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Incident response. Information spillage response | training. Provide information spillage response training [assignment: organization-defined frequency]. Organizations establish requirements for responding to information spillage incidents in incident response plans. Incident response training on a regular basis helps to ensure that organizational personnel understand their individual responsibilities and what specific actions to take when spillage incidents occur.",
          "Incident response. Incident response training | automated training environments. Provide an incident response training environment using [assignment: organization-defined automated mechanisms]. Automated mechanisms can provide a more thorough and realistic incident response training environment. This can be accomplished, for example, by providing more complete coverage of incident response issues, selecting more realistic training scenarios and environments, and stressing the response capability.",
          "Incident response. Incident handling | insider threats. Implement an incident handling capability for incidents involving insider threats. The explicit focus on handling incidents involving insider threats provides additional emphasis on this type of threat and the need for specific incident handling capabilities to provide appropriate and timely responses.",
          "Incident response. Incident response training. a. Provide incident response training to system users consistent with assigned roles and responsibilities:\n\n1. Within [assignment: organization-defined time period] of assuming an incident response role or responsibility or acquiring system access.\n2. When required by system changes.\n3. [Assignment: organization-defined frequency] thereafter.\n\nb. Review and update incident response training content [assignment: organization-defined frequency] and following [assignment: organization-defined events].\n\nIncident response training is associated with the assigned roles and responsibilities of organizational personnel to ensure that the appropriate content and level of detail are included in such training. For example, users may only need to know who to call or how to recognize an incident; system administrators may require additional training on how to handle incidents; and incident responders may receive more specific training on forensics, data collection techniques, reporting, system recovery, and system restoration. Incident response training includes user training in identifying and reporting suspicious activities from external and internal sources. Incident response training for users may be provided as part of AT-2 or AT-3.\n\nEvents that may precipitate an update to incident response training content include, but are not limited to, incident response plan testing or response to an actual incident (lessons learned), assessment or audit findings, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines.",
          "Incident response. Incident response training | simulated events. Incorporate simulated events into incident response training to facilitate the required response by personnel in crisis situations. Organizations establish requirements for responding to incidents in incident response plans. Incorporating simulated events into incident response training helps to ensure that personnel understand their individual responsibilities and what specific actions to take in crisis situations.",
          "Incident response. Incident response assistance | automation support for availability of information and support. Increase the availability of incident response information and support using [assignment: organization-defined automated mechanisms]. Automated mechanisms can provide a push or pull capability for users to obtain incident response assistance. For example, individuals may have access to a website to query the assistance capability, or the assistance capability can proactively send incident response information to users (general distribution or targeted) as part of increasing understanding of current response capabilities and support.",
          "Incident response. Incident reporting. a. Require personnel to report suspected incidents to the organizational incident response capability within [assignment: organization-defined time period]. \nb. Report incident information to [assignment: organization-defined authorities]. \n\nThe types of incidents reported, the content and timeliness of the reports, and the designated reporting authorities reflect applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Incident information can inform risk assessments, control effectiveness assessments, security requirements for acquisitions, and selection criteria for technology products.",
          "Incident response. Incident handling | integrated incident response team. Establish and maintain an integrated incident response team that can be deployed to any location identified by the organization in [assignment: organization-defined time period]. An integrated incident response team is a team of experts that assesses, documents, and responds to incidents so that organizational systems and networks can recover quickly and implement the necessary controls to avoid future incidents. Incident response team personnel include forensic and malicious code analysts, tool developers, systems security and privacy engineers, and real-time operations personnel. The incident handling capability includes performing rapid forensic preservation of evidence and analysis of and response to intrusions. For some organizations, the incident response team can be a cross-organizational entity. \n\nAn integrated incident response team facilitates information sharing and allows organizational personnel (e.g., developers, implementers, and operators) to leverage team knowledge of the threat and implement defensive measures that enable organizations to deter intrusions more effectively. Moreover, integrated teams promote the rapid detection of intrusions, the development of appropriate mitigations, and the deployment of effective defensive measures. \n\nFor example, when an intrusion is detected, the integrated team can rapidly develop an appropriate response for operators to implement, correlate the new incident with information on past intrusions, and augment ongoing cyber intelligence development. Integrated incident response teams are better able to identify adversary tactics, techniques, and procedures that are linked to the operations tempo or specific mission and business functions and to define responsive actions in a way that does not disrupt those mission and business functions. Incident response teams can be distributed within organizations to make the capability resilient.",
          "Incident response. Incident monitoring. Track and document incidents. Documenting incidents includes maintaining records about each incident, the status of the incident, and other pertinent information necessary for forensics, as well as evaluating incident details, trends, and handling. Incident information can be obtained from a variety of sources, including network monitoring, incident reports, incident response teams, user complaints, supply chain partners, audit monitoring, physical access monitoring, and user and administrator reports. IR-4 provides information on the types of incidents that are appropriate for monitoring.",
          "Incident response. Incident monitoring | automated tracking, data collection, and analysis. Track incidents and collect and analyze incident information using [assignment: organization-defined automated mechanisms]. Automated mechanisms for tracking incidents and collecting and analyzing incident information include computer incident response centers or other electronic databases of incidents and network monitoring devices.",
          "Incident response. Incident response plan. A. Develop an incident response plan that:\n\n1. Provides the organization with a roadmap for implementing its incident response capability.\n2. Describes the structure and organization of the incident response capability.\n3. Provides a high-level approach for how the incident response capability fits into the overall organization.\n4. Meets the unique requirements of the organization, which relate to mission, size, structure, and functions.\n5. Defines reportable incidents.\n6. Provides metrics for measuring the incident response capability within the organization.\n7. Defines the resources and management support needed to effectively maintain and mature an incident response capability.\n8. Addresses the sharing of incident information.\n9. Is reviewed and approved by [assignment: organization-defined personnel or roles] [assignment: organization-defined frequency].\n10. Explicitly designates responsibility for incident response to [assignment: organization-defined entities, personnel, or roles].\n\nB. Distribute copies of the incident response plan to [assignment: organization-defined incident response personnel (identified by name and/or role) and organizational elements].\n\nC. Update the incident response plan to address system and organizational changes or problems encountered during plan implementation, execution, or testing.\n\nD. Communicate incident response plan changes to [assignment: organization-defined incident response personnel (identified by name and/or role) and organizational elements].\n\nE. Protect the incident response plan from unauthorized disclosure and modification.\n\nIt is important that organizations develop and implement a coordinated approach to incident response. Organizational mission and business functions determine the structure of incident response capabilities. As part of the incident response capabilities, organizations consider the coordination and sharing of information with external organizations, including external service providers and other organizations involved in the supply chain. For incidents involving personally identifiable information (i.e., breaches), include a process to determine whether notice to oversight organizations or affected individuals is appropriate and provide that notice accordingly.",
          "Incident response. Incident reporting | supply chain coordination. Provide incident information to the provider of the product or service and other organizations involved in the supply chain or supply chain governance for systems or system components related to the incident. Organizations involved in supply chain activities include product developers, system integrators, manufacturers, packagers, assemblers, distributors, vendors, and resellers. Entities that provide supply chain governance include the Federal Acquisition Security Council (FASC). Supply chain incidents include compromises or breaches that involve information technology products, system components, development processes or personnel, distribution processes, or warehousing facilities. Organizations determine the appropriate information to share and consider the value gained from informing external organizations about supply chain incidents, including the ability to improve processes or to identify the root cause of an incident.",
          "Incident response. Incident handling | automated incident handling processes. Support the incident handling process using organization-defined automated mechanisms. Automated mechanisms that support incident handling processes include online incident management systems and tools that support the collection of live response data, full network packet capture, and forensic analysis.",
          "Incident response. Incident handling | information correlation. Correlate incident information and individual incident responses to achieve an organization-wide perspective on incident awareness and response. Sometimes, a threat event, such as a hostile cyber-attack, can only be observed by bringing together information from different sources, including various reports and reporting procedures established by organizations.",
          "Incident response. Incident response assistance. Provide an incident response support resource. This resource is integral to the organizational incident response capability and offers advice and assistance to users of the system for the handling and reporting of incidents. Incident response support resources provided by organizations include help desks, assistance groups, automated ticketing systems (to open and track incident response tickets), and access to forensics services or consumer redress services when required.",
          "Incident response. Incident response testing. Test the effectiveness of the incident response capability for the system [assignment: organization-defined frequency] using the following tests: [assignment: organization-defined tests]. Organizations test incident response capabilities to determine their effectiveness and identify potential weaknesses or deficiencies. Incident response testing includes the use of checklists, walk-through or tabletop exercises, and simulations (parallel or full interrupt). Incident response testing can include a determination of the effects on organizational operations and assets and individuals due to incident response. The use of qualitative and quantitative data aids in determining the effectiveness of incident response processes.",
          "Incident response. Incident reporting | automated reporting. Report incidents using [Assignment: organization-defined automated mechanisms]. The recipients of incident reports are specified in IR-6b. Automated reporting mechanisms include email, posting on websites (with automatic updates), and automated incident response tools and programs.",
          "Incident response. Incident response testing | coordination with related plans. Coordinate incident response testing with organizational elements responsible for related plans. Organizational plans related to incident response testing include:\n\n1. Business continuity plans.\n2. Disaster recovery plans.\n3. Continuity of operations plans.\n4. Contingency plans.\n5. Crisis communications plans.\n6. Critical infrastructure plans.\n7. Occupant emergency plans.",
          "Incident response. Information spillage response. Respond to information spills by:\n\na. Assigning [assignment: organization-defined personnel or roles] with responsibility for responding to information spills.\nb. Identifying the specific information involved in the system contamination.\nc. Alerting [assignment: organization-defined personnel or roles] of the information spill using a method of communication not associated with the spill.\nd. Isolating the contaminated system or system component.\ne. Eradicating the information from the contaminated system or component.\nf. Identifying other systems or system components that may have been subsequently contaminated.\ng. Performing the following additional actions: [assignment: organization-defined actions].\n\nInformation spillage refers to instances where information is placed on systems that are not authorized to process such information. Information spills occur when information that is thought to be of a certain classification or impact level is transmitted to a system and subsequently determined to be of a higher classification or impact level. At that point, corrective action is required. \n\nThe nature of the response is based on the classification or impact level of the spilled information, the security capabilities of the system, the specific nature of the contaminated storage media, and the access authorizations of individuals with authorized access to the contaminated system. \n\nThe methods used to communicate information about the spill after the fact do not involve methods directly associated with the actual spill to minimize the risk of further spreading the contamination before such contamination is isolated and eradicated.",
          "Incident response. Policy and procedures. A. Develop, document, and disseminate to organization-defined personnel or roles:\n1. Organization level incident response policy that addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance. The policy should be consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines.\n2. Procedures to facilitate the implementation of the incident response policy and the associated incident response controls.\n\nB. Designate an organization-defined official to manage the development, documentation, and dissemination of the incident response policy and procedures.\n\nC. Review and update the current incident response:\n1. Policy organization-defined frequency and following organization-defined events.\n2. Procedures organization-defined frequency and following organization-defined events.\n\nThe incident response policy and procedures address the controls in the IR family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures.\n\nPolicies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of incident response policy and procedures. Security and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures.\n\nThe policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations. Procedures can be established for security and privacy programs, mission or business processes, and systems if needed.\n\nProcedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents.\n\nEvents that may precipitate an update to incident response policy and procedures include assessment or audit findings, security incidents or breaches, or changes in laws, executive orders, directives, regulations, policies, standards, and guidelines.\n\nSimply restating controls does not constitute an organizational policy or procedure.",
          "Incident response. Incident handling. a. Implement an incident handling capability for incidents that is consistent with the incident response plan and includes preparation, detection and analysis, containment, eradication, and recovery. \nb. Coordinate incident handling activities with contingency planning activities. \nc. Incorporate lessons learned from ongoing incident handling activities into incident response procedures, training, and testing, and implement the resulting changes accordingly. \nd. Ensure the rigor, intensity, scope, and results of incident handling activities are comparable and predictable across the organization. \n\nOrganizations recognize that incident response capabilities are dependent on the capabilities of organizational systems and the mission and business processes being supported by those systems. Organizations consider incident response as part of the definition, design, and development of mission and business processes and systems. Incident-related information can be obtained from a variety of sources, including audit monitoring, physical access monitoring, and network monitoring; user or administrator reports; and reported supply chain events. \n\nAn effective incident handling capability includes coordination among many organizational entities (e.g., mission or business owners, system owners, authorizing officials, human resources offices, physical security offices, personnel security offices, legal departments, risk executive [function], operations personnel, procurement offices). \n\nSuspected security incidents include the receipt of suspicious email communications that can contain malicious code. Suspected supply chain incidents include the insertion of counterfeit hardware or malicious code into organizational systems or system components. \n\nFor federal agencies, an incident that involves personally identifiable information is considered a breach. A breach results in unauthorized disclosure, the loss of control, unauthorized acquisition, compromise, or a similar occurrence where a person other than an authorized user accesses or potentially accesses personally identifiable information or an authorized user accesses or potentially accesses such information for other than authorized purposes.",
          "Incident response. Information spillage response | post-spill operations. Implement the following procedures to ensure that organizational personnel impacted by information spills can continue to carry out assigned tasks while contaminated systems are undergoing corrective actions:\n\n[Assignment: Organization-defined procedures]. Corrective actions for systems contaminated due to information spillages may be time-consuming. Personnel may not have access to the contaminated systems while corrective actions are being taken, which may potentially affect their ability to conduct organizational business.",
          "Incident response. Information spillage response | exposure to unauthorized personnel. Employ the following controls for personnel exposed to information not within assigned access authorizations: [assignment: organization-defined controls]. Controls include ensuring that personnel who are exposed to spilled information are made aware of the laws, executive orders, directives, regulations, policies, standards, and guidelines regarding the information and the restrictions imposed based on exposure to such information.",
          "Incident response. Incident handling | dynamic reconfiguration. Include the following types of dynamic reconfiguration for organization-defined system components as part of the incident response capability: organization-defined types of dynamic reconfiguration. Dynamic reconfiguration includes changes to router rules, access control lists, intrusion detection or prevention system parameters, and filter rules for guards or firewalls. Organizations may perform dynamic reconfiguration of systems to stop attacks, misdirect attackers, and isolate components of systems, thus limiting the extent of the damage from breaches or compromises. Organizations should include specific time frames for achieving the reconfiguration of systems in the definition of the reconfiguration capability, considering the potential need for rapid response to effectively address cyber threats.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "8_incident_response_and",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "8_incident_response_and"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -1.4440412521362305,
          -1.458036184310913,
          -1.5921787023544312,
          -1.5065600872039795,
          -1.4801077842712402,
          -1.6078100204467773,
          -1.6782159805297852,
          -1.5488736629486084,
          -1.7091635465621948,
          -1.6794389486312866,
          -1.6484917402267456,
          -1.5650700330734253,
          -1.5313998460769653,
          -1.525473952293396,
          -1.5901354551315308,
          -1.6277439594268799,
          -1.7466059923171997,
          -1.648084282875061,
          -1.465836524963379,
          -1.7285027503967285,
          -1.6099554300308228,
          -1.4121921062469482,
          -1.398330807685852,
          -1.743201732635498,
          -1.5810604095458984
         ],
         "y": [
          -0.3195893168449402,
          -0.4787804186344147,
          -0.3382384181022644,
          -0.4232989549636841,
          -0.5274589657783508,
          -0.367130845785141,
          -0.3320048153400421,
          -0.33271539211273193,
          -0.28359246253967285,
          -0.3251652717590332,
          -0.4494858682155609,
          -0.2500808835029602,
          -0.3534076511859894,
          -0.19725285470485687,
          -0.41030171513557434,
          -0.43939489126205444,
          -0.28249362111091614,
          -0.4772818386554718,
          -0.23968249559402466,
          -0.5870880484580994,
          -0.3044579327106476,
          -0.25264209508895874,
          -0.23918506503105164,
          -0.5134084224700928,
          -0.3635057508945465
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "System and communications protection. Policy and procedures. A. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]: 1. [Selection (one or more): organization level; mission/business process-level; system-level] system and communications protection policy that: (a) addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance; and (b) is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines; and 2. Procedures to facilitate the implementation of the system and communications protection policy and the associated system and communications protection controls.\n\nB. Designate an [assignment: organization-defined official] to manage the development, documentation, and dissemination of the system and communications protection policy and procedures.\n\nC. Review and update the current system and communications protection: 1. Policy [assignment: organization-defined frequency] and following [assignment: organization-defined events]; and 2. Procedures [assignment: organization-defined frequency] and following [assignment: organization-defined events].\n\nSystem and communications protection policy and procedures address the controls in the SC family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of system and communications protection policy and procedures. Security and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations. Procedures can be established for security and privacy programs, for mission or business processes, and for systems, if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents. Events that may precipitate an update to system and communications protection policy and procedures include assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Personnel security. Position descriptions. Incorporate security and privacy roles and responsibilities into organizational position descriptions. Specification of security and privacy roles in individual organizational position descriptions facilitates clarity in understanding the security or privacy responsibilities associated with the roles and the role-based security and privacy training requirements for the roles.",
          "Security assessment and authorization. Plan of action and milestones. A. Develop a plan of action and milestones for the system to document the planned remediation actions of the organization. This will help to correct weaknesses or deficiencies noted during the assessment of the controls and to reduce or eliminate known vulnerabilities in the system. \n\nB. Update the existing plan of action and milestones, at a frequency determined by the organization, based on the findings from control assessments, independent audits or reviews, and continuous monitoring activities. \n\nPlans of action and milestones are useful for any type of organization to track planned remedial actions. They are required in authorization packages and are subject to federal reporting requirements established by the OMB.",
          "Personnel security. Position risk designation. a. Assign a risk designation to all organizational positions. \nb. Establish screening criteria for individuals filling those positions. \nc. Review and update position risk designations [assignment: organization-defined frequency]. \n\nPosition risk designations reflect Office of Personnel Management (OPM) policy and guidance. Proper position designation is the foundation of an effective and consistent suitability and personnel security program. The Position Designation System (PDS) assesses the duties and responsibilities of a position to determine the degree of potential damage to the efficiency or integrity of the service due to misconduct of an incumbent of a position and establishes the risk level of that position. \n\nThe PDS assessment also determines if the duties and responsibilities of the position present the potential for position incumbents to bring about a material adverse effect on national security and the degree of that potential effect, which establishes the sensitivity level of a position. The results of the assessment determine what level of investigation is conducted for a position. \n\nRisk designations can guide and inform the types of authorizations that individuals receive when accessing organizational information and information systems. Position screening criteria include explicit information security role appointment requirements. \n\nParts 1400 and 731 of Title 5, Code of Federal Regulations, establish the requirements for organizations to evaluate relevant covered positions for a position sensitivity and position risk designation commensurate with the duties and responsibilities of those positions.",
          "Personnel security. Policy and procedures. A. Develop, document, and disseminate to organization-defined personnel or roles:\n1. Organization level personnel security policy that addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance. The policy should be consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines.\n2. Procedures to facilitate the implementation of the personnel security policy and the associated personnel security controls.\n\nB. Designate an organization-defined official to manage the development, documentation, and dissemination of the personnel security policy and procedures.\n\nC. Review and update the current personnel security:\n1. Policy, organization-defined frequency, and following organization-defined events.\n2. Procedures, organization-defined frequency, and following organization-defined events.\n\nPersonnel security policy and procedures for the controls in the PS family are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on their development.\n\nSecurity and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission level or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies reflecting the complex nature of organizations.\n\nProcedures can be established for security and privacy programs, for mission/business processes, and for systems, if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents.\n\nEvents that may precipitate an update to personnel security policy and procedures include, but are not limited to, assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Identification and authentication. Policy and procedures. A. Develop, document, and disseminate to organization-defined personnel or roles: \n\n1. Organization level identification and authentication policy that addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance. The policy should be consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines.\n\n2. Procedures to facilitate the implementation of the identification and authentication policy and the associated identification and authentication controls.\n\nB. Designate an organization-defined official to manage the development, documentation, and dissemination of the identification and authentication policy and procedures.\n\nC. Review and update the current identification and authentication:\n\n1. Policy organization-defined frequency and following organization-defined events.\n\n2. Procedures organization-defined frequency and following organization-defined events.\n\nThe identification and authentication policy and procedures address the controls in the IA family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of identification and authentication policy and procedures. \n\nSecurity and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations. Procedures can be established for security and privacy programs, for mission or business processes, and for systems, if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents.\n\nEvents that may precipitate an update to identification and authentication policy and procedures include assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Physical and environmental protection. Policy and procedures. A. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]:\n\n1. [Selection (one or more): organization level; mission/business process-level; system-level] physical and environmental protection policy that:\n(a) Addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance; and\n(b) Is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines; and\n\n2. Procedures to facilitate the implementation of the physical and environmental protection policy and the associated physical and environmental protection controls;\n\nB. Designate an [assignment: organization-defined official] to manage the development, documentation, and dissemination of the physical and environmental protection policy and procedures; and\n\nC. Review and update the current physical and environmental protection:\n\n1. Policy [assignment: organization-defined frequency] and following [assignment: organization-defined events]; and\n\n2. Procedures [assignment: organization-defined frequency] and following [assignment: organization-defined events].\n\nPhysical and environmental protection policy and procedures address the controls in the PE family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of physical and environmental protection policy and procedures. Security and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations. Procedures can be established for security and privacy programs, for mission or business processes, and for systems if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents. Events that may precipitate an update to physical and environmental protection policy and procedures include assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Contingency planning. Policy and procedures. A. Develop, document, and disseminate to organization-defined personnel or roles: \n\n1. Organization level contingency planning policy that addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance. The policy should be consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. \n\n2. Procedures to facilitate the implementation of the contingency planning policy and the associated contingency planning controls. \n\nB. Designate an organization-defined official to manage the development, documentation, and dissemination of the contingency planning policy and procedures. \n\nC. Review and update the current contingency planning: \n\n1. Policy organization-defined frequency and following organization-defined events. \n\n2. Procedures organization-defined frequency and following organization-defined events. \n\nContingency planning policy and procedures address the controls in the CP family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of contingency planning policy and procedures. \n\nSecurity and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations. \n\nProcedures can be established for security and privacy programs, for mission or business processes, and for systems, if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents. \n\nEvents that may precipitate an update to contingency planning policy and procedures include assessment or audit findings, security incidents or breaches, or changes in laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Media protection. Policy and procedures. A. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]: 1. [Selection (one or more): organization level; mission/business process-level; system-level] media protection policy that: (a) addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance; and (b) is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines; and 2. procedures to facilitate the implementation of the media protection policy and the associated media protection controls. \n\nB. Designate an [assignment: organization-defined official] to manage the development, documentation, and dissemination of the media protection policy and procedures.\n\nC. Review and update the current media protection: 1. policy [assignment: organization-defined frequency] and following [assignment: organization-defined events]; and 2. procedures [assignment: organization-defined frequency] and following [assignment: organization-defined events]. \n\nMedia protection policy and procedures address the controls in the MP family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of media protection policy and procedures. Security and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations. Procedures can be established for security and privacy programs, for mission or business processes, and for systems, if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents. Events that may precipitate an update to media protection policy and procedures include assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Security assessment and authorization. Policy and procedures. A. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]: 1. [Selection (one or more): organization-level; mission/business process-level; system-level] assessment, authorization, and monitoring policy that: (a) addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance; and (b) is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines; and 2. Procedures to facilitate the implementation of the assessment, authorization, and monitoring policy and the associated assessment, authorization, and monitoring controls. \n\nB. Designate an [assignment: organization-defined official] to manage the development, documentation, and dissemination of the assessment, authorization, and monitoring policy and procedures. \n\nC. Review and update the current assessment, authorization, and monitoring: 1. Policy [assignment: organization-defined frequency] and following [assignment: organization-defined events]; and 2. Procedures [assignment: organization-defined frequency] and following [assignment: organization-defined events]. \n\nAssessment, authorization, and monitoring policy and procedures address the controls in the CA family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of assessment, authorization, and monitoring policy and procedures. Security and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. \n\nThe policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations. Procedures can be established for security and privacy programs, for mission or business processes, and for systems, if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents. \n\nEvents that may precipitate an update to assessment, authorization, and monitoring policy and procedures include assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Personnel security. Personnel screening | information requiring special protective measures. Verify that individuals accessing a system processing, storing, or transmitting information requiring special protection. (a) Have valid access authorizations that are demonstrated by assigned official government duties. And (b) Satisfy [assignment: organization-defined additional personnel screening criteria]. \n\nOrganizational information that requires special protection includes controlled unclassified information. Personnel security criteria include position sensitivity background screening requirements.",
          "Personnel security. Personnel transfer. a. Review and confirm the ongoing operational need for current logical and physical access authorizations to systems and facilities when individuals are reassigned or transferred to other positions within the organization. \nb. Initiate [assignment: organization-defined transfer or reassignment actions] within [assignment: organization-defined time period following the formal transfer action]. \nc. Modify access authorization as needed to correspond with any changes in operational need due to reassignment or transfer. \nd. Notify [assignment: organization-defined personnel or roles] within [assignment: organization-defined time period]. \nPersonnel transfer applies when reassignments or transfers of individuals are permanent or of such extended duration as to make the actions warranted. Organizations define actions appropriate for the types of reassignments or transfers, whether permanent or extended. Actions that may be required for personnel transfers or reassignments to other positions within organizations include returning old and issuing new keys, identification cards, and building passes; closing system accounts and establishing new accounts; changing system access authorizations (i.e., privileges); and providing for access to official records to which individuals had access at previous work locations and in previous system accounts.",
          "System and information integrity. Policy and procedures. a. Develop, document, and disseminate to organization-defined personnel or roles: \n1. Organization-level, system-level, and mission/business process-level system and information integrity policies that:\n(a) Address purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance.\n(b) Are consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines.\n2. Procedures to facilitate the implementation of the system and information integrity policy and associated controls.\n\nb. Designate an organization-defined official to manage the development, documentation, and dissemination of the system and information integrity policy and procedures.\n\nc. Review and update the current system and information integrity policies and procedures:\n1. Policy - organization-defined frequency and following organization-defined events.\n2. Procedures - organization-defined frequency and following organization-defined events.\n\nSystem and information integrity policies and procedures should address the controls in the SI family that are implemented within systems and organizations. The risk management strategy plays a crucial role in establishing these policies and procedures. Collaborative efforts between the security and privacy programs are essential in developing the system and information integrity policies and procedures. Organization-level security and privacy program policies and procedures are generally preferred, as they may eliminate the need for mission- or system-specific policies and procedures. The policy can be incorporated into the general security and privacy policy or represented by multiple policies that reflect the complexity of organizations. Procedures can be established for security and privacy programs, mission or business processes, and systems, if necessary. Procedures outline the implementation of policies or controls and can be directed at individuals or roles. They can be documented within system security and privacy plans or as separate documents. Updates to the system and information integrity policy and procedures may arise from assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Merely restating controls does not constitute an organizational policy or procedure.",
          "Maintenance. Policy and procedures. A. Develop, document, and disseminate to organization-defined personnel or roles:\n\n1. Organization-level maintenance policy that addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance. The policy should be consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines.\n\n2. Procedures to facilitate the implementation of the maintenance policy and the associated maintenance controls.\n\nB. Designate an organization-defined official to manage the development, documentation, and dissemination of the maintenance policy and procedures.\n\nC. Review and update the current maintenance:\n\n1. Policy organization-defined frequency and following organization-defined events.\n\n2. Procedures organization-defined frequency and following organization-defined events.\n\nMaintenance policy and procedures address the controls in the MA family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of maintenance policy and procedures.\n\nSecurity and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations. Procedures can be established for security and privacy programs, for mission or business processes, and for systems if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents.\n\nEvents that may precipitate an update to maintenance policy and procedures include assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "System and services acquisition. Policy and procedures. a. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]: \n1. [Selection (one or more): organization-level; mission/business process-level; system-level] system and services acquisition policy that: \n(a) Addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance.\n(b) Is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. \n2. Procedures to facilitate the implementation of the system and services acquisition policy and the associated system and services acquisition controls. \n\nb. Designate an [assignment: organization-defined official] to manage the development, documentation, and dissemination of the system and services acquisition policy and procedures. \n\nc. Review and update the current system and services acquisition: \n1. Policy [assignment: organization-defined frequency] and following [assignment: organization-defined events]. \n2. Procedures [assignment: organization-defined frequency] and following [assignment: organization-defined events]. \n\nSystem and services acquisition policy and procedures address the controls in the SA family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of system and services acquisition policy and procedures. \n\nSecurity and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations. Procedures can be established for security and privacy programs, for mission or business processes, and for systems if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents. \n\nEvents that may precipitate an update to system and services acquisition policy and procedures include assessment or audit findings, security incidents or breaches, or changes in laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Audit and accountability. Policy and procedures. A. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]:\n1. [Selection (one or more): organization level; mission/business process-level; system-level] audit and accountability policy that:\n(a) Addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance; and\n(b) Is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines; and\n2. Procedures to facilitate the implementation of the audit and accountability policy and the associated audit and accountability controls.\n\nB. Designate an [assignment: organization-defined official] to manage the development, documentation, and dissemination of the audit and accountability policy and procedures.\n\nC. Review and update the current audit and accountability:\n1. Policy [assignment: organization-defined frequency] and following [assignment: organization-defined events]; and\n2. Procedures [assignment: organization-defined frequency] and following [assignment: organization-defined events].\n\nAudit and accountability policy and procedures address the controls in the AU family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of audit and accountability policy and procedures.\n\nSecurity and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations.\n\nProcedures can be established for security and privacy programs, for mission or business processes, and for systems if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents.\n\nEvents that may precipitate an update to audit and accountability policy and procedures include assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Access control. Policy and procedures. A. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]: 1. [Selection (one or more): organization-level; mission/business process-level; system-level] access control policy that:\n(a) Addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance.\n(b) Is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines.\n2. Procedures to facilitate the implementation of the access control policy and the associated access controls.\n\nB. Designate an [assignment: organization-defined official] to manage the development, documentation, and dissemination of the access control policy and procedures.\n\nC. Review and update the current access control:\n1. Policy [assignment: organization-defined frequency] and following [assignment: organization-defined events].\n2. Procedures [assignment: organization-defined frequency] and following [assignment: organization-defined events].\n\nAccess control policy and procedures address the controls in the AC family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of access control policy and procedures. Security and privacy program policies and procedures at the organization level are preferable in general and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies reflecting the complex nature of organizations. Procedures can be established for security and privacy programs, for mission or business processes, and for systems if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents. Events that may precipitate an update to access control policy and procedures include assessment or audit findings, security incidents or breaches, or changes in laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Personnel security. Personnel screening. a. Screen individuals prior to authorizing access to the system.\nb. Rescreen individuals in accordance with [assignment: organization-defined conditions requiring rescreening and, where rescreening is so indicated, the frequency of rescreening].\nPersonnel screening and rescreening activities reflect applicable laws, executive orders, directives, regulations, policies, standards, guidelines, and specific criteria established for the risk designations of assigned positions. Examples of personnel screening include background investigations and agency checks. Organizations may define different rescreening conditions and frequencies for personnel accessing systems based on types of information processed, stored, or transmitted by the systems.",
          "Awareness and training. Policy and procedures. a. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]: 1. [Selection (one or more): organization level; mission/business process-level; system-level] awareness and training policy that: (a) addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance; and (b) is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines; and 2. Procedures to facilitate the implementation of the awareness and training policy and the associated awareness and training controls. \nb. Designate an [assignment: organization-defined official] to manage the development, documentation, and dissemination of the awareness and training policy and procedures. \nc. Review and update the current awareness and training: 1. Policy [assignment: organization-defined frequency] and following [assignment: organization-defined events]; and 2. Procedures [assignment: organization-defined frequency] and following [assignment: organization-defined events].\nAwareness and training policy and procedures address the controls in the AT family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of awareness and training policy and procedures. Security and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations. Procedures can be established for security and privacy programs, for mission or business processes, and for systems, if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents. Events that may precipitate an update to awareness and training policy and procedures include assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Personnel security. Personnel sanctions. a. Employ a formal sanctions process for individuals failing to comply with established information security and privacy policies and procedures. \n\nb. Notify [assignment: organization-defined personnel or roles] within [assignment: organization-defined time period] when a formal employee sanctions process is initiated, identifying the individual sanctioned and the reason for the sanction. \n\nOrganizational sanctions reflect applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Sanctions processes are described in access agreements and can be included as part of general personnel policies for organizations and/or specified in security and privacy policies. \n\nOrganizations consult with the Office of the General Counsel regarding matters of employee sanctions.",
          "Planning. Policy and procedures. A. Develop, document, and disseminate to organization-defined personnel or roles: 1. Organization level planning policy that addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance. The policy should be consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. 2. Procedures to facilitate the implementation of the planning policy and the associated planning controls. \n\nB. Designate an organization-defined official to manage the development, documentation, and dissemination of the planning policy and procedures. \n\nC. Review and update the current planning: 1. Policy organization-defined frequency and following organization-defined events. 2. Procedures organization-defined frequency and following organization-defined events. \n\nPlanning policy and procedures are essential for the controls in the PL family implemented within systems and organizations. The risk management strategy plays a crucial role in establishing such policies and procedures. Security and privacy programs should collaborate on their development as they contribute to security and privacy assurance. Preferably, security and privacy program policies and procedures should be established at the organization level, which may eliminate the need for mission level or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or represented by multiple policies that reflect the complex nature of organizations. Procedures can be established for security and privacy programs, mission/business processes, and systems, if necessary. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents. Events that may require an update to planning policy and procedures include, but are not limited to, assessment or audit findings, security incidents or breaches, or changes in laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Risk assessment. Policy and procedures. A. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]: 1. [Selection (one or more): organization level; mission/business process-level; system-level] risk assessment policy that: (a) addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance; and (b) is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines; and 2. procedures to facilitate the implementation of the risk assessment policy and the associated risk assessment controls; \n\nB. Designate an [assignment: organization-defined official] to manage the development, documentation, and dissemination of the risk assessment policy and procedures; and \n\nC. Review and update the current risk assessment: 1. policy [assignment: organization-defined frequency] and following [assignment: organization-defined events]; and 2. procedures [assignment: organization-defined frequency] and following [assignment: organization-defined events].\n\nRisk assessment policy and procedures address the controls in the RA family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of risk assessment policy and procedures. Security and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies reflecting the complex nature of organizations. Procedures can be established for security and privacy programs, for mission or business processes, and for systems, if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents. Events that may precipitate an update to risk assessment policy and procedures include assessment or audit findings, security incidents or breaches, or changes in laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "9_procedures_policy_and",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "9_procedures_policy_and"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          7.368487358093262,
          7.773169994354248,
          7.5268449783325195,
          7.7437896728515625,
          7.729287624359131,
          7.6188836097717285,
          7.39931583404541,
          7.56076192855835,
          7.511712551116943,
          7.545981407165527,
          7.847005367279053,
          7.945413589477539,
          7.502313613891602,
          7.695706844329834,
          7.147874355316162,
          7.401591777801514,
          7.612697124481201,
          7.851806163787842,
          7.067830562591553,
          7.87616491317749,
          7.5276923179626465,
          7.301778793334961,
          7.570732116699219
         ],
         "y": [
          8.47337818145752,
          8.465035438537598,
          8.62838077545166,
          8.485885620117188,
          8.52348518371582,
          8.393755912780762,
          8.472907066345215,
          8.682016372680664,
          8.68970775604248,
          8.058799743652344,
          8.49955940246582,
          8.485663414001465,
          8.415382385253906,
          8.950154304504395,
          8.606986999511719,
          8.19205093383789,
          8.194231033325195,
          8.520487785339355,
          8.330260276794434,
          8.495709419250488,
          8.712092399597168,
          8.211249351501465,
          8.476690292358398
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "System and services acquisition. Allocation of resources. A. Determine the high-level information security and privacy requirements for the system or system service in mission and business process planning. \nB. Determine, document, and allocate the resources required to protect the system or system service as part of the organizational capital planning and investment control process. \nC. Establish a discrete line item for information security and privacy in organizational programming and budgeting documentation.\n\nResource allocation for information security and privacy includes funding for system and services acquisition, sustainment, and supply chain-related risks throughout the system development life cycle.",
          "System and services acquisition. System documentation. a. Obtain or develop administrator documentation for the system, system component, or system service that describes:\n1. Secure configuration, installation, and operation of the system, component, or service.\n2. Effective use and maintenance of security and privacy functions and mechanisms.\n3. Known vulnerabilities regarding configuration and use of administrative or privileged functions.\n\nb. Obtain or develop user documentation for the system, system component, or system service that describes:\n1. User-accessible security and privacy functions and mechanisms and how to effectively use those functions and mechanisms.\n2. Methods for user interaction, which enable individuals to use the system, component, or service in a more secure manner and protect individual privacy.\n3. User responsibilities in maintaining the security of the system, component, or service and privacy of individuals.\n\nc. Document attempts to obtain system, system component, or system service documentation when such documentation is either unavailable or nonexistent and take [assignment: organization-defined actions] in response.\n\nd. Distribute documentation to [assignment: organization-defined personnel or roles]. System documentation helps personnel understand the implementation and operation of controls. Organizations consider establishing specific measures to determine the quality and completeness of the content provided. System documentation may be used to support the management of supply chain risk, incident response, and other functions.\n\nPersonnel or roles that require documentation include system owners, system security officers, and system administrators. Attempts to obtain documentation include contacting manufacturers or suppliers and conducting web-based searches. The inability to obtain documentation may occur due to the age of the system or component or the lack of support from developers and contractors. When documentation cannot be obtained, organizations may need to recreate the documentation if it is essential to the implementation or operation of the controls.\n\nThe protection provided for the documentation is commensurate with the security category or classification of the system. Documentation that addresses system vulnerabilities may require an increased level of protection. Secure operation of the system includes initially starting the system and resuming secure system operation after a lapse in system operation.",
          "System and services acquisition. Developer security and privacy architecture and design. Require the developer of the system, system component, or system service to produce a design specification and security and privacy architecture that: a. is consistent with the organization's security and privacy architecture that is an integral part of the organization's enterprise architecture; b. accurately and completely describes the required security and privacy functionality and the allocation of controls among physical and logical components; and c. expresses how individual security and privacy functions, mechanisms, and services work together to provide required security and privacy capabilities and a unified approach to protection. Developer security and privacy architecture and design are directed at external developers, although they could also be applied to internal (in-house) development. In contrast, PL-8 is directed at internal developers to ensure that organizations develop a security and privacy architecture that is integrated with the enterprise architecture. The distinction between SA-17 and PL-8 is especially important when organizations outsource the development of systems, system components, or system services and when there is a requirement to demonstrate consistency with the enterprise architecture and security and privacy architecture of the organization. ISO 15408-2, ISO 15408-3, and SP 800-160-1 provide information on security architecture and design, including formal policy models, security-relevant components, formal and informal correspondence, conceptually simple design, and structuring for least privilege and testing.",
          "Planning. System security and privacy plans. a. Develop security and privacy plans for the system that: \n1. Are consistent with the organization's enterprise architecture.\n2. Explicitly define the constituent system components.\n3. Describe the operational context of the system in terms of mission and business processes.\n4. Identify the individuals that fulfill system roles and responsibilities.\n5. Identify the information types processed, stored, and transmitted by the system.\n6. Provide the security categorization of the system, including supporting rationale.\n7. Describe any specific threats to the system that are of concern to the organization.\n8. Provide the results of a privacy risk assessment for systems processing personally identifiable information.\n9. Describe the operational environment for the system and any dependencies on or connections to other systems or system components.\n10. Provide an overview of the security and privacy requirements for the system.\n11. Identify any relevant control baselines or overlays, if applicable.\n12. Describe the controls in place or planned for meeting the security and privacy requirements, including a rationale for any tailoring decisions.\n13. Include risk determinations for security and privacy architecture and design decisions.\n14. Include security- and privacy-related activities affecting the system that require planning and coordination with [assignment: organization-defined individuals or groups].\n15. Are reviewed and approved by the authorizing official or designated representative prior to plan implementation.\n\nb. Distribute copies of the plans and communicate subsequent changes to the plans to [assignment: organization-defined personnel or roles].\nc. Review the plans [assignment: organization-defined frequency].\nd. Update the plans to address changes to the system and environment of operation or problems identified during plan implementation or control assessments.\ne. Protect the plans from unauthorized disclosure and modification.\n\nSystem security and privacy plans are scoped to the system and system components within the defined authorization boundary and contain an overview of the security and privacy requirements for the system and the controls selected to satisfy the requirements. The plans describe the intended application of each selected control in the context of the system with a sufficient level of detail to correctly implement the control and to subsequently assess the effectiveness of the control. The control documentation describes how system-specific and hybrid controls are implemented and the plans and expectations regarding the functionality of the system. System security and privacy plans can also be used in the design and development of systems in support of life cycle-based security and privacy engineering processes. System security and privacy plans are living documents that are updated and adapted throughout the system development life cycle (e.g., during capability determination, analysis of alternatives, requests for proposal, and design reviews). \n\nSection 2.1 describes the different types of requirements that are relevant to organizations during the system development life cycle and the relationship between requirements and controls. Organizations may develop a single, integrated security and privacy plan or maintain separate plans. Security and privacy plans relate security and privacy requirements to a set of controls and control enhancements. The plans describe how the controls and control enhancements meet the security and privacy requirements but do not provide detailed, technical descriptions of the design or implementation of the controls and control enhancements. Security and privacy plans contain sufficient information (including specifications of control parameter values for selection and assignment operations explicitly or by reference) to enable a design and implementation that is unambiguously compliant with the intent of the plans and subsequent determinations of risk to organizational operations and assets, individuals, other organizations, and the nation if the plan is implemented. Security and privacy plans need not be single documents. The plans can be a collection of various documents, including documents that already exist. Effective security and privacy plans make extensive use of references to policies, procedures, and additional documents, including design and implementation specifications where more detailed information can be obtained. The use of references helps reduce the documentation associated with security and privacy programs and maintains the security- and privacy-related information in other established management and operational areas, including enterprise architecture, system development life cycle, systems engineering, and acquisition. Security and privacy plans need not contain detailed contingency plan or incident response plan information but can instead provide—explicitly or by reference—sufficient information to define what needs to be accomplished by those plans. Security- and privacy-related activities that may require coordination and planning with other individuals or groups within the organization include assessments, audits, inspections, hardware and software maintenance, acquisition and supply chain risk management, patch management, and contingency plan testing. Planning and coordination include emergency and nonemergency (i.e., planned or non-urgent unplanned) situations. The process defined by organizations to plan and coordinate security- and privacy-related activities can also be included in other documents, as appropriate.",
          "Planning. Security and privacy architectures. a. Develop security and privacy architectures for the system that: \n1. Describe the requirements and approach to be taken for protecting the confidentiality, integrity, and availability of organizational information. \n2. Describe the requirements and approach to be taken for processing personally identifiable information to minimize privacy risk to individuals. \n3. Describe how the architectures are integrated into and support the enterprise architecture. \n4. Describe any assumptions about, and dependencies on, external systems and services. \n\nb. Review and update the architectures [assignment: organization-defined frequency] to reflect changes in the enterprise architecture. \n\nc. Reflect planned architecture changes in security and privacy plans, concept of operations (conops), criticality analysis, organizational procedures, and procurements and acquisitions. \n\nThe security and privacy architectures at the system level are consistent with the organization-wide security and privacy architectures described in PM-7, which are integral to and developed as part of the enterprise architecture. The architectures include an architectural description, the allocation of security and privacy functionality (including controls), security- and privacy-related information for external interfaces, information being exchanged across the interfaces, and the protection mechanisms associated with each interface. The architectures can also include other information, such as user roles and the access privileges assigned to each role, security and privacy requirements, types of information processed, stored, and transmitted by the system, supply chain risk management requirements, restoration priorities of information and system services, and other protection needs. \n\nSP 800-160-1 provides guidance on the use of security architectures as part of the system development life cycle process. \nOMB M-19-03 requires the use of the systems security engineering concepts described in SP 800-160-1 for high-value assets. \n\nSecurity and privacy architectures are reviewed and updated throughout the system development life cycle, from analysis of alternatives through review of the proposed architecture in the RFP responses to the design reviews before and during implementation (e.g., during preliminary design reviews and critical design reviews). \n\nIn today’s modern computing architectures, it is becoming less common for organizations to control all information resources. There may be key dependencies on external information services and service providers. Describing such dependencies in the security and privacy architectures is necessary for developing a comprehensive mission and business protection strategy. \n\nEstablishing, developing, documenting, and maintaining under configuration control a baseline configuration for organizational systems is critical to implementing and maintaining effective architectures. \n\nThe development of the architectures is coordinated with the Senior Agency Information Security Officer and the Senior Agency Official for Privacy to ensure that the controls needed to support security and privacy requirements are identified and effectively implemented. \n\nIn many circumstances, there may be no distinction between the security and privacy architecture for a system. In other circumstances, security objectives may be adequately satisfied, but privacy objectives may only be partially satisfied by the security requirements. In these cases, consideration of the privacy requirements needed to achieve satisfaction will result in a distinct privacy architecture. The documentation, however, may simply reflect the combined architectures. \n\nPL-8 is primarily directed at organizations to ensure that architectures are developed for the system and, moreover, that the architectures are integrated with or tightly coupled to the enterprise architecture. In contrast, SA-17 is primarily directed at the external information technology product and system developers and integrators. SA-17, which is complementary to PL-8, is selected when organizations outsource the development of systems or components to external entities and when there is a need to demonstrate consistency with the organization’s enterprise architecture and security and privacy architectures.",
          "System and services acquisition. External system services | risk assessments and organizational approvals. (a) Conduct an organizational assessment of risk prior to the acquisition or outsourcing of information security services; and (b) verify that the acquisition or outsourcing of dedicated information security services is approved by [assignment: organization-defined personnel or roles]. Information security services include the operation of security devices, such as firewalls or key management services, as well as incident monitoring, analysis, and response. Risks assessed can include system, mission or business, security, privacy, or supply chain risks.",
          "System and services acquisition. External system services | processing, storage, and service location. Restrict the location of information processing, information or data, or system services to organization-defined locations based on organization-defined requirements or conditions. The location of information processing, information and data storage, or system services can have a direct impact on the ability of organizations to successfully execute their mission and business functions. The impact occurs when external providers control the location of processing, storage, or services. The criteria that external providers use for the selection of processing, storage, or service locations may be different from the criteria that organizations use. For example, organizations may desire that data or information storage locations be restricted to certain locations to help facilitate incident response activities in case of information security incidents or breaches. Incident response activities, including forensic analyses and after-the-fact investigations, may be adversely affected by the governing laws, policies, or protocols in the locations where processing and storage occur and/or the locations from which system services emanate.",
          "System and services acquisition. Security and privacy engineering principles. Apply the following systems security and privacy engineering principles in the specification, design, development, implementation, and modification of the system and system components: [Assignment: organization-defined systems security and privacy engineering principles]. Systems security and privacy engineering principles are closely related to and implemented throughout the system development life cycle (see SA-3). Organizations can apply systems security and privacy engineering principles to new systems under development or to systems undergoing upgrades. For existing systems, organizations apply systems security and privacy engineering principles to system upgrades and modifications to the extent feasible, given the current state of hardware, software, and firmware components within those systems.\n\nThe application of systems security and privacy engineering principles helps organizations develop trustworthy, secure, and resilient systems and reduces the susceptibility to disruptions, hazards, threats, and the creation of privacy problems for individuals. Examples of system security engineering principles include: developing layered protections; establishing security and privacy policies, architecture, and controls as the foundation for design and development; incorporating security and privacy requirements into the system development life cycle; delineating physical and logical security boundaries; ensuring that developers are trained on how to build secure software; tailoring controls to meet organizational needs; and performing threat modeling to identify use cases, threat agents, attack vectors, and patterns, design patterns, and compensating controls needed to mitigate risk.\n\nOrganizations that apply systems security and privacy engineering concepts and principles can facilitate the development of trustworthy, secure systems, system components, and system services; reduce risk to acceptable levels; and make informed risk management decisions. System security engineering principles can also be used to protect against certain supply chain risks, including incorporating tamper-resistant hardware into a design.",
          "System and services acquisition. Development process, standards, and tools | criticality analysis. Require the developer of the system, system component, or system service to perform a criticality analysis: (a) at the following decision points in the system development life cycle: [assignment: organization-defined decision points in the system development life cycle]; and (b) at the following level of rigor: [assignment: organization-defined breadth and depth of criticality analysis]. Criticality analysis performed by the developer provides input to the criticality analysis performed by organizations. Developer input is essential to organizational criticality analysis because organizations may not have access to detailed design documentation for system components that are developed as commercial off-the-shelf products. Such design documentation includes functional specifications, high-level designs, low-level designs, source code, and hardware schematics. Criticality analysis is important for organizational systems that are designated as high-value assets. High-value assets can be moderate or high-impact systems due to heightened adversarial interest or potential adverse effects on the federal enterprise. Developer input is especially important when organizations conduct supply chain criticality analyses.",
          "System and services acquisition. Acquisition process. Include the following requirements, descriptions, and criteria, explicitly or by reference, using standardized contract language in the acquisition contract for the system, system component, or system service:\n\na. Security and privacy functional requirements.\nb. Strength of mechanism requirements.\nc. Security and privacy assurance requirements.\nd. Controls needed to satisfy the security and privacy requirements.\ne. Security and privacy documentation requirements.\nf. Requirements for protecting security and privacy documentation.\ng. Description of the system development environment and environment in which the system is intended to operate.\nh. Allocation of responsibility or identification of parties responsible for information security, privacy, and supply chain risk management.\ni. Acceptance criteria.\n\nSecurity and privacy functional requirements are typically derived from the high-level security and privacy requirements described in SA-2. The derived requirements include security and privacy capabilities, functions, and mechanisms. Strength requirements associated with such capabilities, functions, and mechanisms include the degree of correctness, completeness, resistance to tampering or bypass, and resistance to direct attack. Assurance requirements include development processes, procedures, and methodologies, as well as the evidence from development and assessment activities that provide grounds for confidence that the required functionality is implemented and possesses the required strength of the mechanism. SP 800-160-1 describes the process of requirements engineering as part of the system development life cycle.\n\nControls can be viewed as descriptions of the safeguards and protection capabilities appropriate for achieving the particular security and privacy objectives of the organization and for reflecting the security and privacy requirements of stakeholders. Controls are selected and implemented to satisfy system requirements and include developer and organizational responsibilities. Controls can include technical, administrative, and physical aspects. In some cases, the selection and implementation of a control may necessitate additional specification by the organization in the form of derived requirements or instantiated control parameter values. The derived requirements and control parameter values may be necessary to provide the appropriate level of implementation detail for controls within the system development life cycle.\n\nSecurity and privacy documentation requirements address all stages of the system development life cycle. Documentation provides user and administrator guidance for the implementation and operation of controls. The level of detail required in such documentation is based on the security categorization or classification level of the system and the degree to which organizations depend on the capabilities, functions, or mechanisms to meet risk response expectations. Requirements can include mandated configuration settings that specify allowed functions, ports, protocols, and services. Acceptance criteria for systems, system components, and system services are defined in the same manner as the criteria for any organizational acquisition or procurement.",
          "System and services acquisition. Acquisition process | system, component, and service configurations. Require the developer of the system, system component, or system service to: (a) deliver the system, component, or service with organization-defined security configurations implemented; and (b) use the configurations as the default for any subsequent system, component, or service reinstallation or upgrade. Examples of security configurations include the U.S. Government Configuration Baseline (USGCB), Security Technical Implementation Guides (STIGs), and any limitations on functions, ports, protocols, and services. Security characteristics can include requiring that default passwords have been changed.",
          "System and services acquisition. System development life cycle. A. Acquire, develop, and manage the system using [assignment: organization-defined system development life cycle] that incorporates information security and privacy considerations. \nB. Define and document information security and privacy roles and responsibilities throughout the system development life cycle. \nC. Identify individuals having information security and privacy roles and responsibilities. \nD. Integrate the organizational information security and privacy risk management process into system development life cycle activities. \n\nA system development life cycle process provides the foundation for the successful development, implementation, and operation of organizational systems. The integration of security and privacy considerations early in the system development life cycle is a foundational principle of systems security engineering and privacy engineering. To apply the required controls within the system development life cycle requires a basic understanding of information security and privacy, threats, vulnerabilities, adverse impacts, and risk to critical mission and business functions. The security engineering principles in SA-8 help individuals properly design, code, and test systems and system components. \n\nOrganizations include qualified personnel (e.g., senior agency information security officers, senior agency officials for privacy, security and privacy architects, and security and privacy engineers) in system development life cycle processes to ensure that established security and privacy requirements are incorporated into organizational systems. Role-based security and privacy training programs can ensure that individuals with key security and privacy roles and responsibilities have the experience, skills, and expertise to conduct assigned system development life cycle activities. The effective integration of security and privacy requirements into enterprise architecture also helps to ensure that important security and privacy considerations are addressed throughout the system life cycle and that those considerations are directly related to organizational mission and business processes. This process also facilitates the integration of the information security and privacy architectures into the enterprise architecture, consistent with the risk management strategy of the organization. \n\nBecause the system development life cycle involves multiple organizations (e.g., external suppliers, developers, integrators, service providers), acquisition and supply chain risk management functions and controls play significant roles in the effective management of the system during the life cycle.",
          "System and services acquisition. Acquisition process | design and implementation information for controls. Require the developer of the system, system component, or system service to provide design and implementation information for the controls that includes: [selection (one or more): security-relevant external system interfaces; high-level design; low-level design; source code or hardware schematics; [assignment: organization-defined design and implementation information]] at [assignment: organization-defined level of detail]. Organizations may require different levels of detail in the documentation for the design and implementation of controls in organizational systems, system components, or system services based on mission and business requirements, requirements for resiliency and trustworthiness, and requirements for analysis and testing. Systems can be partitioned into multiple subsystems. Each subsystem within the system can contain one or more modules. The high-level design for the system is expressed in terms of subsystems and the interfaces between subsystems providing security-relevant functionality. The low-level design for the system is expressed in terms of modules and the interfaces between modules providing security-relevant functionality. Design and implementation documentation can include manufacturer, version, serial number, verification hash signature, software libraries used, date of purchase or download, and the vendor or download source. Source code and hardware schematics are referred to as the implementation representation of the system.",
          "System and services acquisition. Developer screening. Require that the developer of [assignment: organization-defined system, system component, or system service] has appropriate access authorizations as determined by assigned [assignment: organization-defined official government duties]. The developer should also satisfy the following additional personnel screening criteria: [assignment: organization-defined additional personnel screening criteria]. Developer screening is directed at external developers. Internal developer screening is addressed by PS-3. Because the system, system component, or system service may be used in critical activities essential to the national or economic security interests of the United States, organizations have a strong interest in ensuring that developers are trustworthy. The degree of trust required of developers may need to be consistent with that of the individuals who access the systems, system components, or system services once deployed. Authorization and personnel screening criteria include clearances, background checks, citizenship, and nationality. Developer trustworthiness may also include a review and analysis of company ownership and relationships that the company has with entities that may potentially affect the quality and reliability of the systems, components, or services being developed. Satisfying the required access authorizations and personnel screening criteria includes providing a list of all individuals who are authorized to perform development activities on the selected system, system component, or system service so that organizations can validate that the developer has satisfied the authorization and screening requirements.",
          "System and services acquisition. Developer testing and evaluation | static code analysis. Require the developer of the system, system component, or system service to employ static code analysis tools to identify common flaws and document the results of the analysis. Static code analysis provides a technology and methodology for security reviews and includes checking for weaknesses in the code as well as for the incorporation of libraries or other included code with known vulnerabilities or that is out-of-date and not supported. Static code analysis can be used to identify vulnerabilities and enforce secure coding practices. It is most effective when used early in the development process, when each code change can automatically be scanned for potential weaknesses. Static code analysis can provide clear remediation guidance and identify defects for developers to fix. Evidence of the correct implementation of static analysis can include aggregate defect density for critical defect types, evidence that defects were inspected by developers or security professionals, and evidence that defects were remediated. A high density of ignored findings, commonly referred to as false positives, indicates a potential problem with the analysis process or the analysis tool. In such cases, organizations weigh the validity of the evidence against evidence from other sources.",
          "System and services acquisition. External system services | identification of functions, ports, protocols, and services. Require providers of the following external system services to identify the functions, ports, protocols, and other services required for the use of such services: [assignment: organization-defined external system services]. Information from external service providers regarding the specific functions, ports, protocols, and services used in the provision of such services can be useful when the need arises to understand the trade-offs involved in restricting certain functions and services or blocking certain ports and protocols.",
          "System and services acquisition. Acquisition process | functional properties of controls. Require the developer of the system, system component, or system service to provide a description of the functional properties of the controls to be implemented. Functional properties of security and privacy controls describe the functionality (i.e., security or privacy capability, functions, or mechanisms) visible at the interfaces of the controls and specifically exclude functionality and data structures internal to the operation of the controls.",
          "System and services acquisition. Acquisition process | functions, ports, protocols, and services in use. Require the developer of the system, system component, or system service to identify the functions, ports, protocols, and services intended for organizational use. The identification of functions, ports, protocols, and services early in the system development life cycle (e.g., during the initial requirements definition and design stages) allows organizations to influence the design of the system, system component, or system service. This early involvement in the system development life cycle helps organizations avoid or minimize the use of functions, ports, protocols, or services that pose unnecessarily high risks and understand the trade-offs involved in blocking specific ports, protocols, or services or requiring system service providers to do so. Early identification of functions, ports, protocols, and services avoids costly retrofitting of controls after the system, component, or system service has been implemented. SA-9 describes the requirements for external system services. Organizations identify which functions, ports, protocols, and services are provided from external sources.",
          "System and services acquisition. Developer testing and evaluation. Require the developer of the system, system component, or system service, at all post-design stages of the system development life cycle, to: a. develop and implement a plan for ongoing security and privacy control assessments; b. perform [selection (one or more): unit; integration; system; regression] testing/evaluation [assignment: organization-defined frequency] at [assignment: organization-defined depth and coverage]; c. produce evidence of the execution of the assessment plan and the results of the testing and evaluation; d. implement a verifiable flaw remediation process; and e. correct flaws identified during testing and evaluation. Developmental testing and evaluation confirms that the required controls are implemented correctly, operating as intended, enforcing the desired security and privacy policies, and meeting established security and privacy requirements. Security properties of systems and the privacy of individuals may be affected by the interconnection of system components or changes to those components. The interconnections or changes—including upgrading or replacing applications, operating systems, and firmware—may adversely affect previously implemented controls. Ongoing assessment during development allows for additional types of testing and evaluation that developers can conduct to reduce or eliminate potential flaws. Testing custom software applications may require approaches such as manual code review, security architecture review, and penetration testing, as well as static analysis, dynamic analysis, binary analysis, or a hybrid of the three analysis approaches. Developers can use the analysis approaches, along with security instrumentation and fuzzing, in a variety of tools and in source code reviews. The security and privacy assessment plans include the specific activities that developers plan to carry out, including the types of analyses, testing, evaluation, and reviews of software and firmware components; the degree of rigor to be applied; the frequency of the ongoing testing and evaluation; and the types of artifacts produced during those processes. The depth of testing and evaluation refers to the rigor and level of detail associated with the assessment process. The coverage of testing and evaluation refers to the scope (i.e., number and type) of the artifacts included in the assessment process. Contracts specify the acceptance criteria for security and privacy assessment plans, flaw remediation processes, and the evidence that the plans and processes have been diligently applied. Methods for reviewing and protecting assessment plans, evidence, and documentation are commensurate with the security category or classification level of the system. Contracts may specify protection requirements for documentation.",
          "System and services acquisition. Development process, standards, and tools. a. Require the developer of the system, system component, or system service to follow a documented development process that:\n1. Explicitly addresses security and privacy requirements.\n2. Identifies the standards and tools used in the development process.\n3. Documents the specific tool options and tool configurations used in the development process.\n4. Documents, manages, and ensures the integrity of changes to the process and/or tools used in development.\n\nb. Review the development process, standards, tools, tool options, and tool configurations [assignment: organization-defined frequency] to determine if the process, standards, tools, tool options, and tool configurations selected and employed can satisfy the following security and privacy requirements: [assignment: organization-defined security and privacy requirements]. \n\nDevelopment tools include programming languages and computer-aided design systems. Reviews of development processes include the use of maturity models to determine the potential effectiveness of such processes. Maintaining the integrity of changes to tools and processes facilitates effective supply chain risk assessment and mitigation. Such integrity requires configuration control throughout the system development life cycle to track authorized changes and prevent unauthorized changes.",
          "System and services acquisition. Developer testing and evaluation | threat modeling and vulnerability analyses. Require the developer of the system, system component, or system service to perform threat modeling and vulnerability analyses during development and the subsequent testing and evaluation of the system, component, or service. This should include the following: \n\n(a) Use the following contextual information: [assignment: organization-defined information concerning impact, environment of operations, known or assumed threats, and acceptable risk levels]. \n\n(b) Employ the following tools and methods: [assignment: organization-defined tools and methods]. \n\n(c) Conduct the modeling and analyses at the following level of rigor: [assignment: organization-defined breadth and depth of modeling and analyses]. \n\n(d) Produce evidence that meets the following acceptance criteria: [assignment: organization-defined acceptance criteria]. \n\nSystems, system components, and system services may deviate significantly from the functional and design specifications created during the requirements and design stages of the system development life cycle. Therefore, updates to threat modeling and vulnerability analyses of those systems, system components, and system services during development and prior to delivery are critical to the effective operation of those systems, components, and services. \n\nThreat modeling and vulnerability analyses at this stage of the system development life cycle ensure that design and implementation changes have been accounted for and that vulnerabilities created because of those changes have been reviewed and mitigated.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "10_system_and_privacy",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "10_system_and_privacy"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          6.357807636260986,
          6.379143714904785,
          6.132722854614258,
          6.248824596405029,
          6.195796966552734,
          6.482988357543945,
          6.484738349914551,
          6.20257568359375,
          5.963885307312012,
          6.230373382568359,
          6.398046970367432,
          6.136088848114014,
          6.343509197235107,
          6.340357303619385,
          6.021573066711426,
          6.422800064086914,
          6.335010528564453,
          6.364743232727051,
          6.191863059997559,
          6.167137622833252,
          6.057326316833496,
          6.259871482849121
         ],
         "y": [
          8.839239120483398,
          8.932731628417969,
          8.599455833435059,
          8.620830535888672,
          8.638836860656738,
          8.900525093078613,
          9.008660316467285,
          8.685300827026367,
          8.337868690490723,
          8.700687408447266,
          8.882938385009766,
          8.59797477722168,
          8.88719654083252,
          8.353177070617676,
          8.263861656188965,
          9.011204719543457,
          8.894639015197754,
          8.971199035644531,
          8.340333938598633,
          8.568727493286133,
          8.411508560180664,
          8.687948226928711
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Risk assessment. Vulnerability monitoring and scanning | breadth and depth of coverage. Define the breadth and depth of vulnerability scanning coverage. The breadth of vulnerability scanning coverage can be expressed as a percentage of components within the system, by the particular types of systems, by the criticality of systems, or by the number of vulnerabilities to be checked. Conversely, the depth of vulnerability scanning coverage can be expressed as the level of the system design that the organization intends to monitor (e.g., component, module, subsystem, element). Organizations can determine the sufficiency of vulnerability scanning coverage with regard to its risk tolerance and other factors. Scanning tools and how the tools are configured may affect the depth and coverage. Multiple scanning tools may be needed to achieve the desired depth and coverage. SP 800-53a provides additional information on the breadth and depth of coverage.",
          "Risk assessment. Vulnerability monitoring and scanning | review historic audit logs. Review historic audit logs to determine if a vulnerability identified in an organization-defined system has been previously exploited within an organization-defined time period. Reviewing historic audit logs to determine if a recently detected vulnerability in a system has been previously exploited by an adversary can provide important information for forensic analyses. Such analyses can help identify, for example, the extent of a previous intrusion, the tradecraft employed during the attack, organizational information exfiltrated or modified, mission or business capabilities affected, and the duration of the attack.",
          "Risk assessment. Vulnerability monitoring and scanning | update vulnerabilities to be scanned. Update the system vulnerabilities to be scanned [selection (one or more): [assignment: organization-defined frequency]; prior to a new scan; when new vulnerabilities are identified and reported]. Due to the complexity of modern software, systems, and other factors, new vulnerabilities are discovered on a regular basis. It is important that newly discovered vulnerabilities are added to the list of vulnerabilities to be scanned to ensure that the organization can take steps to mitigate those vulnerabilities in a timely manner.",
          "Security assessment and authorization. Continuous monitoring | risk monitoring. Ensure risk monitoring is an integral part of the continuous monitoring strategy that includes the following: (a) effectiveness monitoring; (b) compliance monitoring; and (c) change monitoring. Risk monitoring is informed by the established organizational risk tolerance. Effectiveness monitoring determines the ongoing effectiveness of the implemented risk response measures. Compliance monitoring verifies that required risk response measures are implemented. It also verifies that security and privacy requirements are satisfied. Change monitoring identifies changes to organizational systems and environments of operation that may affect security and privacy risk.",
          "Security assessment and authorization. Continuous monitoring. Develop a system-level continuous monitoring strategy and implement continuous monitoring in accordance with the organization-level continuous monitoring strategy. This includes:\n\na. Establishing the following system-level metrics to be monitored: [assignment: organization-defined system-level metrics].\n\nb. Establishing [assignment: organization-defined frequencies] for monitoring and [assignment: organization-defined frequencies] for assessment of control effectiveness.\n\nc. Conducting ongoing control assessments in accordance with the continuous monitoring strategy.\n\nd. Performing ongoing monitoring of system and organization-defined metrics based on the continuous monitoring strategy.\n\ne. Correlating and analyzing information generated by control assessments and monitoring.\n\nf. Taking response actions to address results of the analysis of control assessment and monitoring information.\n\ng. Reporting the security and privacy status of the system to [assignment: organization-defined personnel or roles] [assignment: organization-defined frequency].\n\nContinuous monitoring at the system level enables ongoing awareness of the system's security and privacy posture, supporting organizational risk management decisions. The terms \"continuous\" and \"ongoing\" imply that organizations assess and monitor their controls and risks at a frequency sufficient to support risk-based decisions. Different types of controls may require different monitoring frequencies.\n\nThe results of continuous monitoring generate risk response actions by organizations. When monitoring the effectiveness of multiple controls grouped into capabilities, a root-cause analysis may be necessary to determine the specific control that has failed. Continuous monitoring programs enable organizations to maintain authorizations of systems and common controls in highly dynamic operational environments with changing mission and business needs, threats, vulnerabilities, and technologies.\n\nHaving access to security and privacy information on a continuous basis through reports and dashboards provides organizational officials with the ability to make effective and timely risk management decisions, including ongoing authorization decisions. Automation supports more frequent updates to hardware, software, and firmware inventories, authorization packages, and other system information.\n\nEffectiveness is further enhanced when continuous monitoring outputs are formatted to provide specific, measurable, actionable, relevant, and timely information.\n\nContinuous monitoring activities are scaled based on the security categories of systems. Monitoring requirements, including the need for specific monitoring, may be referenced in other controls and control enhancements, such as AC-2g, AC-2 (7), AC-2 (12) (a), AC-2 (7) (b), AC-2 (7) (c), AC-17 (1), AT-4a, AU-13, AU-13 (1), AU-13 (2), CM-3f, CM-6d, CM-11c, IR-5, MA-2b, MA-3a, MA-4a, PE-3d, PE-6, PE-14b, PE-16, PE-20, PM-6, PM-23, PM-31, PS-7e, SA-9c, SR-4, SC-5 (3) (b), SC-7a, SC-7 (24) (b), SC-18b, SC-43b, and SI-4.",
          "Risk assessment. Vulnerability monitoring and scanning | privileged access. Implement privileged access authorization to [assignment: organization-defined system components] for [assignment: organization-defined vulnerability scanning activities]. In certain situations, the nature of the vulnerability scanning may be more intrusive, or the system component that is the subject of the scanning may contain classified or controlled unclassified information, such as personally identifiable information. Privileged access authorization to selected system components facilitates more thorough vulnerability scanning and protects the sensitive nature of such scanning.",
          "Security assessment and authorization. Control assessments | leveraging results from external organizations. Leverage the results of control assessments performed by [assignment: organization-defined external organization] on [assignment: organization-defined system] when the assessment meets [assignment: organization-defined requirements]. Organizations may rely on control assessments of organizational systems by other (external) organizations. Using such assessments and reusing existing assessment evidence can decrease the time and resources required for assessments by limiting the independent assessment activities that organizations need to perform. The factors that organizations consider in determining whether to accept assessment results from external organizations can vary. Such factors include the organization's past experience with the organization that conducted the assessment, the reputation of the assessment organization, the level of detail of supporting assessment evidence provided, and mandates imposed by applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Accredited testing laboratories that support the Common Criteria program ISO 15408-1, the NIST Cryptographic Module Validation Program (CMVP), or the NIST Cryptographic Algorithm Validation Program (CAVP) can provide independent assessment results that organizations can leverage.",
          "Security assessment and authorization. Control assessments | independent assessors. Employ independent assessors or assessment teams to conduct control assessments. Independent assessors or assessment teams are individuals or groups who conduct impartial assessments of systems. Impartiality means that assessors are free from any perceived or actual conflicts of interest regarding the development, operation, sustainment, or management of the systems under assessment or the determination of control effectiveness. To achieve impartiality, assessors do not create a mutual or conflicting interest with the organizations where the assessments are being conducted, assess their own work, act as management or employees of the organizations they are serving, or place themselves in positions of advocacy for the organizations acquiring their services.\n\nIndependent assessments can be obtained from elements within organizations or be contracted to public or private sector entities outside of organizations. Authorizing officials determine the required level of independence based on the security categories of systems and/or the risk to organizational operations, organizational assets, or individuals. Authorizing officials also determine if the level of assessor independence provides sufficient assurance that the results are sound and can be used to make credible, risk-based decisions. Assessor independence determination includes whether contracted assessment services have sufficient independence, such as when system owners are not directly involved in contracting processes or cannot influence the impartiality of the assessors conducting the assessments.\n\nDuring the system design and development phase, having independent assessors is analogous to having independent SMEs involved in design reviews. When organizations that own the systems are small or the structures of the organizations require that assessments be conducted by individuals that are in the developmental, operational, or management chain of the system owners, independence in assessment processes can be achieved by ensuring that assessment results are carefully reviewed and analyzed by independent teams of experts to validate the completeness, accuracy, integrity, and reliability of the results. Assessments performed for purposes other than to support authorization decisions are more likely to be usable for such decisions when performed by assessors with sufficient independence, thereby reducing the need to repeat assessments.",
          "Risk assessment. Vulnerability monitoring and scanning. a. Monitor and scan for vulnerabilities in the system and hosted applications. [Assignment: Organization-defined frequency and/or randomly in accordance with organization-defined process]. When new vulnerabilities potentially affecting the system are identified and reported.\nb. Employ vulnerability monitoring tools and techniques that facilitate interoperability among tools and automate parts of the vulnerability management process. Use standards for: \n1. Enumerating platforms, software flaws, and improper configurations.\n2. Formatting checklists and test procedures.\n3. Measuring vulnerability impact.\nc. Analyze vulnerability scan reports and results from vulnerability monitoring.\nd. Remediate legitimate vulnerabilities. [Assignment: Organization-defined response times]. In accordance with an organizational assessment of risk.\ne. Share information obtained from the vulnerability monitoring process and control assessments with [Assignment: Organization-defined personnel or roles] to help eliminate similar vulnerabilities in other systems.\nf. Employ vulnerability monitoring tools that include the capability to readily update the vulnerabilities to be scanned. \n\nThe security categorization of information and systems guides the frequency and comprehensiveness of vulnerability monitoring (including scans). Organizations determine the required vulnerability monitoring for system components, ensuring that the potential sources of vulnerabilities such as infrastructure components (e.g., switches, routers, guards, sensors), networked printers, scanners, and copiers are not overlooked. The capability to readily update vulnerability monitoring tools as new vulnerabilities are discovered and announced and as new scanning methods are developed helps to ensure that new vulnerabilities are not missed by employed vulnerability monitoring tools. The vulnerability monitoring tool update process helps to ensure that potential vulnerabilities in the system are identified and addressed as quickly as possible. Vulnerability monitoring and analyses for custom software may require additional approaches such as static analysis, dynamic analysis, binary analysis, or a hybrid of the three approaches. Organizations can use these analysis approaches in source code reviews and in a variety of tools including web-based application scanners, static analysis tools, and binary analyzers. Vulnerability monitoring includes scanning for patch levels, scanning for functions, ports, protocols, and services that should not be accessible to users or devices, and scanning for flow control mechanisms that are improperly configured or operating incorrectly. Vulnerability monitoring may also include continuous vulnerability monitoring tools that use instrumentation to continuously analyze components. Instrumentation-based tools may improve accuracy and may be run throughout an organization without scanning. Vulnerability monitoring tools that facilitate interoperability include tools that are Security Content Automated Protocol (SCAP)-validated. Thus, organizations consider using scanning tools that express vulnerabilities in the Common Vulnerabilities and Exposures (CVE) naming convention and that employ the Open Vulnerability Assessment Language (OVAL) to determine the presence of vulnerabilities. Sources for vulnerability information include the Common Weakness Enumeration (CWE) listing and the National Vulnerability Database (NVD). Control assessments such as red team exercises provide additional sources of potential vulnerabilities for which to scan. Organizations also consider using scanning tools that express vulnerability impact by the Common Vulnerability Scoring System (CVSS). Vulnerability monitoring includes a channel and process for receiving reports of security vulnerabilities from the public at-large. Vulnerability disclosure programs can be as simple as publishing a monitored email address or web form that can receive reports, including notification authorizing good-faith research and disclosure of security vulnerabilities. Organizations generally expect that such research is happening with or without their authorization and can use public vulnerability disclosure channels to increase the likelihood that discovered vulnerabilities are reported directly to the organization for remediation. Organizations may also employ the use of financial incentives (also known as bug bounties) to further encourage external security researchers to report discovered vulnerabilities. Bug bounty programs can be tailored to the organization’s needs. Bounties can be operated indefinitely or over a defined period of time and can be offered to the general public or to a curated group. Organizations may run public and private bounties simultaneously and could choose to offer partially credentialed access to certain participants in order to evaluate security vulnerabilities from privileged vantage points.",
          "Security assessment and authorization. Penetration testing. Conduct penetration testing [assignment: organization-defined frequency] on [assignment: organization-defined systems or system components]. Penetration testing is a specialized type of assessment conducted on systems or individual system components to identify vulnerabilities that could be exploited by adversaries. Penetration testing goes beyond automated vulnerability scanning and is conducted by agents and teams with demonstrable skills and experience that include technical expertise in network, operating system, and/or application-level security. Penetration testing can be used to validate vulnerabilities or determine the degree of penetration resistance of systems to adversaries within specified constraints. Such constraints include time, resources, and skills. Penetration testing attempts to duplicate the actions of adversaries and provides a more in-depth analysis of security- and privacy-related weaknesses or deficiencies. Penetration testing is especially important when organizations are transitioning from older technologies to newer technologies (e.g., transitioning from IPv4 to IPv6 network protocols). Organizations can use the results of vulnerability analyses to support penetration testing activities. Penetration testing can be conducted internally or externally on the hardware, software, or firmware components of a system and can exercise both physical and technical controls. A standard method for penetration testing includes a pretest analysis based on full knowledge of the system, pretest identification of potential vulnerabilities based on the pretest analysis, and testing designed to determine the exploitability of vulnerabilities. All parties agree to the rules of engagement before commencing penetration testing scenarios. Organizations correlate the rules of engagement for the penetration tests with the tools, techniques, and procedures that are anticipated to be employed by adversaries. Penetration testing may result in the exposure of information that is protected by laws or regulations to individuals conducting the testing. Rules of engagement, contracts, or other appropriate mechanisms can be used to communicate expectations for how to protect this information. Risk assessments guide the decisions on the level of independence required for the personnel conducting penetration testing.",
          "Risk assessment. Vulnerability monitoring and scanning | public disclosure program. Establish a public reporting channel for receiving reports of vulnerabilities in organizational systems and system components. The reporting channel is publicly discoverable and contains clear language authorizing good-faith research and the disclosure of vulnerabilities to the organization. The organization does not condition its authorization on an expectation of indefinite non-disclosure to the public by the reporting entity. However, the organization may request a specific time period to properly remediate the vulnerability.",
          "Risk assessment. Risk assessment. A. Conduct a risk assessment, including: 1. identifying threats to and vulnerabilities in the system; 2. determining the likelihood and magnitude of harm from unauthorized access, use, disclosure, disruption, modification, or destruction of the system, the information it processes, stores, or transmits, and any related information; and 3. determining the likelihood and impact of adverse effects on individuals arising from the processing of personally identifiable information. B. Integrate risk assessment results and risk management decisions from the organization and mission or business process perspectives with system-level risk assessments. C. Document risk assessment results in [selection: security and privacy plans; risk assessment report; [assignment: organization-defined document]]. D. Review risk assessment results [assignment: organization-defined frequency]. E. Disseminate risk assessment results to [assignment: organization-defined personnel or roles]. F. Update the risk assessment [assignment: organization-defined frequency] or when there are significant changes to the system, its environment of operation, or other conditions that may impact the security or privacy state of the system. Risk assessments consider threats, vulnerabilities, likelihood, and impact to organizational operations and assets, individuals, other organizations, and the nation. Risk assessments also consider risk from external parties, including contractors who operate systems on behalf of the organization, individuals who access organizational systems, service providers, and outsourcing entities. Organizations can conduct risk assessments at all three levels in the risk management hierarchy (i.e., organization level, mission/business process level, or information system level) and at any stage in the system development life cycle. Risk assessments can also be conducted at various steps in the risk management framework, including preparation, categorization, control selection, control implementation, control assessment, authorization, and control monitoring. Risk assessment is an ongoing activity carried out throughout the system development life cycle. Risk assessments can also address information related to the system, including system design, the intended use of the system, testing results, and supply chain-related information or artifacts. Risk assessments can play an important role in control selection processes, particularly during the application of tailoring guidance and in the earliest phases of capability determination.",
          "Risk assessment. Security categorization. a. Categorize the system and information it processes, stores, and transmits.\nb. Document the security categorization results, including supporting rationale, in the security plan for the system.\nc. Verify that the authorizing official or the authorizing official designated representative reviews and approves the security categorization decision.\nSecurity categories describe the potential adverse impacts or negative consequences to organizational operations, organizational assets, and individuals if organizational information and systems are compromised through a loss of confidentiality, integrity, or availability. Security categorization is also a type of asset loss characterization in systems security engineering processes that is carried out throughout the system development life cycle. Organizations can use privacy risk assessments or privacy impact assessments to better understand the potential adverse effects on individuals. CNSSI 1253 provides additional guidance on categorization for national security systems.\nOrganizations conduct the security categorization process as an organization-wide activity with the direct involvement of Chief Information Officers, Senior Agency Information Security Officers, Senior Agency Officials for Privacy, system owners, mission and business owners, and information owners or stewards. Organizations consider the potential adverse impacts to other organizations and, in accordance with USA PATRIOT and Homeland Security Presidential Directives, potential national-level adverse impacts.\nSecurity categorization processes facilitate the development of inventories of information assets and, along with CM-8, mappings to specific system components where information is processed, stored, or transmitted. The security categorization process is revisited throughout the system development life cycle to ensure that the security categories remain accurate and relevant.",
          "Risk assessment. Risk response. Respond to findings from security and privacy assessments, monitoring, and audits in accordance with organizational risk tolerance. Organizations have many options for responding to risk, including mitigating risk by implementing new controls or strengthening existing controls, accepting risk with appropriate justification or rationale, sharing or transferring risk, or avoiding risk. The risk tolerance of the organization influences risk response decisions and actions. Risk response addresses the need to determine an appropriate response to risk before generating a Plan of Action and Milestones (POA&M) entry. For example, the response may be to accept risk or reject risk, or it may be possible to mitigate the risk immediately so that a POA&M entry is not needed. However, if the risk response is to mitigate the risk and the mitigation cannot be completed immediately, a POA&M entry is generated.",
          "Security assessment and authorization. Penetration testing | independent penetration testing agent or team. Employ an independent penetration testing agent or team to perform penetration testing on the system or system components. Independent penetration testing agents or teams are individuals or groups who conduct impartial penetration testing of organizational systems. Impartiality implies that penetration testing agents or teams are free from perceived or actual conflicts of interest with respect to the development, operation, or management of the systems that are the targets of the penetration testing. CA-2 (1) provides additional information on independent assessments that can be applied to penetration testing.",
          "Security assessment and authorization. Control assessments | specialized assessments. Include as part of control assessments, [assignment: organization-defined frequency]. [Selection: Announced; Unannounced]. [Selection (one or more): In-depth monitoring; Security instrumentation; Automated security test cases; Vulnerability scanning; Malicious user testing; Insider threat assessment; Performance and load testing; Data leakage or data loss assessment; [assignment: organization-defined other forms of assessment]]. Organizations can conduct specialized assessments, including verification and validation, system monitoring, insider threat assessments, malicious user testing, and other forms of testing. These assessments can improve readiness by exercising organizational capabilities and indicating current levels of performance as a means of focusing actions to improve security and privacy. Organizations conduct specialized assessments in accordance with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Authorizing officials approve the assessment methods in coordination with the organizational risk executive function. Organizations can include vulnerabilities uncovered during assessments into vulnerability remediation processes. Specialized assessments can also be conducted early in the system development life cycle (e.g., during initial design, development, and unit testing).",
          "Security assessment and authorization. Continuous monitoring | independent assessment. Employ independent assessors or assessment teams to monitor the controls in the system on an ongoing basis. Organizations maximize the value of control assessments by requiring that assessments be conducted by assessors with appropriate levels of independence. The level of required independence is based on organizational continuous monitoring strategies. Assessor independence provides a degree of impartiality to the monitoring process. To achieve such impartiality, assessors do not create a mutual or conflicting interest with the organizations where the assessments are being conducted, assess their own work, act as management or employees of the organizations they are serving, or place themselves in advocacy positions for the organizations acquiring their services.",
          "Security assessment and authorization. Penetration testing | red team exercises. Employ the following red-team exercises to simulate attempts by adversaries to compromise organizational systems in accordance with applicable rules of engagement: [assignment: organization-defined red team exercises]. Red team exercises extend the objectives of penetration testing by examining the security and privacy posture of organizations and the capability to implement effective cyber defenses. Red team exercises simulate attempts by adversaries to compromise mission and business functions and provide a comprehensive assessment of the security and privacy posture of systems and organizations. Such attempts may include technology-based attacks and social engineering-based attacks. Technology-based attacks include interactions with hardware, software, or firmware components and/or mission and business processes. Social engineering-based attacks include interactions via email, telephone, shoulder surfing, or personal conversations. Red team exercises are most effective when conducted by penetration testing agents and teams with knowledge of and experience with current adversarial tactics, techniques, procedures, and tools. While penetration testing may be primarily laboratory-based testing, organizations can use red team exercises to provide more comprehensive assessments that reflect real-world conditions. The results from red team exercises can be used by organizations to improve security and privacy awareness and training and to assess control effectiveness.",
          "Security assessment and authorization. Control assessments. a. Select the appropriate assessor or assessment team for the type of assessment to be conducted. \nb. Develop a control assessment plan that describes the scope of the assessment, including: \n1. Controls and control enhancements under assessment. \n2. Assessment procedures to be used to determine control effectiveness. \n3. Assessment environment, assessment team, and assessment roles and responsibilities. \nc. Ensure the control assessment plan is reviewed and approved by the authorizing official or designated representative prior to conducting the assessment. \nd. Assess the controls in the system and its environment of operation [assignment: organization-defined frequency] to determine the extent to which the controls are implemented correctly, operating as intended, and producing the desired outcome with respect to meeting established security and privacy requirements. \ne. Produce a control assessment report that documents the results of the assessment. \nf. Provide the results of the control assessment to [assignment: organization-defined individuals or roles]. \nOrganizations ensure that control assessors possess the required skills and technical expertise to develop effective assessment plans and to conduct assessments of system-specific, hybrid, common, and program management controls, as appropriate. The required skills include general knowledge of risk management concepts and approaches as well as comprehensive knowledge of and experience with the hardware, software, and firmware system components implemented. Organizations assess controls in systems and the environments in which those systems operate as part of initial and ongoing authorizations, continuous monitoring, FISMA annual assessments, system design and development, systems security engineering, privacy engineering, and the system development life cycle. Assessments help to ensure that organizations meet information security and privacy requirements, identify weaknesses and deficiencies in the system design and development process, provide essential information needed to make risk-based decisions as part of authorization processes, and comply with vulnerability mitigation procedures. Organizations conduct assessments on the implemented controls as documented in security and privacy plans. Assessments can also be conducted throughout the system development life cycle as part of systems engineering and systems security engineering processes. The design for controls can be assessed as RFPs are developed, responses assessed, and design reviews conducted. If a design to implement controls and subsequent implementation in accordance with the design are assessed during development, the final control testing can be a simple confirmation utilizing previously completed control assessment and aggregating the outcomes. Organizations may develop a single, consolidated security and privacy assessment plan for the system or maintain separate plans. A consolidated assessment plan clearly delineates the roles and responsibilities for control assessment. If multiple organizations participate in assessing a system, a coordinated approach can reduce redundancies and associated costs. Organizations can use other types of assessment activities, such as vulnerability scanning and system monitoring, to maintain the security and privacy posture of systems during the system life cycle. Assessment reports document assessment results in sufficient detail, as deemed necessary by organizations, to determine the accuracy and completeness of the reports and whether the controls are implemented correctly, operating as intended, and producing the desired outcome with respect to meeting requirements. Assessment results are provided to the individuals or roles appropriate for the types of assessments being conducted. For example, assessments conducted in support of authorization decisions are provided to authorizing officials, senior agency officials for privacy, senior agency information security officers, and authorizing official designated representatives. To satisfy annual assessment requirements, organizations can use assessment results from the following sources: initial or ongoing system authorizations, continuous monitoring, systems engineering processes, or system development life cycle activities. Organizations ensure that assessment results are current, relevant to the determination of control effectiveness, and obtained with the appropriate level of assessor independence. Existing control assessment results can be reused to the extent that the results are still valid and can also be supplemented with additional assessments as needed. After the initial authorizations, organizations assess controls during continuous monitoring. Organizations also establish the frequency for ongoing assessments in accordance with organizational continuous monitoring strategies. External audits, including audits by external entities such as regulatory agencies, are outside the scope of CA-2.",
          "Risk assessment. Vulnerability monitoring and scanning | discoverable information. Determine information about the system that is discoverable and take [assignment: organization-defined corrective actions]. Discoverable information includes information that adversaries could obtain without compromising or breaching the system, such as by collecting information that the system is exposing or by conducting extensive web searches. Corrective actions include notifying appropriate organizational personnel, removing designated information, or changing the system to make the designated information less relevant or attractive to adversaries. This enhancement excludes intentionally discoverable information that may be part of a decoy capability (e.g., honeypots, honeynets, or deception nets) deployed by the organization.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "11_assessment_assessments_vulnerability",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "11_assessment_assessments_vulnerability"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          6.328175067901611,
          6.216954231262207,
          6.332403659820557,
          7.123312950134277,
          7.231147289276123,
          6.3754143714904785,
          7.000715255737305,
          6.999617099761963,
          6.4044976234436035,
          6.812456130981445,
          6.342331886291504,
          6.521308422088623,
          6.456562519073486,
          6.590165138244629,
          6.9022536277771,
          6.889406681060791,
          7.024515628814697,
          6.793251991271973,
          6.9844560623168945,
          6.371353626251221,
          6.6850152015686035
         ],
         "y": [
          6.92470645904541,
          6.7941060066223145,
          6.915676593780518,
          7.321052074432373,
          7.477716445922852,
          6.955387592315674,
          7.602222442626953,
          7.570013999938965,
          7.0021162033081055,
          7.486798286437988,
          6.9461774826049805,
          7.177183628082275,
          7.032942295074463,
          7.26137638092041,
          7.49555778503418,
          7.583517551422119,
          7.5164055824279785,
          7.499878406524658,
          7.594363689422607,
          6.920244216918945,
          7.253871917724609
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "System and communications protection. Boundary protection | route traffic to authenticated proxy servers. Route [assignment: organization-defined internal communications traffic] to [assignment: organization-defined external networks] through authenticated proxy servers at managed interfaces. External networks are networks outside of organizational control. A proxy server is a server (i.e., system or application) that acts as an intermediary for clients requesting system resources from non-organizational or other organizational servers. System resources that may be requested include files, connections, web pages, or services. Client requests established through a connection to a proxy server are assessed to manage complexity and provide additional protection by limiting direct connectivity. Web content filtering devices are one of the most common proxy servers that provide access to the internet. Proxy servers can support the logging of Transmission Control Protocol (TCP) sessions and the blocking of specific Uniform Resource Locators (URLs), Internet Protocol (IP) addresses, and domain names. Web proxies can be configured with organization-defined lists of authorized and unauthorized websites. Note that proxy servers may inhibit the use of virtual private networks (VPNs) and create the potential for man-in-the-middle attacks (depending on the implementation).",
          "System and communications protection. Boundary protection | dynamic isolation and segregation. Provide the capability to dynamically isolate [assignment: organization-defined system components] from other system components. The capability to dynamically isolate certain internal system components is useful when it is necessary to partition or separate system components of questionable origin from components that possess greater trustworthiness. Component isolation reduces the attack surface of organizational systems. Isolating selected system components can also limit the damage from successful attacks when such attacks occur.",
          "System and communications protection. Boundary protection | deny by default — allow by exception. Deny network communications traffic by default and allow network communications traffic by exception. Denying by default and allowing by exception applies to inbound and outbound network communications traffic. A deny-all, permit-by-exception network communications traffic policy ensures that only those system connections that are essential and approved are allowed. Deny by default, allow by exception also applies to a system that is connected to an external system.",
          "System and communications protection. Architecture and provisioning for name/address resolution service. Ensure the systems that collectively provide name/address resolution service for an organization are fault-tolerant and implement internal and external role separation. Systems that provide name and address resolution services include Domain Name System (DNS) servers. To eliminate single points of failure in systems and enhance redundancy, organizations employ at least two authoritative Domain Name System servers—one configured as the primary server and the other configured as the secondary server. Additionally, organizations typically deploy the servers in two geographically separated network subnetworks (i.e., not located in the same physical facility). \n\nFor role separation, DNS servers with internal roles only process name and address resolution requests from within organizations (i.e., from internal clients). DNS servers with external roles only process name and address resolution information requests from clients external to organizations (i.e., on external networks, including the internet). Organizations specify clients that can access authoritative DNS servers in certain roles (e.g., by address ranges and explicit lists).",
          "System and communications protection. Boundary protection | prevent exfiltration. (a) Prevent the exfiltration of information; and (b) conduct exfiltration tests [assignment: organization-defined frequency]. Prevention of exfiltration applies to both intentional and unintentional exfiltration of information. Techniques used to prevent the exfiltration of information from systems may be implemented at internal endpoints, external boundaries, and across managed interfaces. These techniques include adherence to protocol formats, monitoring for beaconing activity from systems, disconnecting external network interfaces except when explicitly needed, employing traffic profile analysis to detect deviations from the volume and types of traffic expected, call backs to command and control centers, conducting penetration testing, monitoring for steganography, disassembling and reassembling packet headers, and using data loss and data leakage prevention tools. Devices that enforce strict adherence to protocol formats include deep packet inspection firewalls and extensible markup language (XML) gateways. These devices verify adherence to protocol formats and specifications at the application layer and identify vulnerabilities that cannot be detected by devices that operate at the network or transport layers. The prevention of exfiltration is similar to data loss prevention or data leakage prevention and is closely associated with cross-domain solutions and system guards that enforce information flow requirements.",
          "System and communications protection. Collaborative computing devices and applications. a. Prohibit remote activation of collaborative computing devices and applications with the following exceptions: [assignment: organization-defined exceptions where remote activation is to be allowed]. \n\nb. Provide an explicit indication of use to users physically present at the devices. Collaborative computing devices and applications include remote meeting devices and applications, networked whiteboards, cameras, and microphones. The explicit indication of use includes signals to users when collaborative computing devices and applications are activated.",
          "System and communications protection. Separation of system and user functionality. Separate user functionality, including user interface services, from system management functionality. System management functionality includes functions that are necessary to administer databases, network components, workstations, or servers. These functions typically require privileged user access. \n\nThe separation of user functions from system management functions can be physical or logical. Organizations may choose to separate system management functions from user functions by utilizing different computers, instances of operating systems, central processing units, or network addresses. They can also employ virtualization techniques or a combination of other methods. \n\nThe separation of system management functions from user functions should also extend to web administrative interfaces. These interfaces should employ separate authentication methods compared to users accessing other system resources. \n\nIn addition, it is recommended to isolate administrative interfaces on different domains and implement additional access controls. \n\nAchieving the separation of system and user functionality can be accomplished by applying the systems security engineering design principles outlined in SA-8. This includes SA-8(1), SA-8(3), SA-8(4), SA-8(10), SA-8(12), SA-8(13), SA-8(14), and SA-8(18).",
          "System and communications protection. Secure name/address resolution service (authoritative source). A. Provide additional data origin authentication and integrity verification artifacts along with the authoritative name resolution data the system returns in response to external name/address resolution queries. \nB. Provide the means to indicate the security status of child zones and, if the child supports secure resolution services, enable verification of a chain of trust among parent and child domains when operating as part of a distributed, hierarchical namespace. Providing authoritative source information enables external clients, including remote internet clients, to obtain origin authentication and integrity verification assurances for the host/service name to network address resolution information obtained through the service. Systems that provide name and address resolution services include Domain Name System (DNS) servers. Additional artifacts include DNS Security Extensions (DNSSEC) digital signatures and cryptographic keys. Authoritative data includes DNS resource records. The means for indicating the security status of child zones include the use of delegation signer resource records in the DNS. Systems that use technologies other than the DNS to map between host and service names and network addresses provide other means to assure the authenticity and integrity of response data.",
          "System and communications protection. Boundary protection | external telecommunications services. (a) Implement a managed interface for each external telecommunication service. \n(b) Establish a traffic flow policy for each managed interface. \n(c) Protect the confidentiality and integrity of the information being transmitted across each interface. \n(d) Document each exception to the traffic flow policy with a supporting mission or business need and duration of that need. \n(e) Review exceptions to the traffic flow policy [assignment: organization-defined frequency] and remove exceptions that are no longer supported by an explicit mission or business need. \n(f) Prevent unauthorized exchange of control plane traffic with external networks. \n(g) Publish information to enable remote networks to detect unauthorized control plane traffic from internal networks. \n(h) Filter unauthorized control plane traffic from external networks. External telecommunication services can provide data and/or voice communications services. Examples of control plane traffic include Border Gateway Protocol (BGP) routing, Domain Name System (DNS), and management protocols. See SP 800-189 for additional information on the use of the Resource Public Key Infrastructure (RPKI) to protect BGP routes and detect unauthorized BGP announcements.",
          "System and communications protection. Boundary protection | split tunneling for remote devices. Prevent split tunneling for remote devices connecting to organizational systems, unless the split tunnel is securely provisioned using [assignment: organization-defined safeguards.]. Split tunneling is the process of allowing a remote user or device to establish a non-remote connection with a system and simultaneously communicate via some other connection to a resource in an external network. This method of network access enables a user to access remote devices and simultaneously access uncontrolled networks. Split tunneling might be desirable for remote users to communicate with local system resources, such as printers or file servers. However, split tunneling can facilitate unauthorized external connections, making the system vulnerable to attack and the exfiltration of organizational information. Split tunneling can be prevented by disabling configuration settings that allow such capability in remote devices and by preventing those configuration settings from being configurable by users. Prevention can also be achieved by detecting split tunneling (or configuration settings that allow split tunneling) in the remote device and prohibiting the connection if the remote device is using split tunneling. A Virtual Private Network (VPN) can be used to securely provision a split tunnel. A securely provisioned VPN includes locking connectivity to exclusive, managed, and named environments or to a specific set of pre-approved addresses without user control.",
          "System and communications protection. Boundary protection. a. Monitor and control communications at the external managed interfaces to the system and at key internal managed interfaces within the system. \nb. Implement subnetworks for publicly accessible system components that are physically or logically separated from internal organizational networks. \nc. Connect to external networks or systems only through managed interfaces consisting of boundary protection devices arranged in accordance with an organizational security and privacy architecture. Managed interfaces include gateways, routers, firewalls, guards, network-based malicious code analysis, virtualization systems, or encrypted tunnels implemented within a security architecture. \nSubnetworks that are physically or logically separated from internal networks are referred to as demilitarized zones or DMZs. \nRestricting or prohibiting interfaces within organizational systems includes restricting external web traffic to designated web servers within managed interfaces, prohibiting external traffic that appears to be spoofing internal addresses, and prohibiting internal traffic that appears to be spoofing external addresses. \nSP 800-189 provides additional information on source address validation techniques to prevent ingress and egress of traffic with spoofed addresses. \nCommercial telecommunications services are provided by network components and consolidated management systems shared by customers. These services may also include third party-provided access lines and other service elements. \nSuch services may represent sources of increased risk despite contract security provisions. \nBoundary protection may be implemented as a common control for all or part of an organizational network, such that the boundary to be protected is greater than a system-specific boundary (i.e., an authorization boundary).",
          "System and communications protection. Process isolation. Maintain a separate execution domain for each executing system process. Systems can maintain separate execution domains for each executing process by assigning each process a separate address space. Each system process has a distinct address space so that communication between processes is performed in a manner controlled through the security functions, and one process cannot modify the executing code of another process. Maintaining separate execution domains for executing processes can be achieved, for example, by implementing separate address spaces. Process isolation technologies, including sandboxing or virtualization, logically separate software and firmware from other software, firmware, and data. Process isolation helps limit the access of potentially untrusted software to other system resources. The capability to maintain separate execution domains is available in commercial operating systems that employ multi-state processor technologies.",
          "System and communications protection. Boundary protection | isolation of system components. Employ boundary protection mechanisms to isolate [assignment: organization-defined system components] supporting [assignment: organization-defined missions and/or business functions]. Organizations can isolate system components that perform different mission or business functions. Such isolation limits unauthorized information flows among system components and provides the opportunity to deploy greater levels of protection for selected system components. Isolating system components with boundary protection mechanisms provides the capability for increased protection of individual system components and to more effectively control information flows between those components. Isolating system components provides enhanced protection that limits the potential harm from hostile cyber-attacks and errors. The degree of isolation varies depending upon the mechanisms chosen. Boundary protection mechanisms include routers, gateways, and firewalls that separate system components into physically separate networks or subnetworks; cross-domain devices that separate subnetworks; virtualization techniques; and the encryption of information flows among system components using distinct encryption keys.",
          "System and communications protection. Secure name/address resolution service (recursive or caching resolver). Request and perform data origin authentication and data integrity verification on the name/address resolution responses the system receives from authoritative sources. Each client of name resolution services either performs this validation on its own or has authenticated channels to trusted validation providers. \n\nSystems that provide name and address resolution services for local clients include recursive resolving or caching Domain Name System (DNS) servers. DNS client resolvers either perform validation of DNSSEC signatures, or clients use authenticated channels to recursive resolvers that perform such validations. \n\nSystems that use technologies other than the DNS to map between host and service names and network addresses provide some other means to enable clients to verify the authenticity and integrity of response data.",
          "System and communications protection. Security function isolation. Isolate security functions from non-security functions. Security functions are isolated from non-security functions by means of an isolation boundary implemented within a system via partitions and domains. The isolation boundary controls access to and protects the integrity of the hardware, software, and firmware that perform system security functions. Systems implement code separation in many ways, such as through the provision of security kernels via processor rings or processor modes. For non-kernel code, security function isolation is often achieved through file system protections that protect the code on disk and address space protections that protect executing code. Systems can restrict access to security functions using access control mechanisms and by implementing least privilege capabilities. While the ideal is for all code within the defined security function isolation boundary to only contain security-relevant code, it is sometimes necessary to include non-security functions as an exception. The isolation of security functions from non-security functions can be achieved by applying the systems security engineering design principles in SA-8, including SA-8 (1), SA-8 (3), SA-8 (4), SA-8 (10), SA-8 (12), SA-8 (13), SA-8 (14), and SA-8 (18).",
          "System and communications protection. Boundary protection | access points. Limit the number of external network connections to the system. Limiting the number of external network connections facilitates monitoring of inbound and outbound communications traffic. The Trusted Internet Connection (TIC) Initiative, mandated by the Department of Homeland Security (DHS), is an example of a federal guideline that requires limits on the number of external network connections. Limiting the number of external network connections to the system is important during transition periods from older to newer technologies (e.g., transitioning from IPv4 to IPv6 network protocols). Such transitions may require implementing the older and newer technologies simultaneously during the transition period and thus increase the number of access points to the system.",
          "System and communications protection. Denial-of-service protection. a. [Selection: Protect against; Limit] the effects of the following types of denial-of-service events: [Assignment: Organization-defined types of denial-of-service events]. \nb. Employ the following controls to achieve the denial-of-service objective: [Assignment: Organization-defined controls by type of denial-of-service event]. \n\nDenial-of-service events may occur due to a variety of internal and external causes, such as an attack by an adversary or a lack of planning to support organizational needs with respect to capacity and bandwidth. Such attacks can occur across a wide range of network protocols (e.g., IPv4, IPv6). \n\nA variety of technologies are available to limit or eliminate the origination and effects of denial-of-service events. For example, boundary protection devices can filter certain types of packets to protect system components on internal networks from being directly affected by or the source of denial-of-service attacks. Employing increased network capacity and bandwidth, combined with service redundancy, also reduces the susceptibility to denial-of-service events.",
          "System and communications protection. Boundary protection | fail secure. Prevent systems from entering insecure states in the event of an operational failure of a boundary protection device. Fail-secure is a condition achieved by employing mechanisms to ensure that, in the event of operational failures of boundary protection devices at managed interfaces, systems do not enter unsecure states where intended security properties no longer hold. Managed interfaces include routers, firewalls, and application gateways that reside on protected subnetworks (commonly referred to as demilitarized zones). Failures of boundary protection devices cannot lead to or cause information external to the devices to enter the devices, nor can failures permit unauthorized information releases.",
          "System and communications protection. Boundary protection | host-based protection. Implement organization-defined host-based boundary protection mechanisms at organization-defined system components. Host-based boundary protection mechanisms include host-based firewalls. System components that employ host-based boundary protection mechanisms include servers, workstations, notebook computers, and mobile devices.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "12_boundary_protection_system",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "12_boundary_protection_system"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          9.07001781463623,
          9.035968780517578,
          9.034100532531738,
          8.770063400268555,
          9.01848030090332,
          9.17434310913086,
          9.002105712890625,
          8.752501487731934,
          9.041459083557129,
          9.237348556518555,
          8.994589805603027,
          8.993951797485352,
          8.972097396850586,
          8.771677017211914,
          9.00029182434082,
          9.101818084716797,
          9.053034782409668,
          8.978190422058105,
          8.930608749389648,
          8.996456146240234
         ],
         "y": [
          6.334074020385742,
          6.506253242492676,
          6.317763328552246,
          6.131900310516357,
          6.332925796508789,
          6.788071155548096,
          6.55177640914917,
          6.116491794586182,
          6.349119186401367,
          6.46246337890625,
          6.401765823364258,
          6.530737400054932,
          6.473138809204102,
          6.119060516357422,
          6.54937744140625,
          6.3630475997924805,
          6.310678958892822,
          6.415099620819092,
          6.455676078796387,
          6.395232677459717
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Supply chain risk management family. Supply chain controls and processes. a. Establish a process or processes to identify and address weaknesses or deficiencies in the supply chain elements and processes of [assignment: organization-defined system or system component] in coordination with [assignment: organization-defined supply chain personnel]. \nB. Employ the following controls to protect against supply chain risks to the system, system component, or system service and to limit the harm or consequences from supply chain-related events: [assignment: organization-defined supply chain controls]. \nC. Document the selected and implemented supply chain processes and controls in [Selection: security and privacy plans; supply chain risk management plan; [assignment: organization-defined document]]. \n\nSupply chain elements include organizations, entities, or tools employed for the research and development, design, manufacturing, acquisition, delivery, integration, operations and maintenance, and disposal of systems and system components. \nSupply chain processes include hardware, software, and firmware development processes; shipping and handling procedures; personnel security and physical security programs; configuration management tools, techniques, and measures to maintain provenance; or other programs, processes, or procedures associated with the development, acquisition, maintenance, and disposal of systems and system components. \nSupply chain elements and processes may be provided by organizations, system integrators, or external providers. \nWeaknesses or deficiencies in supply chain elements or processes represent potential vulnerabilities that can be exploited by adversaries to cause harm to the organization and affect its ability to carry out its core missions or business functions. \nSupply chain personnel are individuals with roles and responsibilities in the supply chain.",
          "Supply chain risk management family. Component authenticity | anti-counterfeit training. Train organization-defined personnel or roles to detect counterfeit system components (including hardware, software, and firmware). None.",
          "Supply chain risk management family. Component authenticity. a. Develop and implement an anti-counterfeit policy and procedures that include the means to detect and prevent counterfeit components from entering the system. \nb. Report counterfeit system components to the source of the counterfeit component; organization-defined external reporting organizations; organization-defined personnel or roles. \nSources of counterfeit components include manufacturers, developers, vendors, and contractors. \nAnti-counterfeiting policies and procedures support tamper resistance and provide a level of protection against the introduction of malicious code. \nExternal reporting organizations include CISA.",
          "Supply chain risk management family. Supply chain risk management plan. A. Develop a plan for managing supply chain risks associated with the research and development, design, manufacturing, acquisition, delivery, integration, operations and maintenance, and disposal of the following systems, system components, or system services: [assignment: organization-defined systems, system components, or system services]. \nB. Review and update the supply chain risk management plan [assignment: organization-defined frequency] or as required, to address threat, organizational, or environmental changes. \nC. Protect the supply chain risk management plan from unauthorized disclosure and modification. \n\nThe dependence on products, systems, and services from external providers, as well as the nature of the relationships with those providers, present an increasing level of risk to an organization. Threat actions that may increase security or privacy risks include unauthorized production, the insertion or use of counterfeits, tampering, theft, insertion of malicious software and hardware, and poor manufacturing and development practices in the supply chain. Supply chain risks can be endemic or systemic within a system element or component, a system, an organization, a sector, or the nation. \n\nManaging supply chain risk is a complex, multifaceted undertaking that requires a coordinated effort across an organization to build trust relationships and communicate with internal and external stakeholders. Supply chain risk management (SCRM) activities include identifying and assessing risks, determining appropriate risk response actions, developing SCRM plans to document response actions, and monitoring performance against plans. \n\nThe SCRM plan (at the system-level) is implementation-specific, providing policy implementation, requirements, constraints, and implications. It can either be stand-alone or incorporated into system security and privacy plans. The SCRM plan addresses managing, implementation, and monitoring of SCRM controls and the development/sustainment of systems across the SDLC to support mission and business functions. \n\nBecause supply chains can differ significantly across and within organizations, SCRM plans are tailored to the individual program, organizational, and operational contexts. Tailored SCRM plans provide the basis for determining whether a technology, service, system component, or system is fit for purpose, and as such, the controls need to be tailored accordingly. Tailored SCRM plans help organizations focus their resources on the most critical mission and business functions based on mission and business requirements and their risk environment. \n\nSupply chain risk management plans include an expression of the supply chain risk tolerance for the organization, acceptable supply chain risk mitigation strategies or controls, a process for consistently evaluating and monitoring supply chain risk, approaches for implementing and communicating the plan, a description of and justification for supply chain risk mitigation measures taken, and associated roles and responsibilities. Finally, supply chain risk management plans address requirements for developing trustworthy, secure, privacy-protective, and resilient system components and systems, including the application of the security design principles implemented as part of life cycle-based systems security engineering processes (see SA-8).",
          "Supply chain risk management family. Tamper resistance and detection. Implement a tamper protection program for the system, system component, or system service. Anti-tamper technologies, tools, and techniques provide a level of protection for systems, system components, and services against many threats, including reverse engineering, modification, and substitution. Strong identification, combined with tamper resistance and/or tamper detection, is essential to protecting systems and components during distribution and when in use.",
          "Supply chain risk management family. Component authenticity | configuration control for component service and repair. Maintain configuration control over the following system components awaiting service or repair and serviced or repaired components awaiting return to service: [assignment: organization-defined system components]. None.",
          "Supply chain risk management family. Policy and procedures. A. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]: 1. [Selection (one or more): organization level; mission/business process-level; system-level] supply chain risk management policy that: (a) addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance; and (b) is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines; and 2. Procedures to facilitate the implementation of the supply chain risk management policy and the associated supply chain risk management controls. \n\nB. Designate an [assignment: organization-defined official] to manage the development, documentation, and dissemination of the supply chain risk management policy and procedures. \n\nC. Review and update the current supply chain risk management: 1. Policy [assignment: organization-defined frequency] and following [assignment: organization-defined events]; and 2. Procedures [assignment: organization-defined frequency] and following [assignment: organization-defined events]. \n\nSupply chain risk management policy and procedures address the controls in the SR family as well as supply chain-related controls in other families that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of supply chain risk management policy and procedures. Security and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations. Procedures can be established for security and privacy programs, for mission or business processes, and for systems, if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents. Events that may precipitate an update to supply chain risk management policy and procedures include assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Risk assessment. Risk assessment | supply chain risk assessment. (a) Assess supply chain risks associated with [assignment: organization-defined systems, system components, and system services]; and (b) update the supply chain risk assessment [assignment: organization-defined frequency], when there are significant changes to the relevant supply chain or when changes to the system, environments of operation, or other conditions may necessitate a change in the supply chain. Supply chain-related events include disruption, use of defective components, insertion of counterfeits, theft, malicious development practices, improper delivery practices, and insertion of malicious code. These events can have a significant impact on the confidentiality, integrity, or availability of a system and its information and therefore can also adversely impact organizational operations (including mission, functions, image, or reputation), organizational assets, individuals, other organizations, and the nation. The supply chain-related events may be unintentional or malicious and can occur at any point during the system life cycle. An analysis of supply chain risk can help an organization identify systems or components for which additional supply chain risk mitigations are required.",
          "Supply chain risk management family. Notification agreements. Establish agreements and procedures with entities involved in the supply chain for the system, system component, or system service for the [selection (one or more): notification of supply chain compromises; results of assessments or audits; [assignment: organization-defined information]]. The establishment of agreements and procedures facilitates communications among supply chain entities. Early notification of compromises and potential compromises in the supply chain that can potentially adversely affect or have adversely affected organizational systems or system components is essential for organizations to effectively respond to such incidents. The results of assessments or audits may include open-source information that contributed to a decision or result, and could be used to help the supply chain entity resolve a concern or improve its processes.",
          "Supply chain risk management family. Supplier assessments and reviews. Assess and review the supply chain-related risks associated with suppliers or contractors and the system, system component, or system service they provide [assignment: organization-defined frequency]. An assessment and review of supplier risk includes security and supply chain risk management processes, foreign ownership, control or influence (FOCI), and the ability of the supplier to effectively assess subordinate second-tier and third-tier suppliers and contractors. The reviews may be conducted by the organization or by an independent third party. The reviews consider documented processes, documented controls, all-source intelligence, and publicly available information related to the supplier or contractor. Organizations can use open-source information to monitor for indications of stolen information, poor development and quality control practices, information spillage, or counterfeits. In some cases, it may be appropriate or required to share assessment and review results with other organizations in accordance with any applicable rules, policies, or inter-organizational agreements or contracts.",
          "Supply chain risk management family. Tamper resistance and detection | multiple stages of system development life cycle. Employ anti-tamper technologies, tools, and techniques throughout the system development life cycle. The system development life cycle includes research and development, design, manufacturing, acquisition, delivery, integration, operations and maintenance, and disposal. Organizations use a combination of hardware and software techniques for tamper resistance and detection. Organizations use obfuscation and self-checking to make reverse engineering and modifications more difficult, time-consuming, and expensive for adversaries. The customization of systems and system components can make substitutions easier to detect and, therefore, limit damage.",
          "Supply chain risk management family. Component disposal. Dispose of [assignment: organization-defined data, documentation, tools, or system components] using the following techniques and methods: [assignment: organization-defined techniques and methods]. Data, documentation, tools, or system components can be disposed of at any time during the system development life cycle (not only in the disposal or retirement phase of the life cycle). For example, disposal can occur during research and development, design, prototyping, or operations/maintenance and include methods such as disk cleaning, removal of cryptographic keys, partial reuse of components. Opportunities for compromise during disposal affect physical and logical data, including system documentation in paper-based or digital files; shipping and delivery documentation; memory sticks with software code; or complete routers or servers that include permanent media, which contain sensitive or proprietary information. Additionally, proper disposal of system components helps to prevent such components from entering the gray market.",
          "Supply chain risk management family. Supply chain risk management plan | establish scrm team. Establish a Supply Chain Risk Management team consisting of [assignment: organization-defined personnel, roles, and responsibilities] to lead and support the following SCRM activities: [assignment: organization-defined supply chain risk management activities]. To implement Supply Chain Risk Management plans, organizations establish a coordinated, team-based approach to identify and assess supply chain risks and manage these risks by using programmatic and technical mitigation techniques. The team approach enables organizations to conduct an analysis of their supply chain, communicate with internal and external partners or stakeholders, and gain broad consensus regarding the appropriate resources for SCRM. The SCRM team consists of organizational personnel with diverse roles and responsibilities for leading and supporting SCRM activities, including Risk Executive, Information Technology, Contracting, Information Security, Privacy, Mission or Business, Legal, Supply Chain and Logistics, Acquisition, Business Continuity, and other relevant functions. Members of the SCRM team are involved in various aspects of the SDLC and, collectively, have an awareness of and provide expertise in acquisition processes, legal practices, vulnerabilities, threats, and attack vectors, as well as an understanding of the technical aspects and dependencies of systems. The SCRM team can be an extension of the Security and Privacy Risk Management processes or be included as part of an organizational risk management team.",
          "Supply chain risk management family. Acquisition strategies, tools, and methods. Employ the following acquisition strategies, contract tools, and procurement methods to protect against, identify, and mitigate supply chain risks: [assignment: organization-defined acquisition strategies, contract tools, and procurement methods]. The use of the acquisition process provides an important vehicle to protect the supply chain. There are many useful tools and techniques available, including obscuring the end use of a system or system component, using blind or filtered buys, requiring tamper-evident packaging, or using trusted or controlled distribution. The results from a supply chain risk assessment can guide and inform the strategies, tools, and methods that are most applicable to the situation. Tools and techniques may provide protections against unauthorized production, theft, tampering, insertion of counterfeits, insertion of malicious software or backdoors, and poor development practices throughout the system development life cycle.\n\nOrganizations also consider providing incentives for suppliers who implement controls, promote transparency into their processes and security and privacy practices, provide contract language that addresses the prohibition of tainted or counterfeit components, and restrict purchases from untrustworthy suppliers. Organizations consider providing training, education, and awareness programs for personnel regarding supply chain risk, available mitigation strategies, and when the programs should be employed. Methods for reviewing and protecting development plans, documentation, and evidence are commensurate with the security and privacy requirements of the organization. Contracts may specify documentation protection requirements.",
          "Supply chain risk management family. Inspection of systems or components. Inspect the following systems or system components [selection (one or more): at random; at [assignment: organization-defined frequency], upon [assignment: organization-defined indications of need for inspection]] to detect tampering: [assignment: organization-defined systems or system components]. The inspection of systems or system components for tamper resistance and detection addresses physical and logical tampering and is applied to systems and system components removed from organization-controlled areas. Indications of a need for inspection include changes in packaging, specifications, factory location, or entity in which the part is purchased, and when individuals return from travel to high-risk locations.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "13_supply_chain_risk",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "13_supply_chain_risk"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          4.305728435516357,
          4.2646613121032715,
          4.266964912414551,
          4.319879531860352,
          4.25249719619751,
          4.279866695404053,
          4.327651500701904,
          4.280218601226807,
          4.2122297286987305,
          4.260828971862793,
          4.253894329071045,
          4.383479118347168,
          4.3324995040893555,
          4.271484375,
          4.29494571685791,
          4.28712272644043
         ],
         "y": [
          8.43852710723877,
          8.397477149963379,
          8.401351928710938,
          8.394309043884277,
          8.374809265136719,
          8.449193000793457,
          8.41903305053711,
          8.456615447998047,
          8.502595901489258,
          8.422235488891602,
          8.38637638092041,
          8.521852493286133,
          8.43671703338623,
          8.409282684326172,
          8.449068069458008,
          8.430628776550293
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "System and communications protection. Protection of information at rest | cryptographic protection. Implement cryptographic mechanisms to prevent unauthorized disclosure and modification of the following information at rest on [assignment: organization-defined system components or media]: [assignment: organization-defined information]. The selection of cryptographic mechanisms is based on the need to protect the confidentiality and integrity of organizational information. The strength of the mechanism is commensurate with the security category or classification of the information. Organizations have the flexibility to encrypt information on system components or media or encrypt data structures, including files, records, or fields.",
          "System and communications protection. Information in shared system resources. Prevent unauthorized and unintended information transfer via shared system resources. Preventing unauthorized and unintended information transfer via shared system resources stops information produced by the actions of prior users or roles (or the actions of processes acting on behalf of prior users or roles) from being available to current users or roles (or current processes acting on behalf of current users or roles) that obtain access to shared system resources after those resources have been released back to the system. Information in shared system resources also applies to encrypted representations of information. In other contexts, control of information in shared system resources is referred to as object reuse and residual information protection. Information in shared system resources does not address information remanence, which refers to the residual representation of data that has been nominally deleted; covert channels (including storage and timing channels), where shared system resources are manipulated to violate information flow restrictions; or components within systems for which there are only single users or roles.",
          "System and communications protection. Cryptographic key establishment and management. Establish and manage cryptographic keys when cryptography is employed within the system in accordance with the following key management requirements: [assignment: organization-defined requirements for key generation, distribution, storage, access, and destruction]. Cryptographic key management and establishment can be performed using manual procedures or automated mechanisms with supporting manual procedures. Organizations define key management requirements in accordance with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines and specify appropriate options, parameters, and levels. Organizations manage trust stores to ensure that only approved trust anchors are part of such trust stores. This includes certificates with visibility external to organizational systems and certificates related to the internal operations of systems. NIST CMVP and NIST CAVP provide additional information on validated cryptographic modules and algorithms that can be used in cryptographic key management and establishment.",
          "System and communications protection. Transmission confidentiality and integrity | cryptographic protection. Implement cryptographic mechanisms to prevent unauthorized disclosure of information during transmission. \nEncryption protects information from unauthorized disclosure and modification during transmission. \nCryptographic mechanisms that protect the confidentiality and integrity of information during transmission include TLS and IPsec. \nCryptographic mechanisms used to protect information integrity include cryptographic hash functions that have applications in digital signatures, checksums, and message authentication codes.",
          "Contingency planning. System backup | cryptographic protection. Implement cryptographic mechanisms to prevent unauthorized disclosure and modification of [assignment: organization-defined backup information]. The selection of cryptographic mechanisms is based on the need to protect the confidentiality and integrity of backup information. The strength of the mechanisms selected is commensurate with the security category or classification of the information. Cryptographic protection applies to system backup information in storage at both primary and alternate locations. Organizations that implement cryptographic mechanisms to protect information at rest also consider cryptographic key management solutions.",
          "System and communications protection. Transmission confidentiality and integrity. Protect the confidentiality and integrity of transmitted information. Protecting the confidentiality and integrity of transmitted information applies to internal and external networks as well as any system components that can transmit information, including servers, notebook computers, desktop computers, mobile devices, printers, copiers, scanners, facsimile machines, and radios. Unprotected communication paths are exposed to the possibility of interception and modification. Protecting the confidentiality and integrity of information can be accomplished by physical or logical means. Physical protection can be achieved by using protected distribution systems. A protected distribution system is a wireline or fiber-optics telecommunications system that includes terminals and adequate electromagnetic, acoustical, electrical, and physical controls to permit its use for the unencrypted transmission of classified information. Logical protection can be achieved by employing encryption techniques. Organizations that rely on commercial providers who offer transmission services as commodity services rather than as fully dedicated services may find it difficult to obtain the necessary assurances regarding the implementation of needed controls for transmission confidentiality and integrity. In such situations, organizations determine what types of confidentiality or integrity services are available in standard, commercial telecommunications service packages. If it is not feasible to obtain the necessary controls and assurances of control effectiveness through appropriate contracting vehicles, organizations can implement appropriate compensating controls.",
          "System and communications protection. Cryptographic protection. a. Determine the organization-defined cryptographic uses; and b. Implement the following types of cryptography required for each specified cryptographic use: organization-defined types of cryptography for each specified cryptographic use. Cryptography can be employed to support a variety of security solutions, including the protection of classified information and controlled unclassified information, the provision and implementation of digital signatures, and the enforcement of information separation when authorized individuals have the necessary clearances but lack the necessary formal access approvals. Cryptography can also be used to support random number and hash generation. Generally applicable cryptographic standards include FIPS-validated cryptography and NSA-approved cryptography. For example, organizations that need to protect classified information may specify the use of NSA-approved cryptography. Organizations that need to provision and implement digital signatures may specify the use of FIPS-validated cryptography. Cryptography is implemented in accordance with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines.",
          "System and communications protection. Session authenticity. Protect the authenticity of communication sessions. Protecting session authenticity addresses communication protection at the session level, not at the packet level. Such protection establishes grounds for confidence at both ends of communication sessions in the ongoing identities of other parties and the validity of transmitted information. Authenticity protection includes protecting against man-in-the-middle attacks, session hijacking, and the insertion of false information into sessions.",
          "System and communications protection. Public key infrastructure certificates. a. Issue public key certificates under an [assignment: organization-defined certificate policy] or obtain public key certificates from an approved service provider; and b. Include only approved trust anchors in trust stores or certificate stores managed by the organization. Public Key Infrastructure (PKI) certificates are certificates with visibility external to organizational systems and certificates related to the internal operations of systems, such as application-specific time services. In cryptographic systems with a hierarchical structure, a trust anchor is an authoritative source (i.e., a certificate authority) for which trust is assumed and not derived. A root certificate for a PKI system is an example of a trust anchor. A trust store or certificate store maintains a list of trusted root certificates.",
          "Cryptography and key management (cry). Policy for the use of encryption procedures and key management. Basic criterion: Policies and instructions with technical and organizational safeguards for encryption procedures and key management are documented, communicated, and provided according to SP-01. The following aspects are described:\n\n- Usage of strong encryption procedures and secure network protocols that correspond to the state-of-the-art.\n- Risk-based provisions for the use of encryption aligned with the information classification schemes (cf. AM-06). This includes considering the communication channel, type, strength, and quality of the encryption.\n- Requirements for secure generation, storage, archiving, retrieval, distribution, withdrawal, and deletion of encryption keys.\n- Consideration of relevant legal and regulatory obligations and requirements.\n\nAdditional criterion: \n\nSupplementary information about the criterion:\n\nThe state-of-the-art of strong encryption procedures and secure network protocols is specified in the following BSI technical guidelines valid at the given time:\n\n- BSI TR-02102-1: Cryptographic mechanisms - Recommendations and key lengths.\n- BSI TR-02102-2: Cryptographic mechanisms - Use of Transport Layer Security (TLS).\n- BSI TR-02102-3: Cryptographic mechanisms - Use of Internet Protocol Security (IPSec) and Internet Key Exchange (IKEv2).\n- BSI TR-02102-4: Cryptographic mechanisms - Use of Secure Shell (SSH).\n\nComplementary customer criterion:\n\nNotes on continuous auditing feasibility: Partially, a policy can change ad-hoc. However, the continuous audit of policies is only partially feasible as the only attributes that can be tested are the last change date and the status of review or approval, as far as this information is stored in a system. The content of a policy can hardly be tested automatically.",
          "System and communications protection. Cryptographic key establishment and management | availability. Maintain availability of information in the event of the loss of cryptographic keys by users. Escrowing of encryption keys is a common practice for ensuring availability in the event of key loss. A forgotten passphrase is an example of losing a cryptographic key.",
          "System and communications protection. Protection of information at rest. Protect the confidentiality and integrity of the following information at rest: Organization-defined information at rest. Information at rest refers to the state of information when it is not in process or in transit and is located on system components. Such components include internal or external hard disk drives, storage area network devices, or databases. However, the focus of protecting information at rest is not on the type of storage device or frequency of access but rather on the state of the information. Information at rest addresses the confidentiality and integrity of information and covers user information and system information.\n\nSystem-related information that requires protection includes configurations or rule sets for firewalls, intrusion detection and prevention systems, filtering routers, and authentication information. Organizations may employ different mechanisms to achieve confidentiality and integrity protections, including the use of cryptographic mechanisms and file share scanning. Integrity protection can be achieved, for example, by implementing write-once-read-many (WORM) technologies. When adequate protection of information at rest cannot otherwise be achieved, organizations may employ other controls, including frequent scanning to identify malicious code at rest and secure offline storage in lieu of online storage.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "14_cryptographic_information_key",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "14_cryptographic_information_key"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          9.062499046325684,
          8.761734008789062,
          9.459700584411621,
          9.136056900024414,
          9.245749473571777,
          9.195354461669922,
          9.160303115844727,
          9.208995819091797,
          9.366471290588379,
          9.800851821899414,
          9.388094902038574,
          8.82968521118164,
          9.217957496643066
         ],
         "y": [
          5.209033012390137,
          5.328457355499268,
          4.795503616333008,
          5.1917009353637695,
          4.888413906097412,
          5.283623218536377,
          5.124508857727051,
          5.209173679351807,
          5.004393100738525,
          4.528873920440674,
          4.7868146896362305,
          5.277179718017578,
          5.052306652069092
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Maintenance. Maintenance personnel. a. Establish a process for maintenance personnel authorization and maintain a list of authorized maintenance organizations or personnel. \nb. Verify that non-escorted personnel performing maintenance on the system possess the required access authorizations. \nc. Designate organizational personnel with required access authorizations and technical competence to supervise the maintenance activities of personnel who do not possess the required access authorizations. \n\nMaintenance personnel refers to individuals who perform hardware or software maintenance on organizational systems, while PE-2 addresses physical access for individuals whose maintenance duties place them within the physical protection perimeter of the systems. \n\nTechnical competence of supervising individuals relates to the maintenance performed on the systems, while having required access authorizations refers to maintenance on and near the systems. \n\nIndividuals not previously identified as authorized maintenance personnel—such as information technology manufacturers, vendors, systems integrators, and consultants—may require privileged access to organizational systems, such as when they are required to conduct maintenance activities with little or no notice. \n\nBased on organizational assessments of risk, organizations may issue temporary credentials to these individuals. Temporary credentials may be for one-time use or for very limited time periods.",
          "Maintenance. Nonlocal maintenance. a. Approve and monitor non-local maintenance and diagnostic activities.\nb. Allow the use of non-local maintenance and diagnostic tools only as consistent with organizational policy and documented in the security plan for the system.\nc. Employ strong authentication in the establishment of non-local maintenance and diagnostic sessions.\nd. Maintain records for non-local maintenance and diagnostic activities.\ne. Terminate session and network connections when non-local maintenance is completed.\n\nNon-local maintenance and diagnostic activities are conducted by individuals who communicate through either an external or internal network. Local maintenance and diagnostic activities are carried out by individuals who are physically present at the system location and not communicating across a network connection. Authentication techniques used to establish non-local maintenance and diagnostic sessions reflect the network access requirements in IA-2. Strong authentication requires authenticators that are resistant to replay attacks and employ multi-factor authentication. Strong authenticators include PKI where certificates are stored on a token protected by a password, passphrase, or biometric. \n\nEnforcing requirements in MA-4 is accomplished, in part, by other controls. SP 800-63b provides additional guidance on strong authentication and authenticators.",
          "Maintenance. Maintenance tools | prevent unauthorized removal. Prevent the removal of maintenance equipment containing organizational information by: (a) verifying that there is no organizational information contained on the equipment; (b) sanitizing or destroying the equipment; (c) retaining the equipment within the facility; or (d) obtaining an exemption from [assignment: organization-defined personnel or roles] explicitly authorizing removal of the equipment from the facility. Organizational information includes all information owned by organizations and any information provided to organizations for which the organizations serve as information stewards.",
          "Maintenance. Maintenance tools. a. Approve, control, and monitor the use of system maintenance tools; and b. Review previously approved system maintenance tools [assignment: organization-defined frequency]. Approving, controlling, monitoring, and reviewing maintenance tools address security-related issues associated with maintenance tools that are not within system authorization boundaries and are used specifically for diagnostic and repair actions on organizational systems. Organizations have flexibility in determining roles for the approval of maintenance tools and how that approval is documented. A periodic review of maintenance tools facilitates the withdrawal of approval for outdated, unsupported, irrelevant, or no-longer-used tools. Maintenance tools can include hardware, software, and firmware items and may be pre-installed, brought in with maintenance personnel on media, cloud-based or downloaded from a website. Such tools can be vehicles for transporting malicious code, either intentionally or unintentionally, into a facility and subsequently into systems. Maintenance tools can include hardware and software diagnostic test equipment and packet sniffers. The hardware and software components that support maintenance and are part of the system (including the software implementing utilities such as ping, ls, ipconfig, or the hardware and software implementing the monitoring port of an Ethernet switch) are not addressed by maintenance tools.",
          "Maintenance. Controlled maintenance. a. Schedule, document, and review records of maintenance, repair, and replacement on system components in accordance with manufacturer or vendor specifications and/or organizational requirements.\nb. Approve and monitor all maintenance activities, whether performed on-site or remotely, and whether the system or system components are serviced on-site or removed to another location.\nc. Require that [assignment: organization-defined personnel or roles] explicitly approve the removal of the system or system components from organizational facilities for off-site maintenance, repair, or replacement.\nd. Sanitize equipment to remove the following information from associated media prior to removal from organizational facilities for off-site maintenance, repair, or replacement: [assignment: organization-defined information].\ne. Check all potentially impacted controls to verify that the controls are still functioning properly following maintenance, repair, or replacement actions.\nf. Include the following information in organizational maintenance records: [assignment: organization-defined information].\n\nControlling system maintenance addresses the information security aspects of the system maintenance program and applies to all types of maintenance to system components conducted by local or non-local entities. Maintenance includes peripherals such as scanners, copiers, and printers. Information necessary for creating effective maintenance records includes the date and time of maintenance, a description of the maintenance performed, names of the individuals or group performing the maintenance, the name of the escort, and system components or equipment that is removed or replaced. Organizations consider supply chain-related risks associated with replacement components for systems.",
          "Maintenance. Maintenance tools | inspect media. Check media containing diagnostic and test programs for malicious code before the media is used in the system. If, upon inspection of media containing maintenance, diagnostic, and test programs, organizations determine that the media contains malicious code, the incident is handled consistent with organizational incident handling policies and procedures.",
          "Maintenance. Controlled maintenance | automated maintenance activities. (a) Schedule, conduct, and document maintenance, repair, and replacement actions for the system using [assignment: organization-defined automated mechanisms]. \n(b) Produce up-to-date, accurate, and complete records of all maintenance, repair, and replacement actions requested, scheduled, in process, and completed. \nThe use of automated mechanisms to manage and control system maintenance programs and activities helps to ensure the generation of timely, accurate, complete, and consistent maintenance records.",
          "Maintenance. Maintenance personnel | individuals without appropriate access. (a) Implement procedures for the use of maintenance personnel that lack appropriate security clearances or are not U.S. citizens, that include the following requirements: \n\n(1) Maintenance personnel who do not have needed access authorizations, clearances, or formal access approvals are escorted and supervised during the performance of maintenance and diagnostic activities on the system by approved organizational personnel who are fully cleared, have appropriate access authorizations, and are technically qualified.\n\n(2) Prior to initiating maintenance or diagnostic activities by personnel who do not have needed access authorizations, clearances, or formal access approvals, all volatile information storage components within the system are sanitized and all nonvolatile storage media are removed or physically disconnected from the system and secured.\n\n(b) Develop and implement [assignment: organization-defined alternate controls] in the event a system component cannot be sanitized, removed, or disconnected from the system. \n\nProcedures for individuals who lack appropriate security clearances or who are not U.S. citizens are intended to deny visual and electronic access to classified or controlled unclassified information contained on organizational systems. \n\nProcedures for the use of maintenance personnel can be documented in security plans for the systems.",
          "Maintenance. Maintenance tools | inspect tools. Inspect the maintenance tools used by maintenance personnel for improper or unauthorized modifications. Maintenance tools can be directly brought into a facility by maintenance personnel or downloaded from a vendor's website. If, upon inspection of the maintenance tools, organizations determine that the tools have been modified in an improper manner or the tools contain malicious code, the incident is handled consistent with organizational policies and procedures for incident handling.",
          "Maintenance. Timely maintenance. Obtain maintenance support and/or spare parts for [assignment: organization-defined system components] within [assignment: organization-defined time period] of failure. Organizations specify the system components that result in increased risk to organizational operations and assets, individuals, other organizations, or the nation when the functionality provided by those components is not operational. Organizational actions to obtain maintenance support include having appropriate contracts in place.",
          "Maintenance. Nonlocal maintenance | comparable security and sanitization. (a) Require that nonlocal maintenance and diagnostic services be performed from a system that implements a security capability comparable to the capability implemented on the system being serviced. \n(b) Remove the component to be serviced from the system prior to nonlocal maintenance or diagnostic services, sanitize the component (for organizational information), and after the service is performed, inspect and sanitize the component (for potentially malicious software) before reconnecting the component to the system. \n\nComparable security capability on systems, diagnostic tools, and equipment providing maintenance services implies that the implemented controls on those systems, tools, and equipment are at least as comprehensive as the controls on the system being serviced.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "15_maintenance_diagnostic_tools",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "15_maintenance_diagnostic_tools"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          8.067425727844238,
          8.080973625183105,
          8.044098854064941,
          8.04149055480957,
          8.015584945678711,
          8.110748291015625,
          8.022163391113281,
          8.073863983154297,
          8.065486907958984,
          8.002327919006348,
          8.070575714111328,
          8.054067611694336
         ],
         "y": [
          9.454747200012207,
          9.42147159576416,
          9.487849235534668,
          9.573107719421387,
          9.541626930236816,
          9.649015426635742,
          9.563030242919922,
          9.372588157653809,
          9.591983795166016,
          9.561197280883789,
          9.456902503967285,
          9.515774726867676
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "text": "D1",
          "x": -2.0085968911647796,
          "y": 5.878454826772213,
          "yshift": 10
         },
         {
          "showarrow": false,
          "text": "D2",
          "x": 6.8640509158372875,
          "xshift": 10,
          "y": 12.43206090927124
         }
        ],
        "height": 750,
        "legend": {
         "bordercolor": "Black",
         "borderwidth": 1
        },
        "shapes": [
         {
          "line": {
           "color": "#CFD8DC",
           "width": 2
          },
          "type": "line",
          "x0": 6.8640509158372875,
          "x1": 6.8640509158372875,
          "y0": -0.6751512557268142,
          "y1": 12.43206090927124
         },
         {
          "line": {
           "color": "#9E9E9E",
           "width": 2
          },
          "type": "line",
          "x0": -2.0085968911647796,
          "x1": 15.736698722839355,
          "y0": 5.878454826772213,
          "y1": 5.878454826772213
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.6
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(237,237,237)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(217,217,217)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 1,
            "tickcolor": "rgb(36,36,36)",
            "ticks": "outside"
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "rgb(103,0,31)"
            ],
            [
             0.1,
             "rgb(178,24,43)"
            ],
            [
             0.2,
             "rgb(214,96,77)"
            ],
            [
             0.3,
             "rgb(244,165,130)"
            ],
            [
             0.4,
             "rgb(253,219,199)"
            ],
            [
             0.5,
             "rgb(247,247,247)"
            ],
            [
             0.6,
             "rgb(209,229,240)"
            ],
            [
             0.7,
             "rgb(146,197,222)"
            ],
            [
             0.8,
             "rgb(67,147,195)"
            ],
            [
             0.9,
             "rgb(33,102,172)"
            ],
            [
             1,
             "rgb(5,48,97)"
            ]
           ],
           "sequential": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ]
          },
          "colorway": [
           "#1F77B4",
           "#FF7F0E",
           "#2CA02C",
           "#D62728",
           "#9467BD",
           "#8C564B",
           "#E377C2",
           "#7F7F7F",
           "#BCBD22",
           "#17BECF"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           }
          },
          "shapedefaults": {
           "fillcolor": "black",
           "line": {
            "width": 0
           },
           "opacity": 0.3
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "baxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          }
         }
        },
        "title": {
         "text": "Topic clusters (out of the box)"
        },
        "width": 1200,
        "xaxis": {
         "visible": false
        },
        "yaxis": {
         "visible": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize Topics\n",
    "fig = topic_model.visualize_documents(docs=docs)\n",
    "fig.update_layout(\n",
    "    title=\"Topic clusters (out of the box)\",\n",
    "    legend=dict(bordercolor=\"Black\", borderwidth=1),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train topic model using embeddings from BERT (pre-calculated)\n",
    "embeddings = np.array(list(df['BERTembeddings'].values))\n",
    "topic_model = BERTopic()\n",
    "topics, probs = topic_model.fit_transform(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>55</td>\n",
       "      <td>-1_the_and_of_to</td>\n",
       "      <td>[the, and, of, to, for, system, or, information, that, security]</td>\n",
       "      <td>[Product safety and security (pss). Guidelines and recommendations for cloud customers. Basic criterion: The cloud service provider provides cloud customers with guidelines and recommendations for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>0_and_the_of_to</td>\n",
       "      <td>[and, the, of, to, or, system, information, for, access, organizationdefined]</td>\n",
       "      <td>[Control and monitoring of service providers and suppliers (sso). Monitoring of compliance with requirements. Basic criterion: The cloud service provider monitors compliance with information secur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>1_the_of_and_to</td>\n",
       "      <td>[the, of, and, to, criterion, cloud, in, for, service, are]</td>\n",
       "      <td>[Security policies and instructions (sp). Exceptions from existing policies and instructions. Basic Criterion: Exceptions to the policies and instructions for information security, as well as resp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>2_and_the_or_procedures</td>\n",
       "      <td>[and, the, or, procedures, to, of, policy, organizationdefined, system, security]</td>\n",
       "      <td>[Risk assessment. Policy and procedures. A. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]: 1. [Selection (one or more): organization level; mission/bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>3_and_of_the_system</td>\n",
       "      <td>[and, of, the, system, to, or, information, systems, organizations, organizationdefined]</td>\n",
       "      <td>[System and communications protection. Protection of information at rest. Protect the confidentiality and integrity of the following information at rest: Organization-defined information at rest. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>4_and_the_system_of</td>\n",
       "      <td>[and, the, system, of, or, for, to, components, information, configuration]</td>\n",
       "      <td>[System and services acquisition. Acquisition process | design and implementation information for controls. Require the developer of the system, system component, or system service to provide desi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>5_and_the_of_to</td>\n",
       "      <td>[and, the, of, to, system, or, testing, for, assessment, organizations]</td>\n",
       "      <td>[Security assessment and authorization. Authorization. a. Assign a senior official as the authorizing official for the system. \\nb. Assign a senior official as the authorizing official for common ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>6_the_cloud_of_criterion</td>\n",
       "      <td>[the, cloud, of, criterion, service, is, to, in, for, and]</td>\n",
       "      <td>[Identity and access management (idm). Access to cloud customer data. Basic criterion: The cloud customer is informed by the cloud service provider whenever internal or external employees of the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>7_the_of_service_cloud</td>\n",
       "      <td>[the, of, service, cloud, criterion, and, in, are, to, provider]</td>\n",
       "      <td>[Control and monitoring of service providers and suppliers (sso). Risk assessment of service providers and suppliers. Basic criterion: Service providers and suppliers of the cloud service provider...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  ...                                                                                                                                                                                      Representative_Docs\n",
       "0     -1  ...  [Product safety and security (pss). Guidelines and recommendations for cloud customers. Basic criterion: The cloud service provider provides cloud customers with guidelines and recommendations for...\n",
       "1      0  ...  [Control and monitoring of service providers and suppliers (sso). Monitoring of compliance with requirements. Basic criterion: The cloud service provider monitors compliance with information secur...\n",
       "2      1  ...  [Security policies and instructions (sp). Exceptions from existing policies and instructions. Basic Criterion: Exceptions to the policies and instructions for information security, as well as resp...\n",
       "3      2  ...  [Risk assessment. Policy and procedures. A. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]: 1. [Selection (one or more): organization level; mission/bu...\n",
       "4      3  ...  [System and communications protection. Protection of information at rest. Protect the confidentiality and integrity of the following information at rest: Organization-defined information at rest. ...\n",
       "5      4  ...  [System and services acquisition. Acquisition process | design and implementation information for controls. Require the developer of the system, system component, or system service to provide desi...\n",
       "6      5  ...  [Security assessment and authorization. Authorization. a. Assign a senior official as the authorizing official for the system. \\nb. Assign a senior official as the authorizing official for common ...\n",
       "7      6  ...  [Identity and access management (idm). Access to cloud customer data. Basic criterion: The cloud customer is informed by the cloud service provider whenever internal or external employees of the c...\n",
       "8      7  ...  [Control and monitoring of service providers and suppliers (sso). Risk assessment of service providers and suppliers. Basic criterion: Service providers and suppliers of the cloud service provider...\n",
       "\n",
       "[9 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show summary of topics\n",
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "text",
         "hovertext": [
          "Configuration management. Configuration settings | automated management, application, and verification. Manage, apply, and verify configuration settings for [assignment: organization-defined system components] using [assignment: organization-defined automated mechanisms]. Automated tools (e.g., hardening tools, baseline configuration tools) can improve the accuracy, consistency, and availability of configuration settings information. Automation can also provide data aggregation and data correlation capabilities, alerting mechanisms, and dashboards to support risk-based decision-making within the organization.",
          "Planning. System security and privacy plans. a. Develop security and privacy plans for the system that: \n1. Are consistent with the organization's enterprise architecture.\n2. Explicitly define the constituent system components.\n3. Describe the operational context of the system in terms of mission and business processes.\n4. Identify the individuals that fulfill system roles and responsibilities.\n5. Identify the information types processed, stored, and transmitted by the system.\n6. Provide the security categorization of the system, including supporting rationale.\n7. Describe any specific threats to the system that are of concern to the organization.\n8. Provide the results of a privacy risk assessment for systems processing personally identifiable information.\n9. Describe the operational environment for the system and any dependencies on or connections to other systems or system components.\n10. Provide an overview of the security and privacy requirements for the system.\n11. Identify any relevant control baselines or overlays, if applicable.\n12. Describe the controls in place or planned for meeting the security and privacy requirements, including a rationale for any tailoring decisions.\n13. Include risk determinations for security and privacy architecture and design decisions.\n14. Include security- and privacy-related activities affecting the system that require planning and coordination with [assignment: organization-defined individuals or groups].\n15. Are reviewed and approved by the authorizing official or designated representative prior to plan implementation.\n\nb. Distribute copies of the plans and communicate subsequent changes to the plans to [assignment: organization-defined personnel or roles].\nc. Review the plans [assignment: organization-defined frequency].\nd. Update the plans to address changes to the system and environment of operation or problems identified during plan implementation or control assessments.\ne. Protect the plans from unauthorized disclosure and modification.\n\nSystem security and privacy plans are scoped to the system and system components within the defined authorization boundary and contain an overview of the security and privacy requirements for the system and the controls selected to satisfy the requirements. The plans describe the intended application of each selected control in the context of the system with a sufficient level of detail to correctly implement the control and to subsequently assess the effectiveness of the control. The control documentation describes how system-specific and hybrid controls are implemented and the plans and expectations regarding the functionality of the system. System security and privacy plans can also be used in the design and development of systems in support of life cycle-based security and privacy engineering processes. System security and privacy plans are living documents that are updated and adapted throughout the system development life cycle (e.g., during capability determination, analysis of alternatives, requests for proposal, and design reviews). \n\nSection 2.1 describes the different types of requirements that are relevant to organizations during the system development life cycle and the relationship between requirements and controls. Organizations may develop a single, integrated security and privacy plan or maintain separate plans. Security and privacy plans relate security and privacy requirements to a set of controls and control enhancements. The plans describe how the controls and control enhancements meet the security and privacy requirements but do not provide detailed, technical descriptions of the design or implementation of the controls and control enhancements. Security and privacy plans contain sufficient information (including specifications of control parameter values for selection and assignment operations explicitly or by reference) to enable a design and implementation that is unambiguously compliant with the intent of the plans and subsequent determinations of risk to organizational operations and assets, individuals, other organizations, and the nation if the plan is implemented. Security and privacy plans need not be single documents. The plans can be a collection of various documents, including documents that already exist. Effective security and privacy plans make extensive use of references to policies, procedures, and additional documents, including design and implementation specifications where more detailed information can be obtained. The use of references helps reduce the documentation associated with security and privacy programs and maintains the security- and privacy-related information in other established management and operational areas, including enterprise architecture, system development life cycle, systems engineering, and acquisition. Security and privacy plans need not contain detailed contingency plan or incident response plan information but can instead provide—explicitly or by reference—sufficient information to define what needs to be accomplished by those plans. Security- and privacy-related activities that may require coordination and planning with other individuals or groups within the organization include assessments, audits, inspections, hardware and software maintenance, acquisition and supply chain risk management, patch management, and contingency plan testing. Planning and coordination include emergency and nonemergency (i.e., planned or non-urgent unplanned) situations. The process defined by organizations to plan and coordinate security- and privacy-related activities can also be included in other documents, as appropriate.",
          "Access control. Use of external systems. a. [Selection (one or more): Establish [assignment: organization-defined terms and conditions]; Identify [assignment: organization-defined controls asserted to be implemented on external systems]], consistent with the trust relationships established with other organizations owning, operating, and/or maintaining external systems, allowing authorized individuals to: 1. access the system from external systems; and 2. process, store, or transmit organization-controlled information using external systems; or b. Prohibit the use of [assignment: organizationally-defined types of external systems]. External systems are systems that are used by but not part of organizational systems, and for which the organization has no direct control over the implementation of required controls or the assessment of control effectiveness. External systems include personally owned systems, components, or devices; privately-owned computing and communications devices in commercial or public facilities; systems owned or controlled by nonfederal organizations; systems managed by contractors; and federal information systems that are not owned by, operated by, or under the direct supervision or authority of the organization. External systems also include systems owned or operated by other components within the same organization and systems within the organization with different authorization boundaries. Organizations have the option to prohibit the use of any type of external system or prohibit the use of specified types of external systems (e.g., prohibit the use of any external system that is not organizationally owned or prohibit the use of personally-owned systems). For some external systems (i.e., systems operated by other organizations), the trust relationships that have been established between those organizations and the originating organization may be such that no explicit terms and conditions are required. Systems within these organizations may not be considered external. These situations occur when, for example, there are pre-existing information exchange agreements (either implicit or explicit) established between organizations or components or when such agreements are specified by applicable laws, executive orders, directives, regulations, policies, or standards. Authorized individuals include organizational personnel, contractors, or other individuals with authorized access to organizational systems and over which organizations have the authority to impose specific rules of behavior regarding system access. Restrictions that organizations impose on authorized individuals need not be uniform, as the restrictions may vary depending on trust relationships between organizations. Therefore, organizations may choose to impose different security restrictions on contractors than on state, local, or tribal governments. External systems used to access public interfaces to organizational systems are outside the scope of AC-20. Organizations establish specific terms and conditions for the use of external systems in accordance with organizational security policies and procedures. At a minimum, terms and conditions address the specific types of applications that can be accessed on organizational systems from external systems and the highest security category of information that can be processed, stored, or transmitted on external systems. If the terms and conditions with the owners of the external systems cannot be established, organizations may impose restrictions on organizational personnel using those external systems.",
          "Personnel security. Position risk designation. a. Assign a risk designation to all organizational positions. \nb. Establish screening criteria for individuals filling those positions. \nc. Review and update position risk designations [assignment: organization-defined frequency]. \n\nPosition risk designations reflect Office of Personnel Management (OPM) policy and guidance. Proper position designation is the foundation of an effective and consistent suitability and personnel security program. The Position Designation System (PDS) assesses the duties and responsibilities of a position to determine the degree of potential damage to the efficiency or integrity of the service due to misconduct of an incumbent of a position and establishes the risk level of that position. \n\nThe PDS assessment also determines if the duties and responsibilities of the position present the potential for position incumbents to bring about a material adverse effect on national security and the degree of that potential effect, which establishes the sensitivity level of a position. The results of the assessment determine what level of investigation is conducted for a position. \n\nRisk designations can guide and inform the types of authorizations that individuals receive when accessing organizational information and information systems. Position screening criteria include explicit information security role appointment requirements. \n\nParts 1400 and 731 of Title 5, Code of Federal Regulations, establish the requirements for organizations to evaluate relevant covered positions for a position sensitivity and position risk designation commensurate with the duties and responsibilities of those positions.",
          "Operations (ops). Data backup and recovery – monitoring. Basic criterion: The execution of data backups is monitored by technical and organizational measures. Malfunctions are investigated by qualified staff and rectified promptly to ensure compliance with contractual obligations to cloud customers or the cloud service provider's business requirements regarding the scope and frequency of data backup and the duration of storage.\n\nAdditional criterion: The relevant logs or summarized results are available to the cloud customer in a self-service portal for monitoring the data backup.\n\nSupplementary information about the criterion: If the data backup is not part of the contract concluded between the cloud service provider and the cloud customer, this criterion is not applicable. The cloud service provider must present this situation transparently in the system description.\n\nComplementary customer criterion: Cloud customers ensure, through suitable controls, that the backup of data within their area of responsibility is monitored by technical and organizational measures.\n\nNotes on continuous auditing feasibility: Yes, the execution of different data backups can be performed by continuously auditing the log files and the associated results of the data backup. Any errors in the data backup would be continuously detected and could be explained by appropriate measures and documentation in the audit.",
          "Configuration management. System component inventory | updates during installation and removal. Update the inventory of system components as part of component installations, removals, and system updates. Organizations can improve the accuracy, completeness, and consistency of system component inventories if the inventories are updated as part of component installations or removals or during general system updates. If inventories are not updated at these key times, there is a greater likelihood that the information will not be appropriately captured and documented. System updates include hardware, software, and firmware components.",
          "Contingency planning. Alternate processing site | separation from primary site. Identify an alternate processing site that is sufficiently separated from the primary processing site to reduce susceptibility to the same threats. Threats that affect alternate processing sites are defined in organizational assessments of risk and include natural disasters, structural failures, hostile attacks, and errors of omission or commission. Organizations determine what is considered a sufficient degree of separation between primary and alternate processing sites based on the types of threats that are of concern. For threats such as hostile attacks, the degree of separation between sites is less relevant.",
          "Risk assessment. Risk response. Respond to findings from security and privacy assessments, monitoring, and audits in accordance with organizational risk tolerance. Organizations have many options for responding to risk, including mitigating risk by implementing new controls or strengthening existing controls, accepting risk with appropriate justification or rationale, sharing or transferring risk, or avoiding risk. The risk tolerance of the organization influences risk response decisions and actions. Risk response addresses the need to determine an appropriate response to risk before generating a Plan of Action and Milestones (POA&M) entry. For example, the response may be to accept risk or reject risk, or it may be possible to mitigate the risk immediately so that a POA&M entry is not needed. However, if the risk response is to mitigate the risk and the mitigation cannot be completed immediately, a POA&M entry is generated.",
          "Incident response. Information spillage response. Respond to information spills by:\n\na. Assigning [assignment: organization-defined personnel or roles] with responsibility for responding to information spills.\nb. Identifying the specific information involved in the system contamination.\nc. Alerting [assignment: organization-defined personnel or roles] of the information spill using a method of communication not associated with the spill.\nd. Isolating the contaminated system or system component.\ne. Eradicating the information from the contaminated system or component.\nf. Identifying other systems or system components that may have been subsequently contaminated.\ng. Performing the following additional actions: [assignment: organization-defined actions].\n\nInformation spillage refers to instances where information is placed on systems that are not authorized to process such information. Information spills occur when information that is thought to be of a certain classification or impact level is transmitted to a system and subsequently determined to be of a higher classification or impact level. At that point, corrective action is required. \n\nThe nature of the response is based on the classification or impact level of the spilled information, the security capabilities of the system, the specific nature of the contaminated storage media, and the access authorizations of individuals with authorized access to the contaminated system. \n\nThe methods used to communicate information about the spill after the fact do not involve methods directly associated with the actual spill to minimize the risk of further spreading the contamination before such contamination is isolated and eradicated.",
          "Organisation of information security (ois). Interfaces and dependencies. Basic criterion: Interfaces and dependencies between cloud service delivery activities performed by the cloud service provider and activities performed by third parties are documented and communicated. This includes dealing with the following events: vulnerabilities, security incidents, and malfunctions. The type and scope of the documentation is geared towards the information requirements of the subject matter experts of the affected organizations in order to carry out the activities appropriately (e.g., definition of roles and responsibilities in guidelines, description of cooperation obligations in service descriptions and contracts). The communication of changes to the interfaces and dependencies takes place in a timely manner so that the affected organizations and third parties can react appropriately with organizational and technical measures before the changes take effect.\n\nAdditional criterion: Supplementary information about the criterion. The cloud service provider can define and document the interfaces and dependencies described in the basic criterion in guidelines and instructions. For example, cloud customers’ obligations to cooperate should be described in service descriptions and contracts. \n\nThird parties in the sense of this basic criterion are, e.g., cloud customers and sub-service providers.\n\nComplementary customer criterion: Cloud customers ensure through suitable controls that the guidelines and requirements for compliance with the contractual agreements with the cloud service provider (i.e., responsibilities, cooperation obligations, and interfaces for reporting security incidents) are adequately defined, documented, and set up.\n\nNotes on continuous auditing feasibility: No, an automated continuous audit for critical dependencies and interfaces is currently only possible at a high cost to the cloud service provider.",
          "System and communications protection. Secure name/address resolution service (authoritative source). A. Provide additional data origin authentication and integrity verification artifacts along with the authoritative name resolution data the system returns in response to external name/address resolution queries. \nB. Provide the means to indicate the security status of child zones and, if the child supports secure resolution services, enable verification of a chain of trust among parent and child domains when operating as part of a distributed, hierarchical namespace. Providing authoritative source information enables external clients, including remote internet clients, to obtain origin authentication and integrity verification assurances for the host/service name to network address resolution information obtained through the service. Systems that provide name and address resolution services include Domain Name System (DNS) servers. Additional artifacts include DNS Security Extensions (DNSSEC) digital signatures and cryptographic keys. Authoritative data includes DNS resource records. The means for indicating the security status of child zones include the use of delegation signer resource records in the DNS. Systems that use technologies other than the DNS to map between host and service names and network addresses provide other means to assure the authenticity and integrity of response data.",
          "System and communications protection. Transmission confidentiality and integrity | cryptographic protection. Implement cryptographic mechanisms to prevent unauthorized disclosure of information during transmission. \nEncryption protects information from unauthorized disclosure and modification during transmission. \nCryptographic mechanisms that protect the confidentiality and integrity of information during transmission include TLS and IPsec. \nCryptographic mechanisms used to protect information integrity include cryptographic hash functions that have applications in digital signatures, checksums, and message authentication codes.",
          "Configuration management. Baseline configuration | automation support for accuracy and currency. Maintain the currency, completeness, accuracy, and availability of the baseline configuration of the system using [assignment: organization-defined automated mechanisms]. Automated mechanisms that help organizations maintain consistent baseline configurations for systems include configuration management tools, hardware, software, firmware inventory tools, and network management tools. Automated tools can be used at the organization level, mission and business process level, or system level on workstations, servers, notebook computers, network components, or mobile devices. Tools can be used to track version numbers on operating systems, applications, types of software installed, and current patch levels. Automation support for accuracy and currency can be satisfied by the implementation of CM-8 (2) for organizations that combine system component inventory and baseline configuration activities.",
          "Personnel (hr). Security training and awareness programme. Basic criterion: The cloud service provider operates a target group-oriented security awareness and training program, which is completed by all internal and external employees of the cloud service provider on a regular basis. The program is regularly updated based on changes to policies and instructions and the current threat situation and includes the following aspects: handling system components used to provide the cloud service in the production environment in accordance with applicable policies and procedures; handling cloud customer data in accordance with applicable policies and instructions and applicable legal and regulatory requirements; information about the current threat situation; and correct behavior in the event of security incidents. \n\nAdditional criterion: The learning outcomes achieved through the awareness and training program are measured and evaluated in a target group-oriented manner. The measurements cover quantitative and qualitative aspects. The results are used to improve the awareness and training program. \n\nSupplementary information about the criterion: \n\nComplementary customer criterion: Notes on continuous auditing \n\nFeasibility: Yes, the concept behind the security awareness and training program does not require continuous assessment and is sufficiently covered by the recurring audit. However, the completion of the training can be traced via training portals. For a continuous audit that each employee has completed and, if necessary, repeated the relevant training courses for his role description, a clear system-based definition of the necessary training courses for each role description must be carried out at the cloud service provider. The expected dates which the respective training course is to be completed must also be recorded. The documentation that the training has been completed by the employee and, if necessary, successfully completed with an examination, should take place in the same portal. The auditor then has the option of examining the results of the training courses for employees of the cloud service provider for deviations by automatically and continuously comparing the expected training dates with the actual date on which the employees completed the training.",
          "Awareness and training. Literacy training and awareness | social engineering and mining. Provide literacy training on recognizing and reporting potential and actual instances of social engineering and social mining. Social engineering is an attempt to trick an individual into revealing information or taking an action that can be used to breach, compromise, or otherwise adversely impact a system. Social engineering includes phishing, pretexting, impersonation, baiting, quid pro quo, thread-jacking, social media exploitation, and tailgating. Social mining is an attempt to gather information about the organization that may be used to support future attacks. Literacy training includes information on how to communicate the concerns of employees and management regarding potential and actual instances of social engineering and data mining through organizational channels based on established policies and procedures.",
          "System and information integrity. System monitoring | visibility of encrypted communications. Make provisions so that [assignment: organization-defined encrypted communications traffic] is visible to [assignment: organization-defined system monitoring tools and mechanisms]. Organizations balance the need to encrypt communications traffic to protect data confidentiality with the need to maintain visibility into such traffic from a monitoring perspective. Organizations determine whether the visibility requirement applies to internal encrypted traffic, encrypted traffic intended for external destinations, or a subset of the traffic types.",
          "Access control. Account management | usage conditions. Enforce [assignment: organization-defined circumstances and/or usage conditions] for [assignment: organization-defined system accounts]. Specifying and enforcing usage conditions helps to enforce the principle of least privilege, increase user accountability, and enable effective account monitoring. Account monitoring includes alerts generated if the account is used in violation of organizational parameters. Organizations can describe specific conditions or circumstances under which system accounts can be used, such as by restricting usage to certain days of the week, time of day, or specific durations of time.",
          "Identification and authentication. Authenticator management. Manage system authenticators by:\n\na. Verifying, as part of the initial authenticator distribution, the identity of the individual, group, role, service, or device receiving the authenticator.\n\nb. Establishing initial authenticator content for any authenticators issued by the organization.\n\nc. Ensuring that authenticators have sufficient strength of mechanism for their intended use.\n\nd. Establishing and implementing administrative procedures for initial authenticator distribution, for lost or compromised or damaged authenticators, and for revoking authenticators.\n\ne. Changing default authenticators prior to first use.\n\nf. Changing or refreshing authenticators [assignment: organization-defined time period by authenticator type] or when [assignment: organization-defined events] occur.\n\ng. Protecting authenticator content from unauthorized disclosure and modification.\n\nh. Requiring individuals to take, and having devices implement, specific controls to protect authenticators.\n\ni. Changing authenticators for group or role accounts when membership to those accounts changes.\n\nAuthenticators include passwords, cryptographic devices, biometrics, certificates, one-time password devices, and ID badges. Device authenticators include certificates and passwords.\n\nInitial authenticator content is the actual content of the authenticator (e.g., the initial password). In contrast, the requirements for authenticator content contain specific criteria or characteristics (e.g., minimum password length).\n\nDevelopers may deliver system components with factory default authentication credentials (i.e., passwords) to allow for initial installation and configuration. Default authentication credentials are often well-known, easily discoverable, and present a significant risk.\n\nThe requirement to protect individual authenticators may be implemented via control PL-4 or PS-6 for authenticators in the possession of individuals and by controls AC-3, AC-6, and SC-28 for authenticators stored in organizational systems, including passwords stored in hashed or encrypted formats or files containing encrypted or hashed passwords accessible with administrator privileges.\n\nSystems support authenticator management by organization-defined settings and restrictions for various authenticator characteristics (e.g., minimum password length, validation time window for time synchronous one-time tokens, and number of allowed rejections during the verification stage of biometric authentication).\n\nActions can be taken to safeguard individual authenticators, including maintaining possession of authenticators, not sharing authenticators with others, and immediately reporting lost, stolen, or compromised authenticators.\n\nAuthenticator management includes issuing and revoking authenticators for temporary access when no longer needed.",
          "Audit and accountability. Audit record review, analysis, and reporting | correlation with physical monitoring. Correlate information from audit records with information obtained from monitoring physical access to further enhance the ability to identify suspicious, inappropriate, unusual, or malevolent activity. The correlation of physical audit record information and the audit records from systems may assist organizations in identifying suspicious behavior or supporting evidence of such behavior. For example, the correlation of an individual's identity for logical access to certain systems with the additional physical security information that the individual was present at the facility when the logical access occurred may be useful in investigations.",
          "Access control. Least privilege. Employ the principle of least privilege, allowing only authorized accesses for users (or processes acting on behalf of users) that are necessary to accomplish assigned organizational tasks. Organizations employ least privilege for specific duties and systems. The principle of least privilege is also applied to system processes, ensuring that the processes have access to systems and operate at privilege levels no higher than necessary to accomplish organizational missions or business functions. Organizations consider the creation of additional processes, roles, and accounts as necessary to achieve least privilege. Organizations apply least privilege to the development, implementation, and operation of organizational systems.",
          "Physical and environmental protection. Visitor access records. a. Maintain visitor access records to the facility where the system resides for [assignment: organization- defined time period].\nb. Review visitor access records [assignment: organization-defined frequency].\nc. Report anomalies in visitor access records to [assignment: organization-defined personnel].\n\nVisitor access records include the names and organizations of individuals visiting, visitor signatures, forms of identification, dates of access, entry and departure times, purpose of visits, and the names and organizations of individuals visited. \n\nAccess record reviews determine if access authorizations are current and are still required to support the organizational mission and business functions. Access records are not required for publicly accessible areas.",
          "Identification and authentication. Identity proofing. a. Identity proof users that require accounts for logical access to systems, based on appropriate identity assurance level requirements as specified in applicable standards and guidelines. \nb. Resolve user identities to a unique individual. \nc. Collect, validate, and verify identity evidence. \n\nIdentity proofing is the process of collecting, validating, and verifying a user’s identity information for the purposes of establishing credentials for accessing a system. Identity proofing is intended to mitigate threats to the registration of users and the establishment of their accounts. \n\nStandards and guidelines specifying identity assurance levels for identity proofing include SP 800-63-3 and SP 800-63a. Organizations may be subject to laws, executive orders, directives, regulations, or policies that address the collection of identity evidence. \n\nOrganizational personnel consult with the senior agency official for privacy and legal counsel regarding such requirements.",
          "Product safety and security (pss). Guidelines and recommendations for cloud customers. Basic criterion: The cloud service provider provides cloud customers with guidelines and recommendations for the secure use of the cloud service provided. The information contained therein is intended to assist the cloud customer in the secure configuration, installation, and use of the cloud service, to the extent applicable to the cloud service and the responsibility of the cloud user. The type and scope of the information provided will be based on the needs of subject matter experts of the cloud customers who set information security requirements, implement them, or verify the implementation (e.g. IT, compliance, internal audit). The information in the guidelines and recommendations for the secure use of the cloud service addresses the following aspects, where applicable to the cloud service: instructions for secure configuration; information sources on known vulnerabilities and update mechanisms; error handling and logging mechanisms; authentication mechanisms; roles and rights concept including combinations that result in an elevated risk; and services and functions for administration of the cloud service by privileged users. The information is maintained so that it is applicable to the cloud service provided in the version intended for productive use.\n\nAdditional criterion: Supplementary information about the criterion complementary customer criterion cloud customers ensure through suitable controls that the cloud service provider's information is used to derive policies, concepts, and measures for the secure configuration and use (according to their own risk assessment) of the cloud service. Compliance with these policies, concepts, and measures is checked. Changes to the information are promptly assessed for their impact on these documents, and any necessary changes are implemented.\n\nNotes on continuous auditing feasibility: Partially, the provision of information from the cloud service provider to cloud customers can only be audited continuously to a limited extent. For example, the cloud service provider can make the guidelines and recommendations available via its internal customer portal, which makes continuous audit only partially effective. Here, only an audit for completeness and the last modification date is conceivable, although a discussion of the content of the changes is not effective. For this, a semantic evaluation would be necessary.",
          "Audit and accountability. Audit record review, analysis, and reporting | permitted actions. Specify the permitted actions for each [selection (one or more): system process; role; user] associated with the review, analysis, and reporting of audit record information. Organizations specify permitted actions for system processes, roles, and users associated with the review, analysis, and reporting of audit records through system account management activities. Specifying permitted actions on audit record information is a way to enforce the principle of least privilege. Permitted actions are enforced by the system and include read, write, execute, append, and delete.",
          "Risk assessment. Security categorization. a. Categorize the system and information it processes, stores, and transmits.\nb. Document the security categorization results, including supporting rationale, in the security plan for the system.\nc. Verify that the authorizing official or the authorizing official designated representative reviews and approves the security categorization decision.\nSecurity categories describe the potential adverse impacts or negative consequences to organizational operations, organizational assets, and individuals if organizational information and systems are compromised through a loss of confidentiality, integrity, or availability. Security categorization is also a type of asset loss characterization in systems security engineering processes that is carried out throughout the system development life cycle. Organizations can use privacy risk assessments or privacy impact assessments to better understand the potential adverse effects on individuals. CNSSI 1253 provides additional guidance on categorization for national security systems.\nOrganizations conduct the security categorization process as an organization-wide activity with the direct involvement of Chief Information Officers, Senior Agency Information Security Officers, Senior Agency Officials for Privacy, system owners, mission and business owners, and information owners or stewards. Organizations consider the potential adverse impacts to other organizations and, in accordance with USA PATRIOT and Homeland Security Presidential Directives, potential national-level adverse impacts.\nSecurity categorization processes facilitate the development of inventories of information assets and, along with CM-8, mappings to specific system components where information is processed, stored, or transmitted. The security categorization process is revisited throughout the system development life cycle to ensure that the security categories remain accurate and relevant.",
          "System and information integrity. Spam protection. a. Employ spam protection mechanisms at system entry and exit points to detect and act on unsolicited messages; and b. Update spam protection mechanisms when new releases are available in accordance with organizational configuration management policy and procedures. \n\nSystem entry and exit points include firewalls, remote-access servers, electronic mail servers, web servers, proxy servers, workstations, notebook computers, and mobile devices. Spam can be transported by different means, including email, email attachments, and web accesses. \n\nSpam protection mechanisms include signature definitions.",
          "Physical and environmental protection. Emergency shutoff. a. Provide the capability of shutting off power to [assignment: organization-defined system or individual system components] in emergency situations. \nb. Place emergency shutoff switches or devices in [assignment: organization-defined location by system or system component] to facilitate access for authorized personnel. \nc. Protect emergency power shutoff capability from unauthorized activation. \n\nEmergency power shutoff primarily applies to organizational facilities that contain concentrations of system resources, including data centers, mainframe computer rooms, server rooms, and areas with computer-controlled machinery.",
          "Procurement, development and modification of information systems (dev). Approvals for provision in the production environment. Basic criterion: Authorized personnel or system components of the cloud service provider approve changes to the cloud service based on defined criteria (e.g. test results and required approvals) before these are made available to the cloud customers in the production environment. Cloud customers are involved in the release according to contractual requirements.\n\nAdditional criterion: Supplementary information about the criterion, the definitions for criterion dev-03 apply.\n\nComplementary customer criterion: Where changes are to be approved by the cloud customers in accordance with the contractual agreements before they are made available in the production environment, the cloud customers ensure through suitable controls that authorized and qualified personnel receive the information made available, assess the impact on the ISMS framework, and decide on the approval in accordance with the conditions specified by the cloud service provider.\n\nNotes on continuous auditing feasibility: Yes, verification that all tests have been completed, successfully, and approved by an authorized body can be automated by the cloud service provider and documented in logs. These logs can then be evaluated automatically and continuously by the auditor.",
          "Physical and environmental protection. Monitoring physical access. a. Monitor physical access to the facility where the system resides to detect and respond to physical security incidents. \nb. Review physical access logs [assignment: organization-defined frequency] and upon occurrence of [assignment: organization-defined events or potential indications of events].\nc. Coordinate results of reviews and investigations with the organizational incident response capability.\n\nPhysical access monitoring includes publicly accessible areas within organizational facilities. Examples of physical access monitoring include the employment of guards, video surveillance equipment (i.e., cameras), and sensor devices. \n\nReviewing physical access logs can help identify suspicious activity, anomalous events, or potential threats. The reviews can be supported by audit logging controls, such as AU-2, if the access logs are part of an automated system.\n\nOrganizational incident response capabilities include investigations of physical security incidents and responses to the incidents. Incidents include security violations or suspicious physical access activities. Suspicious physical access activities include accesses outside of normal work hours, repeated accesses to areas not normally accessed, accesses for unusual lengths of time, and out-of-sequence accesses.",
          "Control and monitoring of service providers and suppliers (sso). Policies and instructions for controlling and monitoring third parties. Basic criterion: Policies and instructions for controlling and monitoring third parties (e.g. service providers or suppliers) whose services contribute to the provision of the cloud service are documented, communicated, and provided in accordance with SP-01 with respect to the following aspects:\n\n- Requirements for the assessment of risks resulting from the procurement of third-party services\n- Requirements for the classification of third parties based on the risk assessment by the cloud service provider and the determination of whether the third party is a subcontractor (cf. supplementary information)\n- Information security requirements for the processing, storage, or transmission of information by third parties based on recognized industry standards\n- Information security awareness and training requirements for staff\n- Applicable legal and regulatory requirements\n- Requirements for dealing with vulnerabilities, security incidents, and malfunctions\n- Specifications for the contractual agreement of these requirements\n- Specifications for the monitoring of these requirements\n- Specifications for applying these requirements also to service providers used by the third parties, insofar as the services provided by these service providers also contribute to the provision of the cloud service.\n\nAdditional criterion: Subservice organizations of the cloud service provider are contractually obliged to provide regular reports by independent auditors on the suitability of the design and operating effectiveness of their service-related internal control system. The reports include the complementary subservice organizations that are required, together with the controls of the cloud service provider, to meet the applicable basic criteria of BSI C5 with reasonable assurance. In case no reports can be provided, the cloud service provider agrees to appropriate information and audit rights to assess the suitability and effectiveness of the service-related internal control system, including the complementary controls, by qualified personnel.\n\nSupplementary information about the criterion: Reports by independent auditors on the suitability of the design and operating effectiveness of their service-related internal control system are, for example, attestation reports in accordance with ISAE 3402, IDW PS 951, SOC 2, or BSI C5. Qualified personnel works, for example, in the cloud service provider's internal audit department or is commissioned by the cloud service provider in the form of expert third parties, such as audit firms, and may hold relevant certifications such as \"Certified Internal Auditor (CIA)\". The complementary controls at the subservice provider are necessary in order to, together with the controls of the cloud service provider, fulfill the applicable C5 criteria with reasonable assurance. Applicable legal and regulatory requirements may exist, for example, in the areas of data protection, intellectual property rights, or copyright. If legal or regulatory requirements provide for a regulation deviating from these criteria for the control of subcontractors, these regulations remain unaffected by the C5 criteria.\n\nComplementary customer criterion notes on continuous auditing feasibility: Partially regarding the availability of the documentation, a continuous audit is not practical since the associated processes and steps can be tested in a recurring audit. A continuous audit of whether changes have been made to the policies is possible, provided that these changes are documented by the cloud service provider and can be evaluated. However, an automated audit of the meaningfulness of the changes is difficult to implement. Regarding the proof that a communication/provision has taken place, a continuous audit is considered possible. For this, the cloud service provider would have to realize the notification based on a system (e.g. based on tickets or notes in the respective service provider contract).",
          "System and information integrity. System monitoring | wireless intrusion detection. Employ a wireless intrusion detection system to identify rogue wireless devices and to detect attack attempts and potential compromises or breaches to the system. Wireless signals may radiate beyond organizational facilities. Organizations proactively search for unauthorized wireless connections, including the conduct of thorough scans for unauthorized wireless access points. Wireless scans are not limited to those areas within facilities containing systems but also include areas outside of facilities to verify that unauthorized wireless access points are not connected to organizational systems.",
          "Awareness and training. Role-based training. a. Provide role-based security and privacy training to personnel with the following roles and responsibilities: [assignment: organization-defined roles and responsibilities]. 1. Before authorizing access to the system, information, or performing assigned duties, and [assignment: organization-defined frequency] thereafter. 2. When required by system changes.\nb. Update role-based training content [assignment: organization-defined frequency] and following [assignment: organization-defined events].\nc. Incorporate lessons learned from internal or external security incidents or breaches into role-based training. \nOrganizations determine the content of training based on the assigned roles and responsibilities of individuals as well as the security and privacy requirements of organizations and the systems to which personnel have authorized access, including technical training specifically tailored for assigned duties. Roles that may require role-based training include senior leaders or management officials (e.g., head of agency/chief executive officer, chief information officer, senior accountable official for risk management, senior agency information security officer, senior agency official for privacy), system owners, authorizing officials, system security officers, privacy officers, acquisition and procurement officials, enterprise architects, systems engineers, software developers, systems security engineers, privacy engineers, system, network, and database administrators, auditors, personnel conducting configuration management activities, personnel performing verification and validation activities, personnel with access to system-level software, control assessors, personnel with contingency planning and incident response duties, personnel with privacy management responsibilities, and personnel with access to personally identifiable information. \nComprehensive role-based training addresses management, operational, and technical roles and responsibilities covering physical, personnel, and technical controls. Role-based training also includes policies, procedures, tools, methods, and artifacts for the security and privacy roles defined. Organizations provide the training necessary for individuals to fulfill their responsibilities related to operations and supply chain risk management within the context of organizational security and privacy programs. Role-based training also applies to contractors who provide services to federal agencies. Types of training include web-based and computer-based training, classroom-style training, and hands-on training (including micro-training). Updating role-based training on a regular basis helps to ensure that the content remains relevant and effective. Events that may precipitate an update to role-based training content include, but are not limited to, assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines.",
          "Identification and authentication. Identity proofing | address confirmation. Require that a [selection: registration code. Notice of proofing] be delivered through an out-of-band channel to verify the user's address (physical or digital) of record. To make it more difficult for adversaries to pose as legitimate users during the identity proofing process, organizations can use out-of-band methods to ensure that the individual associated with an address of record is the same individual that participated in the registration. Confirmation can take the form of a temporary enrollment code or a notice of proofing. The delivery address for these artifacts is obtained from records and not self-asserted by the user. The address can include a physical or digital address. A home address is an example of a physical address. Email addresses and telephone numbers are examples of digital addresses.",
          "Access control. Account management. a. Define and document the types of accounts allowed and specifically prohibited for use within the system. \nb. Assign account managers. \nc. Require [assignment: organization-defined prerequisites and criteria] for group and role membership. \nd. Specify: 1. Authorized users of the system. 2. Group and role membership. 3. Access authorizations (i.e., privileges) and [assignment: organization-defined attributes (as required)] for each account. \ne. Require approvals by [assignment: organization-defined personnel or roles] for requests to create accounts. \nf. Create, enable, modify, disable, and remove accounts in accordance with [assignment: organization-defined policy, procedures, prerequisites, and criteria]. \ng. Monitor the use of accounts. \nh. Notify account managers and [assignment: organization-defined personnel or roles] within: 1. [assignment: organization-defined time period] when accounts are no longer required. 2. [assignment: organization-defined time period] when users are terminated or transferred. 3. [assignment: organization-defined time period] when system usage or need-to-know changes for an individual. \ni. Authorize access to the system based on: 1. A valid access authorization. 2. Intended system usage. 3. [assignment: organization-defined attributes (as required)]. \nj. Review accounts for compliance with account management requirements [assignment: organization-defined frequency]. \nk. Establish and implement a process for changing shared or group account authenticators (if deployed) when individuals are removed from the group. \nl. Align account management processes with personnel termination and transfer processes. \n\nExamples of system account types include individual, shared, group, system, guest, anonymous, emergency, developer, temporary, and service. Identification of authorized system users and the specification of access privileges reflect the requirements in other controls in the security plan. Users requiring administrative privileges on system accounts receive additional scrutiny by organizational personnel responsible for approving such accounts and privileged access, including system owner, mission or business owner, senior agency information security officer, or senior agency official for privacy. \n\nTypes of accounts that organizations may wish to prohibit due to increased risk include shared, group, emergency, anonymous, temporary, and guest accounts. Where access involves personally identifiable information, security programs collaborate with the senior agency official for privacy to establish the specific conditions for group and role membership, specify authorized users, group and role membership, and access authorizations for each account, and create, adjust, or remove system accounts in accordance with organizational policies. Policies can include such information as account expiration dates or other factors that trigger the disabling of accounts. Organizations may choose to define access privileges or other attributes by account, type of account, or a combination of the two. Examples of other attributes required for authorizing access include restrictions on time of day, day of week, and point of origin. In defining other system account attributes, organizations consider system-related requirements and mission/business requirements. Failure to consider these factors could affect system availability. \n\nTemporary and emergency accounts are intended for short-term use. Organizations establish temporary accounts as part of normal account activation procedures when there is a need for short-term accounts without the demand for immediacy in account activation. Organizations establish emergency accounts in response to crisis situations and with the need for rapid account activation. Therefore, emergency account activation may bypass normal account authorization processes. Emergency and temporary accounts are not to be confused with infrequently used accounts, including local logon accounts used for special tasks or when network resources are unavailable (may also be known as accounts of last resort). Such accounts remain available and are not subject to automatic disabling or removal dates. Conditions for disabling or deactivating accounts include when shared/group, emergency, or temporary accounts are no longer required and when individuals are transferred or terminated. Changing shared/group authenticators when members leave the group is intended to ensure that former group members do not retain access to the shared or group account. Some types of system accounts may require specialized training.",
          "Access control. Account management | account monitoring for atypical usage. (a) Monitor system accounts for [assignment: organization-defined atypical usage]; and (b) report atypical usage of system accounts to [assignment: organization-defined personnel or roles]. Atypical usage includes accessing systems at certain times of the day or from locations that are not consistent with the normal usage patterns of individuals. Monitoring for atypical usage may reveal rogue behavior by individuals or an attack in progress. Account monitoring may inadvertently create privacy risks since data collected to identify atypical usage may reveal previously unknown information about the behavior of individuals. Organizations assess and document privacy risks from monitoring accounts for atypical usage in their privacy impact assessment and make determinations that are in alignment with their privacy program plan.",
          "System and services acquisition. Allocation of resources. A. Determine the high-level information security and privacy requirements for the system or system service in mission and business process planning. \nB. Determine, document, and allocate the resources required to protect the system or system service as part of the organizational capital planning and investment control process. \nC. Establish a discrete line item for information security and privacy in organizational programming and budgeting documentation.\n\nResource allocation for information security and privacy includes funding for system and services acquisition, sustainment, and supply chain-related risks throughout the system development life cycle.",
          "System and communications protection. Security function isolation. Isolate security functions from non-security functions. Security functions are isolated from non-security functions by means of an isolation boundary implemented within a system via partitions and domains. The isolation boundary controls access to and protects the integrity of the hardware, software, and firmware that perform system security functions. Systems implement code separation in many ways, such as through the provision of security kernels via processor rings or processor modes. For non-kernel code, security function isolation is often achieved through file system protections that protect the code on disk and address space protections that protect executing code. Systems can restrict access to security functions using access control mechanisms and by implementing least privilege capabilities. While the ideal is for all code within the defined security function isolation boundary to only contain security-relevant code, it is sometimes necessary to include non-security functions as an exception. The isolation of security functions from non-security functions can be achieved by applying the systems security engineering design principles in SA-8, including SA-8 (1), SA-8 (3), SA-8 (4), SA-8 (10), SA-8 (12), SA-8 (13), SA-8 (14), and SA-8 (18).",
          "Supply chain risk management family. Acquisition strategies, tools, and methods. Employ the following acquisition strategies, contract tools, and procurement methods to protect against, identify, and mitigate supply chain risks: [assignment: organization-defined acquisition strategies, contract tools, and procurement methods]. The use of the acquisition process provides an important vehicle to protect the supply chain. There are many useful tools and techniques available, including obscuring the end use of a system or system component, using blind or filtered buys, requiring tamper-evident packaging, or using trusted or controlled distribution. The results from a supply chain risk assessment can guide and inform the strategies, tools, and methods that are most applicable to the situation. Tools and techniques may provide protections against unauthorized production, theft, tampering, insertion of counterfeits, insertion of malicious software or backdoors, and poor development practices throughout the system development life cycle.\n\nOrganizations also consider providing incentives for suppliers who implement controls, promote transparency into their processes and security and privacy practices, provide contract language that addresses the prohibition of tainted or counterfeit components, and restrict purchases from untrustworthy suppliers. Organizations consider providing training, education, and awareness programs for personnel regarding supply chain risk, available mitigation strategies, and when the programs should be employed. Methods for reviewing and protecting development plans, documentation, and evidence are commensurate with the security and privacy requirements of the organization. Contracts may specify documentation protection requirements.",
          "System and services acquisition. Acquisition process | use of approved piv products. Employ only information technology products on the FIPS 201-approved products list for Personal Identity Verification (PIV) capability implemented within organizational systems. Products on the FIPS 201-approved products list meet NIST requirements for Personal Identity Verification (PIV) of federal employees and contractors. PIV cards are used for multi-factor authentication in systems and organizations.",
          "Operations (ops). Data backup and recovery – concept. Basic criterion: Policies and instructions for data backup and recovery are documented, communicated, and provided in accordance with SP-01. The following aspects need to be addressed:\n\n- The extent and frequency of data backups and the duration of data retention should align with contractual agreements with cloud customers and the cloud service provider's operational continuity requirements for Recovery Time Objective (RTO) and Recovery Point Objective (RPO).\n- Data should be backed up in an encrypted state-of-the-art form.\n- Access to backed-up data and execution of restores should be performed only by authorized persons.\n- Tests of recovery procedures (cf. OPS-08) should be conducted.\n\nAdditional criterion: Supplementary information about the criterion:\n\n- The data backup concept specifies the type of data backup to be carried out (e.g., type, manner, duration) and identifies any specific data that must be backed up in special cases (e.g., pure use of compute nodes without data storage).\n- Backup procedures should differentiate between backups and snapshots of virtual machines. Snapshots do not replace backups but can be included in the backup strategy to achieve Recovery Point Objectives (RPO) if they are stored outside the original data location.\n- The business requirements of the cloud service provider for the scope, frequency, and duration of data backup should be determined through a business impact analysis (cf. BCM-03) for development and operational processes of the cloud service.\n- If different data backup and recovery procedures exist for data under the responsibility of the cloud customer and the cloud service provider, both variants need to be included in a test according to this criteria catalogue.\n- For procedures to secure the data of the cloud service provider, only the adequacy and implementation of the controls need to be proven, but not their effectiveness.\n- For procedures to secure the data of cloud customers, proof of effectiveness must also be provided.\n\nComplementary customer criterion: Cloud customers need to ensure, through suitable controls, that the contractual agreements made with the cloud service provider regarding the scope, frequency, and duration of data retention meet their business requirements. The business requirements are assessed as part of the business impact analysis (cf. BCM-02).\n\nNotes on continuous auditing feasibility: Partially, a policy can change ad-hoc. However, continuous auditing of policies is only partially feasible as the only attributes that can be tested are the last change date and the status of review or approval, as far as this information is stored in a system. The content of a policy can hardly be tested automatically.",
          "Configuration management. System component inventory | accountability information. Include in the system component inventory information a means for identifying, by name, position, or role, the individuals responsible and accountable for administering those components. Identifying the individuals who are responsible and accountable for administering system components ensures that the assigned components are properly administered. Additionally, it allows organizations to contact those individuals if any action is required, such as when the component is determined to be the source of a breach, needs to be recalled or replaced, or needs to be relocated.",
          "System and communications protection. Information in shared system resources. Prevent unauthorized and unintended information transfer via shared system resources. Preventing unauthorized and unintended information transfer via shared system resources stops information produced by the actions of prior users or roles (or the actions of processes acting on behalf of prior users or roles) from being available to current users or roles (or current processes acting on behalf of current users or roles) that obtain access to shared system resources after those resources have been released back to the system. Information in shared system resources also applies to encrypted representations of information. In other contexts, control of information in shared system resources is referred to as object reuse and residual information protection. Information in shared system resources does not address information remanence, which refers to the residual representation of data that has been nominally deleted; covert channels (including storage and timing channels), where shared system resources are manipulated to violate information flow restrictions; or components within systems for which there are only single users or roles.",
          "Contingency planning. Contingency plan testing | alternate processing site. Test the contingency plan at the alternate processing site: (a) to familiarize contingency personnel with the facility and available resources; and (b) to evaluate the capabilities of the alternate processing site to support contingency operations. Conditions at the alternate processing site may be significantly different than the conditions at the primary site. Having the opportunity to visit the alternate site and experience the actual capabilities available at the site can provide valuable information on potential vulnerabilities that could affect essential organizational mission and business functions. The on-site visit can also provide an opportunity to refine the contingency plan to address the vulnerabilities discovered during testing.",
          "Risk assessment. Vulnerability monitoring and scanning | breadth and depth of coverage. Define the breadth and depth of vulnerability scanning coverage. The breadth of vulnerability scanning coverage can be expressed as a percentage of components within the system, by the particular types of systems, by the criticality of systems, or by the number of vulnerabilities to be checked. Conversely, the depth of vulnerability scanning coverage can be expressed as the level of the system design that the organization intends to monitor (e.g., component, module, subsystem, element). Organizations can determine the sufficiency of vulnerability scanning coverage with regard to its risk tolerance and other factors. Scanning tools and how the tools are configured may affect the depth and coverage. Multiple scanning tools may be needed to achieve the desired depth and coverage. SP 800-53a provides additional information on the breadth and depth of coverage.",
          "Access control. Least privilege | authorize access to security functions. Authorize access for an organization-defined individuals or roles to:\n(a) organization-defined security functions (deployed in hardware, software, and firmware).\n(b) organization-defined security-relevant information.\n\nSecurity functions include establishing system accounts, configuring access authorizations (i.e., permissions, privileges), configuring settings for events to be audited, and establishing intrusion detection parameters. \n\nSecurity-relevant information includes filtering rules for routers or firewalls, configuration parameters for security services, cryptographic key management information, and access control lists.\n\nAuthorized personnel include security administrators, system administrators, system security officers, system programmers, and other privileged users.",
          "Product safety and security (pss). Online register of known vulnerabilities. Basic criteria: The cloud service provider operates or refers to a daily updated online register of known vulnerabilities that affect the cloud service provider and assets provided by the cloud service provider that the cloud customers have to install, provide, or operate themselves under the customers' responsibility. The presentation of the vulnerabilities follows the common vulnerability scoring system (CVSS). The online register is easily accessible to any cloud customer. The information contained therein forms a suitable basis for risk assessment and possible follow-up measures on the part of cloud users. For each vulnerability, it is indicated whether software updates (e.g., patch, update) are available, when they will be rolled out, and whether they will be deployed by the cloud service provider, the cloud customer, or both of them together. \n\nAdditional criteria: Assets provided by the cloud service provider, which must be installed, provided, or operated by cloud users within their area of responsibility, are equipped with automatic update mechanisms. After approval by the respective cloud user, software updates can be rolled out in such a way that they can be distributed to all affected users without human interaction. Supplementary information about the criteria assets provided by the cloud service provider that cloud customers have to install, deploy, or operate themselves in their area of responsibility are, for example, local software clients and apps as well as tools for integrating the cloud service. If the cloud service relies on other cloud services, this registry has to incorporate or refer to the vulnerabilities of those other cloud services in order for this criterion to be met. \n\nComplementary customer criteria: Cloud customers ensure through suitable controls that the information in this register is incorporated sufficiently quickly into their own risk management, evaluated, and if necessary, taken into account in their own area of responsibility. \n\nNotes on continuous auditing feasibility: Yes, a continuous audit includes, above all, whether the information is updated daily. The distribution of software updates must be documented by the cloud service provider (logs). This documentation can then be automatically and continuously evaluated by the auditor to ensure that the software used on assets in the cloud users’ area of responsibility is up-to-date.",
          "Security assessment and authorization. Continuous monitoring | risk monitoring. Ensure risk monitoring is an integral part of the continuous monitoring strategy that includes the following: (a) effectiveness monitoring; (b) compliance monitoring; and (c) change monitoring. Risk monitoring is informed by the established organizational risk tolerance. Effectiveness monitoring determines the ongoing effectiveness of the implemented risk response measures. Compliance monitoring verifies that required risk response measures are implemented. It also verifies that security and privacy requirements are satisfied. Change monitoring identifies changes to organizational systems and environments of operation that may affect security and privacy risk.",
          "Cryptography and key management (cry). Encryption of sensitive data for storage. Basic criterion: The cloud service provider has established procedures and technical safeguards to encrypt cloud customers’ data during storage. The private keys used for encryption are known only to the cloud customer, in accordance with applicable legal and regulatory obligations and requirements. Exceptions follow a specified procedure. The procedures for the use of private keys, including any exceptions, must be contractually agreed with the cloud customer.\n\nAdditional criterion: The private keys used for encryption are known to the customer exclusively and without exception, in accordance with applicable legal and regulatory obligations and requirements.\n\nSupplementary information about the criterion: An exception to the requirement that keys are known only to the cloud customers may be the use of a master key by the cloud service provider. If the cloud service provider establishes a procedure to use a master key, the cloud service provider must perform sample-based checks regarding the suitability and effectiveness of the procedure, on a regular basis. This criterion does not apply to data that cannot be encrypted for the provision of the cloud service for functional reasons.\n\nComplementary customer criterion: Through suitable controls, cloud customers ensure that for parts of the cloud service under their responsibility (e.g., virtual machines within an IaaS solution), their data is encrypted during storage in accordance with the respective protection requirements.\n\nNotes on continuous auditing feasibility: Partially, the encryption of data of cloud customers is configured centrally; therefore, it is only suitable for continuous auditing to a limited extent. Exceptions to the encryption of data, according to a specified procedure, and the coordination of this with cloud customers should be documented and approved. This, too, is only suitable to a limited extent for continuous auditing, as these exceptions are decided on a case-by-case basis and do not occur at a high enough frequency. In a continuous audit, the system status can be queried to determine whether the encryption is active and whether the approved exceptions are being adhered to.",
          "Access control. Remote access | protection of confidentiality and integrity using encryption. Implement cryptographic mechanisms to protect the confidentiality and integrity of remote access sessions. Virtual private networks can be used to protect the confidentiality and integrity of remote access sessions. Transport Layer Security (TLS) is an example of a cryptographic protocol that provides end-to-end communication security over networks and is used for internet communications and online transactions.",
          "Access control. Account management | automated system account management. Support the management of system accounts using [assignment: organization-defined automated mechanisms]. Automated system account management includes using automated mechanisms to create, enable, modify, disable, and remove accounts. Notify account managers when an account is created, enabled, modified, disabled, or removed, or when users are terminated or transferred. Monitor system account usage. Report atypical system account usage. Automated mechanisms can include internal system functions and email, telephonic, and text messaging notifications.",
          "System and information integrity. Policy and procedures. a. Develop, document, and disseminate to organization-defined personnel or roles: \n1. Organization-level, system-level, and mission/business process-level system and information integrity policies that:\n(a) Address purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance.\n(b) Are consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines.\n2. Procedures to facilitate the implementation of the system and information integrity policy and associated controls.\n\nb. Designate an organization-defined official to manage the development, documentation, and dissemination of the system and information integrity policy and procedures.\n\nc. Review and update the current system and information integrity policies and procedures:\n1. Policy - organization-defined frequency and following organization-defined events.\n2. Procedures - organization-defined frequency and following organization-defined events.\n\nSystem and information integrity policies and procedures should address the controls in the SI family that are implemented within systems and organizations. The risk management strategy plays a crucial role in establishing these policies and procedures. Collaborative efforts between the security and privacy programs are essential in developing the system and information integrity policies and procedures. Organization-level security and privacy program policies and procedures are generally preferred, as they may eliminate the need for mission- or system-specific policies and procedures. The policy can be incorporated into the general security and privacy policy or represented by multiple policies that reflect the complexity of organizations. Procedures can be established for security and privacy programs, mission or business processes, and systems, if necessary. Procedures outline the implementation of policies or controls and can be directed at individuals or roles. They can be documented within system security and privacy plans or as separate documents. Updates to the system and information integrity policy and procedures may arise from assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Merely restating controls does not constitute an organizational policy or procedure.",
          "Identification and authentication. Identification and authentication (non-organizational users) | acceptance of external authenticators. (a) Accept only external authenticators that are NIST-compliant; and (b) document and maintain a list of accepted external authenticators. Acceptance of only NIST-compliant external authenticators applies to organizational systems that are accessible to the public (e.g., public-facing websites). External authenticators are issued by nonfederal government entities and are compliant with SP 800-63b. Approved external authenticators meet or exceed the minimum federal government-wide technical, security, privacy, and organizational maturity requirements. Meeting or exceeding federal requirements allows federal government relying parties to trust external authenticators in connection with an authentication transaction at a specified authenticator assurance level.",
          "System and services acquisition. Developer screening. Require that the developer of [assignment: organization-defined system, system component, or system service] has appropriate access authorizations as determined by assigned [assignment: organization-defined official government duties]. The developer should also satisfy the following additional personnel screening criteria: [assignment: organization-defined additional personnel screening criteria]. Developer screening is directed at external developers. Internal developer screening is addressed by PS-3. Because the system, system component, or system service may be used in critical activities essential to the national or economic security interests of the United States, organizations have a strong interest in ensuring that developers are trustworthy. The degree of trust required of developers may need to be consistent with that of the individuals who access the systems, system components, or system services once deployed. Authorization and personnel screening criteria include clearances, background checks, citizenship, and nationality. Developer trustworthiness may also include a review and analysis of company ownership and relationships that the company has with entities that may potentially affect the quality and reliability of the systems, components, or services being developed. Satisfying the required access authorizations and personnel screening criteria includes providing a list of all individuals who are authorized to perform development activities on the selected system, system component, or system service so that organizations can validate that the developer has satisfied the authorization and screening requirements.",
          "Contingency planning. Contingency training. A. Provide contingency training to system users consistent with assigned roles and responsibilities. \n\n1. Within the organization-defined time period of assuming a contingency role or responsibility. \n2. When required by system changes. \n3. Organization-defined frequency thereafter. \n\nB. Review and update contingency training content. \nOrganization-defined frequency and following organization-defined events. \n\nContingency training provided by organizations is linked to the assigned roles and responsibilities of organizational personnel to ensure the appropriate content and level of detail is included. For example, some individuals may only need to know when and where to report for duty during contingency operations and if normal duties are affected. System administrators may require additional training on how to establish systems at alternate processing and storage sites. Organizational officials may receive more specific training on how to conduct mission-essential functions in designated off-site locations and how to establish communications with other governmental entities for purposes of coordination on contingency-related activities. \n\nTraining for contingency roles or responsibilities reflects the specific continuity requirements in the contingency plan. Events that may precipitate an update to contingency training content include, but are not limited to, contingency plan testing or an actual contingency (lessons learned), assessment or audit findings, security incidents or breaches, or changes in laws, executive orders, directives, regulations, policies, standards, and guidelines. \n\nAt the discretion of the organization, participation in a contingency plan test or exercise, including lessons learned sessions subsequent to the test or exercise, may satisfy contingency plan training requirements.",
          "Audit and accountability. Event logging. a. Identify the types of events that the system is capable of logging in support of the audit function: [Assignment: organization-defined event types that the system is capable of logging]. \nb. Coordinate the event logging function with other organizational entities requiring audit-related information to guide and inform the selection criteria for events to be logged. \nc. Specify the following event types for logging within the system: [Assignment: organization-defined event types (subset of the event types defined in AU-2a.) along with the frequency of (or situation requiring) logging for each identified event type]. \nd. Provide a rationale for why the event types selected for logging are deemed to be adequate to support after-the-fact investigations of incidents. \ne. Review and update the event types selected for logging [Assignment: organization-defined frequency].\n\nAn event is an observable occurrence in a system. The types of events that require logging are those events that are significant and relevant to the security of systems and the privacy of individuals. Event logging also supports specific monitoring and auditing needs. Event types include password changes, failed logons or failed accesses related to systems, security or privacy attribute changes, administrative privilege usage, PIV credential usage, data action changes, query parameters, or external credential usage. \n\nIn determining the set of event types that require logging, organizations consider the monitoring and auditing appropriate for each of the controls to be implemented. For completeness, event logging includes all protocols that are operational and supported by the system. To balance monitoring and auditing requirements with other system needs, event logging requires identifying the subset of event types that are logged at a given point in time. \n\nFor example, organizations may determine that systems need the capability to log every file access successful and unsuccessful, but not activate that capability except for specific circumstances due to the potential burden on system performance. The types of events that organizations desire to be logged may change. Reviewing and updating the set of logged events is necessary to help ensure that the events remain relevant and continue to support the needs of the organization. \n\nOrganizations consider how the types of logging events can reveal information about individuals that may give rise to privacy risk and how best to mitigate such risks. For example, there is the potential to reveal personally identifiable information in the audit trail, especially if the logging event is based on patterns or time of usage. Event logging requirements, including the need to log specific event types, may be referenced in other controls and control enhancements. These include AC-2(4), AC-3(10), AC-6(9), AC-17(1), CM-3f, CM-5(1), IA-3(3)(b), MA-4(1), MP-4(2), PE-3, PM-21, PT-7, RA-8, SC-7(9), SC-7(15), SI-3(8), SI-4(22), SI-7(8), and SI-10(1). \n\nOrganizations include event types that are required by applicable laws, executive orders, directives, policies, regulations, standards, and guidelines. Audit records can be generated at various levels, including at the packet level as information traverses the network. Selecting the appropriate level of event logging is an important part of a monitoring and auditing capability and can identify the root causes of problems. When defining event types, organizations consider the logging necessary to cover related event types, such as the steps in distributed, transaction-based processes, and the actions that occur in service-oriented architectures.",
          null
         ],
         "marker": {
          "color": "#CFD8DC",
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "other",
         "showlegend": false,
         "type": "scattergl",
         "x": [
          10.97171401977539,
          8.285576820373535,
          10.781049728393555,
          6.198742866516113,
          8.564499855041504,
          10.261123657226562,
          9.990263938903809,
          10.064929008483887,
          11.19943904876709,
          8.53537368774414,
          8.561917304992676,
          12.750914573669434,
          11.054265975952148,
          8.539346694946289,
          9.94413948059082,
          7.75214958190918,
          7.714847564697266,
          6.638518810272217,
          10.131428718566895,
          8.848254203796387,
          7.86443567276001,
          6.71519660949707,
          8.619528770446777,
          8.25267505645752,
          6.695074558258057,
          9.766021728515625,
          9.711006164550781,
          8.510452270507812,
          10.799691200256348,
          8.690022468566895,
          8.980957984924316,
          7.298487663269043,
          8.394129753112793,
          8.191686630249023,
          8.741332054138184,
          11.089123725891113,
          8.098224639892578,
          6.680322647094727,
          9.941121101379395,
          8.56645679473877,
          11.0409517288208,
          6.262563228607178,
          10.070612907409668,
          9.993010520935059,
          8.355082511901855,
          11.180135726928711,
          9.596309661865234,
          8.574370384216309,
          9.252708435058594,
          8.001252174377441,
          11.162859916687012,
          8.42392635345459,
          6.688788890838623,
          6.616933345794678,
          8.04685115814209,
          8.939287185668945
         ],
         "y": [
          8.281309127807617,
          7.979546546936035,
          6.815500259399414,
          9.787711143493652,
          11.270874977111816,
          8.07427978515625,
          7.254077911376953,
          7.256441116333008,
          9.614616394042969,
          11.236410140991211,
          9.362457275390625,
          6.075748443603516,
          8.3277587890625,
          11.297011375427246,
          7.328246593475342,
          6.896927356719971,
          8.459653854370117,
          9.261411666870117,
          8.198202133178711,
          8.929463386535645,
          8.413045883178711,
          9.24652099609375,
          11.244251251220703,
          7.9881720542907715,
          9.235990524291992,
          7.658018589019775,
          6.642323017120361,
          11.266436576843262,
          8.617093086242676,
          11.175395965576172,
          8.79954719543457,
          8.316084861755371,
          9.17483901977539,
          9.047658920288086,
          8.893050193786621,
          8.260931968688965,
          7.526130676269531,
          9.243643760681152,
          7.119062900543213,
          11.268613815307617,
          8.31226634979248,
          9.73121166229248,
          7.484130382537842,
          7.319557189941406,
          7.999131679534912,
          9.771140098571777,
          6.755321502685547,
          11.312787055969238,
          6.235128879547119,
          8.658676147460938,
          9.77027416229248,
          8.052393913269043,
          9.234477043151855,
          9.29520034790039,
          8.952130317687988,
          8.722332000732422
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Configuration management. Access restrictions for change | automated access enforcement and audit records. (a) Enforce access restrictions using organization-defined automated mechanisms. \n(b) Automatically generate audit records of the enforcement actions. \nOrganizations log system accesses associated with applying configuration changes to ensure that configuration change control is implemented and to support after-the-fact actions should organizations discover any unauthorized changes.",
          "System and information integrity. System monitoring | risk for individuals. Implement organization-defined additional monitoring of individuals who have been identified by organization-defined sources as posing an increased level of risk. Indications of increased risk from individuals can be obtained from different sources, including personnel records, intelligence agencies, law enforcement organizations, and other sources. The monitoring of individuals is coordinated with the management, legal, security, privacy, and human resource officials who conduct such monitoring. Monitoring is conducted in accordance with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines.",
          "Physical and environmental protection. Fire protection. Employ and maintain fire detection and suppression systems that are supported by an independent energy source. The provision of fire detection and suppression systems applies primarily to organizational facilities that contain concentrations of system resources, including data centers, server rooms, and mainframe computer rooms. Fire detection and suppression systems that may require an independent energy source include sprinkler systems and smoke detectors. An independent energy source is an energy source, such as a microgrid, that is separate or can be separated from the energy sources providing power for the other parts of the facility.",
          "System and information integrity. Flaw remediation. a. Identify, report, and correct system flaws.\nb. Test software and firmware updates related to flaw remediation for effectiveness and potential side effects before installation.\nc. Install security-relevant software and firmware updates within [assignment: organization-defined time period] of the release of the updates.\nd. Incorporate flaw remediation into the organizational configuration management process.\n\nThe need to remediate system flaws applies to all types of software and firmware. Organizations identify systems affected by software flaws, including potential vulnerabilities resulting from those flaws, and report this information to designated organizational personnel with information security and privacy responsibilities.\n\nSecurity-relevant updates include patches, service packs, and malicious code signatures. Organizations also address flaws discovered during assessments, continuous monitoring, incident response activities, and system error handling.\n\nBy incorporating flaw remediation into configuration management processes, required remediation actions can be tracked and verified. Organization-defined time periods for updating security-relevant software and firmware may vary based on a variety of risk factors, including the security category of the system, the criticality of the update (i.e., severity of the vulnerability related to the discovered flaw), the organizational risk tolerance, the mission supported by the system, or the threat environment.\n\nSome types of flaw remediation may require more testing than other types. Organizations determine the type of testing needed for the specific type of flaw remediation activity under consideration and the types of changes that are to be configuration-managed. \n\nIn some situations, organizations may determine that the testing of software or firmware updates is not necessary or practical, such as when implementing simple malicious code signature updates. In testing decisions, organizations consider whether security-relevant software or firmware updates are obtained from authorized sources with appropriate digital signatures.",
          "Access control. Remote access | monitoring and control. Employ automated mechanisms to monitor and control remote access methods. Monitoring and control of remote access methods allows organizations to detect attacks and help ensure compliance with remote access policies by auditing the connection activities of remote users on a variety of system components, including servers, notebook computers, workstations, smartphones, and tablets. Audit logging for remote access is enforced by AU-2. Audit events are defined in AU-2a.",
          "Risk assessment. Vulnerability monitoring and scanning | privileged access. Implement privileged access authorization to [assignment: organization-defined system components] for [assignment: organization-defined vulnerability scanning activities]. In certain situations, the nature of the vulnerability scanning may be more intrusive, or the system component that is the subject of the scanning may contain classified or controlled unclassified information, such as personally identifiable information. Privileged access authorization to selected system components facilitates more thorough vulnerability scanning and protects the sensitive nature of such scanning.",
          "System and communications protection. Session authenticity. Protect the authenticity of communication sessions. Protecting session authenticity addresses communication protection at the session level, not at the packet level. Such protection establishes grounds for confidence at both ends of communication sessions in the ongoing identities of other parties and the validity of transmitted information. Authenticity protection includes protecting against man-in-the-middle attacks, session hijacking, and the insertion of false information into sessions.",
          "System and information integrity. System monitoring | analyze traffic and covert exfiltration. Analyze outbound communications traffic at external interfaces to the system and at the following interior points to detect covert exfiltration of information: [assignment: organization-defined interior points within the system]. Organization-defined interior points include subnetworks and subsystems. Covert means that can be used to exfiltrate information include steganography.",
          "System and communications protection. Boundary protection | access points. Limit the number of external network connections to the system. Limiting the number of external network connections facilitates monitoring of inbound and outbound communications traffic. The Trusted Internet Connection (TIC) Initiative, mandated by the Department of Homeland Security (DHS), is an example of a federal guideline that requires limits on the number of external network connections. Limiting the number of external network connections to the system is important during transition periods from older to newer technologies (e.g., transitioning from IPv4 to IPv6 network protocols). Such transitions may require implementing the older and newer technologies simultaneously during the transition period and thus increase the number of access points to the system.",
          "Access control. Wireless access | antennas and transmission power levels. Select radio antennas and calibrate transmission power levels to reduce the probability that signals from wireless access points can be received outside of organization-controlled boundaries. Actions that may be taken to limit unauthorized use of wireless communications outside of organization-controlled boundaries include reducing the power of wireless transmissions so that the transmissions are less likely to emit a signal that can be captured outside of the physical perimeters of the organization, employing measures such as emissions security to control wireless emanations, and using directional or beamforming antennas that reduce the likelihood that unintended receivers will be able to intercept signals. Prior to taking such mitigating actions, organizations can conduct periodic wireless surveys to understand the radio frequency profile of organizational systems as well as other systems that may be operating in the area.",
          "System and communications protection. Network disconnect. Terminate the network connection associated with a communications session at the end of the session or after [assignment: organization-defined time period] of inactivity. Network disconnect applies to internal and external networks. Terminating network connections associated with specific communications sessions includes de-allocating TCP/IP address or port pairs at the operating system level and de-allocating the networking assignments at the application level if multiple application sessions are using a single operating system-level network connection. Periods of inactivity may be established by organizations and include time periods by type of network access or for specific network accesses.",
          "Identification and authentication. Identity proofing | identity evidence. Require evidence of individual identification be presented to the registration authority. Identity evidence, such as documentary evidence or a combination of documents and biometrics, reduces the likelihood of individuals using fraudulent identification to establish an identity or, at least, increases the work factor of potential adversaries. The forms of acceptable evidence are consistent with the risks to the systems, roles, and privileges associated with the user's account.",
          "Physical and environmental protection. Access control for transmission. Control physical access to [assignment: organization-defined system distribution and transmission lines] within organizational facilities using [assignment: organization-defined security controls]. Security controls applied to system distribution and transmission lines prevent accidental damage, disruption, and physical tampering. Such controls may also be necessary to prevent eavesdropping or modification of unencrypted transmissions. Security controls used to control physical access to system distribution and transmission lines include disconnected or locked spare jacks, locked wiring closets, protection of cabling by conduit or cable trays, and wiretapping sensors.",
          "System and information integrity. System monitoring | privileged users. Implement the following additional monitoring of privileged users: [assignment: organization-defined additional monitoring]. Privileged users have access to more sensitive information, including security-related information, than the general user population. Access to such information means that privileged users can potentially do greater damage to systems and organizations than non-privileged users. Therefore, implementing additional monitoring on privileged users helps to ensure that organizations can identify malicious activity at the earliest possible time and take appropriate actions.",
          "Incident response. Incident reporting. a. Require personnel to report suspected incidents to the organizational incident response capability within [assignment: organization-defined time period]. \nb. Report incident information to [assignment: organization-defined authorities]. \n\nThe types of incidents reported, the content and timeliness of the reports, and the designated reporting authorities reflect applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Incident information can inform risk assessments, control effectiveness assessments, security requirements for acquisitions, and selection criteria for technology products.",
          "Operations (ops). Managing vulnerabilities, malfunctions and errors – system hardening. Basic criterion: System components in the production environment used to provide the cloud service under the cloud service provider's responsibility are hardened according to generally accepted industry standards. The hardening requirements for each system component are documented. If non-modifiable (\"immutable\") images are used, compliance with the hardening specifications as defined in the hardening requirements is checked upon the creation of the images. Configuration and log files regarding the continuous availability of the images are retained.\n\nAdditional criterion: System components in the cloud service provider's area of responsibility are automatically monitored for compliance with hardening specifications. Deviations from the specifications are automatically reported to the appropriate departments of the cloud service provider for immediate assessment and action.\n\nSupplementary information about the criterion: System components in the sense of the basic criterion are objects required for the information security of the cloud service during the creation, processing, storage, transmission, deletion, or destruction of information in the cloud service provider's area of responsibility. For example, firewalls, load balancers, web servers, application servers, and database servers. These system components consist of hardware and software objects. This criterion is limited to software objects such as hypervisors, operating systems, databases, programming interfaces (APIs), images (e.g., for virtual machines and containers), and applications for logging and monitoring security events. The configuration and log files for non-modifiable images include, for example, the configuration of the images used with regard to implemented hardening specifications including version history, and logs for file integrity monitoring of images in productive use. Generally accepted industry standards include, for example, the security configuration benchmark of the \"Centre for Internet Security\" (CIS) or the corresponding modules in the BSI IT-Grundschutz-Kompendium. Compliance with hardening specifications can be monitored with, for example, file integrity monitoring.\n\nComplementary customer criterion: Cloud customers ensure through suitable controls that layers of the cloud service which are under their responsibility are hardened according to generally established and accepted industry standards. The hardening specifications applied are derived from a risk assessment of the planned usage of the cloud service.\n\nNotes on continuous auditing feasibility: Yes, the verification of compliance with the specifications for the hardening of system components can be automatically tested and subsequently documented (logs). The auditor can evaluate these logs automatically and continuously and thus carry out a continuous audit.",
          "Audit and accountability. Audit log storage capacity. Allocate audit log storage capacity to accommodate [assignment: organization-defined audit log retention requirements]. Organizations consider the types of audit logging to be performed and the audit log processing requirements when allocating audit log storage capacity. Allocating sufficient audit log storage capacity reduces the likelihood of such capacity being exceeded and resulting in the potential loss or reduction of audit logging capability.",
          "System and services acquisition. Developer testing and evaluation | threat modeling and vulnerability analyses. Require the developer of the system, system component, or system service to perform threat modeling and vulnerability analyses during development and the subsequent testing and evaluation of the system, component, or service. This should include the following: \n\n(a) Use the following contextual information: [assignment: organization-defined information concerning impact, environment of operations, known or assumed threats, and acceptable risk levels]. \n\n(b) Employ the following tools and methods: [assignment: organization-defined tools and methods]. \n\n(c) Conduct the modeling and analyses at the following level of rigor: [assignment: organization-defined breadth and depth of modeling and analyses]. \n\n(d) Produce evidence that meets the following acceptance criteria: [assignment: organization-defined acceptance criteria]. \n\nSystems, system components, and system services may deviate significantly from the functional and design specifications created during the requirements and design stages of the system development life cycle. Therefore, updates to threat modeling and vulnerability analyses of those systems, system components, and system services during development and prior to delivery are critical to the effective operation of those systems, components, and services. \n\nThreat modeling and vulnerability analyses at this stage of the system development life cycle ensure that design and implementation changes have been accounted for and that vulnerabilities created because of those changes have been reviewed and mitigated.",
          "Awareness and training. Policy and procedures. a. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]: 1. [Selection (one or more): organization level; mission/business process-level; system-level] awareness and training policy that: (a) addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance; and (b) is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines; and 2. Procedures to facilitate the implementation of the awareness and training policy and the associated awareness and training controls. \nb. Designate an [assignment: organization-defined official] to manage the development, documentation, and dissemination of the awareness and training policy and procedures. \nc. Review and update the current awareness and training: 1. Policy [assignment: organization-defined frequency] and following [assignment: organization-defined events]; and 2. Procedures [assignment: organization-defined frequency] and following [assignment: organization-defined events].\nAwareness and training policy and procedures address the controls in the AT family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of awareness and training policy and procedures. Security and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations. Procedures can be established for security and privacy programs, for mission or business processes, and for systems, if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents. Events that may precipitate an update to awareness and training policy and procedures include assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Incident response. Incident monitoring | automated tracking, data collection, and analysis. Track incidents and collect and analyze incident information using [assignment: organization-defined automated mechanisms]. Automated mechanisms for tracking incidents and collecting and analyzing incident information include computer incident response centers or other electronic databases of incidents and network monitoring devices.",
          "System and communications protection. Boundary protection | isolation of system components. Employ boundary protection mechanisms to isolate [assignment: organization-defined system components] supporting [assignment: organization-defined missions and/or business functions]. Organizations can isolate system components that perform different mission or business functions. Such isolation limits unauthorized information flows among system components and provides the opportunity to deploy greater levels of protection for selected system components. Isolating system components with boundary protection mechanisms provides the capability for increased protection of individual system components and to more effectively control information flows between those components. Isolating system components provides enhanced protection that limits the potential harm from hostile cyber-attacks and errors. The degree of isolation varies depending upon the mechanisms chosen. Boundary protection mechanisms include routers, gateways, and firewalls that separate system components into physically separate networks or subnetworks; cross-domain devices that separate subnetworks; virtualization techniques; and the encryption of information flows among system components using distinct encryption keys.",
          "Physical and environmental protection. Environmental controls | monitoring with alarms and notifications. Employ environmental control monitoring that provides an alarm or notification of changes potentially harmful to personnel or equipment to [assignment: organization-defined personnel or roles]. The alarm or notification may be an audible alarm or a visual message in real-time to personnel or roles defined by the organization. Such alarms and notifications can help minimize harm to individuals and damage to organizational assets by facilitating a timely incident response.",
          "Physical and environmental protection. Monitoring physical access | intrusion alarms and surveillance equipment. Monitor physical access to the facility where the system resides using physical intrusion alarms and surveillance equipment. Physical intrusion alarms can be employed to alert security personnel when unauthorized access to the facility is attempted. Alarm systems work in conjunction with physical barriers, physical access control systems, and security guards by triggering a response when these other forms of security have been compromised or breached. Physical intrusion alarms can include different types of sensor devices, such as motion sensors, contact sensors, and broken glass sensors. Surveillance equipment includes video cameras installed at strategic locations throughout the facility.",
          "Maintenance. Maintenance tools | inspect media. Check media containing diagnostic and test programs for malicious code before the media is used in the system. If, upon inspection of media containing maintenance, diagnostic, and test programs, organizations determine that the media contains malicious code, the incident is handled consistent with organizational incident handling policies and procedures.",
          "Control and monitoring of service providers and suppliers (sso). Monitoring of compliance with requirements. Basic criterion: The cloud service provider monitors compliance with information security requirements and applicable legal and regulatory requirements in accordance with policies and instructions concerning controlling and monitoring of third parties. Monitoring includes a regular review of the following evidence to the extent that such evidence is to be provided by third parties in accordance with the contractual agreements: reports on the quality of the service provided; certificates of the management systems' compliance with international standards; independent third-party reports on the suitability and operating effectiveness of their service-related internal control systems; and records of the third parties on the handling of vulnerabilities, security incidents, and malfunctions. The frequency of the monitoring corresponds to the classification of the third party based on the risk assessment conducted by the cloud service provider (cf. SSO-02). The results of the monitoring are included in the review of the third party's risk assessment. Identified violations and deviations are subjected to analysis, evaluation, and treatment in accordance with the risk management procedure (cf. OIS-07). \n\nAdditional criterion: The procedures for monitoring compliance with the requirements are supplemented by automatic procedures relating to the following aspects: configuration of system components; performance and availability of system components; response time to malfunctions and security incidents; and recovery time (time until completion of error handling). Identified violations and discrepancies are automatically reported to the responsible personnel or system components of the cloud service provider for prompt assessment and action. \n\nSupplementary information about the criterion: Evidence for the review of the suitability and operating effectiveness of the service-related internal control system includes reports in accordance with ISAE 3402, IDW PS 951, SOC 2, or BSI C5. In the evidence provided by the third parties, the cloud service provider reviews, for example, the following aspects and, if necessary, incorporates the findings into the risk assessment in order to derive and initiate mitigating actions: the scope and the validity respectively the period covered by the evidence; for attestation reports: qualifications of the opinion, included deviations/other observations including management's response and corresponding controls to be implemented and executed by the cloud service provider; disclosed subcontractors incl. any changes among those (e.g. additional subcontractor); and stated security incidents. \n\nComplementary customer criterion: Cloud customers ensure through suitable controls that they stay informed about subservice organizations of their cloud service provider (e.g. on the basis of the information in the C5 attestation report) and decide on the basis of their need for protection of their data processed and stored in the cloud service whether further action should be taken to monitor and check these subservice organizations. \n\nNotes on continuous auditing feasibility: Partially, a continuous audit of some of the required evidence, such as the reviews conducted and their results, can be performed once the cloud service provider documents the associated steps using a tool. However, a review on content-level, such as reviewing the response to risk assessments and violations of service provider requirements, is difficult as it requires a semantic understanding. As a result, at least parts of the criterion are suitable for continuous audit.",
          "Configuration management. Baseline configuration | retention of previous configurations. Retain [assignment: organization-defined number] of previous versions of baseline configurations of the system to support rollback. Retaining previous versions of baseline configurations to support rollback includes hardware, software, firmware, configuration files, configuration records, and associated documentation.",
          "Contingency planning. Contingency plan | coordinate with related plans. Coordinate contingency plan development with organizational elements responsible for related plans. Plans that are related to contingency plans include:\n- Business continuity plans\n- Disaster recovery plans\n- Critical infrastructure plans\n- Continuity of operations plans\n- Crisis communications plans\n- Insider threat implementation plans\n- Data breach response plans\n- Cyber incident response plans\n- Breach response plans\n- Occupant emergency plans.",
          "Configuration management. Least functionality | periodic review. (A) Review the system [assignment: organization-defined frequency] to identify unnecessary and/or nonsecure functions, ports, protocols, software, and services; and (B) disable or remove [assignment: organization-defined functions, ports, protocols, software, and services within the system deemed to be unnecessary and/or nonsecure]. Organizations review functions, ports, protocols, and services provided by systems or system components to determine the functions and services that are candidates for elimination. Such reviews are especially important during transition periods from older technologies to newer technologies (e.g., transition from IPv4 to IPv6). These technology transitions may require implementing the older and newer technologies simultaneously during the transition period and returning to minimum essential functions, ports, protocols, and services at the earliest opportunity. Organizations can either decide the relative security of the function, port, protocol, and/or service or base the security decision on the assessment of other entities. Insecure protocols include Bluetooth, FTP, and peer-to-peer networking.",
          "Incident response. Incident reporting | automated reporting. Report incidents using [Assignment: organization-defined automated mechanisms]. The recipients of incident reports are specified in IR-6b. Automated reporting mechanisms include email, posting on websites (with automatic updates), and automated incident response tools and programs.",
          "Incident response. Incident handling | insider threats. Implement an incident handling capability for incidents involving insider threats. The explicit focus on handling incidents involving insider threats provides additional emphasis on this type of threat and the need for specific incident handling capabilities to provide appropriate and timely responses.",
          "System and information integrity. Software, firmware, and information integrity. a. Employ integrity verification tools to detect unauthorized changes to the following software, firmware, and information: [assignment: organization-defined software, firmware, and information]. \nb. Take the following actions when unauthorized changes to the software, firmware, and information are detected: [assignment: organization-defined actions]. Unauthorized changes to software, firmware, and information can occur due to errors or malicious activity. Software includes operating systems (with key internal components such as kernels or drivers), middleware, and applications. Firmware interfaces include Unified Extensible Firmware Interface (UEFI) and Basic Input/Output System (BIOS). Information includes personally identifiable information and metadata that contains security and privacy attributes associated with information. Integrity checking mechanisms, including parity checks, cyclical redundancy checks, cryptographic hashes, and associated tools, can automatically monitor the integrity of systems and hosted applications.",
          "Contingency planning. System recovery and reconstitution | transaction recovery. Implement transaction recovery for systems that are transaction-based. Transaction-based systems include database management systems and transaction processing systems. Mechanisms supporting transaction recovery include transaction rollback and transaction journaling.",
          "Incident response. Incident response assistance. Provide an incident response support resource. This resource is integral to the organizational incident response capability and offers advice and assistance to users of the system for the handling and reporting of incidents. Incident response support resources provided by organizations include help desks, assistance groups, automated ticketing systems (to open and track incident response tickets), and access to forensics services or consumer redress services when required.",
          "Audit and accountability. Response to audit logging process failures | storage capacity warning. Provide a warning to organization-defined personnel, roles, and/or locations within the organization-defined time period, when the allocated audit log storage volume reaches the organization-defined percentage of the repository's maximum audit log storage capacity. Please note that organizations may have multiple audit log storage repositories distributed across multiple system components. Each repository may have different storage volume capacities.",
          "System and information integrity. System monitoring | automated tools and mechanisms for real-time analysis. Employ automated tools and mechanisms to support near real-time analysis of events. Automated tools and mechanisms include host-based, network-based, transport-based, or storage-based event monitoring tools and mechanisms or security information and event management (SIEM) technologies that provide real-time analysis of alerts and notifications generated by organizational systems. Automated monitoring techniques can create unintended privacy risks because automated controls may connect to external or otherwise unrelated systems. The matching of records between these systems may create linkages with unintended consequences. Organizations assess and document these risks in their Privacy Impact Assessment and make determinations that are in alignment with their privacy program plan.",
          "Risk assessment. Vulnerability monitoring and scanning | discoverable information. Determine information about the system that is discoverable and take [assignment: organization-defined corrective actions]. Discoverable information includes information that adversaries could obtain without compromising or breaching the system, such as by collecting information that the system is exposing or by conducting extensive web searches. Corrective actions include notifying appropriate organizational personnel, removing designated information, or changing the system to make the designated information less relevant or attractive to adversaries. This enhancement excludes intentionally discoverable information that may be part of a decoy capability (e.g., honeypots, honeynets, or deception nets) deployed by the organization.",
          "Contingency planning. System recovery and reconstitution. Provide for the recovery and reconstitution of the system to a known state within [assignment: organization-defined time period consistent with recovery time and recovery point objectives] after a disruption, compromise, or failure. Recovery is executing contingency plan activities to restore organizational mission and business functions. Reconstitution takes place following recovery and includes activities for returning systems to fully operational states. Recovery and reconstitution operations reflect mission and business priorities; recovery point, recovery time, and reconstitution objectives; and organizational metrics consistent with contingency plan requirements. Reconstitution includes the deactivation of interim system capabilities that may have been needed during recovery operations. Reconstitution also includes assessments of fully restored system capabilities, reestablishment of continuous monitoring activities, system reauthorization (if required), and activities to prepare the system and organization for future disruptions, breaches, compromises, or failures. Recovery and reconstitution capabilities can include automated mechanisms and manual procedures. Organizations establish recovery time and recovery point objectives as part of contingency planning.",
          "System and information integrity. System monitoring | system-wide intrusion detection system. Connect and configure individual intrusion detection tools into a system-wide intrusion detection system. Linking individual intrusion detection tools into a system-wide intrusion detection system provides additional coverage and effective detection capabilities. The information contained in one intrusion detection tool can be shared widely across the organization, making the system-wide detection capability more robust and powerful.",
          "Incident response. Information spillage response | exposure to unauthorized personnel. Employ the following controls for personnel exposed to information not within assigned access authorizations: [assignment: organization-defined controls]. Controls include ensuring that personnel who are exposed to spilled information are made aware of the laws, executive orders, directives, regulations, policies, standards, and guidelines regarding the information and the restrictions imposed based on exposure to such information.",
          "Supply chain risk management family. Component authenticity | configuration control for component service and repair. Maintain configuration control over the following system components awaiting service or repair and serviced or repaired components awaiting return to service: [assignment: organization-defined system components]. None.",
          "Maintenance. Controlled maintenance. a. Schedule, document, and review records of maintenance, repair, and replacement on system components in accordance with manufacturer or vendor specifications and/or organizational requirements.\nb. Approve and monitor all maintenance activities, whether performed on-site or remotely, and whether the system or system components are serviced on-site or removed to another location.\nc. Require that [assignment: organization-defined personnel or roles] explicitly approve the removal of the system or system components from organizational facilities for off-site maintenance, repair, or replacement.\nd. Sanitize equipment to remove the following information from associated media prior to removal from organizational facilities for off-site maintenance, repair, or replacement: [assignment: organization-defined information].\ne. Check all potentially impacted controls to verify that the controls are still functioning properly following maintenance, repair, or replacement actions.\nf. Include the following information in organizational maintenance records: [assignment: organization-defined information].\n\nControlling system maintenance addresses the information security aspects of the system maintenance program and applies to all types of maintenance to system components conducted by local or non-local entities. Maintenance includes peripherals such as scanners, copiers, and printers. Information necessary for creating effective maintenance records includes the date and time of maintenance, a description of the maintenance performed, names of the individuals or group performing the maintenance, the name of the escort, and system components or equipment that is removed or replaced. Organizations consider supply chain-related risks associated with replacement components for systems.",
          "Access control. Use of external systems | portable storage devices — restricted use. Restrict the use of organization-controlled portable storage devices by authorized individuals on external systems using [assignment: organization-defined restrictions]. \n\nLimits on the use of organization-controlled portable storage devices in external systems include restrictions on how the devices may be used and under what conditions the devices may be used.",
          "System and services acquisition. Developer-provided training. Require the developer of the system, system component, or system service to provide the following training on the correct use and operation of the implemented security and privacy functions, controls, and/or mechanisms: [assignment: organization-defined training]. Developer-provided training applies to external and internal (in-house) developers. Training personnel is essential to ensuring the effectiveness of the controls implemented within organizational systems. Types of training include web-based and computer-based training, classroom-style training, and hands-on training (including micro-training). Organizations can also request training materials from developers to conduct in-house training or offer self-training to organizational personnel. Organizations determine the type of training necessary and may require different types of training for different security and privacy functions, controls, and mechanisms.",
          "Physical and environmental protection. Water damage protection. Protect the system from damage resulting from water leakage by providing master shutoff or isolation valves that are accessible, working properly, and known to key personnel. The provision of water damage protection primarily applies to organizational facilities that contain concentrations of system resources, including data centers, server rooms, and mainframe computer rooms. Isolation valves can be employed in addition to or in lieu of master shutoff valves to shut off water supplies in specific areas of concern without affecting the entire organization.",
          "Identification and authentication. Identification and authentication (organizational users) | access to accounts — replay resistant. Implement replay-resistant authentication mechanisms for access to privileged accounts and non-privileged accounts. Authentication processes resist replay attacks if it is impractical to achieve successful authentications by replaying previous authentication messages. Replay-resistant techniques include protocols that use nonces or challenges such as time synchronous or cryptographic authenticators.",
          "System and services acquisition. External system services | risk assessments and organizational approvals. (a) Conduct an organizational assessment of risk prior to the acquisition or outsourcing of information security services; and (b) verify that the acquisition or outsourcing of dedicated information security services is approved by [assignment: organization-defined personnel or roles]. Information security services include the operation of security devices, such as firewalls or key management services, as well as incident monitoring, analysis, and response. Risks assessed can include system, mission or business, security, privacy, or supply chain risks.",
          "Operations (ops). Managing vulnerabilities, malfunctions and errors – measurements, analyses and assessments of procedures. Basic criterion: The cloud service provider regularly measures, analyzes, and assesses the procedures with which vulnerabilities and incidents are handled to verify their continued suitability, appropriateness, and effectiveness. Results are evaluated at least quarterly by accountable departments at the cloud service provider to initiate continuous improvement actions and to verify their effectiveness. \n\nAdditional criterion: Supplementary information about the criterion includes common vulnerabilities and exposures (CVE) or similar methods that are suitable for documenting vulnerabilities and incidents. \n\nComplementary customer criterion: Notes on continuous auditing feasibility - Yes, the measurements, analyses, and evaluations are based on data that could be continuously queried in order to verify the plausibility of the results derived from them. The initiation and review of measures for continuous improvement require a manual audit.",
          "Configuration management. Access restrictions for change. Define, document, approve, and enforce physical and logical access restrictions associated with changes to the system. Changes to the hardware, software, or firmware components of systems or the operational procedures related to the system can potentially have significant effects on the security of the systems or individuals' privacy. Therefore, organizations permit only qualified and authorized individuals to access systems for purposes of initiating changes. Access restrictions include physical and logical access controls (see AC-3 and PE-3), software libraries, workflow automation, media libraries, abstract layers (i.e., changes implemented into external interfaces rather than directly into systems), and change windows (i.e., changes occur only during specified times).",
          "System and information integrity. Spam protection | automatic updates. Automatically update spam protection mechanisms [assignment: organization-defined frequency]. Using automated mechanisms to update spam protection mechanisms helps to ensure that updates occur on a regular basis and provide the latest content and protection capabilities.",
          "Incident response. Information spillage response | training. Provide information spillage response training [assignment: organization-defined frequency]. Organizations establish requirements for responding to information spillage incidents in incident response plans. Incident response training on a regular basis helps to ensure that organizational personnel understand their individual responsibilities and what specific actions to take when spillage incidents occur.",
          "Maintenance. Timely maintenance. Obtain maintenance support and/or spare parts for [assignment: organization-defined system components] within [assignment: organization-defined time period] of failure. Organizations specify the system components that result in increased risk to organizational operations and assets, individuals, other organizations, or the nation when the functionality provided by those components is not operational. Organizational actions to obtain maintenance support include having appropriate contracts in place.",
          "Maintenance. Maintenance tools | inspect tools. Inspect the maintenance tools used by maintenance personnel for improper or unauthorized modifications. Maintenance tools can be directly brought into a facility by maintenance personnel or downloaded from a vendor's website. If, upon inspection of the maintenance tools, organizations determine that the tools have been modified in an improper manner or the tools contain malicious code, the incident is handled consistent with organizational policies and procedures for incident handling.",
          "Contingency planning. Telecommunications services | single points of failure. Obtain alternate telecommunications services to reduce the likelihood of sharing a single point of failure with primary telecommunications services. In certain circumstances, telecommunications service providers or services may share the same physical lines, which increases the vulnerability of a single failure point. It is important to have provider transparency for the actual physical transmission capability for telecommunication services.",
          "Access control. Remote access | managed access control points. Route remote accesses through authorized and managed network access control points. Organizations consider the Trusted Internet Connections (TIC) initiative - DHS TIC requirements for external network connections, since limiting the number of access control points for remote access reduces attack surfaces.",
          "Physical and environmental protection. Water damage protection | automation support. Detect the presence of water near the system and alert [assignment: organization-defined personnel or roles] using [assignment: organization-defined automated mechanisms]. Automated mechanisms include notification systems, water detection sensors, and alarms.",
          "Physical and environmental protection. Emergency power. Provide an uninterruptible power supply to facilitate an orderly shutdown of the system or transition of the system to long-term alternate power in the event of a primary power source loss. An uninterruptible power supply (UPS) is an electrical system or mechanism that provides emergency power when there is a failure of the main power source. A UPS is typically used to protect computers, data centers, telecommunication equipment, or other electrical equipment where an unexpected power disruption could cause injuries, fatalities, serious mission or business disruption, or loss of data or information. A UPS differs from an emergency power system or backup generator in that the UPS provides near-instantaneous protection from unanticipated power interruptions from the main power source by providing energy stored in batteries, supercapacitors, or flywheels. The battery duration of a UPS is relatively short but provides sufficient time to start a standby power source, such as a backup generator, or properly shut down the system.",
          "Access control. Device lock | pattern-hiding displays. Conceal, via the device lock, information previously visible on the display with a publicly viewable image. The pattern-hiding display can include static or dynamic images, such as patterns used with screen savers, photographic images, solid colors, clock, battery life indicator, or a blank screen. Controlled unclassified information is not displayed.",
          "Identification and authentication. Authenticator management | password-based authentication. For password-based authentication: \n\n(a) Maintain a list of commonly-used, expected, or compromised passwords and update the list [assignment: organization-defined frequency] and when organizational passwords are suspected to have been compromised directly or indirectly. \n(b) Verify, when users create or update passwords, that the passwords are not found on the list of commonly-used, expected, or compromised passwords in ia-5 (1) (a). \n(c) Transmit passwords only over cryptographically-protected channels. \n(d) Store passwords using an approved salted key derivation function, preferably using a keyed hash. \n(e) Require immediate selection of a new password upon account recovery. \n(f) Allow user selection of long passwords and passphrases, including spaces and all printable characters. \n(g) Employ automated tools to assist the user in selecting strong password authenticators. \n(h) Enforce the following composition and complexity rules [assignment: organization-defined composition and complexity rules].\n\nPassword-based authentication applies to passwords regardless of whether they are used in single-factor or multi-factor authentication. Long passwords or passphrases are preferable over shorter passwords. Enforced composition rules provide marginal security benefits while decreasing usability. However, organizations may choose to establish certain rules for password generation (e.g., minimum character length for long passwords) under certain circumstances and can enforce this requirement in ia-5 (1) (h).\n\nAccount recovery can occur, for example, in situations when a password is forgotten. Cryptographically protected passwords include salted one-way cryptographic hashes of passwords. The list of commonly used, compromised, or expected passwords includes passwords obtained from previous breach corpuses, dictionary words, and repetitive or sequential characters. The list includes context-specific words, such as the name of the service, username, and derivatives thereof.",
          "System and communications protection. Cryptographic protection. a. Determine the organization-defined cryptographic uses; and b. Implement the following types of cryptography required for each specified cryptographic use: organization-defined types of cryptography for each specified cryptographic use. Cryptography can be employed to support a variety of security solutions, including the protection of classified information and controlled unclassified information, the provision and implementation of digital signatures, and the enforcement of information separation when authorized individuals have the necessary clearances but lack the necessary formal access approvals. Cryptography can also be used to support random number and hash generation. Generally applicable cryptographic standards include FIPS-validated cryptography and NSA-approved cryptography. For example, organizations that need to protect classified information may specify the use of NSA-approved cryptography. Organizations that need to provision and implement digital signatures may specify the use of FIPS-validated cryptography. Cryptography is implemented in accordance with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines.",
          "Configuration management. Configuration change control | automated documentation, notification, and prohibition of changes. Use [assignment: organization-defined automated mechanisms] to:\n(a) document proposed changes to the system.\n(b) notify [assignment: organization-defined approval authorities] of proposed changes to the system and request change approval.\n(c) highlight proposed changes to the system that have not been approved or disapproved within [assignment: organization-defined time period].\n(d) prohibit changes to the system until designated approvals are received.\n(e) document all changes to the system.\n(f) notify [assignment: organization-defined personnel] when approved changes to the system are completed.\nNone.",
          "Personnel security. Policy and procedures. A. Develop, document, and disseminate to organization-defined personnel or roles:\n1. Organization level personnel security policy that addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance. The policy should be consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines.\n2. Procedures to facilitate the implementation of the personnel security policy and the associated personnel security controls.\n\nB. Designate an organization-defined official to manage the development, documentation, and dissemination of the personnel security policy and procedures.\n\nC. Review and update the current personnel security:\n1. Policy, organization-defined frequency, and following organization-defined events.\n2. Procedures, organization-defined frequency, and following organization-defined events.\n\nPersonnel security policy and procedures for the controls in the PS family are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on their development.\n\nSecurity and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission level or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies reflecting the complex nature of organizations.\n\nProcedures can be established for security and privacy programs, for mission/business processes, and for systems, if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents.\n\nEvents that may precipitate an update to personnel security policy and procedures include, but are not limited to, assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Contingency planning. System recovery and reconstitution | restore within time period. Provide the capability to restore system components within [assignment: organization-defined restoration time periods] from configuration-controlled and integrity-protected information representing a known, operational state for the components. Restoration of system components includes reimaging, which restores the components to known, operational states.",
          "Physical and environmental protection. Policy and procedures. A. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]:\n\n1. [Selection (one or more): organization level; mission/business process-level; system-level] physical and environmental protection policy that:\n(a) Addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance; and\n(b) Is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines; and\n\n2. Procedures to facilitate the implementation of the physical and environmental protection policy and the associated physical and environmental protection controls;\n\nB. Designate an [assignment: organization-defined official] to manage the development, documentation, and dissemination of the physical and environmental protection policy and procedures; and\n\nC. Review and update the current physical and environmental protection:\n\n1. Policy [assignment: organization-defined frequency] and following [assignment: organization-defined events]; and\n\n2. Procedures [assignment: organization-defined frequency] and following [assignment: organization-defined events].\n\nPhysical and environmental protection policy and procedures address the controls in the PE family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of physical and environmental protection policy and procedures. Security and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations. Procedures can be established for security and privacy programs, for mission or business processes, and for systems if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents. Events that may precipitate an update to physical and environmental protection policy and procedures include assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Configuration management. Least functionality | prevent program execution. Prevent program execution in accordance with [selection (one or more): [assignment: organization-defined policies, rules of behavior, and/or access agreements regarding software program usage and restrictions]; rules authorizing the terms and conditions of software program usage]. Prevention of program execution addresses organizational policies, rules of behavior, and/or access agreements that restrict software usage and the terms and conditions imposed by the developer or manufacturer, including software licensing and copyrights. Restrictions include prohibiting auto-execute features, restricting roles allowed to approve program execution, permitting or prohibiting specific software programs, or restricting the number of program instances executed at the same time.",
          "System and communications protection. Fail in known state. Failures to achieve a organization-defined known system state for the following failures on the indicated components while preserving organization-defined system state information in failure: (list of organization-defined types of system failures on organization-defined system components). Failure in a known state addresses security concerns in accordance with the mission and business needs of organizations. Failure in a known state prevents the loss of confidentiality, integrity, or availability of information in the event of failures of organizational systems or system components. Failure in a known safe state helps to prevent systems from failing to a state that may cause injury to individuals or destruction to property. Preserving system state information facilitates system restart and return to the operational mode with less disruption of mission and business processes.",
          "System and information integrity. Memory protection. Implement the following controls to protect the system memory from unauthorized code execution: [assignment: organization-defined controls]. Some adversaries launch attacks with the intent of executing code in non-executable regions of memory or in memory locations that are prohibited. Controls employed to protect memory include data execution prevention and address space layout randomization. Data execution prevention controls can either be hardware-enforced or software-enforced, with hardware enforcement providing the greater strength of mechanism.",
          "System and communications protection. Collaborative computing devices and applications. a. Prohibit remote activation of collaborative computing devices and applications with the following exceptions: [assignment: organization-defined exceptions where remote activation is to be allowed]. \n\nb. Provide an explicit indication of use to users physically present at the devices. Collaborative computing devices and applications include remote meeting devices and applications, networked whiteboards, cameras, and microphones. The explicit indication of use includes signals to users when collaborative computing devices and applications are activated.",
          "Physical and environmental protection. Emergency lighting. Employ and maintain automatic emergency lighting for the system that activates in the event of a power outage or disruption and that covers emergency exits and evacuation routes within the facility. The provision of emergency lighting applies primarily to organizational facilities that contain concentrations of system resources, including data centers, server rooms, and mainframe computer rooms. Emergency lighting provisions for the system are described in the contingency plan for the organization. If emergency lighting for the system fails or cannot be provided, organizations should consider alternate processing sites for power-related contingencies.",
          "Personnel security. Position descriptions. Incorporate security and privacy roles and responsibilities into organizational position descriptions. Specification of security and privacy roles in individual organizational position descriptions facilitates clarity in understanding the security or privacy responsibilities associated with the roles and the role-based security and privacy training requirements for the roles.",
          "Maintenance. Maintenance personnel | individuals without appropriate access. (a) Implement procedures for the use of maintenance personnel that lack appropriate security clearances or are not U.S. citizens, that include the following requirements: \n\n(1) Maintenance personnel who do not have needed access authorizations, clearances, or formal access approvals are escorted and supervised during the performance of maintenance and diagnostic activities on the system by approved organizational personnel who are fully cleared, have appropriate access authorizations, and are technically qualified.\n\n(2) Prior to initiating maintenance or diagnostic activities by personnel who do not have needed access authorizations, clearances, or formal access approvals, all volatile information storage components within the system are sanitized and all nonvolatile storage media are removed or physically disconnected from the system and secured.\n\n(b) Develop and implement [assignment: organization-defined alternate controls] in the event a system component cannot be sanitized, removed, or disconnected from the system. \n\nProcedures for individuals who lack appropriate security clearances or who are not U.S. citizens are intended to deny visual and electronic access to classified or controlled unclassified information contained on organizational systems. \n\nProcedures for the use of maintenance personnel can be documented in security plans for the systems.",
          "Audit and accountability. Audit record review, analysis, and reporting | central review and analysis. Provide and implement the capability to centrally review and analyze audit records from multiple components within the system. Automated mechanisms for centralized reviews and analyses include Security Information and Event Management (SIEM) products.",
          "Supply chain risk management family. Tamper resistance and detection. Implement a tamper protection program for the system, system component, or system service. Anti-tamper technologies, tools, and techniques provide a level of protection for systems, system components, and services against many threats, including reverse engineering, modification, and substitution. Strong identification, combined with tamper resistance and/or tamper detection, is essential to protecting systems and components during distribution and when in use.",
          "Maintenance. Maintenance personnel. a. Establish a process for maintenance personnel authorization and maintain a list of authorized maintenance organizations or personnel. \nb. Verify that non-escorted personnel performing maintenance on the system possess the required access authorizations. \nc. Designate organizational personnel with required access authorizations and technical competence to supervise the maintenance activities of personnel who do not possess the required access authorizations. \n\nMaintenance personnel refers to individuals who perform hardware or software maintenance on organizational systems, while PE-2 addresses physical access for individuals whose maintenance duties place them within the physical protection perimeter of the systems. \n\nTechnical competence of supervising individuals relates to the maintenance performed on the systems, while having required access authorizations refers to maintenance on and near the systems. \n\nIndividuals not previously identified as authorized maintenance personnel—such as information technology manufacturers, vendors, systems integrators, and consultants—may require privileged access to organizational systems, such as when they are required to conduct maintenance activities with little or no notice. \n\nBased on organizational assessments of risk, organizations may issue temporary credentials to these individuals. Temporary credentials may be for one-time use or for very limited time periods.",
          "Risk assessment. Vulnerability monitoring and scanning | update vulnerabilities to be scanned. Update the system vulnerabilities to be scanned [selection (one or more): [assignment: organization-defined frequency]; prior to a new scan; when new vulnerabilities are identified and reported]. Due to the complexity of modern software, systems, and other factors, new vulnerabilities are discovered on a regular basis. It is important that newly discovered vulnerabilities are added to the list of vulnerabilities to be scanned to ensure that the organization can take steps to mitigate those vulnerabilities in a timely manner.",
          "Access control. Wireless access. a. Establish configuration requirements, connection requirements, and implementation guidance for each type of wireless access; and b. Authorize each type of wireless access to the system prior to allowing such connections. Wireless technologies include microwave, packet radio (ultra-high frequency or very high frequency), 802.11x, and Bluetooth. Wireless networks use authentication protocols that provide authenticator protection and mutual authentication.",
          "Media protection. Media use. a. [selection: Restrict; Prohibit] the use of [assignment: organization-defined types of system media] on [assignment: organization-defined systems or system components] using [assignment: organization-defined controls]; and b. Prohibit the use of portable storage devices in organizational systems when such devices have no identifiable owner. System media includes both digital and non-digital media. Digital media includes diskettes, magnetic tapes, flash drives, compact discs, digital versatile discs, and removable hard disk drives. Non-digital media includes paper and microfilm. Media use protections also apply to mobile devices with information storage capabilities. In contrast to MP-2, which restricts user access to media, MP-7 restricts the use of certain types of media on systems. For example, restricting or prohibiting the use of flash drives or external hard disk drives. Organizations use technical and non-technical controls to restrict the use of system media. Organizations may restrict the use of portable storage devices, for example, by using physical cages on workstations to prohibit access to certain external ports or disabling or removing the ability to insert, read, or write to such devices. Organizations may also limit the use of portable storage devices to only approved devices, including devices provided by the organization, devices provided by other approved organizations, and devices that are not personally owned. Finally, organizations may restrict the use of portable storage devices based on the type of device. For example, by prohibiting the use of writable, portable storage devices and implementing this restriction by disabling or removing the capability to write to such devices. Requiring identifiable owners for storage devices reduces the risk of using such devices by allowing organizations to assign responsibility for addressing known vulnerabilities in the devices.",
          "System and information integrity. System monitoring | unauthorized network services. (a) Detect network services that have not been authorized or approved by [assignment: organization-defined authorization or approval processes]; and (b) [selection (one or more): audit; alert [assignment: organization-defined personnel or roles]] when detected. Unauthorized or unapproved network services include services in service-oriented architectures that lack organizational verification or validation and may therefore be unreliable or serve as malicious rogues for valid services.",
          "System and communications protection. System time synchronization. Synchronize system clocks within and between systems and system components. Time synchronization of system clocks is essential for the correct execution of many system services, including identification and authentication processes that involve certificates and time-of-day restrictions as part of access control. Denial of service or failure to deny expired credentials may result without properly synchronized clocks within and between systems and system components. Time is commonly expressed in Coordinated Universal Time (UTC), a modern continuation of Greenwich Mean Time (GMT), or local time with an offset from UTC. The granularity of time measurements refers to the degree of synchronization between system clocks and reference clocks, such as clocks synchronizing within hundreds of milliseconds or tens of milliseconds. Organizations may define different time granularities for system components. Time service can be critical to other security capabilities—such as access control and identification and authentication—depending on the nature of the mechanisms used to support the capabilities.",
          "Incident response. Incident handling | information correlation. Correlate incident information and individual incident responses to achieve an organization-wide perspective on incident awareness and response. Sometimes, a threat event, such as a hostile cyber-attack, can only be observed by bringing together information from different sources, including various reports and reporting procedures established by organizations.",
          "System and information integrity. Flaw remediation | time to remediate flaws and benchmarks for corrective actions. (a) Measure the time between flaw identification and flaw remediation. \n(b) Establish the following benchmarks for taking corrective actions: [assignment: organization-defined benchmarks]. \n\nOrganizations determine the average time it takes to correct system flaws after they have been identified. Subsequently, they establish organizational benchmarks (i.e., time frames) for taking corrective actions. Benchmarks can be determined based on the type of flaw or the severity of the potential vulnerability, especially if the flaw can be exploited.",
          "Identification and authentication. Authenticator management | protection of authenticators. Protect authenticators commensurate with the security category of the information to which the use of the authenticator permits access. For systems that contain multiple security categories of information without reliable physical or logical separation between categories, authenticators used to grant access to the systems are protected commensurate with the highest security category of information on the systems. Security categories of information are determined as part of the security categorization process.",
          "Physical security (ps). Protection against interruptions caused by power failures and other such risks. Basic criterion: Measures to prevent the failure of the technical supply facilities required for the operation of system components with which information from cloud customers is processed are documented and set up in accordance with the security requirements of the cloud service provider (cf. PS-01 Security Concept). The following aspects should be considered:\n\n- Operational redundancy (n+1) in power and cooling supply.\n- Use of appropriately sized uninterruptible power supplies (UPS) and emergency power systems (NEA) designed to ensure that all data remains undamaged in the event of a power failure.\n- The functionality of UPS and NEA should be checked at least annually by suitable tests and exercises (cf. BCM-04 – Verification, Updating, and Testing of Business Continuity).\n- Maintenance (servicing, inspection, repair) of the utilities should be conducted in accordance with the manufacturer’s recommendations.\n- Protection of power supply and telecommunications lines against interruption, interference, damage, and eavesdropping.\n- The protection should be checked regularly, but at least every two years, as well as in the case of suspected manipulation by qualified personnel. The following aspects should be considered:\n  - Traces of violent attempts to open closed distributors.\n  - Up-to-dateness of the documentation in the distribution list.\n  - Conformity of the actual wiring and patching with the documentation.\n  - The short-circuits and earthing of unneeded cables are intact.\n  - Absence of impermissible installations and modifications.\n\nAdditional criterion: Uninterruptible power supplies (UPS) and emergency power supplies (NPS) should be designed to meet the availability requirements defined in the Service Level Agreement. The cooling supply should be designed in such a way that the permissible operating and environmental parameters are also ensured on at least five consecutive days with the highest outside temperatures measured to date within a radius of at least 50 km around the locations of the premises and buildings, with a safety margin of 3K (in relation to the outside temperature). The cloud service provider has previously determined the highest outdoor temperatures measured to date (cf. PS-01 Security Concept). The connection to the telecommunications network should have sufficient redundancy to ensure that the failure of a telecommunications network does not impair the security or performance of the cloud service provider.\n\nSupplementary information about the criterion: Measures to prevent the failure of the technical supply facilities include power supply, cooling, fire-fighting technology, telecommunications, security technology, etc. Cloud service providers can ensure that all data remains undamaged in the event of a power failure by shutting down servers following a defined procedure. Power supply and telecommunications lines can be protected against interruption, interference, damage, and eavesdropping by, for example, underground supply via different supply routes.\n\nComplementary customer criterion: Notes on continuous auditing feasibility: Partially, the physical security of premises, as well as failure precautions of the technical supply facilities, should be ensured on-site by an inspection of the data center. Therefore, a continuous examination is achievable only to a limited extent. If the built-in technology for failure prevention produces evaluable log data, this requirement can partly be audited continuously. However, this does not replace an inspection. Otherwise, a continuous inspection can be carried out at least partially by indicating the last inspection date.",
          "Supply chain risk management family. Notification agreements. Establish agreements and procedures with entities involved in the supply chain for the system, system component, or system service for the [selection (one or more): notification of supply chain compromises; results of assessments or audits; [assignment: organization-defined information]]. The establishment of agreements and procedures facilitates communications among supply chain entities. Early notification of compromises and potential compromises in the supply chain that can potentially adversely affect or have adversely affected organizational systems or system components is essential for organizations to effectively respond to such incidents. The results of assessments or audits may include open-source information that contributed to a decision or result, and could be used to help the supply chain entity resolve a concern or improve its processes.",
          "Contingency planning. Alternate storage site | accessibility. Identify potential accessibility problems to the alternate storage site in the event of an area-wide disruption or disaster and outline explicit mitigation actions. Area-wide disruptions refer to those types of disruptions that are broad in geographic scope, with such determinations made by organizations based on organizational assessments of risk.\n\nExplicit mitigation actions include duplicating backup information at other alternate storage sites if access problems occur at originally designated alternate sites. Additionally, planning for physical access to retrieve backup information is necessary if electronic accessibility to the alternate site is disrupted.",
          "System and information integrity. Error handling. a. Generate error messages that provide information necessary for corrective actions without revealing information that could be exploited, and \nb. Reveal error messages only to organization-defined personnel or roles. Organizations should consider the structure and content of error messages. The extent to which systems can handle error conditions is guided and informed by organizational policy and operational requirements. Exploitable information includes stack traces and implementation details. Erroneous logon attempts with passwords mistakenly entered as the username, mission or business information that can be derived from, if not stated explicitly by, the information recorded, and personally identifiable information such as account numbers, social security numbers, and credit card numbers. Error messages may also provide a covert channel for transmitting information.",
          "Contingency planning. Alternate storage site | recovery time and recovery point objectives. Configure the alternate storage site to facilitate recovery operations in accordance with recovery time and recovery point objectives. Organizations establish recovery time and recovery point objectives as part of contingency planning. Configuration of the alternate storage site includes physical facilities and the systems supporting recovery operations that ensure accessibility and correct execution.",
          "System and communications protection. Boundary protection | host-based protection. Implement organization-defined host-based boundary protection mechanisms at organization-defined system components. Host-based boundary protection mechanisms include host-based firewalls. System components that employ host-based boundary protection mechanisms include servers, workstations, notebook computers, and mobile devices.",
          "Audit and accountability. Response to audit logging process failures | real-time alerts. Provide an alert within [assignment: organization-defined real-time period] to [assignment: organization-defined personnel, roles, and/or locations] when the following audit failure events occur: [assignment: organization-defined audit logging failure events requiring real-time alerts]. Alerts provide organizations with urgent messages. Real-time alerts provide these messages at information technology speed (i.e., the time from event detection to alert occurs in seconds or less).",
          "Access control. Account management | automated temporary and emergency account management. Automatically remove temporary and emergency accounts after an organization-defined time period for each type of account. Management of temporary and emergency accounts includes the removal or disabling of such accounts automatically after a predefined time period, rather than at the convenience of the system administrator. Automatic removal or disabling of accounts provides a more consistent implementation.",
          "Access control. Least privilege | privilege levels for code execution. Prevent the following software from executing at higher privilege levels than users executing the software: [assignment: organization-defined software]. In certain situations, software applications or programs need to execute with elevated privileges to perform required functions. However, depending on the software functionality and configuration, if the privileges required for execution are at a higher level than the privileges assigned to organizational users invoking such applications or programs, those users may indirectly be provided with greater privileges than assigned.",
          "Incident response. Incident response training | automated training environments. Provide an incident response training environment using [assignment: organization-defined automated mechanisms]. Automated mechanisms can provide a more thorough and realistic incident response training environment. This can be accomplished, for example, by providing more complete coverage of incident response issues, selecting more realistic training scenarios and environments, and stressing the response capability.",
          "Access control. Account management | disable accounts for high-risk individuals. Disable accounts of individuals within [assignment: organization-defined time period] of discovery of [assignment: organization-defined significant risks]. Users who pose a significant security and/or privacy risk include individuals for whom reliable evidence indicates either the intention to use authorized access to systems to cause harm or through whom adversaries will cause harm. Such harm includes adverse impacts to organizational operations, organizational assets, individuals, other organizations, or the nation. Close coordination among system administrators, legal staff, human resource managers, and authorizing officials is essential when disabling system accounts for high-risk individuals.",
          "Access control. Information sharing. a. Enable authorized users to determine whether access authorizations assigned to a sharing partner match the information's access and use restrictions for [assignment: organization-defined information sharing circumstances where user discretion is required]. \nB. Employ [assignment: organization-defined automated mechanisms or manual processes] to assist users in making information sharing and collaboration decisions. Information sharing applies to information that may be restricted in some manner based on some formal or administrative determination. Examples of such information include contract-sensitive information, classified information related to special access programs or compartments, privileged information, proprietary information, and personally identifiable information. Security and privacy risk assessments, as well as applicable laws, regulations, and policies, can provide useful inputs to these determinations. Depending on the circumstances, sharing partners may be defined at the individual, group, or organizational level. Information may be defined by content, type, security category, or special access program or compartment. Access restrictions may include non-disclosure agreements (NDA). Information flow techniques and security attributes may be used to provide automated assistance to users making sharing and collaboration decisions.",
          "Access control. Remote access | privileged commands and access. (a) Authorize the execution of privileged commands and access to security-relevant information via remote access only in a format that provides accessible evidence and for the following needs: [assignment: organization-defined needs]. \n\n(b) Document the rationale for remote access in the security plan for the system. Remote access to systems represents a significant potential vulnerability that can be exploited by adversaries. As such, restricting the execution of privileged commands and access to security-relevant information via remote access reduces the exposure of the organization and the susceptibility to threats by adversaries to the remote access capability.",
          "System and services acquisition. Development process, standards, and tools. a. Require the developer of the system, system component, or system service to follow a documented development process that:\n1. Explicitly addresses security and privacy requirements.\n2. Identifies the standards and tools used in the development process.\n3. Documents the specific tool options and tool configurations used in the development process.\n4. Documents, manages, and ensures the integrity of changes to the process and/or tools used in development.\n\nb. Review the development process, standards, tools, tool options, and tool configurations [assignment: organization-defined frequency] to determine if the process, standards, tools, tool options, and tool configurations selected and employed can satisfy the following security and privacy requirements: [assignment: organization-defined security and privacy requirements]. \n\nDevelopment tools include programming languages and computer-aided design systems. Reviews of development processes include the use of maturity models to determine the potential effectiveness of such processes. Maintaining the integrity of changes to tools and processes facilitates effective supply chain risk assessment and mitigation. Such integrity requires configuration control throughout the system development life cycle to track authorized changes and prevent unauthorized changes.",
          "System and information integrity. System monitoring | correlate monitoring information. Correlating information from monitoring tools and mechanisms employed throughout the system is crucial. Doing so can provide a more comprehensive view of system activity. It allows for the identification of attack patterns that may otherwise go unnoticed. To achieve this, it is important to understand the capabilities and limitations of diverse monitoring tools and mechanisms. By maximizing the use of the information generated by these tools, organizations can develop, operate, and maintain effective monitoring programs. This correlation of monitoring information becomes even more critical during technology transitions, such as the shift from IPv4 to IPv6 network protocols.",
          "Audit and accountability. Protection of audit information | cryptographic protection. Implement cryptographic mechanisms to protect the integrity of audit information and audit tools. Cryptographic mechanisms used for protecting the integrity of audit information include signed hash functions using asymmetric cryptography. This enables the distribution of the public key to verify the hash information while maintaining the confidentiality of the secret key used to generate the hash.",
          "System and communications protection. Boundary protection. a. Monitor and control communications at the external managed interfaces to the system and at key internal managed interfaces within the system. \nb. Implement subnetworks for publicly accessible system components that are physically or logically separated from internal organizational networks. \nc. Connect to external networks or systems only through managed interfaces consisting of boundary protection devices arranged in accordance with an organizational security and privacy architecture. Managed interfaces include gateways, routers, firewalls, guards, network-based malicious code analysis, virtualization systems, or encrypted tunnels implemented within a security architecture. \nSubnetworks that are physically or logically separated from internal networks are referred to as demilitarized zones or DMZs. \nRestricting or prohibiting interfaces within organizational systems includes restricting external web traffic to designated web servers within managed interfaces, prohibiting external traffic that appears to be spoofing internal addresses, and prohibiting internal traffic that appears to be spoofing external addresses. \nSP 800-189 provides additional information on source address validation techniques to prevent ingress and egress of traffic with spoofed addresses. \nCommercial telecommunications services are provided by network components and consolidated management systems shared by customers. These services may also include third party-provided access lines and other service elements. \nSuch services may represent sources of increased risk despite contract security provisions. \nBoundary protection may be implemented as a common control for all or part of an organizational network, such that the boundary to be protected is greater than a system-specific boundary (i.e., an authorization boundary).",
          "System and information integrity. System monitoring | analyze communications traffic anomalies. Analyze outbound communications traffic at the external interfaces to the system and selected (organization-defined interior points within the system) to discover anomalies. Organization-defined interior points include subnetworks and subsystems. Anomalies within organizational systems include large file transfers, long-time persistent connections, attempts to access information from unexpected locations, the use of unusual protocols and ports, the use of unmonitored network protocols (e.g., IPv6 usage during IPv4 transition), and attempted communications with suspected malicious external addresses.",
          "Audit and accountability. Audit record review, analysis, and reporting. a. Review and analyze system audit records [assignment: organization-defined frequency] for indications of [assignment: organization-defined inappropriate or unusual activity] and the potential impact of the inappropriate or unusual activity. \nb. Report findings to [assignment: organization-defined personnel or roles]. \nc. Adjust the level of audit record review, analysis, and reporting within the system when there is a change in risk based on law enforcement information, intelligence information, or other credible sources of information.\n\nAudit record review, analysis, and reporting covers information security- and privacy-related logging performed by organizations, including logging that results from the monitoring of account usage, remote access, wireless connectivity, mobile device connection, configuration settings, system component inventory, use of maintenance tools and non-local maintenance, physical access, temperature and humidity, equipment delivery and removal, communications at system interfaces, and use of mobile code or voice over internet protocol (VoIP). Findings can be reported to organizational entities that include the incident response team, help desk, and security or privacy offices. If organizations are prohibited from reviewing and analyzing audit records or unable to conduct such activities, the review or analysis may be carried out by other organizations granted such authority. The frequency, scope, and/or depth of the audit record review, analysis, and reporting may be adjusted to meet organizational needs based on new information received.",
          "Access control. Least privilege | network access to privileged commands. Authorize network access to [assignment: organization-defined privileged commands] only for [assignment: organization-defined compelling operational needs] and document the rationale for such access in the security plan for the system. Network access is any access across a network connection, in lieu of local access (i.e., the user being physically present at the device).",
          "Audit and accountability. Audit record reduction and report generation. Provide and implement an audit record reduction and report generation capability that: \n\na. Supports on-demand audit record review, analysis, and reporting requirements, as well as after-the-fact investigations of incidents. \n\nb. Does not alter the original content or time ordering of audit records. \n\nAudit record reduction is a process that manipulates collected audit log information and organizes it into a summary format that is more meaningful to analysts. \n\nAudit record reduction and report generation capabilities do not always emanate from the same system or the same organizational entities that conduct audit logging activities. \n\nThe audit record reduction capability includes modern data mining techniques with advanced data filters to identify anomalous behavior in audit records. \n\nThe report generation capability provided by the system can generate customizable reports. \n\nTime ordering of audit records can be an issue if the granularity of the timestamp in the record is insufficient.",
          "Identification and authentication. Identification and authentication (organizational users) | individual authentication with group authentication. When shared accounts or authenticators are employed, require users to be individually authenticated before granting access to the shared accounts or resources. Individual authentication prior to shared group authentication mitigates the risk of using group accounts or authenticators.",
          "Physical and environmental protection. Location of system components. Position system components within the facility to minimize potential damage from physical and environmental hazards, such as floods, fires, tornadoes, earthquakes, hurricanes, terrorism, vandalism, an electromagnetic pulse, electrical interference, and other forms of incoming electromagnetic radiation. Also, consider the location of entry points where unauthorized individuals may be near systems, even if they are not granted access. Such proximity can increase the risk of unauthorized access to organizational communications using wireless packet sniffers or microphones, or unauthorized disclosure of information.",
          "Risk assessment. Vulnerability monitoring and scanning | public disclosure program. Establish a public reporting channel for receiving reports of vulnerabilities in organizational systems and system components. The reporting channel is publicly discoverable and contains clear language authorizing good-faith research and the disclosure of vulnerabilities to the organization. The organization does not condition its authorization on an expectation of indefinite non-disclosure to the public by the reporting entity. However, the organization may request a specific time period to properly remediate the vulnerability.",
          "Access control. Access control for mobile devices | full device or container-based encryption. Employ full-device encryption or container-based encryption to protect the confidentiality and integrity of information on organization-defined mobile devices. Container-based encryption provides a more fine-grained approach to data and information encryption on mobile devices, including encrypting selected data structures such as files, records, or fields.",
          "Access control. Account management | automated audit actions. Automatically audit account creation, modification, enabling, disabling, and removal actions. Account management audit records are defined in accordance with AU-2 and reviewed, analyzed, and reported in accordance with AU-6.",
          "System and services acquisition. System documentation. a. Obtain or develop administrator documentation for the system, system component, or system service that describes:\n1. Secure configuration, installation, and operation of the system, component, or service.\n2. Effective use and maintenance of security and privacy functions and mechanisms.\n3. Known vulnerabilities regarding configuration and use of administrative or privileged functions.\n\nb. Obtain or develop user documentation for the system, system component, or system service that describes:\n1. User-accessible security and privacy functions and mechanisms and how to effectively use those functions and mechanisms.\n2. Methods for user interaction, which enable individuals to use the system, component, or service in a more secure manner and protect individual privacy.\n3. User responsibilities in maintaining the security of the system, component, or service and privacy of individuals.\n\nc. Document attempts to obtain system, system component, or system service documentation when such documentation is either unavailable or nonexistent and take [assignment: organization-defined actions] in response.\n\nd. Distribute documentation to [assignment: organization-defined personnel or roles]. System documentation helps personnel understand the implementation and operation of controls. Organizations consider establishing specific measures to determine the quality and completeness of the content provided. System documentation may be used to support the management of supply chain risk, incident response, and other functions.\n\nPersonnel or roles that require documentation include system owners, system security officers, and system administrators. Attempts to obtain documentation include contacting manufacturers or suppliers and conducting web-based searches. The inability to obtain documentation may occur due to the age of the system or component or the lack of support from developers and contractors. When documentation cannot be obtained, organizations may need to recreate the documentation if it is essential to the implementation or operation of the controls.\n\nThe protection provided for the documentation is commensurate with the security category or classification of the system. Documentation that addresses system vulnerabilities may require an increased level of protection. Secure operation of the system includes initially starting the system and resuming secure system operation after a lapse in system operation.",
          "Maintenance. Nonlocal maintenance | comparable security and sanitization. (a) Require that nonlocal maintenance and diagnostic services be performed from a system that implements a security capability comparable to the capability implemented on the system being serviced. \n(b) Remove the component to be serviced from the system prior to nonlocal maintenance or diagnostic services, sanitize the component (for organizational information), and after the service is performed, inspect and sanitize the component (for potentially malicious software) before reconnecting the component to the system. \n\nComparable security capability on systems, diagnostic tools, and equipment providing maintenance services implies that the implemented controls on those systems, tools, and equipment are at least as comprehensive as the controls on the system being serviced.",
          "Incident response. Incident handling | automated incident handling processes. Support the incident handling process using organization-defined automated mechanisms. Automated mechanisms that support incident handling processes include online incident management systems and tools that support the collection of live response data, full network packet capture, and forensic analysis.",
          "Personnel security. Personnel screening | information requiring special protective measures. Verify that individuals accessing a system processing, storing, or transmitting information requiring special protection. (a) Have valid access authorizations that are demonstrated by assigned official government duties. And (b) Satisfy [assignment: organization-defined additional personnel screening criteria]. \n\nOrganizational information that requires special protection includes controlled unclassified information. Personnel security criteria include position sensitivity background screening requirements.",
          "Incident response. Incident response assistance | automation support for availability of information and support. Increase the availability of incident response information and support using [assignment: organization-defined automated mechanisms]. Automated mechanisms can provide a push or pull capability for users to obtain incident response assistance. For example, individuals may have access to a website to query the assistance capability, or the assistance capability can proactively send incident response information to users (general distribution or targeted) as part of increasing understanding of current response capabilities and support.",
          "Maintenance. Controlled maintenance | automated maintenance activities. (a) Schedule, conduct, and document maintenance, repair, and replacement actions for the system using [assignment: organization-defined automated mechanisms]. \n(b) Produce up-to-date, accurate, and complete records of all maintenance, repair, and replacement actions requested, scheduled, in process, and completed. \nThe use of automated mechanisms to manage and control system maintenance programs and activities helps to ensure the generation of timely, accurate, complete, and consistent maintenance records.",
          "System and services acquisition. External system services | identification of functions, ports, protocols, and services. Require providers of the following external system services to identify the functions, ports, protocols, and other services required for the use of such services: [assignment: organization-defined external system services]. Information from external service providers regarding the specific functions, ports, protocols, and services used in the provision of such services can be useful when the need arises to understand the trade-offs involved in restricting certain functions and services or blocking certain ports and protocols.",
          "Supply chain risk management family. Component authenticity | anti-counterfeit training. Train organization-defined personnel or roles to detect counterfeit system components (including hardware, software, and firmware). None.",
          "Media protection. Media sanitization | equipment testing. Test sanitization equipment and procedures [assignment: organization-defined frequency] to ensure that the intended sanitization is being achieved. Testing of sanitization equipment and procedures may be conducted by qualified and authorized external entities, including federal agencies or external service providers.",
          "Audit and accountability. Audit record review, analysis, and reporting | automated process integration. Integrate audit record review, analysis, and reporting processes using [assignment: organization-defined automated mechanisms]. Organizational processes that benefit from integrated audit record review, analysis, and reporting include incident response, continuous monitoring, contingency planning, investigation, and response to suspicious activities, and Inspector General audits.",
          "Security assessment and authorization. Plan of action and milestones. A. Develop a plan of action and milestones for the system to document the planned remediation actions of the organization. This will help to correct weaknesses or deficiencies noted during the assessment of the controls and to reduce or eliminate known vulnerabilities in the system. \n\nB. Update the existing plan of action and milestones, at a frequency determined by the organization, based on the findings from control assessments, independent audits or reviews, and continuous monitoring activities. \n\nPlans of action and milestones are useful for any type of organization to track planned remedial actions. They are required in authorization packages and are subject to federal reporting requirements established by the OMB.",
          "Physical and environmental protection. Environmental controls. a. Maintain [selection (one or more): temperature; humidity; pressure; radiation; [assignment: organization-defined environmental control]] levels within the facility where the system resides at [assignment: organization-defined acceptable levels]. \n\nb. Monitor environmental control levels [assignment: organization-defined frequency]. \n\nThe provision of environmental controls applies primarily to organizational facilities that contain concentrations of system resources (e.g., data centers, mainframe computer rooms, and server rooms). Insufficient environmental controls, especially in very harsh environments, can have a significant adverse impact on the availability of systems and system components that are needed to support organizational mission and business functions.",
          "System and communications protection. Process isolation. Maintain a separate execution domain for each executing system process. Systems can maintain separate execution domains for each executing process by assigning each process a separate address space. Each system process has a distinct address space so that communication between processes is performed in a manner controlled through the security functions, and one process cannot modify the executing code of another process. Maintaining separate execution domains for executing processes can be achieved, for example, by implementing separate address spaces. Process isolation technologies, including sandboxing or virtualization, logically separate software and firmware from other software, firmware, and data. Process isolation helps limit the access of potentially untrusted software to other system resources. The capability to maintain separate execution domains is available in commercial operating systems that employ multi-state processor technologies.",
          "Access control. Account management | disable accounts. Disable accounts within [assignment: organization-defined time period] when the accounts: (a) have expired; (b) are no longer associated with a user or individual; (c) are in violation of organizational policy; or (d) have been inactive for [assignment: organization-defined time period]. Disabling expired, inactive, or otherwise anomalous accounts supports the concepts of least privilege and least functionality, which reduce the attack surface of the system.",
          "System and communications protection. Policy and procedures. A. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]: 1. [Selection (one or more): organization level; mission/business process-level; system-level] system and communications protection policy that: (a) addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance; and (b) is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines; and 2. Procedures to facilitate the implementation of the system and communications protection policy and the associated system and communications protection controls.\n\nB. Designate an [assignment: organization-defined official] to manage the development, documentation, and dissemination of the system and communications protection policy and procedures.\n\nC. Review and update the current system and communications protection: 1. Policy [assignment: organization-defined frequency] and following [assignment: organization-defined events]; and 2. Procedures [assignment: organization-defined frequency] and following [assignment: organization-defined events].\n\nSystem and communications protection policy and procedures address the controls in the SC family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of system and communications protection policy and procedures. Security and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations. Procedures can be established for security and privacy programs, for mission or business processes, and for systems, if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents. Events that may precipitate an update to system and communications protection policy and procedures include assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Physical and environmental protection. Access control for output devices. Control physical access to output from [assignment: organization-defined output devices] to prevent unauthorized individuals from obtaining the output. Controlling physical access to output devices includes placing output devices in locked rooms or other secured areas with keypad or card reader access controls and allowing access to authorized individuals only. Also, placing output devices in locations that can be monitored by personnel, installing monitor or screen filters, and using headphones. Examples of output devices include monitors, printers, scanners, audio devices, facsimile machines, and copiers.",
          "Contingency planning. Alternate processing site | preparation for use. Prepare the alternate processing site so that the site can serve as the operational site supporting essential mission and business functions. Site preparation includes establishing configuration settings for systems at the alternate processing site consistent with the requirements for such settings at the primary site and ensuring that essential supplies and logistical considerations are in place.",
          "System and information integrity. Malicious code protection. A. Implement [selection (one or more): signature-based; non-signature-based] malicious code protection mechanisms at system entry and exit points to detect and eradicate malicious code. \nB. Automatically update malicious code protection mechanisms as new releases are available in accordance with organizational configuration management policy and procedures. \nC. Configure malicious code protection mechanisms to: \n1. Perform periodic scans of the system [assignment: organization-defined frequency] and real-time scans of files from external sources at [selection (one or more): endpoint; network entry and exit points] as the files are downloaded, opened, or executed in accordance with organizational policy. \n2. [selection (one or more): block malicious code; quarantine malicious code; take [assignment: organization-defined action]]; and send an alert to [assignment: organization-defined personnel or roles] in response to malicious code detection. \nD. Address the receipt of false positives during malicious code detection and eradication and the resulting potential impact on the availability of the system. \n\nSystem entry and exit points include firewalls, remote access servers, workstations, electronic mail servers, web servers, proxy servers, notebook computers, and mobile devices. \n\nMalicious code includes viruses, worms, trojan horses, and spyware. Malicious code can also be encoded in various formats contained within compressed or hidden files or hidden in files using techniques such as steganography. Malicious code can be inserted into systems in a variety of ways, including by electronic mail, the world-wide web, and portable storage devices. Malicious code insertions occur through the exploitation of system vulnerabilities. \n\nA variety of technologies and methods exist to limit or eliminate the effects of malicious code. Malicious code protection mechanisms include both signature- and non-signature-based technologies. Non-signature-based detection mechanisms include artificial intelligence techniques that use heuristics to detect, analyze, and describe the characteristics or behavior of malicious code and to provide controls against such code for which signatures do not yet exist or for which existing signatures may not be effective. Malicious code for which active signatures do not yet exist or may be ineffective includes polymorphic malicious code (i.e., code that changes signatures when it replicates). Non-signature-based mechanisms also include reputation-based technologies. \n\nIn addition to the above technologies, pervasive configuration management, comprehensive software integrity controls, and anti-exploitation software may be effective in preventing the execution of unauthorized code. Malicious code may be present in commercial off-the-shelf software as well as custom-built software and could include logic bombs, backdoors, and other types of attacks that could affect organizational mission and business functions. \n\nIn situations where malicious code cannot be detected by detection methods or technologies, organizations rely on other types of controls, including secure coding practices, configuration management and control, trusted procurement processes, and monitoring practices to ensure that software does not perform functions other than the functions intended. \n\nOrganizations may determine that, in response to the detection of malicious code, different actions may be warranted. For example, organizations can define actions in response to malicious code detection during periodic scans, the detection of malicious downloads, or the detection of maliciousness when attempting to open or execute files.",
          "Access control. Account management | restrictions on use of shared and group accounts. Only permit the use of shared and group accounts that meet [assignment: organization-defined conditions for establishing shared and group accounts]. Before permitting the use of shared or group accounts, organizations should consider the increased risk due to the lack of accountability associated with such accounts.",
          "System and information integrity. Security alerts, advisories, and directives. a. Receive system security alerts, advisories, and directives from [assignment: organization-defined external organizations] on an ongoing basis. \nb. Generate internal security alerts, advisories, and directives as deemed necessary. \nc. Disseminate security alerts, advisories, and directives to: [selection (one or more): [assignment: organization-defined personnel or roles]; [assignment: organization-defined elements within the organization]; [assignment: organization-defined external organizations]]. \nd. Implement security directives in accordance with established time frames, or notify the issuing organization of the degree of noncompliance. \n\nThe Cybersecurity and Infrastructure Security Agency (CISA) generates security alerts and advisories to maintain situational awareness throughout the federal government. Security directives are issued by OMB or other designated organizations with the responsibility and authority to issue such directives. Compliance with security directives is essential due to the critical nature of many of these directives and the potential (immediate) adverse effects on organizational operations and assets, individuals, other organizations, and the nation should the directives not be implemented in a timely manner. \n\nExternal organizations include supply chain partners, external mission or business partners, external service providers, and other peer or supporting organizations.",
          "Identification and authentication. Identity proofing | in-person validation and verification. Require that the validation and verification of identity evidence be conducted in person, before a designated registration authority. In-person proofing reduces the likelihood of fraudulent credentials being issued because it requires the physical presence of individuals, the presentation of physical identity documents, and actual face-to-face interactions with designated registration authorities.",
          "Security assessment and authorization. Continuous monitoring | independent assessment. Employ independent assessors or assessment teams to monitor the controls in the system on an ongoing basis. Organizations maximize the value of control assessments by requiring that assessments be conducted by assessors with appropriate levels of independence. The level of required independence is based on organizational continuous monitoring strategies. Assessor independence provides a degree of impartiality to the monitoring process. To achieve such impartiality, assessors do not create a mutual or conflicting interest with the organizations where the assessments are being conducted, assess their own work, act as management or employees of the organizations they are serving, or place themselves in advocacy positions for the organizations acquiring their services.",
          "Contingency planning. Alternate storage site | separation from primary site. Identify an alternate storage site that is sufficiently separated from the primary storage site to reduce susceptibility to the same threats. Threats that affect alternate storage sites are defined in organizational risk assessments and include natural disasters, structural failures, hostile attacks, and errors of omission or commission. Organizations determine what is considered a sufficient degree of separation between primary and alternate storage sites based on the types of threats that are of concern. For threats such as hostile attacks, the degree of separation between sites is less relevant.",
          "Access control. Wireless access | disable wireless networking. Disable, when not intended for use, wireless networking capabilities embedded within system components prior to issuance and deployment. Wireless networking capabilities that are embedded within system components represent a significant potential vulnerability that can be exploited by adversaries. Disabling wireless capabilities when not needed for essential organizational missions or functions can reduce susceptibility to threats by adversaries involving wireless technologies.",
          "Configuration management. Information location | automated tools to support information location. Use automated tools to identify organization-defined information by information type on organization-defined system components to ensure controls are in place to protect organizational information and individual privacy. The use of automated tools helps to increase the effectiveness and efficiency of the information location capability implemented within the system. Automation also helps organizations manage the data produced during information location activities and share such information across the organization. The output of automated information location tools can be used to guide and inform system architecture and design decisions.",
          "System and information integrity. Software, firmware, and information integrity | automated notifications of integrity violations. Employ automated tools that provide notification to [assignment: organization-defined personnel or roles] upon discovering discrepancies during integrity verification. The employment of automated tools to report system and information integrity violations and to notify organizational personnel in a timely manner is essential to effective risk response. Personnel with an interest in system and information integrity violations include mission and business owners, system owners, senior agency information security official, senior agency official for privacy, system administrators, software developers, systems integrators, information security officers, and privacy officers.",
          "Configuration management. Configuration settings | respond to unauthorized changes. Take the following actions in response to unauthorized changes to organization-defined configuration settings: alerting designated organizational personnel, restoring established configuration settings, or halting affected system processing in extreme cases.",
          "System and information integrity. Security alerts, advisories, and directives | automated alerts and advisories. Broadcast security alert and advisory information throughout the organization using organization-defined automated mechanisms. The significant number of changes to organizational systems and environments of operation requires the dissemination of security-related information to a variety of organizational entities that have a direct interest in the success of the organizational mission and business functions. Based on information provided by security alerts and advisories, changes may be required at one or more of the three levels related to the management of risk, including the governance level, mission and business process level, and the information system level.",
          "Identity and access management (idm). Privileged access rights. Basic criterion: Privileged access rights for internal and external employees, as well as technical users of the cloud service provider, are assigned and changed in accordance with the policy for managing user accounts and access rights (cf. idm-01) or a separate specific policy. Privileged access rights are personalized, limited in time according to a risk assessment, and assigned as necessary for the execution of tasks (\"need-to-know principle\"). Technical users are assigned to internal or external employees of the cloud service provider. Activities of users with privileged access rights are logged in order to detect any misuse of privileged access in suspicious cases. The logged information is automatically monitored for defined events that may indicate misuse. When such an event is identified, the responsible personnel are automatically informed so that they can promptly assess whether misuse has occurred and take corresponding action. In the event of proven misuse of privileged access rights, disciplinary measures are taken in accordance with hr-04.\n\nAdditional criterion: Supplementary information about the criterion \"privileged access rights\" in the sense of the basic criterion: are those that enable employees of the cloud service provider to perform any of the following activities: read or write access to the cloud customers' data processed, stored, or transmitted in the cloud service, unless such data is encrypted or the encryption can be deactivated for access by the cloud service provider; and changes to the operational and/or security configuration of the system components in the production environment, in particular the starting, stopping, deleting, or deactivating of system components, if this can affect the confidentiality, integrity, or availability of the data of the cloud customers (also indirectly, e.g. by deactivating the logging and monitoring of security-relevant events). Misused privileged access rights can be treated e.g. as a security incident, cf. sim-01.\n\nComplementary customer criterion: Notes on continuous auditing feasibility: partially, the assignment of audit authorizations must be audited manually. This includes the classification as privileged, personalization, and evaluation of the need-to-know principle. The time limit could be read, but the implementation effort would be very high. A continuous audit does not appear to be sensible here. Only the system status could be audited continuously. The automatic triggering of a notification in suspicious cases could be compared with documented measures to handle these cases. However, this entire process must be digitized for this purpose, and the effort involved currently appears to be very high. However, a continuous audit could show the time of the last manual audit.",
          "Access control. Account management | inactivity logout. Require that users log out when [assignment: organization-defined time period of expected inactivity or description of when to log out]. Inactivity logout is behavior- or policy-based and requires users to take physical action to log out when they are expecting inactivity longer than the defined period. Automatic enforcement of inactivity logout is addressed by AC-11.",
          "Organisation of information security (ois). Information security policy. Basic criterion: The top management of the cloud service provider has adopted an information security policy and communicated it to internal and external employees, as well as cloud customers. The policy describes the following:\n\n- The importance of information security, based on the requirements of cloud customers in relation to information security.\n- The security objectives and desired security level, based on the business goals and tasks of the cloud service provider.\n- The most important aspects of the security strategy to achieve the set security objectives.\n- The organizational structure for information security in the ISMS application area.\n\nAdditional criterion:\n\nSupplementary information about the criterion: The top management refers to a natural person or group of persons who make the final decisions for the institution and are responsible for those decisions.\n\nComplementary customer criterion:\n\nNotes on continuous auditing feasibility: \nPartially, a policy can change ad-hoc. However, the continuous audit of policies is only partially feasible as the only attributes that can be tested are the last change date and the status of review or approval, as far as this information is stored in a system. The content of a policy can hardly be tested automatically.",
          "Audit and accountability. Audit record review, analysis, and reporting | correlate audit record repositories. Analyze and correlate audit records across different repositories to gain organization-wide situational awareness. Organization-wide situational awareness includes awareness across all three levels of risk management (i.e., organizational level, mission/business process level, and information system level) and supports cross-organization awareness.",
          "Access control. Information flow enforcement | flow control of encrypted information. Prevent encrypted information from bypassing [assignment: organization-defined information flow control mechanisms] by [selection (one or more): decrypting the information; blocking the flow of the encrypted information; terminating communication sessions attempting to pass encrypted information; [assignment: organization-defined procedure or method]]. Flow control mechanisms include content checking, security policy filters, and data type identifiers. The term encryption is extended to cover encoded data not recognized by filtering mechanisms.",
          "Incident response. Incident response testing | coordination with related plans. Coordinate incident response testing with organizational elements responsible for related plans. Organizational plans related to incident response testing include:\n\n1. Business continuity plans.\n2. Disaster recovery plans.\n3. Continuity of operations plans.\n4. Contingency plans.\n5. Crisis communications plans.\n6. Critical infrastructure plans.\n7. Occupant emergency plans.",
          "Audit and accountability. Audit record generation | system-wide and time-correlated audit trail. Compile audit records from [assignment: organization-defined system components] into a system-wide (logical or physical) audit trail that is time-correlated to within [assignment: organization-defined level of tolerance for the relationship between time stamps of individual records in the audit trail]. Audit trails are time-correlated if the time stamps in the individual audit records can be reliably related to the time stamps in other audit records to achieve a time ordering of the records within organizational tolerances.",
          "Supply chain risk management family. Tamper resistance and detection | multiple stages of system development life cycle. Employ anti-tamper technologies, tools, and techniques throughout the system development life cycle. The system development life cycle includes research and development, design, manufacturing, acquisition, delivery, integration, operations and maintenance, and disposal. Organizations use a combination of hardware and software techniques for tamper resistance and detection. Organizations use obfuscation and self-checking to make reverse engineering and modifications more difficult, time-consuming, and expensive for adversaries. The customization of systems and system components can make substitutions easier to detect and, therefore, limit damage.",
          "Physical and environmental protection. Physical access control | system access. Enforce physical access authorizations to the system, in addition to the physical access controls for the facility at [assignment: organization-defined physical spaces containing one or more components of the system]. Control of physical access to the system provides additional physical security for those areas within facilities where there is a concentration of system components.",
          "Incident response. Incident response testing. Test the effectiveness of the incident response capability for the system [assignment: organization-defined frequency] using the following tests: [assignment: organization-defined tests]. Organizations test incident response capabilities to determine their effectiveness and identify potential weaknesses or deficiencies. Incident response testing includes the use of checklists, walk-through or tabletop exercises, and simulations (parallel or full interrupt). Incident response testing can include a determination of the effects on organizational operations and assets and individuals due to incident response. The use of qualitative and quantitative data aids in determining the effectiveness of incident response processes.",
          "Audit and accountability. Protection of audit information | access by subset of privileged users. Authorize access to management of audit logging functionality to only [assignment: organization-defined subset of privileged users or roles]. Individuals or roles with privileged access to a system and who are also the subject of an audit by that system may affect the reliability of the audit information by inhibiting audit activities or modifying audit records. Requiring privileged access to be further defined between audit-related privileges and other privileges limits the number of users or roles with audit-related privileges.",
          "Identification and authentication. Identification and authentication (non-organizational users) | use of defined profiles. Conform to the following profiles for identity management. [Assignment: Organization-defined identity management profiles.] Organizations define profiles for identity management based on open identity management standards. To ensure that open identity management standards are viable, robust, reliable, sustainable, and interoperable as documented, the federal government assesses and scopes the standards and technology implementations against applicable laws, executive orders, directives, policies, regulations, standards, and guidelines.",
          "Access control. Publicly accessible content. A. Designate individuals authorized to make information publicly accessible.\nB. Train authorized individuals to ensure that publicly accessible information does not contain nonpublic information.\nC. Review the proposed content of information prior to posting onto the publicly accessible system to ensure that nonpublic information is not included.\nD. Review the content on the publicly accessible system for nonpublic information [assignment: organization-defined frequency] and remove such information, if discovered.\n\nIn accordance with applicable laws, executive orders, directives, policies, regulations, standards, and guidelines, the public is not authorized to have access to nonpublic information, including information protected under the privacy and proprietary information. \n\nPublicly accessible content addresses systems that are controlled by the organization and accessible to the public, typically without identification or authentication. Posting information on non-organizational systems (e.g., non-organizational public websites, forums, and social media) is covered by organizational policy. \n\nWhile organizations may have individuals who are responsible for developing and implementing policies about the information that can be made publicly accessible, publicly accessible content addresses the management of the individuals who make such information publicly accessible.",
          "Physical and environmental protection. Emergency power | alternate power supply — minimal operational capability. Provide an alternate power supply for the system that is activated [selection: manually; automatically] and that can maintain minimally required operational capability in the event of an extended loss of the primary power source. Provision of an alternate power supply with minimal operating capability can be satisfied by accessing a secondary commercial power supply or other external power supply.",
          "System and information integrity. Software, firmware, and information integrity | integrity checks. Perform an integrity check of organization-defined software, firmware, and information at startup. At organization-defined transitional states or security-relevant events, perform an integrity check. Perform an integrity check at organization-defined frequency. Security-relevant events include the identification of new threats to which organizational systems are susceptible and the installation of new hardware, software, or firmware. Transitional states include system startup, restart, shutdown, and abort.",
          "Supply chain risk management family. Component authenticity. a. Develop and implement an anti-counterfeit policy and procedures that include the means to detect and prevent counterfeit components from entering the system. \nb. Report counterfeit system components to the source of the counterfeit component; organization-defined external reporting organizations; organization-defined personnel or roles. \nSources of counterfeit components include manufacturers, developers, vendors, and contractors. \nAnti-counterfeiting policies and procedures support tamper resistance and provide a level of protection against the introduction of malicious code. \nExternal reporting organizations include CISA.",
          "Media protection. Media access. Restrict access to [assignment: organization-defined types of digital and/or non-digital media] to [assignment: organization-defined personnel or roles]. System media includes digital and non-digital media. Digital media includes flash drives, diskettes, magnetic tapes, external or removable hard disk drives (e.g., solid state, magnetic), compact discs, and digital versatile discs. Non-digital media includes paper and microfilm. Denying access to patient medical records in a community hospital unless the individuals seeking access to such records are authorized healthcare providers is an example of restricting access to non-digital media. Limiting access to the design specifications stored on compact discs in the media library to individuals on the system development team is an example of restricting access to digital media.",
          "Contingency planning. Contingency plan testing. a. Test the contingency plan for the system [assignment: organization-defined frequency] using the following tests to determine the effectiveness of the plan and the readiness to execute the plan: [assignment: organization-defined tests]. \nb. Review the contingency plan test results. \nc. Initiate corrective actions if needed. \n\nMethods for testing contingency plans to determine the effectiveness of the plans and identify potential weaknesses include checklists, walk-through, and tabletop exercises, simulations (parallel or full interrupt), and comprehensive exercises. Organizations conduct testing based on the requirements in contingency plans and include a determination of the effects on organizational operations, assets, and individuals due to contingency operations. Organizations have flexibility and discretion in the breadth, depth, and timelines of corrective actions.",
          "Personnel security. Access agreements. a. Develop and document access agreements for organizational systems.\nb. Review and update the access agreements [assignment: organization-defined frequency].\nc. Verify that individuals requiring access to organizational information and systems:\n1. Sign appropriate access agreements prior to being granted access.\n2. Re-sign access agreements to maintain access to organizational systems when access agreements have been updated or [assignment: organization-defined frequency].\nAccess agreements include nondisclosure agreements, acceptable use agreements, rules of behavior, and conflict-of-interest agreements. Signed access agreements include an acknowledgement that individuals have read, understand, and agree to abide by the constraints associated with organizational systems to which access is authorized. Organizations can use electronic signatures to acknowledge access agreements unless specifically prohibited by organizational policy.",
          "Physical and environmental protection. Monitoring physical access | monitoring physical access to systems. Monitor physical access to the system, in addition to the physical access monitoring of the facility, at [assignment: organization-defined physical spaces containing one or more components of the system]. Monitoring physical access to systems provides additional monitoring for those areas within facilities where there is a concentration of system components, including server rooms, media storage areas, and communications centers. Physical access monitoring can be coordinated with intrusion detection systems and system monitoring capabilities to provide comprehensive and integrated threat coverage for the organization.",
          "Maintenance. Maintenance tools | prevent unauthorized removal. Prevent the removal of maintenance equipment containing organizational information by: (a) verifying that there is no organizational information contained on the equipment; (b) sanitizing or destroying the equipment; (c) retaining the equipment within the facility; or (d) obtaining an exemption from [assignment: organization-defined personnel or roles] explicitly authorizing removal of the equipment from the facility. Organizational information includes all information owned by organizations and any information provided to organizations for which the organizations serve as information stewards.",
          "Incident response. Incident response training | simulated events. Incorporate simulated events into incident response training to facilitate the required response by personnel in crisis situations. Organizations establish requirements for responding to incidents in incident response plans. Incorporating simulated events into incident response training helps to ensure that personnel understand their individual responsibilities and what specific actions to take in crisis situations.",
          "Security policies and instructions (sp). Documentation, communication and provision of policies and instructions. Basic criterion: Policies and instructions (including concepts and guidelines) are derived from the information security policy and are documented according to a uniform structure. They are communicated and made available to all internal and external employees of the cloud service provider in an appropriate manner. The policies and instructions are version controlled and approved by the top management of the cloud service provider or an authorized body. The policies and instructions describe at least the following aspects: objectives; scope; roles and responsibilities, including staff qualification requirements and the establishment of substitution rules; roles and dependencies on other organizations (especially cloud customers and sub-service organizations); steps for the execution of the security strategy; and applicable legal and regulatory requirements.\n\nAdditional criterion: Supplementary information about the criterion. The appropriateness of the demand-oriented communication and provision must be assessed against the size and complexity of the cloud service provider's organization and the type of cloud service offered. Possible criteria are: integration of guidelines and instructions in the onboarding of new employees; training and information campaigns when adopting new or revising existing policies and instructions; form of provision.\n\nPolicies and instructions are required for the following basic criteria in which the content is specified in more detail: risk management policy (OIS-06); acceptable use and handling of assets policy (AM-02); security requirements for premises and buildings (PS-01); physical site access control (PS-04); concept for protection against malware (OPS-04); concept for data protection and recovery (OPS-06); concept for logging and monitoring (OPS-10); concept for metadata handling (OPS-11); concept for handling of vulnerabilities, malfunctions, and errors (OPS-18); policy for system and data access authorizations (IDM-01); policy for the use of encryption procedures and key management (CRY-01); policies for data transmission (COS-08); policies for the development/procurement of information systems (DEV-01); policies for changes to information systems (DEV-03); policies and instructions for controlling and monitoring third parties (SSO-01); policy for security incident management (SIM-01); business impact analysis policies and procedures (BCM-02); policy for planning and conducting audits (COM-02).\n\nComplementary customer criterion: Notes on continuous auditing feasibility: partially regarding the uniformity and content of the policies and instructions, there is a need for manual testing, so continuous testing cannot be fully achieved. The communication/provision of policies and instructions can be queried via various registers. Registries for all approved policies and instructions can serve as a basis for reviewing the policies/instructions provided in the usual channels and may be combined with a conditional access check. These requirements must first be met by the cloud service provider. Versioning after approval by authorized personnel can be automatically audited and is therefore suitable for continuous audit.",
          "Physical and environmental protection. Power equipment and cabling. Protect power equipment and power cabling for the system from damage and destruction. Organizations determine the types of protection necessary for the power equipment and cabling employed at different locations that are both internal and external to organizational facilities and environments of operation. Types of power equipment and cabling include internal cabling and uninterruptible power sources in offices or data centers, generators and power cabling outside of buildings, and power sources for self-contained components such as satellites, vehicles, and other deployable systems.",
          "System and communications protection. Denial-of-service protection. a. [Selection: Protect against; Limit] the effects of the following types of denial-of-service events: [Assignment: Organization-defined types of denial-of-service events]. \nb. Employ the following controls to achieve the denial-of-service objective: [Assignment: Organization-defined controls by type of denial-of-service event]. \n\nDenial-of-service events may occur due to a variety of internal and external causes, such as an attack by an adversary or a lack of planning to support organizational needs with respect to capacity and bandwidth. Such attacks can occur across a wide range of network protocols (e.g., IPv4, IPv6). \n\nA variety of technologies are available to limit or eliminate the origination and effects of denial-of-service events. For example, boundary protection devices can filter certain types of packets to protect system components on internal networks from being directly affected by or the source of denial-of-service attacks. Employing increased network capacity and bandwidth, combined with service redundancy, also reduces the susceptibility to denial-of-service events.",
          "Access control. Wireless access | authentication and encryption. Protect wireless access to the system using authentication of users and encryption. Wireless networking capabilities represent a significant potential vulnerability that can be exploited by adversaries. To protect systems with wireless access points, strong authentication of users and devices, along with strong encryption, can reduce susceptibility to threats by adversaries involving wireless technologies.",
          "Audit and accountability. Content of audit records. Ensure that audit records contain information that establishes the following: a. What type of event occurred; b. When the event occurred; c. Where the event occurred; d. Source of the event; e. Outcome of the event; and f. Identity of any individuals, subjects, or objects/entities associated with the event. Audit record content that may be necessary to support the auditing function includes event descriptions (item a), timestamps (item b), source and destination addresses (item c), user or process identifiers (items d and f), success or fail indications (item e), and filenames involved (items a, c, e, and f). Event outcomes include indicators of event success or failure and event-specific results, such as the system security and privacy posture after the event occurred. Organizations consider how audit records can reveal information about individuals that may give rise to privacy risks and how best to mitigate such risks. For example, there is the potential to reveal personally identifiable information in the audit trail, especially if the trail records inputs or is based on patterns or time of usage.",
          "Operations (ops). Logging and monitoring – accountability. Basic criterion: The log data generated allows for an unambiguous identification of user accesses at the tenant level to support (forensic) analysis in the event of a security incident. Interfaces are available to conduct forensic analyses and perform backups of infrastructure components and their network communication.\n\nAdditional criterion: Upon request of the cloud customer, the cloud service provider provides the logs relating to the cloud customer in an appropriate form and in a timely manner so that the cloud customer can investigate any incidents relating to them.\n\nSupplementary information about the criterion: Infrastructure components in the sense of this criterion are, for example, fabric controllers, network components, and virtualization servers.\n\nComplementary customer criterion: Cloud customers ensure through suitable controls that unique user IDs are assigned, which allow for a corresponding analysis in the event of a security incident.\n\nNotes on continuous auditing feasibility: No. For the generated logging data to allow unambiguous identification of user accesses at the tenant level, the creation of this data must be configured accordingly. This configuration does not have to be audited continuously but only if it is changed. The interfaces can also be audited initially and then tested again if changes are made.",
          "System and information integrity. System monitoring | inbound and outbound communications traffic. (A) Determine criteria for unusual or unauthorized activities or conditions for inbound and outbound communications traffic.\n(B) Monitor inbound and outbound communications traffic [Assignment: organization-defined frequency] for [Assignment: organization-defined unusual or unauthorized activities or conditions].\n\nUnusual or unauthorized activities or conditions related to system inbound and outbound communications traffic include internal traffic that indicates the presence of malicious code or unauthorized use of legitimate code or credentials within organizational systems or propagating among system components, signaling to external systems, and the unauthorized exporting of information. Evidence of malicious code or unauthorized use of legitimate code or credentials is used to identify potentially compromised systems or system components.",
          "Organisation of information security (ois). Contact with relevant government agencies and interest groups. Basic criterion: The cloud service provider leverages relevant authorities and interest groups in order to stay informed about current threats and vulnerabilities. The information flows into the procedures for handling risks (cf. OIS-06) and vulnerabilities (cf. OPS-19). \n\nAdditional criterion: If the cloud service is used by public sector organizations in Germany, the cloud service provider leverages contacts with the National IT Situation Centre and the CERT Association of the BSI. \n\nSupplementary information about the criterion: Relevant contacts are, for example, the Federal Office for Information Security (BSI), OWASP Foundation, and CERT networks such as DFN-CERT and TF-CSIRT. \n\nPublic sector organizations in Germany are, for example, authorities and ministries. \n\nComplementary customer criterion notes on continuous auditing feasibility: Yes, a continuous audit of the cloud service provider's contacts with relevant authorities and stakeholders can be achieved by continuously storing relevant information on a monthly basis, such as a list of contacted entities and evidence of receipt of a response. \n\nA continuous flow of information demonstrates a constant connection to relevant authorities and interest groups. Furthermore, the distribution of the information and, if necessary, the documentation of the handling of identified risks and vulnerabilities could be continuously audited for the coverage of this criterion.",
          "Contingency planning. Contingency training | simulated events. Incorporate simulated events into contingency training to facilitate effective response by personnel in crisis situations. The use of simulated events creates an environment for personnel to experience actual threat events, including cyber-attacks that disable websites, ransomware attacks that encrypt organizational data on servers, hurricanes that damage or destroy organizational facilities, or hardware or software failures.",
          "Audit and accountability. Audit record retention. Retain audit records for [assignment: organization-defined time period consistent with records retention policy] to provide support for after-the-fact investigations of incidents and to meet regulatory and organizational information retention requirements. Organizations retain audit records until it is determined that the records are no longer needed for administrative, legal, audit, or other operational purposes. This includes the retention and availability of audit records relative to Freedom of Information Act (FOIA) requests, subpoenas, and law enforcement actions. Organizations develop standard categories of audit records relative to such types of actions and standard response processes for each type of action. The National Archives and Records Administration (NARA) General Records Schedules provide federal policy on records retention.",
          "Personnel security. Personnel termination | automated actions. Use organization-defined automated mechanisms to notify organization-defined personnel or roles of individual termination actions or disable access to system resources. In organizations with many employees, not all personnel who need to know about termination actions receive the appropriate notifications. Even if such notifications are received, they may not occur in a timely manner. Automated mechanisms can be used to send automatic alerts or notifications to organizational personnel or roles when individuals are terminated. Such automatic alerts or notifications can be conveyed in a variety of ways, including via telephone, electronic mail, text message, or websites. Automated mechanisms can also be employed to quickly and thoroughly disable access to system resources after an employee is terminated.",
          "Access control. Least privilege | prohibit non-privileged users from executing privileged functions. Prevent non-privileged users from executing privileged functions. Privileged functions include disabling, circumventing, or altering implemented security or privacy controls, establishing system accounts, performing system integrity checks, and administering cryptographic key management activities. Non-privileged users are individuals who do not possess appropriate authorizations. Privileged functions that require protection from non-privileged users include circumventing intrusion detection and prevention mechanisms or malicious code protection mechanisms. Preventing non-privileged users from executing privileged functions is enforced by AC-3.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "0_and_the_of",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "0_and_the_of"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          12.15090560913086,
          13.936285972595215,
          11.778837203979492,
          12.016623497009277,
          9.708419799804688,
          13.335798263549805,
          13.005546569824219,
          12.3090181350708,
          10.943461418151855,
          11.172877311706543,
          11.76574993133545,
          12.316204071044922,
          12.538861274719238,
          12.080676078796387,
          13.224733352661133,
          12.630843162536621,
          12.630290031433105,
          12.569869995117188,
          12.313199043273926,
          14.048690795898438,
          11.248635292053223,
          13.860220909118652,
          12.712860107421875,
          12.274469375610352,
          13.501252174377441,
          13.163912773132324,
          13.205301284790039,
          10.756802558898926,
          13.129105567932129,
          14.063977241516113,
          11.401566505432129,
          11.651932716369629,
          13.24830436706543,
          12.571840286254883,
          11.07995319366455,
          12.091142654418945,
          11.906669616699219,
          11.792189598083496,
          13.525019645690918,
          13.848981857299805,
          12.219704627990723,
          14.100685119628906,
          11.478865623474121,
          12.466039657592773,
          11.93519401550293,
          13.296401023864746,
          12.041032791137695,
          10.932533264160156,
          13.198558807373047,
          13.334665298461914,
          13.208112716674805,
          13.596076965332031,
          11.846362113952637,
          12.010100364685059,
          13.694618225097656,
          11.381659507751465,
          13.156231880187988,
          12.589707374572754,
          11.92176628112793,
          13.778759002685547,
          12.57044506072998,
          13.616533279418945,
          12.536019325256348,
          11.734583854675293,
          11.770346641540527,
          12.084896087646484,
          12.503210067749023,
          11.694317817687988,
          14.093626022338867,
          12.588380813598633,
          13.155561447143555,
          13.262590408325195,
          11.904446601867676,
          12.022342681884766,
          12.289880752563477,
          11.725790023803711,
          11.942268371582031,
          11.128283500671387,
          12.412654876708984,
          11.818921089172363,
          12.94982624053955,
          14.130208969116211,
          11.730199813842773,
          11.986751556396484,
          12.001527786254883,
          12.961156845092773,
          11.4592924118042,
          12.553823471069336,
          12.351015090942383,
          11.298717498779297,
          13.999731063842773,
          11.534806251525879,
          12.660922050476074,
          11.793536186218262,
          11.775213241577148,
          12.544458389282227,
          11.958370208740234,
          11.9790678024292,
          11.795110702514648,
          11.493459701538086,
          12.29917049407959,
          11.44621467590332,
          12.14664077758789,
          12.555747032165527,
          12.150444984436035,
          12.013400077819824,
          12.163999557495117,
          11.997206687927246,
          12.183568000793457,
          13.826597213745117,
          13.53931713104248,
          12.177630424499512,
          13.718515396118164,
          11.782431602478027,
          13.620640754699707,
          11.866127967834473,
          14.080852508544922,
          12.365385055541992,
          11.040209770202637,
          10.927080154418945,
          11.94982624053955,
          12.560256004333496,
          12.674820899963379,
          12.281511306762695,
          11.410593032836914,
          14.106494903564453,
          11.89159107208252,
          12.182804107666016,
          11.734485626220703,
          11.105395317077637,
          11.990837097167969,
          11.903058052062988,
          12.487358093261719,
          13.968914985656738,
          11.876315116882324,
          12.605561256408691,
          9.729166030883789,
          13.431660652160645,
          13.956292152404785,
          9.614459037780762,
          13.092531204223633,
          12.438215255737305,
          11.80075740814209,
          12.135826110839844,
          11.823131561279297,
          12.395196914672852,
          11.101794242858887,
          11.76344108581543,
          12.313157081604004,
          10.433835983276367,
          13.467414855957031,
          11.329962730407715,
          11.769123077392578,
          11.7282075881958,
          13.047561645507812,
          12.792217254638672,
          13.292032241821289,
          12.123147964477539,
          13.795158386230469,
          11.353963851928711,
          11.187880516052246,
          10.781137466430664,
          12.693737983703613,
          11.596689224243164,
          12.759344100952148,
          13.206939697265625,
          11.516825675964355,
          11.361863136291504,
          11.138923645019531,
          12.326112747192383
         ],
         "y": [
          7.20699405670166,
          5.3664021492004395,
          6.189924240112305,
          8.569345474243164,
          5.865536212921143,
          5.569265842437744,
          5.590641498565674,
          5.111639499664307,
          6.74937105178833,
          6.751680374145508,
          7.191556930541992,
          5.121817588806152,
          5.874166965484619,
          5.481007099151611,
          6.1319899559021,
          8.745729446411133,
          7.929640769958496,
          8.854180335998535,
          8.580156326293945,
          5.300769805908203,
          7.0063910484313965,
          5.4925031661987305,
          5.630563259124756,
          5.187149524688721,
          5.877738952636719,
          5.2899699211120605,
          6.126773357391357,
          6.586796283721924,
          5.292040824890137,
          5.2773966789245605,
          7.129499435424805,
          6.982851505279541,
          6.121337413787842,
          7.908603191375732,
          7.155824184417725,
          5.312880992889404,
          8.34101676940918,
          6.149924278259277,
          5.804908752441406,
          5.120730400085449,
          8.562658309936523,
          5.261805057525635,
          7.244714736938477,
          5.722996711730957,
          6.802047252655029,
          5.954066276550293,
          6.538536071777344,
          6.737977981567383,
          5.2331390380859375,
          6.000698089599609,
          5.416083335876465,
          5.7957258224487305,
          6.439382553100586,
          5.386013984680176,
          5.640169143676758,
          5.785260200500488,
          5.272680282592773,
          8.700180053710938,
          8.526116371154785,
          5.539886474609375,
          8.903650283813477,
          5.667322635650635,
          8.840069770812988,
          6.702870845794678,
          7.0652995109558105,
          5.743858337402344,
          8.626876831054688,
          5.605424880981445,
          5.270594120025635,
          8.916685104370117,
          5.544787883758545,
          5.6028971672058105,
          8.621383666992188,
          6.6773481369018555,
          5.756098747253418,
          8.706551551818848,
          5.411636829376221,
          6.103236675262451,
          5.042414665222168,
          5.96734094619751,
          5.2864460945129395,
          5.280569553375244,
          7.450740337371826,
          8.372803688049316,
          5.516454696655273,
          5.72546911239624,
          7.1496477127075195,
          7.913301944732666,
          7.669768333435059,
          6.459604740142822,
          5.3370256423950195,
          7.278861045837402,
          6.111979007720947,
          6.4886794090271,
          7.53251314163208,
          5.590522766113281,
          6.736608982086182,
          8.56890869140625,
          6.305834770202637,
          8.183577537536621,
          5.151238918304443,
          8.0722017288208,
          7.218458652496338,
          5.682053565979004,
          6.333469867706299,
          5.53582763671875,
          6.3833160400390625,
          8.615764617919922,
          8.519148826599121,
          5.5931854248046875,
          5.828820705413818,
          8.444462776184082,
          5.562305450439453,
          6.50771427154541,
          5.128957271575928,
          6.410632133483887,
          5.277162075042725,
          6.371737480163574,
          6.676528453826904,
          6.76677942276001,
          5.601848602294922,
          8.864726066589355,
          5.587864398956299,
          5.182737350463867,
          7.027218341827393,
          5.25117301940918,
          8.066073417663574,
          7.2404961585998535,
          6.41453742980957,
          8.210758209228516,
          7.52608585357666,
          6.884076118469238,
          8.785096168518066,
          5.228405475616455,
          6.305846214294434,
          8.732012748718262,
          5.852943420410156,
          5.833733558654785,
          5.270065784454346,
          5.92692756652832,
          6.017765045166016,
          8.04948616027832,
          6.0624871253967285,
          5.291977405548096,
          7.155728340148926,
          8.209470748901367,
          7.20120096206665,
          7.401895046234131,
          5.170864105224609,
          7.668867588043213,
          5.71783447265625,
          7.010724067687988,
          7.7638630867004395,
          7.6131062507629395,
          5.370296478271484,
          5.211172580718994,
          5.993168354034424,
          6.403852462768555,
          5.457834720611572,
          7.062338352203369,
          6.803915977478027,
          6.578598499298096,
          8.740228652954102,
          7.211784839630127,
          8.527668952941895,
          5.8998613357543945,
          7.5938310623168945,
          7.505941390991211,
          6.547974109649658,
          6.588098526000977
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Identity and access management (idm). Granting and change of user accounts and access rights. Basic criterion: Specified procedures for granting and modifying user accounts and access rights for internal and external employees of the cloud service provider as well as for system components involved in automated authorization processes of the cloud service provider ensure compliance with the role and rights concept as well as the policy for managing user accounts and access rights.\n\nAdditional criterion: The cloud service provider offers cloud customers a self-service with which they can independently assign and change user accounts and access rights.\n\nSupplementary information about the criterion: Complementary customer criterion notes on continuous auditing feasibility: No. A continuous audit of procedures is strongly dependent on the underlying systematics and automation of the cloud service provider's procedures. This may vary in individual cases, but in general, a continuous audit does not appear to be effective.",
          "Security policies and instructions (sp). Exceptions from existing policies and instructions. Basic Criterion: Exceptions to the policies and instructions for information security, as well as respective controls, go through the OIS-06 risk management process. This includes the approval of these exceptions and the acceptance of the associated risks by the risk owners. The approvals of exceptions are documented, limited in time, and reviewed for appropriateness at least annually by the risk owners.\n\nAdditional Criterion: Supplementary information about the criterion exceptions, in the sense of the basic criterion, can have organizational or technical causes. For example, an organizational unit may need to deviate from the intended processes and procedures to meet the requirements of a cloud customer. Additionally, a system component may lack technical properties to configure it according to the applicable requirements. Cloud customers can use appropriate controls to ensure that they obtain information from the cloud service provider about deviations from information security policies and instructions. This allows them to assess and appropriately manage the associated risks to their own information security.\n\nComplementary Customer Criterion: Notes on continuous auditing feasibility: Partially, exceptions to policies and instructions are to be reviewed annually. However, the continuous audit of these exceptions is only partially feasible, as the only attributes that can be tested are the last change date and the status or review or approval, as far as this information is stored in a system. The content of an exception can hardly be tested automatically.\n\n5.3 Personnel (HR) Objective: Ensure that employees understand their responsibilities, are aware of their responsibilities with regard to information security, and that the organization's assets are protected in the event of changes in responsibilities or termination.",
          "Planning. Rules of behavior. a. Establish and provide to individuals requiring access to the system, the rules that describe their responsibilities and expected behavior for information and system usage, security, and privacy.\nb. Receive a documented acknowledgment from such individuals, indicating that they have read, understand, and agree to abide by the rules of behavior, before authorizing access to information and the system.\nc. Review and update the rules of behavior [assignment: organization-defined frequency].\nd. Require individuals who have acknowledged a previous version of the rules of behavior to read and re-acknowledge [selection (one or more): [assignment: organization-defined frequency]; when the rules are revised or updated].\n\nRules of behavior represent a type of access agreement for organizational users. Other types of access agreements include nondisclosure agreements, conflict-of-interest agreements, and acceptable use agreements (see ps-6). Organizations consider rules of behavior based on individual user roles and responsibilities and differentiate between rules that apply to privileged users and rules that apply to general users. Establishing rules of behavior for some types of non-organizational users, including individuals who receive information from federal systems, is often not feasible given the large number of such users and the limited nature of their interactions with the systems. Rules of behavior for organizational and non-organizational users can also be established in ac-8.\n\nThe related Controls section provides a list of controls that are relevant to organizational rules of behavior. PL-4b, the documented acknowledgment portion of the control, may be satisfied by the literacy training and awareness and role-based training programs conducted by organizations if such training includes rules of behavior. Documented acknowledgments for rules of behavior include electronic or physical signatures and electronic agreement check boxes or radio buttons.",
          "Asset management (am). Asset classification and labelling. Basic criterion: Assets are classified and, if possible, labeled. The classification and labeling of an asset reflect the protection needs of the information it processes, stores, or transmits. The need for protection is determined by the individuals or groups responsible for the assets of the cloud service provider, according to a uniform schema. The schema provides levels of protection for the confidentiality, integrity, availability, and authenticity protection objectives. \n\nAdditional criterion: Logging and monitoring applications take the asset protection needs into account in order to inform the responsible stakeholder of events that could lead to a violation of the protection goals, so that the necessary measures are taken with an appropriate priority. Actions for events on assets with a higher level of protection take precedence over events on assets with a lower need for protection. \n\nSupplementary information about the criterion: If the cloud service provider does not make a differentiated classification of the assets, all assets are to be assigned to the highest defined protection requirement. \n\nComplementary customer criterion: Cloud customers can use appropriate controls to ensure that the need for protection of the information that can be processed or stored with the cloud service is adequately determined. Cloud customers can also use appropriate controls to ensure that the information processed or stored with the cloud service is protected against tampering, copying, modifying, redirecting, or deleting in accordance with its protection needs. \n\nNotes on continuous auditing feasibility: Yes, the classification of the assets and the determination of the need for protection should take place during the initial acquisition of the assets. Thus, the classification should also be documented in an asset management tool. The determination of the protection requirement can also be carried out in a standardized form and stored digitally. If there are changes in the classification, these should also be recorded in logs. The auditor can then automatically test whether all assets on the platform are classified and whether the classification was determined using a standardized format. For changes in the classification, it can be automatically reconstructed whether these were also carried out based on the uniform schema. For this purpose, the logs produced can be evaluated as part of a continuous audit. \n\n5.5 Physical Security (PS) \n\nObjective: Prevent unauthorized physical access and protect against theft, damage, loss, and outage of operations.",
          "Identity and access management (idm). Withdraw or adjust access rights as the task area changes. Basic criterion: Access rights are promptly revoked if the job responsibilities of the cloud service provider's internal or external staff or the tasks of system components involved in the cloud service provider's automated authorization processes change. Privileged access rights are adjusted or revoked within 48 hours after the change taking effect. All other access rights are adjusted or revoked within 14 days. After revocation, the procedure for granting user accounts and access rights (cf. idm-02) must be repeated. \n\nAdditional criterion: Supplementary information about the criterion changes in the task area of internal and external employees can be triggered by changes in the employment relationship (e.g., termination, transfer) or in contracts and agreements. For privileged access rights, the definition in idm-06 applies. \n\nComplementary customer criterion: \nNotes on continuous auditing feasibility: Yes, it is necessary to record the changes to the task area in terms of content together with the date of entry into force in order to compare these with the adjustments made to the access rights. A continuous audit seems possible but requires a great deal of effort to implement.",
          "Dealing with investigation requests from government agencies (inq). Limiting access to or disclosure of data in investigation requests. Basic criterion: The cloud service provider's procedures establish access to or disclose data of cloud customers in the context of investigation requests from governmental agencies. These procedures ensure that the agencies only gain access to or insight into the data that is the subject of the investigation request. If clear limitation of the data is not possible, the cloud service provider anonymizes or pseudonymizes the data. This ensures that government agencies can only assign it to those cloud customers who are the subject of the investigation request. \n\nAdditional criterion: Supplementary information about the criterion complementary customer criterion notes on continuous auditing feasibility. Partially, a separate role for the investigator is to be provided (cf. also inq-03). It is conceivable that certain data types for this role may not be visible, pseudonymized or anonymized. Additionally, data of customers that are not part of the investigation may be excluded. However, this requires manual effort in the configuration and assignment of the investigator role. Under these conditions, however, a continuous audit of whether and to what extent the investigator had access to data is conceivable. \n\n5.17 Product Safety and Security (PSS): Objective: Provides up-to-date information on the secure configuration and known vulnerabilities of the cloud service for cloud customers. It also provides appropriate mechanisms for troubleshooting and logging, as well as authentication and authorization of users of cloud customers.",
          "Access control. Account management | privileged user accounts. (a) Establish and administer privileged user accounts in accordance with [selection: a role-based access scheme; an attribute-based access scheme]. \n(b) Monitor privileged role or attribute assignments. \n(c) Monitor changes to roles or attributes. \n(d) Revoke access when privileged role or attribute assignments are no longer appropriate. \n\nPrivileged roles are organization-defined roles assigned to individuals that allow those individuals to perform certain security-relevant functions that ordinary users are not authorized to perform. Privileged roles include key management, account management, database administration, system and network administration, and web administration. \n\nA role-based access scheme organizes permitted system access and privileges into roles. In contrast, an attribute-based access scheme specifies allowed system access and privileges based on attributes.",
          "Maintenance. Nonlocal maintenance. a. Approve and monitor non-local maintenance and diagnostic activities.\nb. Allow the use of non-local maintenance and diagnostic tools only as consistent with organizational policy and documented in the security plan for the system.\nc. Employ strong authentication in the establishment of non-local maintenance and diagnostic sessions.\nd. Maintain records for non-local maintenance and diagnostic activities.\ne. Terminate session and network connections when non-local maintenance is completed.\n\nNon-local maintenance and diagnostic activities are conducted by individuals who communicate through either an external or internal network. Local maintenance and diagnostic activities are carried out by individuals who are physically present at the system location and not communicating across a network connection. Authentication techniques used to establish non-local maintenance and diagnostic sessions reflect the network access requirements in IA-2. Strong authentication requires authenticators that are resistant to replay attacks and employ multi-factor authentication. Strong authenticators include PKI where certificates are stored on a token protected by a password, passphrase, or biometric. \n\nEnforcing requirements in MA-4 is accomplished, in part, by other controls. SP 800-63b provides additional guidance on strong authentication and authenticators.",
          "Communication security (cos). Documentation of the network topology. Basic criterion: The documentation of the logical structure of the network used to provision or operate the cloud service is traceable and up-to-date. This is to avoid administrative errors during live operation and to ensure timely recovery in the event of malfunctions, in accordance with contractual obligations. The documentation should show how the subnets are allocated and how the network is zoned and segmented. Additionally, it should indicate the geographical locations where the cloud customers' data is stored.\n\nAdditional criterion: Supplementary information about the criterion zoning includes segmentation of the subnets with a firewall implemented at the network perimeters.\n\nComplementary customer criterion: Notes on continuous auditing feasibility: No, the documentation of the logical structure of the network is rarely changed and is stored centrally. Therefore, a continuous audit is not effective. However, a continuous audit could provide the date of the last change to the documentation.",
          "Identification and authentication. Identification and authentication (organizational users) | acceptance of piv credentials. Accept and electronically verify personal identity verification-compliant credentials. Acceptance of personal identity verification (PIV)-compliant credentials applies to organizations implementing logical access control and physical access control systems. PIV-compliant credentials are those credentials issued by federal agencies that conform to FIPS Publication 201 and supporting guidance documents. The adequacy and reliability of PIV card issuers are authorized using SP 800-79-2. Acceptance of PIV-compliant credentials includes derived PIV credentials, the use of which is addressed in SP 800-166. The DoD Common Access Card (CAC) is an example of a PIV credential.",
          "Compliance (com). Internal audits of the information security management system. Basic criterion: Subject matter experts check the compliance of the Information Security Management System at regular intervals, at least annually, with the relevant and applicable legal, regulatory, self-imposed, or contractual requirements (cf. com-01) as well as compliance with the policies and instructions (cf. sp-01) within their scope of responsibility (cf. ois-01) through internal audits. Identified vulnerabilities and deviations are subject to risk assessment in accordance with the risk management procedure (cf. ois-06), and follow-up measures are defined and tracked (cf. ops-18). Additional criterion: Internal audits are supplemented by procedures to automatically monitor applicable requirements of policies and instructions with regard to the following aspects: configuration of system components to provide the cloud service within the cloud service provider's area of responsibility; performance and availability of these system components; response time to malfunctions and security incidents; recovery time (time to completion of error handling). Identified vulnerabilities and deviations are automatically reported to the appropriate cloud service provider's subject matter experts for immediate assessment and action. Cloud customers can view compliance with selected contractual requirements in real-time. Supplementary information about the criterion: Subject matter experts operate, e.g., in the cloud service provider's internal revision department or expert third parties commissioned by the cloud service provider, such as auditing companies, and may hold relevant certifications such as \"Certified Internal Auditor (CIA)\". With regard to ISMS compliance, see Section 9.2 of ISO/IEC 27001. Complementary customer criterion notes on continuous auditing feasibility: Yes, the regular performance of an internal audit of the ISMS can be set up as part of compliance monitoring. For this purpose, the results of the internal audit must be digitally documented, as well as the individual audit steps. A continuous audit of this internal audit is not effective but can only be considered after compliance monitoring has been set up. The continuous audit can then supply the date of the last audit as the output value.",
          "System and information integrity. Information input validation. Check the validity of the following information inputs: [assignment: organization-defined information inputs to the system]. Checking the valid syntax and semantics of system inputs - including character set, length, numerical range, and acceptable values - verifies that inputs match specified definitions for format and content. For example, if the organization specifies that numerical values between 1-100 are the only acceptable inputs for a field in a given application, inputs of 387, abc, or %k% are invalid inputs and are not accepted as input to the system. Valid inputs are likely to vary from field to field within a software application. Applications typically follow well-defined protocols that use structured messages (i.e., commands or queries) to communicate between software modules or system components. Structured messages can contain raw or unstructured data interspersed with metadata or control information. If software applications use attacker-supplied inputs to construct structured messages without properly encoding such messages, then the attacker could insert malicious commands or special characters that can cause the data to be interpreted as control information or metadata. Consequently, the module or component that receives the corrupted output will perform the wrong operations or otherwise interpret the data incorrectly. Prescreening inputs prior to passing them to interpreters prevents the content from being unintentionally interpreted as commands. Input validation ensures accurate and correct inputs and prevents attacks such as cross-site scripting and a variety of injection attacks.",
          "Business continuity management (bcm). Planning business continuity. Basic criterion: Based on the business impact analysis, a single framework for operational continuity and business plan planning will be implemented, documented, and enforced to ensure that all plans are consistent. Planning is based on established standards, which are documented in a \"Statement of Applicability\". Business continuity plans and contingency plans take the following aspects into account: \n\n- Defined purpose and scope with consideration of the relevant dependencies.\n- Accessibility and comprehensibility of the plans for persons who are to act accordingly.\n- Ownership by at least one designated person responsible for review, updating, and approval.\n- Defined communication channels, roles, and responsibilities, including notification of the customer.\n- Recovery procedures, manual interim solutions, and reference information (taking into account prioritization in the recovery of cloud infrastructure components and services and alignment with customers).\n- Methods for putting the plans into effect.\n- Continuous process improvement.\n- Interfaces to security incident management. \n\nAdditional criterion: \n\nSupplementary information about the criterion: The consistency of plans, according to the basic criterion, must also be maintained when different locations are used.\n\nComplementary customer criterion: \n\nCloud customers ensure through suitable controls that the results of the business impact analysis are sufficiently considered when planning the operational continuity and the business plan in order to provide for the effects of a failure of the cloud service or cloud service provider. \n\nCloud customers ensure through suitable controls that the availability of the cloud service, its recovery time according to the BCM plan, and the data loss of the cloud service are consistent with their own availability requirements and tolerable data loss. \n\nNotes on continuous auditing feasibility: \n\nNo, the introduction of the framework and the business plan based on a business impact analysis is a manual process of the cloud service provider. A continuous audit is not practical. The plans can be tested as part of the recurring audit.",
          "Asset management (am). Commitment to permissible use, safe handling and return of assets. Basic criterion: The cloud service provider's internal and external employees are provably committed to the policies and instructions for acceptable use and safe handling of assets before they can be used. If the cloud service provider has determined in a risk assessment that loss or unauthorized access could compromise the information security of the cloud service, any assets handed over are provably returned upon termination of employment.\n\nAdditional criterion: Physical assets of internal and external employees are managed centrally. Central management enables software, data, and policy distribution, as well as remote deactivation, deletion, or locking.\n\nSupplementary information about the criterion:\nThe basic criterion essentially concerns mobile devices (e.g., notebooks, tablets, smartphones, etc.) where confidential information is stored. Unauthorized access to these devices can be used to obtain privileged access to the cloud service (e.g., if these are used as security tokens for authentication).\n\nComplementary customer criterion notes on continuous auditing feasibility: Yes, the obligation of the employees to follow the policies and instructions can be made in digital form. This can be used to create a monitoring system that documents the non-obligation to employee guidelines in the form of logs. In this case, the auditor can check the exceptions in the form of logs and request evidence of what additional steps the cloud service provider has taken in these cases to minimize the risk. The compliant use of the assets can then be ensured via an agent system that checks active assets. The status of this system can then be queried by the auditor for a continuous audit.",
          "Asset management (am). Asset inventory. Basic criterion: The cloud service provider has established procedures for inventorying assets. The inventory is performed automatically and/or by the people or teams responsible for the assets to ensure a complete, accurate, valid, and consistent inventory throughout the asset lifecycle. Assets are recorded with the information needed to apply the risk management procedure (cf. OIS-07), including the measures taken to manage these risks throughout the asset lifecycle. Changes to this information are logged.\n\nAdditional criterion: Logging and monitoring applications take into account the information collected on the assets to identify the impact on cloud services and functions in case of events that could lead to a breach of protection objectives. It also supports information provided to affected cloud customers in accordance with contractual agreements.\n\nSupplementary information about the criterion: Assets within the meaning of this criteria area are the objects required for the information security of the cloud service. This includes the creation, processing, storage, transmission, deletion, or destruction of information in the cloud service provider's area of responsibility. Examples of these objects are firewalls, load balancers, web servers, application servers, and database servers. \n\nThese objects consist of hardware and software objects. Hardware objects are physical and virtual infrastructure resources (e.g., servers, storage systems, network components) as well as end devices if the cloud service provider has determined in a risk assessment that they could endanger the information security of the cloud service in the event of loss or unauthorized access (e.g., mobile devices used as security tokens for authentication). Software objects include hypervisors, containers, operating systems, databases, microservices, and programming interfaces (APIs).\n\nThe lifecycle of an asset includes: acquisition, commissioning, maintenance, decommissioning, and disposal.\n\nComplementary customer criterion notes on continuous auditing feasibility: Yes, the cloud service provider must ensure that assets are automatically captured in a database. Automatic capture of physical assets must also be ensured. However, it would be conceivable to automatically capture these assets when logging onto a network for the first time. The creation of virtual assets can be directly linked to the entry into the database. If all assets are recorded automatically, changes to the database can be documented (logs), and these logs can then be continuously evaluated.\n\nIt is important to ensure that the information contained in the inventory and logs is complete. If automated processes are available, the auditor can create an evaluation of the changes in the inventory based on the logs. To check the completeness, the first step would be to query all current assets at the cloud service provider. This asset list could then be compared with the entries in the asset management database.",
          "Supply chain risk management family. Supply chain risk management plan. A. Develop a plan for managing supply chain risks associated with the research and development, design, manufacturing, acquisition, delivery, integration, operations and maintenance, and disposal of the following systems, system components, or system services: [assignment: organization-defined systems, system components, or system services]. \nB. Review and update the supply chain risk management plan [assignment: organization-defined frequency] or as required, to address threat, organizational, or environmental changes. \nC. Protect the supply chain risk management plan from unauthorized disclosure and modification. \n\nThe dependence on products, systems, and services from external providers, as well as the nature of the relationships with those providers, present an increasing level of risk to an organization. Threat actions that may increase security or privacy risks include unauthorized production, the insertion or use of counterfeits, tampering, theft, insertion of malicious software and hardware, and poor manufacturing and development practices in the supply chain. Supply chain risks can be endemic or systemic within a system element or component, a system, an organization, a sector, or the nation. \n\nManaging supply chain risk is a complex, multifaceted undertaking that requires a coordinated effort across an organization to build trust relationships and communicate with internal and external stakeholders. Supply chain risk management (SCRM) activities include identifying and assessing risks, determining appropriate risk response actions, developing SCRM plans to document response actions, and monitoring performance against plans. \n\nThe SCRM plan (at the system-level) is implementation-specific, providing policy implementation, requirements, constraints, and implications. It can either be stand-alone or incorporated into system security and privacy plans. The SCRM plan addresses managing, implementation, and monitoring of SCRM controls and the development/sustainment of systems across the SDLC to support mission and business functions. \n\nBecause supply chains can differ significantly across and within organizations, SCRM plans are tailored to the individual program, organizational, and operational contexts. Tailored SCRM plans provide the basis for determining whether a technology, service, system component, or system is fit for purpose, and as such, the controls need to be tailored accordingly. Tailored SCRM plans help organizations focus their resources on the most critical mission and business functions based on mission and business requirements and their risk environment. \n\nSupply chain risk management plans include an expression of the supply chain risk tolerance for the organization, acceptable supply chain risk mitigation strategies or controls, a process for consistently evaluating and monitoring supply chain risk, approaches for implementing and communicating the plan, a description of and justification for supply chain risk mitigation measures taken, and associated roles and responsibilities. Finally, supply chain risk management plans address requirements for developing trustworthy, secure, privacy-protective, and resilient system components and systems, including the application of the security design principles implemented as part of life cycle-based systems security engineering processes (see SA-8).",
          "Asset management (am). Acceptable use and safe handling of assets policy. Basic criterion: Policies and instructions for acceptable use and safe handling of assets are documented, communicated, and provided in accordance with SP-01. They address the following aspects of the asset lifecycle as applicable to the asset:\n\n- Approval procedures for acquisition, commissioning, maintenance, decommissioning, and disposal by authorized personnel or system components\n- Inventory\n- Classification and labeling based on the need for protection of the information and measures\n- Measures for the level of protection identified\n- Secure configuration of mechanisms for error handling, logging, encryption, authentication, and authorization\n- Requirements for versions of software and images as well as application of patches\n- Handling of software for which support and security patches are not available anymore\n- Restriction of software installations or use of services\n- Protection against malware\n- Remote deactivation, deletion, or blocking\n- Physical delivery and transport\n- Dealing with incidents and vulnerabilities\n- Complete and irrevocable deletion of the data upon decommissioning\n\nAdditional criterion: Supplementary information about the criterion and complementary customer criterion notes on continuous auditing feasibility:\n\nPartially, a policy can change ad-hoc. However, the continuous audit of policies is only partially feasible as the only attributes that can be tested are the last change date and the status of review or approval, as far as this information is stored in a system. The content of a policy can hardly be tested automatically.",
          "System and communications protection. Boundary protection | split tunneling for remote devices. Prevent split tunneling for remote devices connecting to organizational systems, unless the split tunnel is securely provisioned using [assignment: organization-defined safeguards.]. Split tunneling is the process of allowing a remote user or device to establish a non-remote connection with a system and simultaneously communicate via some other connection to a resource in an external network. This method of network access enables a user to access remote devices and simultaneously access uncontrolled networks. Split tunneling might be desirable for remote users to communicate with local system resources, such as printers or file servers. However, split tunneling can facilitate unauthorized external connections, making the system vulnerable to attack and the exfiltration of organizational information. Split tunneling can be prevented by disabling configuration settings that allow such capability in remote devices and by preventing those configuration settings from being configurable by users. Prevention can also be achieved by detecting split tunneling (or configuration settings that allow split tunneling) in the remote device and prohibiting the connection if the remote device is using split tunneling. A Virtual Private Network (VPN) can be used to securely provision a split tunnel. A securely provisioned VPN includes locking connectivity to exclusive, managed, and named environments or to a specific set of pre-approved addresses without user control.",
          "Operations (ops). Logging and monitoring – concept. Basic criterion: The cloud service provider has established policies and instructions that govern the logging and monitoring of events on system components within its area of responsibility. These policies and instructions are documented, communicated, and provided according to SP-01 with respect to the following aspects: \n- Definition of events that could lead to a violation of the protection goals \n- Specifications for activating, stopping, and pausing the various logs \n- Information regarding the purpose and retention period of the logs \n- Define roles and responsibilities for setting up and monitoring logging \n- Time synchronization of system components \n- Compliance with legal and regulatory frameworks \n\nAdditional criterion: Supplementary information about the criterion legal and regulatory frameworks can define, for example, legal requirements for retention and deletion of data. \n\nComplementary Customer Criterion: Cloud customers ensure, through suitable controls, that appropriate logging and monitoring of events that may affect the security and availability of the cloud service (e.g., administrator activities, system failures, authentication checks, data deletions, etc.) takes place for those layers of the cloud service under their responsibility. \n\nNotes on Continuous Auditing Feasibility: Partially, a policy can change ad-hoc. However, the continuous audit of policies is only partially feasible as the only attributes that can be tested are the last change date and the status of review or approval, as far as this information is stored in a system. The content of a policy can hardly be tested automatically.",
          "Operations (ops). Logging and monitoring – metadata management concept. Basic criterion: Policies and instructions for the secure handling of metadata (usage data) are documented, communicated, and provided according to SP-01 with regard to the following aspects: \n\n- Metadata is collected and used solely for billing, incident management, and security incident management purposes. \n\n- Exclusively anonymous metadata is used to deploy and enhance the cloud service, ensuring that no conclusions can be drawn about the cloud customer or user. \n\n- No commercial use of metadata is allowed. \n\n- Storage of metadata is for a fixed period reasonably related to the purposes of the collection. \n\n- Immediate deletion of metadata is required if the purposes of the collection are fulfilled and further storage is no longer necessary. \n\n- Provision of metadata to cloud customers is done according to contractual agreements. \n\nAdditional criterion: Personal data is automatically removed from the log data before the cloud service provider processes it, to the extent that it is technically possible. The removal should be performed in a way that allows the cloud service provider to continue using the log data for the purpose for which it was collected. \n\nSupplementary information about the criterion: Metadata refers to all data generated by the cloud service provider through the use of its service by the cloud customer, excluding content-related data. This includes login/logout times, IP addresses, customers' GPS location, resources used (network, storage, computer), accessed data, data sharing, and communication details. This data is used for billing purposes, (security) incident management, and can also be utilized for analyzing customer behavior and making decision-making and work processes visible to the cloud service provider, depending on the specific cloud service. The criteria aim to provide a transparent and clear definition of the collection and use of metadata. \n\nIn addition, metadata also refers to data generated when the cloud service provider accesses customer data (e.g., for indexing). \n\nComplementary customer criterion notes on continuous auditing feasibility: Partially, policy changes can occur ad-hoc. However, continuous auditing of policies is only partially feasible, as the only attributes that can be tested are the last change date and the status of review or approval, to the extent that this information is stored in a system. The content of a policy can hardly be tested automatically.",
          "Dealing with investigation requests from government agencies (inq). Informing cloud customers about investigation requests. Basic criterion: The cloud service provider informs the affected cloud customer(s) without undue delay, unless the applicable legal basis on which the government agency is based prohibits this or there are clear indications of illegal actions in connection with the use of the cloud service. \nAdditional criterion: Supplementary information about the criterion. This does not affect other legal or regulatory requirements that require earlier information for cloud customers. \nComplementary customer criterion: Cloud customers ensure through suitable controls that such notifications are received and legally checked according to their own specifications and possibilities. \nNotes on continuous auditing feasibility: Partially for internal process monitoring at the cloud service provider and facilitation of the audit, a continuous audit of the period between receipt of the request and information of the customers is conceivable. However, as this depends on local legal basis, the effort to establish this in the respective regions will be quite high. If a transaction processing system is implemented at the cloud service provider, at least the process in this system can be continuously audited.",
          "Portability and interoperability (pi). Documentation and safety of input and output interfaces. Basic criteria: The cloud service can be accessed by other cloud services or IT systems of cloud customers through documented inbound and outbound interfaces. Furthermore, the interfaces are clearly documented for subject matter experts on how they can be used to retrieve the data. Communication takes place through standardized communication protocols that ensure the confidentiality and integrity of the transmitted information, according to its protection requirements. Communication over untrusted networks is encrypted according to CRY-02. The type and scope of the documentation on the interfaces are geared to the needs of the cloud customers' subject matter experts to enable the use of these interfaces. The information is maintained in a way that is applicable for the cloud service's version intended for productive use. \n\nAdditional criteria: Supplementary information about the criterion complementary customer criterion. Cloud customers ensure, through suitable controls, that the provided interfaces (and their security) are adequate for their protection requirements, by means of appropriate checks before the start of use of the cloud service and each time the interfaces are changed. \n\nNotes on continuous auditing feasibility: Partially, the defined input and output interfaces of cloud services are rarely changed. Therefore, it is sufficient for the auditor to test these interfaces, the communication of potential changes, and the associated documentation as part of the recurring audit. In a continuous audit, however, the system status of the interfaces could be queried and evaluated continuously.",
          "Communication security (cos). Policies for data transmission. Basic criterion: Policies and instructions with technical and organizational safeguards are documented, communicated, and provided to protect the transmission of data against unauthorized interception, manipulation, copying, modification, redirection, or destruction. These policies and instructions should reference the classification of information (cf. am-06). \nAdditional criterion: A safeguard against unauthorized interception, manipulation, copying, modification, redirection, or destruction of data during transmission is the use of transport encryption according to cry-02. \nComplementary customer criterion: Cloud customers should ensure, through suitable controls, that the transmitted data to the cloud service is protected against tampering, copying, modifying, redirecting, or deleting based on their protection needs. \nNotes on continuous auditing feasibility: It is not feasible to continuously audit policies as they can change ad-hoc. However, the last change date and status of review or approval can be tested if this information is stored in a system. The content of a policy is difficult to test automatically. \n5.10 Portability and Interoperability (PI) \nObjective: Enable the ability to access the cloud service through other cloud services or IT systems of the cloud customers, retrieve the stored data at the end of the contractual relationship, and securely delete it from the cloud service provider.",
          "Product safety and security (pss). Confidentiality of authentication information. Basic criterion: If passwords are used as authentication information for the cloud service, their confidentiality is ensured by the following procedures: \n- Users can initially create the password themselves or must change an initial password when logging into the cloud service for the first time.\n- An initial password loses its validity after a maximum of 14 days.\n- When creating passwords, compliance with the length and complexity requirements of the cloud service provider (cf. idm-09) or the cloud customer is technically enforced.\n- The user is informed about changing or resetting the password.\n- The server-side storage takes place using state-of-the-art cryptographically strong hash functions in combination with at least 32-bit long salt values.\n\nAdditional criterion: Supplementary information about the criterion: \n- The state-of-the-art regarding cryptographically strong hash functions is described in the current version of the BSI Technical Guideline TR-02102-1 \"Cryptographic Mechanisms: Recommendations and Key Lengths\".\n- In version 2019-01 of this guideline, these were: SHA-256, SHA-512/256, SHA-384, SHA-512; and SHA3-256, SHA3-384, SHA3-512.\n\nComplementary customer criterion: \n- Cloud customers ensure through suitable controls that they use sufficiently secure passwords (cf. idm-09) according to their own assessment and that the risks of unauthorized access associated with their own choice are borne.\n\nNotes on continuous auditing feasibility: \n- No compliance with security policies for password assignment is configured centrally and adjusted at a low frequency.\n- A continuous audit is therefore only of limited use.",
          "Procurement, development and modification of information systems (dev). Safety training and awareness programme regarding continuous software delivery and associated systems, components or tools.. Basic criterion: The cloud service provider provides a training program for regular, target group-oriented security training and awareness for internal and external employees on standards and methods of secure software development and provision, as well as on how to use the tools used for this purpose. The program is regularly reviewed and updated with regard to the applicable policies and instructions, the assigned roles and responsibilities, and the tools used.\n\nAdditional criterion: Supplementary information about the criterion.\n\nComplementary customer criterion: Notes on continuous auditing feasibility.\n\nFeasibility: Yes, the cloud service provider can automatically check the valid policies and instructions, the assigned roles and responsibilities, and the tools used and document the results in logs. These logs can be automatically evaluated by the auditor, and thus, a continuous audit can be carried out.",
          "Risk assessment. Criticality analysis. Identify critical system components and functions by performing a criticality analysis for organization-defined systems, system components, or system services at organization-defined decision points in the system development life cycle. Not all system components, functions, or services necessarily require significant protections. For example, criticality analysis is a key tenet of supply chain risk management and informs the prioritization of protection activities.\n\nThe identification of critical system components and functions considers applicable laws, executive orders, regulations, directives, policies, standards, system functionality requirements, system and component interfaces, and system and component dependencies. Systems engineers conduct a functional decomposition of a system to identify mission-critical functions and components.\n\nThe functional decomposition includes the identification of organizational missions supported by the system, decomposition into the specific functions to perform those missions, and traceability to the hardware, software, and firmware components that implement those functions, including when the functions are shared by many components within and external to the system.\n\nThe operational environment of a system or a system component may impact the criticality, including the connections to and dependencies on cyber-physical systems, devices, system-of-systems, and outsourced IT services. System components that allow unmediated access to critical system components or functions are considered critical due to the inherent vulnerabilities that such components create.\n\nComponent and function criticality are assessed in terms of the impact of a component or function failure on the organizational missions that are supported by the system that contains the components and functions. Criticality analysis is performed when an architecture or design is being developed, modified, or upgraded. If such analysis is performed early in the system development life cycle, organizations may be able to modify the system design to reduce the critical nature of these components and functions, such as by adding redundancy or alternate paths into the system design.\n\nCriticality analysis can also influence the protection measures required by development contractors. In addition to criticality analysis for systems, system components, and system services, criticality analysis of information is an important consideration. Such analysis is conducted as part of security categorization in RA-2.",
          "Business continuity management (bcm). Business impact analysis policies and instructions. Basic criteria: Policies and instructions to determine the impact of any malfunction to the cloud service or enterprise are documented, communicated, and made available in accordance with SP-01. The following aspects are considered as minimum: \n\n- Possible scenarios based on a risk analysis \n- Identification of critical products and services \n- Identify dependencies, including processes (including resources required), applications, business partners, and third parties \n- Capture threats to critical products and services \n- Identification of effects resulting from planned and unplanned malfunctions and changes over time \n- Determination of the maximum acceptable duration of malfunctions \n- Identification of restoration priorities \n- Determination of time targets for the resumption of critical products and services within the maximum acceptable time period (RTO) \n- Determination of time targets for the maximum reasonable period during which data can be lost and not recovered (RPO) \n- Estimation of the resources needed for resumption\n\nAdditional criteria: Supplementary information about the criterion scenarios to be considered according to the basic criteria are, for example, the loss of personnel, buildings, infrastructure, and service providers. \n\nComplementary customer criteria: Cloud customers ensure through suitable controls that the scenarios for a failure of the cloud service or the cloud service provider are sufficiently considered in the context of their business impact analysis.\n\nNotes on continuous auditing feasibility: Partially, a policy can change ad-hoc. However, the continuous audit of policies is only partially feasible as the only attributes that can be tested are the last change date and the status of review or approval, as far as this information is stored in a system. The content of a policy can hardly be tested automatically.",
          "Organisation of information security (ois). Risk management policy. Basic criteria: Policies and instructions for risk management procedures are documented, communicated, and provided in accordance with SP-01. The following aspects should be addressed:\n\n- Identification of risks associated with the loss of confidentiality, integrity, availability, and authenticity of information within the scope of the ISMS and assigning risk owners.\n- Analysis of the probability and impact of occurrence and determination of the level of risk.\n- Evaluation of the risk analysis based on defined criteria for risk acceptance and prioritization of handling.\n- Handling of risks through measures, including approval of authorization and acceptance of residual risks by risk owners.\n- Documentation of the activities implemented to enable consistent, valid, and comparable results.\n\nAdditional criterion: Supplementary information about the criterion is that the risk level can be determined by qualitative, semi-quantitative, and quantitative methods (cf. ISO 31010) based on the likelihood and impacts.\n\nComplementary customer criterion: Notes on continuous auditing feasibility: Partially, a policy can change ad-hoc. However, the continuous audit of policies is only partially feasible as the only attributes that can be tested are the last change date and the status of review or approval, as far as this information is stored in a system. The content of a policy can hardly be tested automatically.",
          "Communication security (cos). Monitoring of connections in the cloud service provider’s network. Basic criterion: A distinction is made between trusted and untrusted networks. Based on a risk assessment, these are separated into different security zones for internal and external network areas (and DMZ, if applicable). Physical and virtualized network environments are designed and configured to restrict and monitor the established connection to trusted or untrusted networks according to the defined security requirements. The entirety of the conception and configuration undertaken to monitor the connections mentioned is assessed in a risk-oriented manner, at least annually, with regard to the resulting security requirements. Identified vulnerabilities and deviations are subject to risk assessment in accordance with the risk supplementary information about the criterion. The review of the security requirements depends on the measures implemented to design the networks. For example, monitoring and reviewing firewall rules or log files for abnormalities, as well as visual inspections of physical network components for changes.\n\nComplementary customer criterion: Cloud customers ensure through suitable controls that the virtual networks within the cloud service for which they are responsible are designed, configured, and documented in accordance with their network security requirements (e.g. logical segmentation of the cloud customer's organizational units).\n\nNotes on continuous auditing feasibility: Yes, if the business justification and the regular review of the monitoring concept are documented in a standardized way, these processes can be evaluated automatically. Thus, a continuous audit can be conducted. The separation of the networks is suitable for continuous auditing as well since the status of the separation can be continuously audited here.",
          "Identity and access management (idm). Confidentiality of authentication information. Basic criterion: The allocation of authentication information to access system components used to provide the cloud service to internal and external users of the cloud provider and system components that are involved in automated authorization processes of the cloud provider is done in an orderly manner that ensures the confidentiality of the information. If passwords are used as authentication information, their confidentiality is ensured by the following procedures, as far as technically possible: \n\n- Users can initially create the password themselves or must change an initial password when logging on to the system component for the first time. \n- An initial password loses its validity after a maximum of 14 days. \n- When creating passwords, compliance with the password specifications (cf. idm-09) is enforced as far as technically possible. \n- The user is informed about changing or resetting the password. \n- The server-side storage takes place using cryptographically strong hash functions. \n- Deviations are evaluated by means of a risk analysis and mitigating measures derived from this are implemented. \n\nAdditional criterion: \nThe users sign a declaration in which they assure that they treat personal (or shared) authentication information confidentially and keep it exclusively for themselves (within the members of the group). \n\nSupplementary information about the criterion: \nArgon2i, for example, is suitable for using a password hash function. Insofar as this is legally binding, declarations can be signed using an electronic signature. \n\nComplementary customer criterion: \nNotes on continuous auditing feasibility: Yes, if the implementation is enforced by appropriate system configuration (automated control), the status or the last change of the configuration can be checked regularly.",
          "Planning. Baseline tailoring. Tailor the selected control baseline by applying specified tailoring actions. The concept of tailoring allows organizations to specialize or customize a set of baseline controls by applying a defined set of tailoring actions. Tailoring actions facilitate such specialization and customization by allowing organizations to develop security and privacy plans that reflect their specific mission and business functions, the environments where their systems operate, the threats and vulnerabilities that can affect their systems, and any other conditions or situations that can impact their mission or business success. Tailoring guidance is provided in SP 800-53b. Tailoring a control baseline is accomplished by identifying and designating common controls, applying scoping considerations, selecting compensating controls, assigning values to control parameters, supplementing the control baseline with additional controls as needed, and providing information for control implementation. The general tailoring actions in SP 800-53b can be supplemented with additional actions based on the needs of organizations. Tailoring actions can be applied to the baselines in SP 800-53b in accordance with the security and privacy requirements from FISMA, privacy, and OMB A-130. Alternatively, other communities of interest adopting different control baselines can apply the tailoring actions in SP 800-53b to specialize or customize the controls that represent the specific needs and concerns of those entities.",
          "Communication security (cos). Networks for administration. Basic criterion: There are separate networks for the administrative management of the infrastructure and for the operation of management consoles. These networks are logically or physically separated from the cloud customer's network and protected from unauthorized access by multi-factor authentication (cf. idm-09). Networks used by the cloud service provider to migrate or create virtual machines are also physically or logically separated from other networks.\n\nAdditional criterion: Supplementary information about the criterion complementary customer criterion notes on continuous auditing feasibility: No, a continuous audit is not practical since infrastructure components and the logical and physical separation of the networks are implemented initially. A continuous audit of these components may require a system status, but it is difficult to test all aspects continuously.",
          "Configuration management. Access restrictions for change | privilege limitation for production and operation. (a) Limit privileges to change system components and system-related information within a production or operational environment; and (b) review and reevaluate privileges [assignment: organization-defined frequency]. In many organizations, systems support multiple mission and business functions. Limiting privileges to change system components with respect to operational systems is necessary because changes to a system component may have far-reaching effects on mission and business processes supported by the system. The relationships between systems and mission/business processes are, in some cases, unknown to developers. System-related information includes operational procedures.",
          "Operations (ops). Logging and monitoring – storage of the logging data. Basic criterion: The cloud service provider retains the generated log data and keeps them in an appropriate, unchangeable, and aggregated form, regardless of the source of such data, so that a central, authorized evaluation of the data is possible. Log data is deleted if it is no longer required for the purpose for which they were collected. Between logging servers and the assets to be logged, authentication takes place to protect the integrity and authenticity of the information transmitted and stored. The transfer takes place using state-of-the-art encryption or a dedicated administration network (out-of-band management).\n\nAdditional criterion: The cloud service provider provides customer-specific logging (in terms of scope and duration of retention period) upon the request of the cloud customer. Depending on the protection requirements of the cloud service provider and the technical feasibility, a logical or physical separation of log and customer data is carried out.\n\nSupplementary information about the criterion:\nComplementary customer criterion\nNotes on continuous auditing feasibility: Yes, the storage of logging data at a central location can be documented by logs when the data is saved. The deletion of this data can also be automated and documented by logs. The auditor can then perform an automated and continuous evaluation of these logs.",
          "Access control. Remote access. a. Establish and document usage restrictions, configuration/connection requirements, and implementation guidance for each type of remote access allowed; and b. Authorize each type of remote access to the system prior to allowing such connections. Remote access is access to organizational systems (or processes acting on behalf of users) that communicate through external networks such as the internet. Types of remote access include dial-up, broadband, and wireless. Organizations use encrypted Virtual Private Networks (VPNs) to enhance confidentiality and integrity for remote connections. The use of encrypted VPNs provides sufficient assurance to the organization that it can effectively treat such connections as internal networks if the cryptographic mechanisms used are implemented in accordance with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Still, VPN connections traverse external networks, and the encrypted VPN does not enhance the availability of remote connections. VPNs with encrypted tunnels can also affect the ability to adequately monitor network communications traffic for malicious code. Remote access controls apply to systems other than public web servers or systems designed for public access. Authorization of each remote access type addresses authorization prior to allowing remote access without specifying the specific formats for such authorization. While organizations may use information exchange and system connection security agreements to manage remote access connections to other systems, such agreements are addressed as part of CA-3. Enforcing access restrictions for remote access is addressed via AC-3.",
          "Control and monitoring of service providers and suppliers (sso). Directory of service providers and suppliers. Basic criterion: The cloud service provider maintains a directory for controlling and monitoring the service providers and suppliers who contribute services to the delivery of the cloud service. The following information is maintained in the directory: company name, address, locations of data processing and storage, responsible contact person at the service provider/supplier, responsible contact person at the cloud service provider, description of the service, classification based on the risk assessment, beginning of service usage, and proof of compliance with contractually agreed requirements. The information in the list is checked at least annually for completeness, accuracy, and validity.\n\nAdditional criterion: Supplementary information about the criterion. It is not necessary to maintain a single central register in order to fulfill the basic criterion. \n\nComplementary customer criterion: Notes on continuous auditing feasibility. No ad-hoc completeness checks on the specified criteria can safely take place automatically, as can a comparison of changed data with relevant company databases. This can be set up by the cloud service provider. The auditor can then examine deviations as part of the recurring audit. However, due to the frequency and the completeness analysis, a continuous audit is not efficient due to the large effort required.",
          "System and services acquisition. Developer security and privacy architecture and design. Require the developer of the system, system component, or system service to produce a design specification and security and privacy architecture that: a. is consistent with the organization's security and privacy architecture that is an integral part of the organization's enterprise architecture; b. accurately and completely describes the required security and privacy functionality and the allocation of controls among physical and logical components; and c. expresses how individual security and privacy functions, mechanisms, and services work together to provide required security and privacy capabilities and a unified approach to protection. Developer security and privacy architecture and design are directed at external developers, although they could also be applied to internal (in-house) development. In contrast, PL-8 is directed at internal developers to ensure that organizations develop a security and privacy architecture that is integrated with the enterprise architecture. The distinction between SA-17 and PL-8 is especially important when organizations outsource the development of systems, system components, or system services and when there is a requirement to demonstrate consistency with the enterprise architecture and security and privacy architecture of the organization. ISO 15408-2, ISO 15408-3, and SP 800-160-1 provide information on security architecture and design, including formal policy models, security-relevant components, formal and informal correspondence, conceptually simple design, and structuring for least privilege and testing.",
          "Business continuity management (bcm). Top management responsibility. Basic criterion: The top management (or a member of the top management) of the cloud service provider is named as the process owner of business continuity and emergency management. They are responsible for establishing the process within the company as well as ensuring compliance with the guidelines. They must ensure that sufficient resources are made available for an effective process. People in management and other relevant leadership positions demonstrate leadership and commitment to this issue by encouraging employees to actively contribute to the effectiveness of continuity and emergency management.\n\nAdditional criterion: Supplementary information about the criterion\n\nComplementary customer criterion: \n\nNotes on continuous auditing feasibility: No, the responsibilities for continuity and emergency management processes are initially named and rarely changed afterwards. Therefore, a continuous audit is not effective. However, a continuous audit can return the date of the last revision of the guidelines for continuity and emergency management.",
          "Planning. Security and privacy architectures. a. Develop security and privacy architectures for the system that: \n1. Describe the requirements and approach to be taken for protecting the confidentiality, integrity, and availability of organizational information. \n2. Describe the requirements and approach to be taken for processing personally identifiable information to minimize privacy risk to individuals. \n3. Describe how the architectures are integrated into and support the enterprise architecture. \n4. Describe any assumptions about, and dependencies on, external systems and services. \n\nb. Review and update the architectures [assignment: organization-defined frequency] to reflect changes in the enterprise architecture. \n\nc. Reflect planned architecture changes in security and privacy plans, concept of operations (conops), criticality analysis, organizational procedures, and procurements and acquisitions. \n\nThe security and privacy architectures at the system level are consistent with the organization-wide security and privacy architectures described in PM-7, which are integral to and developed as part of the enterprise architecture. The architectures include an architectural description, the allocation of security and privacy functionality (including controls), security- and privacy-related information for external interfaces, information being exchanged across the interfaces, and the protection mechanisms associated with each interface. The architectures can also include other information, such as user roles and the access privileges assigned to each role, security and privacy requirements, types of information processed, stored, and transmitted by the system, supply chain risk management requirements, restoration priorities of information and system services, and other protection needs. \n\nSP 800-160-1 provides guidance on the use of security architectures as part of the system development life cycle process. \nOMB M-19-03 requires the use of the systems security engineering concepts described in SP 800-160-1 for high-value assets. \n\nSecurity and privacy architectures are reviewed and updated throughout the system development life cycle, from analysis of alternatives through review of the proposed architecture in the RFP responses to the design reviews before and during implementation (e.g., during preliminary design reviews and critical design reviews). \n\nIn today’s modern computing architectures, it is becoming less common for organizations to control all information resources. There may be key dependencies on external information services and service providers. Describing such dependencies in the security and privacy architectures is necessary for developing a comprehensive mission and business protection strategy. \n\nEstablishing, developing, documenting, and maintaining under configuration control a baseline configuration for organizational systems is critical to implementing and maintaining effective architectures. \n\nThe development of the architectures is coordinated with the Senior Agency Information Security Officer and the Senior Agency Official for Privacy to ensure that the controls needed to support security and privacy requirements are identified and effectively implemented. \n\nIn many circumstances, there may be no distinction between the security and privacy architecture for a system. In other circumstances, security objectives may be adequately satisfied, but privacy objectives may only be partially satisfied by the security requirements. In these cases, consideration of the privacy requirements needed to achieve satisfaction will result in a distinct privacy architecture. The documentation, however, may simply reflect the combined architectures. \n\nPL-8 is primarily directed at organizations to ensure that architectures are developed for the system and, moreover, that the architectures are integrated with or tightly coupled to the enterprise architecture. In contrast, SA-17 is primarily directed at the external information technology product and system developers and integrators. SA-17, which is complementary to PL-8, is selected when organizations outsource the development of systems or components to external entities and when there is a need to demonstrate consistency with the organization’s enterprise architecture and security and privacy architectures.",
          "System and communications protection. Separation of system and user functionality. Separate user functionality, including user interface services, from system management functionality. System management functionality includes functions that are necessary to administer databases, network components, workstations, or servers. These functions typically require privileged user access. \n\nThe separation of user functions from system management functions can be physical or logical. Organizations may choose to separate system management functions from user functions by utilizing different computers, instances of operating systems, central processing units, or network addresses. They can also employ virtualization techniques or a combination of other methods. \n\nThe separation of system management functions from user functions should also extend to web administrative interfaces. These interfaces should employ separate authentication methods compared to users accessing other system resources. \n\nIn addition, it is recommended to isolate administrative interfaces on different domains and implement additional access controls. \n\nAchieving the separation of system and user functionality can be accomplished by applying the systems security engineering design principles outlined in SA-8. This includes SA-8(1), SA-8(3), SA-8(4), SA-8(10), SA-8(12), SA-8(13), SA-8(14), and SA-8(18).",
          "Dealing with investigation requests from government agencies (inq). Legal assessment of investigative inquiries. Basic criterion: Investigation requests from government agencies are subjected to a legal assessment by subject matter experts of the cloud service provider. The assessment determines whether the government agency has an applicable and legally valid legal basis and what further steps need to be taken.\n\nAdditional criterion: Supplementary information about the criterion complementary customer criterion. Cloud customers ensure through suitable controls that the type and scope of government investigation requests and the associated disclosure of their own data has been dealt with in their own risk management and that the use of the cloud service only takes place when this risk has been deemed acceptable.\n\nNotes on continuous auditing feasibility: No. Although a continuous audit of the performance of the assessment and its documentation is conceivable, a continuous audit is not practical. Rather, the criterion aims at the qualification of the auditing personnel as well as the process behind it, which is both subject to manual audit.",
          "Operations (ops). Logging and monitoring – identification of events. Basic criterion: The logging data is automatically monitored for events that may violate the protection goals in accordance with the logging and monitoring requirements. This also includes the detection of relationships between events (event correlation). Identified events are automatically reported to the appropriate departments for prompt evaluation and action.\n\nAdditional criterion: Additional information about the criterion. Supplementary information about the criterion.\n\nComplementary customer criterion: Complementary notes on continuous auditing feasibility: Yes, the cloud service provider can automatically test the list of assets critical for monitoring and record this test in logs. The auditor can audit the log files for irregularities automatically and continuously.",
          "Organisation of information security (ois). Application of the risk management policy. Basic criterion: The cloud service provider executes the process for handling risks as needed or at least once a year. The following aspects are taken into account when identifying risks, insofar as they are applicable to the cloud service provided and are within the area of responsibility of the cloud service provider: processing, storage, or transmission of data of cloud customers with different protection needs; occurrence of vulnerabilities and malfunctions in technical protective measures for separating shared resources; attacks via access points, including interfaces accessible from public networks; conflicting tasks and areas of responsibility that cannot be separated for organizational or technical reasons; and dependencies on subservice organizations. The analysis, evaluation, and treatment of risks, including the approval of actions and acceptance of residual risks, are reviewed for adequacy at least annually by the risk owners.\n\nAdditional criterion supplementary information about the criterion: This criterion applies only to risks that reside within the area of responsibility of the cloud service provider. Risks that arise for the cloud customer when using the cloud service are not covered by this criterion. When outsourcing activities for the provision of cloud services to subservice organizations, the responsibility for these risks remains with the cloud service provider. Requirements for measures to manage these risks can be found in the criteria area \"Control and monitoring of service providers and suppliers (SSO)\". Shared resources are e.g. networks, RAM, or storage.\n\nComplementary customer criterion notes on continuous auditing feasibility: Partially, the procedure for handling risks must be tested at least once a year and is therefore part of the standard audit cycle. However, the continuous audit of handling risk is only partially feasible as the only attributes that can be tested are the last review date and the status of review or approval, as far as this information is stored in a system. The content of the risks can hardly be tested automatically.\n\n5.2 Security policies and instructions (SP) objective: Provide policies and instructions regarding security requirements and to support business requirements.",
          "Physical security (ps). Physical site access control. Basic criterion: At access points to premises and buildings related to the cloud service provided, physical access controls are set up in accordance with the cloud service provider's security requirements (cf. PS-01 security concept) to prevent unauthorized access. Access controls are supported by an access control system. The requirements for the access control system are documented, communicated, and provided in a policy or concept in accordance with SP-01 and include the following aspects: \n\n- Specified procedure for the granting and revoking of access authorizations (cf. IDM-02) based on the principle of least authorization (\"least-privilege principle\") and as necessary for the performance of tasks (\"need-to-know principle\").\n- Automatic revocation of access authorizations if they have not been used for a period of 2 months.\n- Automatic withdrawal of access authorizations if they have not been used for a period of 6 months.\n- Two-factor authentication for access to areas hosting system components that process cloud customer information.\n- Visitors and external personnel are tracked individually by the access control during their work in the premises and buildings, identified as such (e.g., by visible wearing of a visitor pass), and supervised during their stay.\n- Existence and nature of access logging that enables the cloud service provider, in the sense of an effectiveness audit, to check whether only defined personnel have entered the premises and buildings related to the cloud service provided.\n\nAdditional criterion: Supplementary information about the criterion complementary customer criterion notes on continuous auditing:\n\nFeasibility: Yes. Access control via an access card system can be documented by the cloud service provider in the form of logs. These logs can be evaluated automatically. In addition, unauthorized access can also be traced through these logs. This can also be evaluated automatically. Therefore, a continuous audit is possible. Insofar as the withdrawal of access authorizations is standardized and documented in the same way, an automated evaluation is also possible here, and thus, a continuous audit can be carried out.",
          "Security incident management (sim). Processing of security incidents. Basic criterion: Subject matter experts of the cloud service provider, together with external security providers where appropriate, classify, prioritize, and perform root-cause analyses for events that could constitute a security incident.\n\nAdditional criterion: The cloud service provider simulates the identification, analysis, and defense of security incidents and attacks at least once a year through appropriate tests and exercises (e.g. red team training).\n\nSupplementary information about the criterion: Complementary customer criterion notes on continuous auditing feasibility: Yes, the cloud service provider documents all security incidents in digital form, which contains information about the classification, prioritization, and root cause analysis of the incidents. The root cause analysis should be standardized to facilitate continuous auditing. An automatic and continuous evaluation of these security incidents can then be carried out by the auditor by excluding the logs or tickets produced and testing whether the security incident has been classified and prioritized and whether these steps have been carried out based on a standardized root cause analysis. The continuous audit thus provides a constant statement as to whether security incidents have been correctly recorded, classified, and subjected to a root cause analysis.",
          "Operations (ops). Logging and monitoring – configuration. Basic criterion: Access to system components for logging and monitoring in the cloud service provider’s area of responsibility is restricted to authorized users. Changes to the configuration are made in accordance with the applicable policies (cf. dev-03). \n\nAdditional criterion: Access to system components for logging and monitoring in the cloud service provider’s area of responsibility requires two-factor authentication. \n\nSupplementary information about the criterion: \nComplementary customer criterion notes on continuous auditing feasibility: Yes, the continuous audit of this access restriction can be tested by log files of all changes to access rights for the system components for logging and monitoring. Changes can be automatically and continuously audited according to the person’s sense and need for access.",
          "Organisation of information security (ois). Segregation of duties. Basic criterion: Conflicting tasks and responsibilities are separated based on an OIS-06 risk assessment to reduce the risk of unauthorized or unintended changes or misuse of cloud customer data processed, stored, or transmitted in the cloud service. The risk assessment covers the following areas, insofar as these are applicable to the provision of the cloud service and are in the area of responsibility of the cloud service provider: \n\nAdministration of rights profiles, approval and assignment of access and access authorizations (cf. IDM-01)\nDevelopment, testing, and release of changes (cf. DEV-01)\nOperation of the system components. \n\nIf separation cannot be established for organizational or technical reasons, measures are in place to monitor the activities in order to detect unauthorized or unintended changes as well as misuse and to take appropriate actions. \n\nAdditional criterion: \n\nSupplementary information about the criterion identified events that may constitute unauthorized or unintentional changes to or misuse of cloud customer data may, for example, be treated as a security incident (cf. SIM-01). \n\nComplementary customer criterion: \n\nNotes on continuous auditing feasibility: \n\nYes, continuous audit is possible, especially in the case of changes to role profiles and responsibilities. This would require an initial check of the defined roles and responsibilities by the cloud service provider. The roles that are added or changed on a monthly basis could then be automated and continuously checked.",
          "Cryptography and key management (cry). Secure key management. Basic criterion: Procedures and technical safeguards for secure key management in the area of responsibility of the cloud service provider include at least the following aspects: \n- Generation of keys for different cryptographic systems and applications \n- Issuing and obtaining public-key certificates \n- Provisioning and activation of the keys \n- Secure storage of keys (separation of key management system from application and middleware level), including description of how authorized users get access \n- Changing or updating cryptographic keys, including policies defining under which conditions and in which manner the changes and/or updates are to be realized \n- Handling of compromised keys \n- Withdrawal and deletion of keys \n- If pre-shared keys are used, the specific provisions relating to the safe use of this procedure are specified separately\n\nAdditional criterion: Supplementary information about the criterion\n  \nKeys should be withdrawn or deleted, e.g. in the event of compromise or employee changes. The cloud service provider protects the keys which are created and inserted into the cloud service by the cloud customers according to the same criteria as the keys created by the cloud service provider.\n\nComplementary customer criterion: Notes on continuous auditing feasibility\n  \nPartially for procedures and technical measures for key management to take into account the required aspects, these aspects must be implemented in the corresponding configuration. These configurations are rarely changed, and only these changes would have to be audited continuously. However, the system status could be reviewed and, in the event of irregularities, indicated and documented.\n\n5.9 Communication security (COS) \n\nObjective: Ensure the protection of information in networks and the corresponding information processing systems.",
          "Compliance (com). Policy for planning and conducting audits. Basic criterion: Policies and instructions for planning and conducting audits are documented, communicated, and made available in accordance with SP-01. They address the following aspects: \n- Restriction to read-only access to system components in accordance with the agreed audit plan and as necessary to perform the activities. \n- Activities that may result in malfunctions to the cloud service or breaches of contractual requirements are performed during scheduled maintenance windows or outside peak periods. \n- Logging and monitoring of activities. \n\nAdditional criterion: The cloud service provider grants its cloud customers contractually guaranteed information and audit rights. \n\nSupplementary information about the criterion: \n- Complementary customer criterion - Cloud customers ensure through suitable controls that appropriate responses are made to malfunctions to the cloud service through such audits. \n- To the extent that contractually guaranteed information and audit rights exist, the cloud customers ensure through suitable controls that these rights are designed and executed in accordance with their own requirements. \n\nNotes on continuous auditing feasibility: \nPartially, a policy can change ad-hoc. However, the continuous audit of policies is only partially feasible as the only attributes that can be tested are the last change date and the status of review or approval, as far as this information is stored in a system. The content of a policy can hardly be tested automatically.",
          "Business continuity management (bcm). Verification, updating and testing of the business continuity. Basic criterion: The business impact analysis, business continuity plans, and contingency plans are reviewed, updated, and tested on a regular basis (at least annually) or after significant organizational or environmental changes. Tests involve affected customers (tenants) and relevant third parties. The tests are documented, and results are taken into account for future operational continuity measures.\n\nAdditional criterion: In addition to the tests, exercises are also carried out which, among other things, have resulted in scenarios from security incidents that have already occurred in the past.\n\nSupplementary information about the criterion: Tests are primarily conducted at the operational level and are aimed at operational target groups. Tests include, e.g.: test of technical precautionary measures; functional tests; and plan review. Exercises also take place on a tactical and strategic level. These include, e.g.: plan meeting; staff exercise; command post exercise; communication and alerting exercise; simulation of scenarios; and emergency or full exercise. After a completed exercise: review and possible adaptation of the existing alarm plan.\n\nRelevant third parties are, in particular, service providers and suppliers of the cloud service provider who contribute to the provision of the cloud service (cf. basic criteria sso-02 and sso-05).\n\nComplementary customer criterion: Cloud customers ensure through suitable controls that measures to prevent the impact of a cloud service or cloud service provider outage are regularly reviewed, updated, tested, and exercised. The cloud service provider is involved in the tests and exercises in accordance with the contractual agreements. Cloud customers ensure through suitable controls that the results of the cloud service provider's BCM tests and exercises are incorporated into their own BCM and that they are fully appreciated with regard to ensuring the customer's operational continuity. In tests and exercises that involve the customer and therefore require own measures on the customer side, cloud customers ensure that the appropriate measures for coping with the scenario are practiced and tested by means of suitable BCM controls.\n\nNotes on continuous auditing feasibility: Partially implementing the tests of the operational continuity plans in an annual cycle does not make the continuous audit of the entire criterion effective. The effort for both cloud service providers and auditors to automate and continuously test this process would be higher than the results. However, it is possible to continuously audit whether a test was carried out within the required time span. To do this, the cloud service provider must document, in a standardized manner, that and when a test was carried out.\n\n5.15 Compliance (COM)\n\nObjective: Avoid non-compliance with legal, regulatory, self-imposed, or contractual information security and compliance requirements.",
          "Personnel (hr). Confidentiality agreements. Basic criterion: The non-disclosure or confidentiality agreements to be agreed with internal employees, external service providers, and suppliers of the cloud service provider are based on the requirements identified by the cloud service provider for the protection of confidential information and operational details. The agreements are to be accepted by external service providers and suppliers when the contract is agreed. The agreements must be accepted by internal employees of the cloud service provider before authorization to access data of cloud customers is granted. The requirements must be documented and reviewed at regular intervals (at least annually). If the review shows that the requirements need to be adapted, the non-disclosure or confidentiality agreements are updated. The cloud service provider must inform the internal employees, external service providers, and suppliers and obtain confirmation of the updated confidentiality or non-disclosure agreement.\n\nAdditional criterion: Supplementary information about the criterion in a confidentiality agreement. It should be described: which information must be kept confidential; the period for which this confidentiality agreement applies; what actions must be taken upon termination of this agreement, e.g. destruction or return of data medium; how the ownership of information is regulated; what rules apply to the use and disclosure of confidential information to other partners if necessary; and the consequences of a breach of the agreement. Confidentiality or non-disclosure agreements can be signed by means of an electronic signature, insofar as this is legally binding.\n\nComplementary customer criterion: Notes on continuous auditing feasibility: Yes, the signing of confidentiality agreements with internal employees, external service providers, and suppliers can be standardized and stored digitally. An automated continuous evaluation can then be carried out to check whether all parties have signed such a confidentiality agreement and whether the agreement is up-to-date.\n\n5.4 Asset Management (AM)\n\nObjective: Identify the organization's own assets and ensure an appropriate level of protection throughout their lifecycle.",
          "Personnel (hr). Employment terms and conditions. Basic criterion: The cloud service provider's internal and external employees are required, by the employment terms and conditions, to comply with applicable policies and instructions relating to information security. The information security policy, and the policies and instructions based on it, must be acknowledged by the internal and external personnel in a documented form before access is granted to any cloud customer data or system components under the responsibility of the cloud service provider, used to provide the cloud service in the production environment.\n\nAdditional criterion: Supplementary information about the criterion. The cloud service provider ensures that the policies and instructions reflect applicable legal and regulatory requirements in accordance with SP-01.\n\nComplementary customer criterion: Notes on continuous auditing feasibility. Yes, due to the obligation of employees to comply with certain requirements, a continuous audit is not practical. Compliance with the requirements can be verified as part of a standard audit cycle. A continuous audit of the granting of access, only after acknowledgement of the instructions, is achievable as long as the cloud service provider designs the approval system to document the appropriate data (e.g., date of acknowledgement, which data the employee had access to and when). A clear definition and differentiation of customer data, as well as data in the productive environment, is essential. With the help of this data, the auditor can perform a comparison and detect deviations accordingly. The data could be monitored using an agent on a monitoring system.",
          "Configuration management. Configuration change control | cryptography management. Ensure that cryptographic mechanisms used to provide the following controls are under configuration management: [assignment: organization-defined controls]. The controls referenced in the control enhancement refer to security and privacy controls from the control catalog. Regardless of the cryptographic mechanisms employed, processes and procedures are in place to manage those mechanisms. For example, if system components use certificates for identification and authentication, a process is implemented to address the expiration of those certificates.",
          "Asset management (am). Commissioning of hardware. Basic criterion: The cloud service provider has an approval process for the use of hardware to be commissioned, which is used to provide the cloud service in the production environment, in which the risks arising from the commissioning are identified, analyzed and mitigated. Approval is granted after verification of the secure configuration of the mechanisms for error handling, logging, encryption, authentication, and authorization according to the intended use and based on the applicable policies. \n\nAdditional criterion: \n\nSupplementary information about the criterion: The basic criterion applies only to physical hardware objects, such as servers, storage systems, and network components. Virtual hardware and software objects are considered in the criteria areas (ops) and (dev). The approval process typically considers both the basic approval to use the hardware and the final approval of the configured assets. \n\nComplementary customer criterion: \n\nNotes on continuous auditing feasibility: \n\nYes, the approval of the commissioning of hardware by authorized personnel or system components must be digitally documented to allow continuous testing. A ticketing system, for example, is suitable for this purpose. Both the instance and the verification of the configuration must be stored in the respective ticket. This makes it possible for the auditor to check the tickets in an automated procedure. This requires an automated comparison of the authorized instance against a database containing all potential approvers. In addition, the verification of the configuration in the ticket must be audited automatically. The compliant use of the assets can then be ensured via an agent system which checks active assets. The status of this system can then be queried by the auditor for a continuous audit.",
          "Identity and access management (idm). Authentication mechanisms. Basic criterion: System components in the cloud service provider's area of responsibility that are used to provide the cloud service, authenticate users of the cloud service provider's internal and external employees, as well as system components that are involved in the cloud service provider's automated authorization processes. Access to the production environment requires two-factor or multi-factor authentication. Within the production environment, user authentication takes place through passwords, digitally signed certificates, or procedures that achieve at least an equivalent level of security. If digitally signed certificates are used, administration is carried out in accordance with the guideline for key management (cf. cry-01). The password requirements are derived from a risk assessment and documented, communicated, and provided in a password policy according to sp-01. Compliance with the requirements is enforced by the configuration of the system components, as far as technically possible. Additional criterion: Access to the non-production environment requires two-factor or multi-factor authentication. Within the non-production environment, users are authenticated using passwords, digitally signed certificates, or procedures that provide at least an equivalent level of security.\n\nSupplementary information about the criterion: Complementary customer criterion notes on continuous auditing feasibility: Yes, if the implementation is enforced by appropriate system configuration (automated control), the status of the configuration or its last change can be checked regularly.\n\n5.8 Cryptography and Key Management (CRY)\n\nObjective: Ensure appropriate and effective use of cryptography to protect the confidentiality, authenticity, or integrity of information.",
          "Procurement, development and modification of information systems (dev). Version control. Basic criterion: Version control procedures are set up to track dependencies of individual changes and to restore affected system components back to their previous state as a result of errors or identified vulnerabilities. \n\nAdditional criterion: Version control procedures provide appropriate safeguards to ensure that the integrity and availability of cloud customer data is not compromised when system components are restored back to their previous state. \n\nSupplementary information about the criterion: \n\nComplementary customer criterion notes on continuous auditing feasibility: Yes, the procedures for version control of the cloud service provider, and if necessary, resetting to previous states can be automated. This must be documented in logs. An automatic evaluation of these logs makes continuous auditing possible.",
          "Operations (ops). Managing vulnerabilities, malfunctions and errors – penetration tests. Basic criterion: The cloud service provider has penetration tests carried out by qualified internal personnel or external service providers at least once a year. The penetration tests are carried out according to a documented test methodology and include the system components relevant to the provision of the cloud service in the area of responsibility of the cloud service provider, which have been identified as such in a risk analysis. The cloud service provider assesses the severity of the findings made in penetration tests according to defined criteria. For findings with medium or high criticality regarding the confidentiality, integrity, or availability of the cloud service, actions must be taken within defined time windows for prompt remediation or mitigation.\n\nAdditional criterion: The tests are carried out every six months. They must always be performed by independent external auditors. Internal personnel for penetration tests may support the external service providers.\n\nSupplementary information about the criterion: Vulnerabilities should be classified according to damage potential, and a period of time should be specified for the required response. The following classification, according to the BSI publication \"Ein Praxis-Leitfaden für IS-Penetrationstests,\" can serve as an orientation: high: immediate reaction; medium: short-term response; low: medium-term response; and information: long-term response.\n\nComplementary customer criterion: Notes on continuous auditing feasibility: Partially, since penetration tests are carried out annually, a continuous audit is not practical since the effort required to automate the execution of the test is probably greater than the benefit.",
          "Identity and access management (idm). Policy for user accounts and access rights. Basic criterion: A role and rights concept based on the business and security requirements of the cloud service provider, as well as a policy for managing user accounts and access rights for internal and external employees of the cloud service provider, and system components that have a role in automated authorization processes of the cloud service provider, are documented, communicated, and made available. According to SP-01, the following principles are applied: assignment of unique usernames; granting and modifying user accounts and access rights based on the \"least-privilege-principle\" and the \"need-to-know\" principle; segregation of duties between operational and monitoring functions (\"segregation of duties\"); segregation of duties between managing, approving, and assigning user accounts and access rights; approval by authorized individuals or systems for granting or modifying user accounts and access rights before accessing data of the cloud customer or system components used to provision the cloud service; regular review of assigned user accounts and access rights; blocking and removing access accounts in the event of inactivity; time-based or event-driven removal or adjustment of access rights in the event of changes to job responsibilities; two-factor or multi-factor authentication for users with privileged access; and requirements for the approval and documentation of the management of user accounts and access rights. \n\nAdditional criterion: Supplementary information about the criterion and system components in the sense of the basic criterion can be found in the definition in OPS-23. Automated authorization processes in the sense of this basic criterion concern procedures for automated software provisioning (continuous delivery), as well as for automated provisioning and deprovisioning of user accounts and access rights based on approved requests. \n\nComplementary customer criterion: Notes on continuous auditing feasibility: Partially, a policy can change ad-hoc. However, the continuous audit of policies is only partially feasible, as the only attributes that can be tested are the last change date and the status of review or approval, as far as this information is stored in a system. The content of a policy can hardly be tested automatically. The aspects mentioned in the policy can be converted into individual criteria and embedded in a continuous audit. Individual aspects of the policy which can be examined on an ongoing basis include: unique username; segregation of duties; rights profile management (approvals); authorized bodies or individuals; regular review; deactivation due to inactivity; and multi-factor authentication. \n\nApproval and documentation: Individual aspects of the policy which cannot be continuously examined in a practicable manner include: implementation of least-privilege/need-to-know principles; and withdrawal or adjustment of access rights as the task area changes.",
          "Security assessment and authorization. Penetration testing | red team exercises. Employ the following red-team exercises to simulate attempts by adversaries to compromise organizational systems in accordance with applicable rules of engagement: [assignment: organization-defined red team exercises]. Red team exercises extend the objectives of penetration testing by examining the security and privacy posture of organizations and the capability to implement effective cyber defenses. Red team exercises simulate attempts by adversaries to compromise mission and business functions and provide a comprehensive assessment of the security and privacy posture of systems and organizations. Such attempts may include technology-based attacks and social engineering-based attacks. Technology-based attacks include interactions with hardware, software, or firmware components and/or mission and business processes. Social engineering-based attacks include interactions via email, telephone, shoulder surfing, or personal conversations. Red team exercises are most effective when conducted by penetration testing agents and teams with knowledge of and experience with current adversarial tactics, techniques, procedures, and tools. While penetration testing may be primarily laboratory-based testing, organizations can use red team exercises to provide more comprehensive assessments that reflect real-world conditions. The results from red team exercises can be used by organizations to improve security and privacy awareness and training and to assess control effectiveness.",
          "Contingency planning. Telecommunications services | priority of service provisions. (a) Develop primary and alternate telecommunications service agreements that contain priority-of-service provisions in accordance with availability requirements (including recovery time objectives). (b) Request telecommunications service priority for all telecommunications services used for national security emergency preparedness if the primary and/or alternate telecommunications services are provided by a common carrier. Organizations should consider the potential mission or business impact in situations where telecommunications service providers are servicing other organizations with similar priority of service provisions.\n\nTelecommunications Service Priority (TSP) is a Federal Communications Commission (FCC) program that directs telecommunications service providers (e.g., wireline and wireless phone companies) to give preferential treatment to users enrolled in the program when they need to add new lines or have their lines restored following a disruption of service, regardless of the cause. The FCC sets the rules and policies for the TSP program, and the Department of Homeland Security manages the TSP program. The TSP program is always in effect and not contingent on a major disaster or attack taking place. Federal sponsorship is required to enroll in the TSP program.",
          "Access control. Access control for mobile devices. A. Establish configuration requirements, connection requirements, and implementation guidance for organization-controlled mobile devices, to include when such devices are outside of controlled areas. \nB. Authorize the connection of mobile devices to organizational systems.\n\nA mobile device is a computing device that has a small form factor such that it can easily be carried by a single individual. It is designed to operate without a physical connection, possesses local, non-removable or removable data storage, and includes a self-contained power source. Mobile device functionality may also include voice communication capabilities, on-board sensors that allow the device to capture information, and/or built-in features for synchronizing local data with remote locations. Examples include smartphones and tablets. Mobile devices are typically associated with a single individual. The processing, storage, and transmission capability of the mobile device may be comparable to or merely a subset of notebook/desktop systems, depending on the nature and intended purpose of the device.\n\nProtection and control of mobile devices are behavior or policy-based and require users to take physical action to protect and control such devices when outside of controlled areas. Controlled areas are spaces for which organizations provide physical or procedural controls to meet the requirements established for protecting information and systems. Due to the large variety of mobile devices with different characteristics and capabilities, organizational restrictions may vary for the different classes or types of such devices.\n\nUsage restrictions and specific implementation guidance for mobile devices include:\n- Configuration management\n- Device identification and authentication\n- Implementation of mandatory protective software\n- Scanning devices for malicious code\n- Updating virus protection software\n- Scanning for critical software updates and patches\n- Conducting primary operating system (and possibly other resident software) integrity checks\n- Disabling unnecessary hardware\n\nUsage restrictions and authorization to connect may vary among organizational systems. For example, the organization may authorize the connection of mobile devices to its network and impose a set of usage restrictions, while a system owner may withhold authorization for mobile device connection to specific applications or impose additional usage restrictions before allowing mobile device connections to a system.\n\nAdequate security for mobile devices goes beyond the requirements specified in AC-19. Many safeguards for mobile devices are reflected in other controls. AC-20 addresses mobile devices that are not organization-controlled.",
          "Configuration management. Least functionality | authorized software — allow-by-exception. (a) Identify [assignment: organization-defined software programs authorized to execute on the system]. \n(b) Employ a deny-all, permit-by-exception policy to allow the execution of authorized software programs on the system. \n(c) Review and update the list of authorized software programs [assignment: organization-defined frequency]. Authorized software programs can be limited to specific versions or from a specific source. \nTo facilitate a comprehensive authorized software process and increase the strength of protection for attacks that bypass application-level authorized software, software programs may be decomposed into and monitored at different levels of detail. These levels include applications, application programming interfaces, application modules, scripts, system processes, system services, kernel functions, registries, drivers, and dynamic link libraries. \nThe concept of permitting the execution of authorized software may also be applied to user actions, system ports and protocols, IP addresses/ranges, websites, and MAC addresses. Organizations consider verifying the integrity of authorized software programs using digital signatures, cryptographic checksums, or hash functions. Verification of authorized software can occur either prior to execution or at system startup. The identification of authorized URLs for websites is addressed in CA-3 (5) and SC-7.",
          "Configuration management. System component inventory | automated maintenance. Maintain the currency, completeness, accuracy, and availability of the inventory of system components using [assignment: organization-defined automated mechanisms]. Organizations maintain system inventories to the extent feasible. For example, virtual machines can be difficult to monitor because such machines are not visible to the network when not in use. In such cases, organizations maintain as up-to-date, complete, and accurate an inventory as is deemed reasonable. Automated maintenance can be achieved by the implementation of CM-2 (2) for organizations that combine system component inventory and baseline configuration activities.",
          "Dealing with investigation requests from government agencies (inq). Conditions for access to or disclosure of data in investigation requests. Basic criterion: Access to or disclosure of cloud customer data in connection with government investigation requests is subject to the proviso that the cloud service provider's legal assessment has shown that an applicable and valid legal basis exists and that the investigation request must be granted on that basis.\n\nAdditional criterion:\n\n- Supplementary information about the criterion\n- Complementary customer criterion\n- Notes on continuous auditing feasibility: Yes, to the extent that a separate role is assigned to the investigator in order to gain access to the data. The prerequisites specified in the request can be entered and checked by the system and linked to the assignment of the investigator role. A continuous query can then be made to ensure that the role was only granted if the prerequisites defined by the system were fulfilled. Deviations can be audited manually.",
          "Procurement, development and modification of information systems (dev). Policies for the development/ procurement of information systems. Basic criterion: Policies and instructions with technical and organizational measures for the secure development of the cloud service are documented, communicated and provided in accordance with SP-01. The policies and instructions contain guidelines for the entire lifecycle of the cloud service and are based on recognized standards and methods with regard to the following aspects: security in software development (requirements, design, implementation, testing, and verification); security in software deployment (including continuous delivery); and security in operation (reaction to identified faults and vulnerabilities). \n\nAdditional criterion: In procurement, products are preferred which have been certified according to the \"Common Criteria for Information Technology Security Evaluation\" (short: Common Criteria - CC) according to evaluation assurance level EAL 4. If non-certified products are to be procured instead of available certified products, a risk assessment is carried out in accordance with OIS-07.\n\nSupplementary information about the criterion: The software provision can be carried out, for example, with continuous delivery methods. Accepted standards and methods are, for example: ISO/IEC 27034; and OWASP Secure Software Development Lifecycle (S-SDLC). \n\nComplementary customer criterion notes on continuous auditing feasibility: No. The contents of the policies and instructions for the proper development or procurement of information systems do not change at a high frequency. A continuous audit of this documentation is not practical. Therefore, the integration of these tests into the recurring audit is sufficient.",
          "Cryptography and key management (cry). Policy for the use of encryption procedures and key management. Basic criterion: Policies and instructions with technical and organizational safeguards for encryption procedures and key management are documented, communicated, and provided according to SP-01. The following aspects are described:\n\n- Usage of strong encryption procedures and secure network protocols that correspond to the state-of-the-art.\n- Risk-based provisions for the use of encryption aligned with the information classification schemes (cf. AM-06). This includes considering the communication channel, type, strength, and quality of the encryption.\n- Requirements for secure generation, storage, archiving, retrieval, distribution, withdrawal, and deletion of encryption keys.\n- Consideration of relevant legal and regulatory obligations and requirements.\n\nAdditional criterion: \n\nSupplementary information about the criterion:\n\nThe state-of-the-art of strong encryption procedures and secure network protocols is specified in the following BSI technical guidelines valid at the given time:\n\n- BSI TR-02102-1: Cryptographic mechanisms - Recommendations and key lengths.\n- BSI TR-02102-2: Cryptographic mechanisms - Use of Transport Layer Security (TLS).\n- BSI TR-02102-3: Cryptographic mechanisms - Use of Internet Protocol Security (IPSec) and Internet Key Exchange (IKEv2).\n- BSI TR-02102-4: Cryptographic mechanisms - Use of Secure Shell (SSH).\n\nComplementary customer criterion:\n\nNotes on continuous auditing feasibility: Partially, a policy can change ad-hoc. However, the continuous audit of policies is only partially feasible as the only attributes that can be tested are the last change date and the status of review or approval, as far as this information is stored in a system. The content of a policy can hardly be tested automatically.",
          "Product safety and security (pss). Session management. Basic criterion: To protect confidentiality, availability, integrity, and authenticity during interactions with the cloud service, a suitable session management system is used that at least corresponds to the state-of-the-art and is protected against known attacks. Mechanisms are implemented that invalidate a session after it has been detected as inactive. The inactivity can be detected by time measurement. In this case, the time interval can be configured by the cloud service provider or – if technically possible – by the cloud customer.\n\nAdditional criterion: Supplementary information about the criterion of known attacks includes manipulation, forgery, session takeover, denial of service attacks, enveloping, replay, and null cipher attacks.\n\nComplementary customer criterion: Cloud customers can use appropriate controls to ensure that they are using the session management protection features of the cloud service in accordance with their own ISMS. They also set the time period after which a session becomes invalid according to their own ISMS specifications.\n\nNotes on continuous auditing feasibility: Partially, the use of session management is controlled by configurations. These configurations are changed or adapted at a low frequency, so continuous auditing is only partially effective. Nevertheless, monitoring the status of the underlying authentication system is conceivable, but only deviations from target configurations can be checked. Whether these deviations are normal must still be tested in a manual audit.",
          "Operations (ops). Separation of datasets in the cloud infrastructure. Basic criterion: Cloud customer data stored and processed on shared virtual and physical resources is securely and strictly separated according to a documented approach based on OIS-07 risk analysis to ensure the confidentiality and integrity of this data. \n\nAdditional criterion: Resources in the storage network are segmented by secure zoning (LUN binding and LUN masking). Supplementary information about the criterion shared resources include memory, cores, and storage networks. \n\nTechnical segregation (separation) of the stored and processed data of cloud customers into shared resources can be achieved through firewalls, access lists, tagging, VLANs, virtualization, and measures in the storage network (e.g., LUN binding and LUN masking). \n\nWhere the adequacy and effectiveness of segregation cannot be assessed with reasonable assurance (e.g., due to complex implementation), evidence may also be provided through expert third-party review results (e.g., penetration tests to validate the concept). \n\nThe segregation of transmitted data is subject to control COS-06. \n\nComplementary customer criterion: Cloud customers ensure through suitable controls that the functions provided by the cloud service for segregating shared virtual and physical resources are used in such a way that risks related to segregation are adequately addressed according to the data's protection requirements. \n\nNotes on continuous auditing feasibility: Partially, the segregation according to a documented concept is implemented by means of a configuration that does not change with high frequency. A continuous audit of this configuration could check whether the configuration and thus the segregation of the data is implemented correctly. However, the effort for a continuous audit would be high, and the benefit limited due to the low change rate of the configuration. Thus, a continuous audit would only be of limited use here. If compliance with the measures taken is monitored, this criterion can be audited automatically. It would also be conceivable to continuously audit the actual data segregation. For this purpose, the cloud service provider would have to set up appropriate agents to monitor the data flow between the customer instances (or its absence) on a permanent and documented basis (logs). \n\n5.7 Identity and Access Management (IDM) \n\nObjective: Secure the authorization and authentication of users of the cloud service provider (typically privileged users) to prevent unauthorized access.",
          "Supply chain risk management family. Supply chain risk management plan | establish scrm team. Establish a Supply Chain Risk Management team consisting of [assignment: organization-defined personnel, roles, and responsibilities] to lead and support the following SCRM activities: [assignment: organization-defined supply chain risk management activities]. To implement Supply Chain Risk Management plans, organizations establish a coordinated, team-based approach to identify and assess supply chain risks and manage these risks by using programmatic and technical mitigation techniques. The team approach enables organizations to conduct an analysis of their supply chain, communicate with internal and external partners or stakeholders, and gain broad consensus regarding the appropriate resources for SCRM. The SCRM team consists of organizational personnel with diverse roles and responsibilities for leading and supporting SCRM activities, including Risk Executive, Information Technology, Contracting, Information Security, Privacy, Mission or Business, Legal, Supply Chain and Logistics, Acquisition, Business Continuity, and other relevant functions. Members of the SCRM team are involved in various aspects of the SDLC and, collectively, have an awareness of and provide expertise in acquisition processes, legal practices, vulnerabilities, threats, and attack vectors, as well as an understanding of the technical aspects and dependencies of systems. The SCRM team can be an extension of the Security and Privacy Risk Management processes or be included as part of an organizational risk management team.",
          "Operations (ops). Logging and monitoring – availability of the monitoring software. Basic criterion: The cloud service provider monitors the system components for logging and monitoring in its area of responsibility. Failures are automatically and promptly reported to the cloud service provider's responsible departments so that they can assess the failures and take the required action.\n\nAdditional criterion: The system components for logging and monitoring are designed in such a way that the overall functionality is not restricted if individual components fail.\n\nSupplementary information about the criterion:\n\nComplementary customer criterion notes on continuous auditing feasibility: Yes, automatically communicated failures can be tracked in logs. A continuous and automated audit of these failures can be carried out by evaluating these logs.",
          "Identity and access management (idm). Locking and withdrawal of user accounts in the event of inactivity or multiple failed logins. Basic criterion: User accounts of internal and external employees of the cloud service provider, as well as for system components involved in automated authorization processes of the cloud service provider, are automatically locked if they have not been used for a period of two months. Approval from authorized personnel or system components is required to unlock these accounts. Locked user accounts are automatically revoked after six months. After revocation, the procedure for granting user accounts and access rights (cf. idm-02) must be repeated. \n\nAdditional criterion: Supplementary information about the criterion locking can result from a longer absence of the employee, for example, due to illness, parental leave, or sabbatical. \n\nComplementary customer criterion: Notes on continuous auditing feasibility: Yes, automated processes can easily be included in the continuous audit. Appropriate evaluation and reporting mechanisms must be used by the cloud service provider. The auditor must use data analyses to detect deviations.",
          "Operations (ops). Data backup and recovery – storage. Basic criterion: The cloud service provider transfers data to be backed up to a remote location or transports it on backup media to a remote location. If the data backup is transmitted to the remote location via a network, the data backup or the transmission of the data takes place in an encrypted form that corresponds to the state-of-the-art. The distance to the main site is chosen after sufficient consideration of the factors recovery times and impact of disasters on both sites. The physical and environmental security measures at the remote site are at the same level as at the main site.\n\nAdditional criterion:\nSupplementary information about the criterion: If the data backup is not part of the contract concluded between the cloud service provider and the cloud customer, this criterion is not applicable. The cloud service provider must present this situation transparently in the system description.\n\nA remote location can be, for example, another data center of the cloud service provider.\n\nComplementary customer criterion:\nNotes on continuous auditing feasibility: Yes. If the data is transported physically, a continuous audit of this criterion means that the successful storage has been confirmed. In the case of electronic transmission, the log files of the transmission can be continuously evaluated, and the result of this audit can be transmitted.",
          "System and communications protection. Architecture and provisioning for name/address resolution service. Ensure the systems that collectively provide name/address resolution service for an organization are fault-tolerant and implement internal and external role separation. Systems that provide name and address resolution services include Domain Name System (DNS) servers. To eliminate single points of failure in systems and enhance redundancy, organizations employ at least two authoritative Domain Name System servers—one configured as the primary server and the other configured as the secondary server. Additionally, organizations typically deploy the servers in two geographically separated network subnetworks (i.e., not located in the same physical facility). \n\nFor role separation, DNS servers with internal roles only process name and address resolution requests from within organizations (i.e., from internal clients). DNS servers with external roles only process name and address resolution information requests from clients external to organizations (i.e., on external networks, including the internet). Organizations specify clients that can access authoritative DNS servers in certain roles (e.g., by address ranges and explicit lists).",
          "Communication security (cos). Security requirements for connections in the cloud service provider’s network. Basic criterion: Specific security requirements are designed, published, and provided for establishing connections within the cloud service provider's network. The security requirements define, for the cloud service provider's area of responsibility, in which cases the security zones are to be separated and in which cases cloud customers are to be logically or physically segregated. They also define which communication relationships and network and application protocols are permitted in each case. Additionally, the security requirements detail how the data traffic for administration and monitoring is segregated from each other on the network level, which internal, cross-location communication is permitted, and which cross-network communication is allowed.\n\nAdditional criterion: Management procedures (cf. OIS-06) and follow-up measures (cf. OPS-18) are defined and tracked. At specified intervals, the business justification for using all services, protocols, and ports is reviewed. \n\nSupplementary information: The review also includes the justifications for compensatory measures for the use of protocols that are considered insecure. Cross-location communication can be realized, for example, for individual regions or data centers via WAN, LAN, VPN, RAS.\n\nComplementary customer criterion: Additional criterion notes on continuous auditing feasibility: No. The required security requirements are centrally documented and rarely changed. Continuous auditing is not practical.",
          "Product safety and security (pss). Images for virtual machines and containers. Basic criterion: If cloud customers operate virtual machines or containers with the cloud service, the cloud service provider must ensure the following aspects: The cloud customer can restrict the selection of images of virtual machines or containers according to their specifications so that users of this cloud customer can only launch the images or containers released according to these restrictions. If the cloud service provider provides images of virtual machines or containers to the cloud customer, the cloud service provider must appropriately inform the cloud customer of the changes made to the previous version. In addition, these images provided by the cloud service provider must be hardened according to generally accepted industry standards. \n\nAdditional criterion: At startup and runtime of virtual machine or container images, an integrity check must be performed that detects image manipulations and reports them to the cloud customer. \n\nSupplementary information about the criterion: This criterion is typically not applicable to the SaaS service model. Generally accepted industry standards are, for example, the Security Configuration Benchmark of the Centre for Internet Security (CIS) or the corresponding modules in the BSI IT-Grundschutz-Kompendium. \n\nComplementary customer criterion: Cloud customers must use appropriate controls to ensure that the images of virtual machines or containers they operate with the cloud service comply with their information security management requirements and that the results of the integrity checks at startup and at runtime are processed according to these requirements. \n\nNotes on continuous auditing feasibility: Partially, these functions must be centrally audited at regular intervals but not continuously. Therefore, it is sufficient to integrate this into the recurring audit. With an agent system, it would be possible to continuously query the configurations of the individual virtual machines and thus compare them with the target image. This could also be set up on demand and thus become part of the control that takes over the integrity check.",
          "Physical security (ps). Protection from fire and smoke. Basic criterion: Premises and buildings related to the cloud service provided are protected from fire and smoke by structural, technical, and organizational measures that meet the security requirements of the cloud service provider (cf. PS-01 security concept). This includes the following aspects:\n\na) Structural measures: Establishment of fire sections with a fire resistance duration of at least 90 minutes for all structural parts.\n\nb) Technical measures: Early fire detection with automatic voltage release. The monitored areas are sufficiently fragmented to ensure that the prevention of the spread of incipient fires is proportionate to the maintenance of the availability of the cloud service provided. This includes an extinguishing system or oxygen reduction and a fire alarm system with reporting to the local fire department.\n\nc) Organizational measures: Regular fire protection inspections to check compliance with fire protection requirements and regular fire protection exercises.\n\nAdditional criterion: The environmental parameters are monitored. When the permitted control range is exceeded, alarm messages are generated and forwarded to the cloud service provider's subject matter experts.\n\nSupplementary information about the criterion: The monitoring of the environmental parameters is addressed in PS-01. When exceeding the allowed control range, alarm messages are generated and forwarded to the responsible cloud service provider. Structural parts include walls, ceilings, floors, doors, ventilation flaps, etc.\n\nComplementary customer criterion notes on continuous auditing feasibility: Yes, continuous testing is possible insofar as the built-in technology for testing the protective measures produces evaluable data, and these are stored in a standardized form. This would allow the security measures to be continuously evaluated by the auditor. If this technology is not fully available and an inspection of the data center is necessary, the possibility of continuous auditing is achievable only to a limited extent.",
          "Procurement, development and modification of information systems (dev). Policies for changes to information systems. Basic criterion: Policies and instructions with technical and organizational safeguards for change management of system components of the cloud service within the scope of software deployment are documented, communicated, and provided according to SP-01. The following aspects should be considered:\n\n1. Criteria for risk assessment, categorization, and prioritization of changes.\n2. Related requirements for the type and scope of testing to be performed and necessary approvals for the development/implementation of the change.\n3. Approvals for releases of changes in the production environment by authorized personnel or system components.\n4. Requirements for the performance and documentation of tests.\n5. Requirements for segregation of duties during development, testing, and release of changes.\n6. Requirements for informing cloud customers about the type and scope of changes and their obligations to cooperate based on contractual agreements.\n7. Requirements for documenting changes in system, operational, and user documentation.\n8. Requirements for the implementation and documentation of emergency changes, maintaining the same level of security as normal changes.\n\nAdditional criterion: Supplementary information about changes in the sense of the basic criterion refers to those that can lead to changes in the configuration, functionality, or security of system components of the cloud service in the production environment. This includes changes to the infrastructure and source code. If individual changes are combined in a new release, update, patch, or comparable software object for software provisioning, this software object is considered a change within the meaning of the basic criterion, but not the individual changes contained therein. Changes to the existing network configuration must also undergo a specified procedure as they are necessary for the effective segregation of cloud customers. Personnel and system components authorized to approve changes must adhere to the requirements for access and access authorizations (cf. IDM-01), following a specified procedure (cf. IDM-02). Relevant information includes descriptions of new functions. The cloud customer's obligations to cooperate may include carrying out certain tests.\n\nComplementary customer criterion: Notes on continuous auditing feasibility: No, the contents of the policies and instructions for managing and modifying system components are not changed at a high frequency. A continuous audit of this documentation is therefore not effective. It is sufficient to integrate these tests into the recurring audit.",
          "Operations (ops). Capacity management – controlling of resources. Basic criterion: Depending on the capabilities of the respective service model, the cloud customer can control and monitor the allocation of the system resources assigned to the customer for administration/use in order to avoid overcrowding of resources and to achieve sufficient performance.\n\nAdditional criterion: Supplementary information about the criterion resources, according to the possibilities of the service model, are, for example, computing capacity; storage capacity; configuration of network properties; application programming interfaces (APIs); and databases.\n\nComplementary customer criterion: Cloud customers ensure through suitable controls that they manage and monitor the system resources in their area of responsibility.\n\nNotes on continuous auditing feasibility: Partially, the existence of tools for controlling resources by the cloud customers themselves is, in itself, a continuous process, which can be continuously checked provided that the cloud service provider can prove the functionality of these tools by means of logs. However, continuously checking this only generates limited value. The functionality of the provided tools can be continuously audited if they are documented and can be evaluated by the cloud service provider.",
          "Procurement, development and modification of information systems (dev). Separation of environments. Basic criterion: Production environments are physically or logically separated from test or development environments to prevent unauthorized access to cloud customer data, the spread of malware, or changes to system components. Data contained in the production environments is not used in test or development environments to avoid compromising their confidentiality.\n\nAdditional criterion: Supplementary information about the criterion complementary customer criterion notes on continuous auditing feasibility: Yes, since fundamental changes in test or development environments that would affect the physical or logical separation are rarely made, a continuous audit is not practical. The respective environments must be tested initially and then audited again if changes are made.\n\n5.12 Control and monitoring of service providers and suppliers (SSO) objective: Ensure the protection of information that service providers or suppliers of the cloud service provider (subcontractors) can access and monitor the agreed services and security requirements.",
          "Asset management (am). Decommissioning of hardware. Basic criterion: The decommissioning of hardware used to operate system components supporting the cloud service production environment, under the responsibility of the cloud service provider, requires approval based on the applicable policies. The decommissioning includes the complete and permanent deletion of the data or proper destruction of the media.\n\nAdditional criterion: Supplementary information about the criterion: The deletion of data or physical destruction of data mediums can take place, for example, according to DIN 66399 or BSI IT-Grundschutz Module Con.6.\n\nComplementary customer criterion: \n\nNotes on continuous auditing feasibility: Yes, the approval of the decommissioning of hardware by authorized personnel or system components must be digitally documented to allow continuous testing. A ticketing system, for example, is suitable for this purpose. Both the instance and the verification of the complete deletion of the data must be stored in the respective ticket. This enables the auditor to check the tickets in an automated procedure. This requires an automated comparison of the authorized instance against a database containing all potential approvers. In addition, the deletion of the data documented in the ticket must be audited automatically. The compliant use of the assets can be ensured via an agent system which checks active assets. The status of this system can then be queried by the auditor for a continuous audit.",
          "Physical security (ps). Surveillance of operational and environmental parameters. Basic criterion: The operating parameters of the technical utilities (cf. PS-06) and the environmental parameters of the premises and buildings related to the cloud service provided are monitored and controlled in accordance with the security requirements of the cloud service provider (cf. PS-01 security concept). When the permitted control range is exceeded, the responsible departments of the cloud provider are automatically informed in order to promptly initiate the necessary measures for return to the control range.\n\nAdditional criterion; supplementary information about the criterion: Operating parameters and environmental parameters of the premises and buildings include, for example, air temperature and humidity, leakage.\n\nComplementary customer criterion: Notes on continuous auditing feasibility: Yes, the monitoring and control of the operating parameters of the technical supply facilities is carried out automatically and documented in a standardized manner, for example, in logs. These logs are then automated by the inspector and can be continuously evaluated.\n\n5.6 Operations (OPS)\n\nObjective: Ensure proper and regular operation, including appropriate measures for planning and monitoring capacity, protection against malware, logging and monitoring events, and dealing with vulnerabilities, malfunctions, and failures.",
          "Operations (ops). Data backup and recovery – regular testing. Basic criterion: Restore procedures are tested regularly, at least annually. The tests allow an assessment to be made as to whether the contractual agreements as well as the specifications for the maximum tolerable downtime (Recovery Time Objective, RTO) and the maximum permissible data loss (Recovery Point Objective, RPO) are adhered to (cf. BCM-02). Deviations from the specifications are reported to the responsible personnel or system components so that these can promptly assess the deviations and initiate the necessary actions. \n\nAdditional criterion: At the customer's request, the cloud service provider informs the cloud customer of the results of the recovery tests. Recovery tests are embedded in the cloud service provider's emergency management. \n\nSupplementary information about the criterion: If the data backup is not part of the contract concluded between the cloud service provider and the cloud customer, this criterion is not applicable. The cloud service provider must present this situation transparently in the system description. \n\nComplementary customer criterion notes on continuous auditing feasibility: Partially, if the tests on the restoration procedures are performed at regular intervals, the time of execution and results can be audited automatically. However, the effort of a continuous audit of this criterion is high and the added value limited if the tests are carried out in an annual cycle.",
          "Procurement, development and modification of information systems (dev). Risk assessment, categorisation and prioritisation of changes. Basic criterion: In accordance with the applicable policies (cf. dev-03), changes are subjected to a risk assessment with regard to potential effects on the system components concerned and are categorized and prioritized accordingly. Additional criterion: In accordance with the contractual agreements, meaningful information about the occasion, time, duration, type, and scope of the change is submitted to authorized bodies of the cloud customer so that they can carry out their own risk assessment before the change is made available in the production environment. Regardless of the contractual agreements, this is done for changes that have the highest risk category based on their risk assessment. Supplementary information about the criterion: Complementary customer criterion notes on continuous auditing feasibility: Yes, the evaluation of changes in releases can be standardized and automated by the cloud service provider. If this evaluation is carried out in standardized and digital form (tickets/logs), an automated evaluation can be carried out by the auditor.",
          "Personnel (hr). Responsibilities in the event of termination or change of employment. Basic criterion: Internal and external employees have been informed about the responsibilities arising from employment terms and conditions relating to information security, which will remain in place when their employment is terminated or changed, and for how long. \n\nAdditional criterion: Supplementary information about the criterion: The cloud service provider ensures that the policies and instructions reflect applicable legal and regulatory requirements in accordance with SP-01. \n\nComplementary customer criterion: Notes on continuous auditing feasibility: Yes. As part of a comprehensive, system-based documentation of HR data, it is conceivable that the employee will receive confirmation that he or she has been informed about the required topics. This should be requested again at the end of the employment relationship. If such documentation was available in standardized and digital form, the auditor would be able to check each termination for this confirmation and identify any deviations. This makes continuous verification possible.",
          "Access control. Information flow enforcement. Enforce approved authorizations for controlling the flow of information within the system and between connected systems based on [assignment: organization-defined information flow control policies]. Information flow control regulates where information can travel within a system and between systems (in contrast to who is allowed to access the information) and without regard to subsequent accesses to that information. Flow control restrictions include blocking external traffic that claims to be from within the organization, keeping export-controlled information from being transmitted in the clear to the internet, restricting web requests that are not from the internal web proxy server, and limiting information transfers between organizations based on data structures and content. \n\nTransferring information between organizations may require an agreement specifying how the information flow is enforced (see ca-3). Transferring information between systems in different security or privacy domains with different security or privacy policies introduces the risk that such transfers violate one or more domain security or privacy policies. In such situations, information owners/stewards provide guidance at designated policy enforcement points between connected systems. Organizations consider mandating specific architectural solutions to enforce specific security and privacy policies. Enforcement includes prohibiting information transfers between connected systems (i.e., allowing access only), verifying write permissions before accepting information from another security or privacy domain or connected system, employing hardware mechanisms to enforce one-way information flows, and implementing trustworthy regrading mechanisms to reassess security or privacy attributes and labels. Organizations commonly employ information flow control policies and enforcement mechanisms to control the flow of information between designated sources and destinations within systems and between connected systems. Flow control is based on the characteristics of the information and/or the information path. Enforcement occurs, for example, in boundary protection devices that employ rule sets or establish configuration settings that restrict system services, provide a packet-filtering capability based on header information, or provide a message-filtering capability based on message content. \n\nOrganizations also consider the trustworthiness of filtering and/or inspection mechanisms (i.e., hardware, firmware, and software components) that are critical to information flow enforcement. Control enhancements 3 through 32 primarily address cross-domain solution needs that focus on more advanced filtering techniques, in-depth analysis, and stronger flow enforcement mechanisms implemented in cross-domain products, such as high-assurance guards. Such capabilities are generally not available in commercial off-the-shelf products. Information flow enforcement also applies to control plane traffic (e.g., routing and DNS).",
          "System and communications protection. Public key infrastructure certificates. a. Issue public key certificates under an [assignment: organization-defined certificate policy] or obtain public key certificates from an approved service provider; and b. Include only approved trust anchors in trust stores or certificate stores managed by the organization. Public Key Infrastructure (PKI) certificates are certificates with visibility external to organizational systems and certificates related to the internal operations of systems, such as application-specific time services. In cryptographic systems with a hierarchical structure, a trust anchor is an authoritative source (i.e., a certificate authority) for which trust is assumed and not derived. A root certificate for a PKI system is an example of a trust anchor. A trust store or certificate store maintains a list of trusted root certificates.",
          "Product safety and security (pss). Roles and rights concept. Basic criterion: The cloud service provider provides cloud users with a roles and rights concept for managing access rights. It describes rights profiles for the functions provided by the cloud service. The rights profiles are suitable for enabling cloud users to manage access authorizations and permissions in accordance with the principle of least privilege and how it is necessary for the performance of tasks (\"need-to-know principle\") and to implement the principle of functional separation between operational and controlling functions (\"separation of duties\").\n\nAdditional criterion: Supplementary information about the criterion. In IaaS, a role and rights concept would describe, among other things, the rights profiles for the following functions of the cloud service: \n\n- Administration of the states of virtual machines (start, pause, stop) as well as for their migration or monitoring; \n- Management of available images that can be used to create virtual machines; \n- Management of virtual networks (e.g., configuration of virtual routers and switches). \n\nComplementary customer criterion: Cloud customers ensure through suitable controls that: \n\n- The granting of permissions to users in their area of responsibility is subject to authorization; \n- The appropriateness of the assigned authorizations is regularly reviewed and authorizations are adjusted or withdrawn in a timely manner in the event of necessary changes (e.g., employee resignation). \n\nNotes on continuous auditing feasibility: Partially, the existence of a roles and rights concept in the form of a configuration in the system can be monitored. However, it should be noted that, regarding the content of this concept, only deviations from target configurations can be checked. Whether these deviations are desired or not must still be recorded in a manual audit.",
          "Communication security (cos). Technical safeguards. Basic criterion: Based on the results of a risk analysis carried out according to ISO-06, the cloud service provider has implemented technical safeguards that are suitable to promptly detect and respond to network-based attacks. These attacks are based on irregular incoming or outgoing traffic patterns and/or distributed denial of service (DDoS) attacks. The corresponding technical protection measures are documented, communicated, and provided in accordance with SP-01. \n\nAdditional criterion: Technical measures ensure that no unknown (physical or virtual) devices join the cloud service provider's (physical or virtual) network. This can be achieved through measures such as MACsec according to IEEE 802.1x:2010. \n\nSupplementary information about the criterion: Network-based attacks can include MAC spoofing and ARP poisoning attacks. \n\nComplementary customer criterion: Cloud customers are responsible for ensuring suitable controls for parts of the cloud service under their responsibility (e.g., virtual machines within an IaaS solution). They should detect and respond to network-based attacks based on anomalous inbound and outbound traffic patterns, such as MAC spoofing, ARP poisoning attacks, and DDoS attacks, in a timely manner. \n\nNotes on continuous auditing feasibility: The technical protective measures are suitable for continuous auditing, but they are rarely changed. However, the data fed into the overall SIEM system and the detection of correlating events are suitable for continuous auditing. This data can be evaluated automatically and continuously, as can the monitoring of correlating events.",
          "Security policies and instructions (sp). Review and approval of policies and instructions. Basic criterion: Information security policies and instructions are reviewed at least annually for adequacy by the cloud service provider's subject matter experts. The review shall consider at least the following aspects: organizational and technical changes in the procedures for providing the cloud service and legal and regulatory changes in the cloud service provider's environment. Revised policies and instructions are approved before they become effective.\n\nAdditional Criterion:\nSupplementary information about the criterion:\nComplementary customer criterion notes on continuous auditing feasibility:\nPartially, a continuous automated audit of the content changes to policies and instructions is only partially practicable at the current state-of-the-art. A continuous audit of the reviewers' authorization and expertise does not appear to be effective either, as this cannot be linked to specified parameters of an automated evaluation. A continuous examination of this criterion could therefore only consist of returning the date of the last examination.",
          "Personnel security. Personnel termination. Upon termination of individual employment: a. Disable system access within [assignment: organization-defined time period]. b. Terminate or revoke any authenticators and credentials associated with the individual. c. Conduct exit interviews that include a discussion of [assignment: organization-defined information security topics]. d. Retrieve all security-related organizational system-related property. e. Retain access to organizational information and systems formerly controlled by the terminated individual. \n\nSystem property includes hardware authentication tokens, system administration technical manuals, keys, identification cards, and building passes. Exit interviews ensure that terminated individuals understand the security constraints imposed by being former employees and that proper accountability is achieved for system-related property. Security topics at exit interviews include reminding individuals of nondisclosure agreements and potential limitations on future employment. Exit interviews may not always be possible for some individuals, including in cases related to the unavailability of supervisors, illnesses, or job abandonment. Exit interviews are important for individuals with security clearances. The timely execution of termination actions is essential for individuals who have been terminated for cause. In certain situations, organizations consider disabling the system accounts of individuals who are being terminated prior to the individuals being notified.",
          "Personnel (hr). Disciplinary measures. Basic criterion: In the event of violations of policies and instructions or applicable legal and regulatory requirements, actions are taken in accordance with a defined policy that includes the following aspects: verifying whether a violation has occurred; and consideration of the nature and severity of the violation and its impact. The internal and external employees of the cloud service provider are informed about possible disciplinary measures. The use of disciplinary measures is appropriately documented.\n\nAdditional criterion: Supplementary information about the criterion. The cloud service provider ensures that the policies and instructions reflect applicable legal and regulatory requirements in accordance with SP-01.\n\nComplementary customer criterion: Notes on continuous auditing feasibility: No continuous audit is not practical, as the associated processes and steps can be tested once within a recurring audit. A system-based definition of the violations as well as the corresponding regulations does not appear practical, since in this context individual case decisions are often necessary which cannot be covered by predefined algorithms.",
          "System and information integrity. System monitoring | system-generated alerts. Alert [assignment: organization-defined personnel or roles] when the following system-generated indications of compromise or potential compromise occur: [assignment: organization-defined compromise indicators]. Alerts may be generated from a variety of sources, including audit records or inputs from malicious code protection mechanisms, intrusion detection or prevention mechanisms, or boundary protection devices such as firewalls, gateways, and routers. Alerts can be automated and may be transmitted telephonically, by electronic mail messages, or by text messaging. Organizational personnel on the alert notification list can include system administrators, mission or business owners, system owners, information owners/stewards, senior agency information security officers, senior agency officials for privacy, system security officers, or privacy officers. In contrast to alerts generated by the system, alerts generated by organizations in SI-4 (12) focus on information sources external to the system, such as suspicious activity reports and reports on potential insider threats.",
          "System and services acquisition. External system services. a. Require that providers of external system services comply with organizational security and privacy requirements and employ the following controls: [assignment: organization-defined controls]. \nb. Define and document organizational oversight and user roles and responsibilities with regard to external system services. \nc. Employ the following processes, methods, and techniques to monitor control compliance by external service providers on an ongoing basis: [assignment: organization-defined processes, methods, and techniques]. \n\nExternal system services are provided by an external provider, and the organization has no direct control over the implementation of the required controls or the assessment of control effectiveness. Organizations establish relationships with external service providers in a variety of ways, including through business partnerships, contracts, interagency agreements, lines of business arrangements, licensing agreements, joint ventures, and supply chain exchanges. \n\nThe responsibility for managing risks from the use of external system services remains with authorizing officials. For services external to organizations, a chain of trust requires that organizations establish and retain a certain level of confidence that each provider in the consumer-provider relationship provides adequate protection for the services rendered. The extent and nature of this chain of trust vary based on relationships between organizations and the external providers. Organizations document the basis for the trust relationships so that the relationships can be monitored. \n\nExternal system services documentation includes government, service providers, end user security roles and responsibilities, and service-level agreements. Service-level agreements define the expectations of performance for implemented controls, describe measurable outcomes, and identify remedies and response requirements for identified instances of noncompliance.",
          "Personnel (hr). Verification of qualification and trustworthiness. Basic criterion: The competency and integrity of all internal and external employees of the cloud service provider with access to cloud customer data or system components under the cloud service provider's responsibility, who are responsible for providing the cloud service in the production environment, shall be verified prior to commencement of employment in accordance with local legislation and regulations by the cloud service provider. To the extent permitted by law, the review will cover the following areas: \n\n- Verification of the person through an identity card. \n- Verification of the CV. \n- Verification of academic titles and degrees. \n- Request for a police clearance certificate for applicants. \n- Certificate of good conduct or national equivalent. \n- Evaluation of the risk of potential blackmail. \n\nAdditional criterion: \nSupplementary information about the criterion: External employees, in the sense of the criteria, are those who perform activities in accordance with the processes and procedures of the cloud service provider. Employees of sub-service providers who perform activities according to their own processes and procedures are not covered by this criterion. The verification of qualification and trustworthiness can be supported by a specialized service provider. Depending on national legislation, national equivalents of the German certificate of good conduct may also be permitted. The assessment of the extent to which a potential employee can be blackmailed can be carried out, for example, by checking their creditworthiness. \n\nComplementary customer criterion notes on continuous auditing feasibility: Partially, continuous auditing is only partially achievable due to complications arising from local deviations in laws and regulations. It would be conceivable to continuously query the process steps stored in the system for each new hire in relation to the specified areas, based on a list of employees maintained in the HR system where new hires are registered. To do this, the cloud service provider would have to go through and document these steps, applying a system-based approach. The auditor could then use an agent or a connected monitoring system to detect any deviations from the standard process.",
          "Operations (ops). Protection against malware – concept. Basic criterion: Policies and instructions with specifications for protection against malware are documented, communicated, and provided in accordance with SP-01. The following aspects should be considered:\n\n- Use of system-specific protection mechanisms\n- Operating protection programs on system components under the responsibility of the cloud service provider that are used to provide the cloud service in the production environment\n- Operation of protection programs for employees’ terminal equipment \n\nAdditional criterion: The cloud service provider creates regular reports on the checks performed, which are reviewed and analyzed by authorized bodies or committees. \n\nPolicies and instructions should describe the technical measures taken to securely configure and monitor the management console (both the customer’s self-service and the service provider’s cloud administration) to protect it from malware. Updates should be applied at the highest frequency that the vendor(s) contractually offer(s). \n\nSupplementary information about the criterion \"protection programs for employee devices\" can be, for example, server-based protection programs that scan files in attachments on the server or filter network traffic.\n\nComplementary customer criterion notes on continuous auditing feasibility: Partially, a policy can change ad-hoc. However, the continuous audit of policies is only partially feasible, as the only attributes that can be tested are the last change date and the status of review or approval, as far as this information is stored in a system. The content of a policy can hardly be tested automatically.",
          "System and services acquisition. Developer testing and evaluation | static code analysis. Require the developer of the system, system component, or system service to employ static code analysis tools to identify common flaws and document the results of the analysis. Static code analysis provides a technology and methodology for security reviews and includes checking for weaknesses in the code as well as for the incorporation of libraries or other included code with known vulnerabilities or that is out-of-date and not supported. Static code analysis can be used to identify vulnerabilities and enforce secure coding practices. It is most effective when used early in the development process, when each code change can automatically be scanned for potential weaknesses. Static code analysis can provide clear remediation guidance and identify defects for developers to fix. Evidence of the correct implementation of static analysis can include aggregate defect density for critical defect types, evidence that defects were inspected by developers or security professionals, and evidence that defects were remediated. A high density of ignored findings, commonly referred to as false positives, indicates a potential problem with the analysis process or the analysis tool. In such cases, organizations weigh the validity of the evidence against evidence from other sources.",
          "Identification and authentication. Authentication feedback. Obscure feedback of authentication information during the authentication process to protect the information from possible exploitation and use by unauthorized individuals. Authentication feedback from systems does not provide information that would allow unauthorized individuals to compromise authentication mechanisms. For some types of systems, such as desktops or notebooks with relatively large monitors, the threat (referred to as shoulder surfing) may be significant. For other types of systems, such as mobile devices with small displays, the threat may be less significant and is balanced against the increased likelihood of typographic input errors due to small keyboards. Thus, the means for obscuring authentication feedback is selected accordingly. Obscuring authentication feedback includes displaying asterisks when users type passwords into input devices or displaying feedback for a very limited time before obscuring it.",
          "Configuration management. System component inventory | automated unauthorized component detection. (A) Detect the presence of unauthorized hardware, software, and firmware components within the system using [assignment: organization-defined automated mechanisms]. [Assignment: Organization-defined frequency].\n\n(B) Take the following actions when unauthorized components are detected: [Selection (one or more): disable network access by such components; isolate the components; notify [assignment: organization-defined personnel or roles]].\n\nAutomated unauthorized component detection is applied in addition to monitoring for unauthorized remote connections and mobile devices. Monitoring for unauthorized system components may be accomplished on an ongoing basis or by periodic scanning of systems for that purpose. Automated mechanisms may also be used to prevent the connection of unauthorized components (see CM-7 (9)). Automated mechanisms can be implemented in systems or in separate system components.\n\nWhen acquiring and implementing automated mechanisms, organizations consider whether such mechanisms depend on the ability of the system component to support an agent or supplicant in order to be detected since some types of components do not have or cannot support agents (e.g., IoT devices, sensors).\n\nIsolation can be achieved, for example, by placing unauthorized system components in separate domains or subnets or quarantining such components. This type of component isolation is commonly referred to as sandboxing.",
          "System and information integrity. System monitoring | automated organization-generated alerts. Alert [assignment: organization-defined personnel or roles] using [assignment: organization-defined automated mechanisms] when the following indications of inappropriate or unusual activities with security or privacy implications occur: [assignment: organization-defined activities that trigger alerts]. Organizational personnel on the system alert notification list include system administrators, mission or business owners, system owners, senior agency information security officer, senior agency official for privacy, system security officers, or privacy officers. Automated organization-generated alerts are the security alerts generated by organizations and transmitted using automated means. The sources for organization-generated alerts are focused on other entities such as suspicious activity reports and reports on potential insider threats. In contrast to alerts generated by the organization, alerts generated by the system in SI-4 (5) focus on information sources that are internal to the systems, such as audit records.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "1_the_of_and",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "1_the_of_and"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          4.1546454429626465,
          1.854248285293579,
          2.4837698936462402,
          4.248509883880615,
          1.7120341062545776,
          4.515169620513916,
          6.869996547698975,
          4.223384857177734,
          4.460287570953369,
          1.5811985731124878,
          2.7912046909332275,
          2.2242305278778076,
          2.664170503616333,
          3.4961090087890625,
          4.814018726348877,
          1.7070256471633911,
          1.7899081707000732,
          2.1810576915740967,
          4.018876075744629,
          3.177497625350952,
          5.093799591064453,
          5.188072681427002,
          5.164445877075195,
          3.51222562789917,
          4.342597961425781,
          2.525099754333496,
          2.7102108001708984,
          3.3497674465179443,
          2.619537591934204,
          2.7347183227539062,
          4.231729507446289,
          4.081523895263672,
          1.595642328262329,
          3.14629864692688,
          2.473963499069214,
          4.620728492736816,
          1.563421607017517,
          5.221259117126465,
          2.587101936340332,
          2.117767810821533,
          1.7686535120010376,
          1.754110336303711,
          3.1255857944488525,
          3.5957345962524414,
          4.331271648406982,
          5.041034698486328,
          3.141780138015747,
          3.7314302921295166,
          4.69307279586792,
          4.121129989624023,
          4.580227851867676,
          1.8129230737686157,
          4.190256118774414,
          2.6881160736083984,
          1.9673426151275635,
          5.170235633850098,
          4.088730335235596,
          1.574013113975525,
          1.696834921836853,
          2.105954885482788,
          4.017287731170654,
          1.5061415433883667,
          2.3392603397369385,
          1.80791175365448,
          2.8881959915161133,
          5.596648693084717,
          5.012722015380859,
          3.639394521713257,
          2.4498677253723145,
          5.194927215576172,
          5.080214023590088,
          5.1755194664001465,
          2.4144606590270996,
          3.156007766723633,
          3.5093765258789062,
          4.622804641723633,
          3.13128662109375,
          4.185880661010742,
          5.231198310852051,
          3.8269999027252197,
          4.5277628898620605,
          3.9671640396118164,
          3.802159309387207,
          3.6677467823028564,
          2.725996494293213,
          2.3703548908233643,
          4.028621196746826,
          3.134171724319458,
          3.6003570556640625,
          2.547029972076416,
          3.6376428604125977,
          1.5984082221984863,
          2.4003608226776123,
          2.675234317779541,
          3.7118685245513916,
          2.2895753383636475,
          2.417706251144409,
          2.294926404953003,
          2.446845531463623,
          3.350057601928711
         ],
         "y": [
          10.23414421081543,
          9.044075012207031,
          8.523775100708008,
          9.828094482421875,
          8.904708862304688,
          10.243756294250488,
          7.502691268920898,
          9.791325569152832,
          10.719012260437012,
          8.662797927856445,
          9.435126304626465,
          8.39156436920166,
          9.378039360046387,
          9.58308219909668,
          9.869690895080566,
          8.579750061035156,
          9.052351951599121,
          8.482072830200195,
          10.44300365447998,
          9.502148628234863,
          11.105574607849121,
          11.153985977172852,
          11.177420616149902,
          9.674849510192871,
          10.61909294128418,
          8.30290412902832,
          9.08558464050293,
          9.87502384185791,
          9.366606712341309,
          9.412982940673828,
          9.794958114624023,
          10.393888473510742,
          8.697732925415039,
          9.6126070022583,
          8.324031829833984,
          10.851323127746582,
          8.67780876159668,
          11.100062370300293,
          8.538714408874512,
          8.48367977142334,
          9.021690368652344,
          9.007469177246094,
          9.582310676574707,
          9.87680435180664,
          10.277289390563965,
          11.302026748657227,
          9.6643705368042,
          10.270097732543945,
          10.881479263305664,
          10.10995101928711,
          10.183268547058105,
          9.12333869934082,
          9.826079368591309,
          9.40233325958252,
          8.903427124023438,
          11.136611938476562,
          10.428030967712402,
          8.723651885986328,
          8.573368072509766,
          8.513544082641602,
          9.657073020935059,
          8.75064754486084,
          8.371562004089355,
          9.154583930969238,
          9.496870040893555,
          11.165690422058105,
          10.13485336303711,
          9.738814353942871,
          8.36072826385498,
          11.140177726745605,
          11.126835823059082,
          11.134307861328125,
          8.302877426147461,
          9.60356616973877,
          9.630976676940918,
          10.555898666381836,
          9.556253433227539,
          10.091788291931152,
          11.146285057067871,
          10.149285316467285,
          10.755936622619629,
          10.340718269348145,
          10.272024154663086,
          10.257519721984863,
          8.804930686950684,
          8.708893775939941,
          10.404350280761719,
          9.581043243408203,
          10.204360008239746,
          8.47484016418457,
          10.243988037109375,
          8.700582504272461,
          8.447831153869629,
          9.395986557006836,
          10.276512145996094,
          8.35149097442627,
          8.267329216003418,
          8.348567962646484,
          8.312255859375,
          9.602478981018066
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "System and services acquisition. Acquisition process | functions, ports, protocols, and services in use. Require the developer of the system, system component, or system service to identify the functions, ports, protocols, and services intended for organizational use. The identification of functions, ports, protocols, and services early in the system development life cycle (e.g., during the initial requirements definition and design stages) allows organizations to influence the design of the system, system component, or system service. This early involvement in the system development life cycle helps organizations avoid or minimize the use of functions, ports, protocols, or services that pose unnecessarily high risks and understand the trade-offs involved in blocking specific ports, protocols, or services or requiring system service providers to do so. Early identification of functions, ports, protocols, and services avoids costly retrofitting of controls after the system, component, or system service has been implemented. SA-9 describes the requirements for external system services. Organizations identify which functions, ports, protocols, and services are provided from external sources.",
          "Configuration management. Impact analyses. Analyze changes to the system to determine potential security and privacy impacts prior to change implementation. Organizational personnel with security or privacy responsibilities conduct impact analyses. Individuals conducting impact analyses possess the necessary skills and technical expertise to analyze the changes to systems as well as the security or privacy ramifications.\n\nImpact analyses include:\n- Reviewing security and privacy plans, policies, and procedures to understand control requirements.\n- Reviewing system design documentation and operational procedures to understand control implementation and how specific system changes might affect the controls.\n- Reviewing the impact of changes on organizational supply chain partners with stakeholders.\n- Determining how potential changes to a system create new risks to the privacy of individuals and the ability of implemented controls to mitigate those risks.\n\nImpact analyses also include risk assessments to understand the impact of the changes and determine if additional controls are required.",
          "Audit and accountability. Protection of audit information. A. Protect audit information and audit logging tools from unauthorized access, modification, and deletion.\nB. Alert [assignment: organization-defined personnel or roles] upon detection of unauthorized access, modification, or deletion of audit information.\nAudit information includes all information needed to successfully audit system activity, such as audit records, audit log settings, audit reports, and personally identifiable information. Audit logging tools are those programs and devices used to conduct system audit and logging activities.\nProtection of audit information focuses on technical protection and limits the ability to access and execute audit logging tools to authorized individuals. Physical protection of audit information is addressed by both media protection controls and physical and environmental protection controls.",
          "Audit and accountability. Response to audit logging process failures. a. Alert (assignment: organization-defined personnel or roles) within (assignment: organization-defined time period) in the event of an audit logging process failure. B. Take the following additional actions: (assignment: organization-defined additional actions). Audit logging process failures include software and hardware errors, failures in audit log capturing mechanisms, and reaching or exceeding audit log storage capacity. Organization-defined actions include overwriting the oldest audit records, shutting down the system, and stopping the generation of audit records. Organizations may choose to define additional actions for audit logging process failures based on the type of failure, the location of the failure, the severity of the failure, or a combination of such factors. When the audit logging process failure is related to storage, the response is carried out for the audit log storage repository (i.e., the distinct system component where the audit logs are stored), the system on which the audit logs reside, the total audit log storage capacity of the organization (i.e., all audit log storage repositories combined), or all three. Organizations may decide to take no additional actions after alerting designated roles or personnel.",
          "Personnel security. External personnel security. a. Establish personnel security requirements, including security roles and responsibilities for external providers.\nb. Require external providers to comply with personnel security policies and procedures established by the organization.\nc. Document personnel security requirements.\nd. Require external providers to notify [assignment: organization-defined personnel or roles] of any personnel transfers or terminations of external personnel who possess organizational credentials and/or badges, or who have system privileges within [assignment: organization-defined time period].\ne. Monitor provider compliance with personnel security requirements.\n\nExternal provider refers to organizations other than the organization operating or acquiring the system. External providers include service bureaus, contractors, and other organizations that provide system development, information technology services, testing or assessment services, outsourced applications, and network/security management. Organizations explicitly include personnel security requirements in acquisition-related documents.\n\nExternal providers may have personnel working at organizational facilities with credentials, badges, or system privileges issued by organizations. Notifications of external personnel changes ensure the appropriate termination of privileges and credentials. Organizations define the transfers and terminations deemed reportable by security-related characteristics that include functions, roles, and the nature of credentials or privileges associated with transferred or terminated individuals.",
          "Awareness and training. Literacy training and awareness | insider threat. Provide literacy training on recognizing and reporting potential indicators of insider threat. Potential indicators and possible precursors of insider threat can include behaviors such as inordinate, long-term job dissatisfaction; attempts to gain access to information not required for job performance; unexplained access to financial resources; bullying or harassment of fellow employees; workplace violence; and other serious violations of policies, procedures, directives, regulations, rules, or practices. Literacy training includes how to communicate the concerns of employees and management regarding potential indicators of insider threat through channels established by the organization and in accordance with established policies and procedures. Organizations may consider tailoring insider threat awareness topics to the role. For example, training for managers may be focused on changes in the behavior of team members, while training for employees may be focused on more general observations.",
          "System and services acquisition. Unsupported system components. a. Replace system components when support for the components is no longer available from the developer, vendor, or manufacturer; or b. Provide the following options for alternative sources for continued support for unsupported components [selection (one or more): in-house support; [assignment: organization-defined support from external providers]]. Support for system components includes software patches, firmware updates, replacement parts, and maintenance contracts. An example of unsupported components includes when vendors no longer provide critical software patches or product updates, which can result in an opportunity for adversaries to exploit weaknesses in the installed components. Exceptions to replacing unsupported system components include systems that provide critical mission or business capabilities where newer technologies are not available or where the systems are so isolated that installing replacement components is not an option. Alternative sources for support address the need to provide continued support for system components that are no longer supported by the original manufacturers, developers, or vendors when such components remain essential to organizational mission and business functions. If necessary, organizations can establish in-house support by developing customized patches for critical software components or, alternatively, obtain the services of external providers who provide ongoing support for the designated unsupported components through contractual relationships. Such contractual relationships can include open-source software value-added vendors. The increased risk of using unsupported system components can be mitigated, for example, by prohibiting the connection of such components to public or uncontrolled networks, or implementing other forms of isolation.",
          "Audit and accountability. Content of audit records | additional audit information. Generate audit records containing the following additional information: [assignment: organization-defined additional information]. The ability to add information generated in audit records is dependent on system functionality to configure the audit record content. Organizations may consider additional information in audit records, including, but not limited to, access control or flow control rules invoked, and individual identities of group account users. Organizations may also consider limiting additional audit record information to only information that is explicitly needed for audit requirements. This facilitates the use of audit trails and audit logs by not including information in audit records that could potentially be misleading, make it more difficult to locate information of interest, or increase the risk to individuals' privacy.",
          "Contingency planning. System backup. a. Conduct backups of user-level information contained in [assignment: organization-defined system components] [assignment: organization-defined frequency consistent with recovery time and recovery point objectives].\nb. Conduct backups of system-level information contained in the system [assignment: organization-defined frequency consistent with recovery time and recovery point objectives].\nc. Conduct backups of system documentation, including security- and privacy-related documentation [assignment: organization-defined frequency consistent with recovery time and recovery point objectives].\nd. Protect the confidentiality, integrity, and availability of backup information. System-level information includes system state information, operating system software, middleware, application software, and licenses. User-level information includes information other than system-level information. Mechanisms employed to protect the integrity of system backups include digital signatures and cryptographic hashes. Protection of system backup information while in transit is addressed by mp-5 and sc-8. System backups reflect the requirements in contingency plans as well as other organizational requirements for backing up information. Organizations may be subject to laws, executive orders, directives, regulations, or policies with requirements regarding specific categories of information (e.g., personal health information). Organizational personnel consult with the senior agency official for privacy and legal counsel regarding such requirements.",
          "Configuration management. Baseline configuration | configure systems and components for high-risk areas. (a) Issue [assignment: organization-defined systems or system components] with [assignment: organization-defined configurations] to individuals traveling to locations that the organization deems to be of significant risk; and (b) apply the following controls to the systems or components when the individuals return from travel: [assignment: organization-defined controls]. When it is known that systems or system components will be in high-risk areas external to the organization, additional controls may be implemented to counter the increased threat in such areas. For example, organizations can take actions for notebook computers used by individuals departing on and returning from travel. Actions include determining the locations that are of concern, defining the required configurations for the components, ensuring that components are configured as intended before travel is initiated, and applying controls to the components after travel is completed. Specially configured notebook computers include computers with sanitized hard drives, limited applications, and more stringent configuration settings. Controls applied to mobile devices upon return from travel include examining the mobile device for signs of physical tampering and purging and reimaging disk drives. Protecting information that resides on mobile devices is addressed in the MP (Media Protection) family.",
          "Contingency planning. Policy and procedures. A. Develop, document, and disseminate to organization-defined personnel or roles: \n\n1. Organization level contingency planning policy that addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance. The policy should be consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. \n\n2. Procedures to facilitate the implementation of the contingency planning policy and the associated contingency planning controls. \n\nB. Designate an organization-defined official to manage the development, documentation, and dissemination of the contingency planning policy and procedures. \n\nC. Review and update the current contingency planning: \n\n1. Policy organization-defined frequency and following organization-defined events. \n\n2. Procedures organization-defined frequency and following organization-defined events. \n\nContingency planning policy and procedures address the controls in the CP family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of contingency planning policy and procedures. \n\nSecurity and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations. \n\nProcedures can be established for security and privacy programs, for mission or business processes, and for systems, if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents. \n\nEvents that may precipitate an update to contingency planning policy and procedures include assessment or audit findings, security incidents or breaches, or changes in laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Portability and interoperability (pi). Contractual agreements for the provision of data. Basic Criterion: In contractual agreements, the following aspects are defined with regard to the termination of the contractual relationship, insofar as these are applicable to the cloud service: type, scope, and format of the data the cloud service provider provides to the cloud customer; definition of the timeframe within which the cloud service provider makes the data available to the cloud customer; definition of the point in time as of which the cloud service provider makes the data inaccessible to the cloud customer and deletes it; and the cloud customers’ responsibilities and obligations to cooperate for the provision of the data. The definitions are based on the needs of subject matter experts of potential customers who assess the suitability of the cloud service with regard to a dependency on the cloud service provider as well as legal and regulatory requirements.\n\nAdditional Criterion: The design of the aspects is based on legal and regulatory requirements in the environment of the cloud service provider. The cloud service provider identifies the requirements regularly, at least once a year, and checks them for actuality and adjusts the contractual agreements accordingly.\n\nSupplementary Information about the Criterion: The type and scope of the data and the responsibilities for its provision depend on the service model of the cloud service or the services and functions provided. In the case of IaaS and PaaS, the cloud customer is generally responsible for extracting and backing up the data that is stored in the cloud service before termination of the contractual relationship (cf. complementary requirement). The cloud service provider’s responsibility is typically limited to the provision of data for the configuration of the infrastructure or platform that the cloud customer has set up within its environment (e.g., configuration of networks, images of virtual machines and containers). With SaaS, the cloud customer typically relies on export functions provided by the cloud service provider. Data created by the cloud customer should be available in the same format as stored in the cloud service. Other data, including relevant log files and metadata, should be available in an applicable standard format, such as CSV, JSON, or XML.\n\nIn Germany, legal requirements for retention can be found, for example, in the German Tax Code (§ 147 AO) and the German Commercial Code (§ 257 HGB). These provide for a retention obligation of six or ten years.\n\nComplementary Customer Criterion: Cloud customers ensure through suitable controls that the data to which they are contractually entitled is requested from the cloud service provider at the end of the contract or accessed via defined interfaces (the type and scope of the data correspond to the contractual agreements that were concluded prior to the use of the cloud service) and that it is stored in accordance with the legal requirements applicable to this data.\n\nNotes on Continuous Auditing Feasibility: No, the cloud service provider should have a standardized template for its contracts. Hence, all contracts are structured according to the same pattern. This template is rarely changed. Therefore, a continuous audit is not practical. Therefore, it is sufficient to test the contracts and the associated template as part of the recurring audit.",
          "Configuration management. Software usage restrictions. a. Use software and associated documentation in accordance with contract agreements and copyright laws. \nb. Track the use of software and associated documentation protected by quantity licenses to control copying and distribution. \nc. Control and document the use of peer-to-peer file sharing technology to ensure that this capability is not used for the unauthorized distribution, display, performance, or reproduction of copyrighted work. \n\nSoftware license tracking can be accomplished by manual or automated methods, depending on organizational needs. Examples of contract agreements include software license agreements and non-disclosure agreements.",
          "Risk assessment. Policy and procedures. A. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]: 1. [Selection (one or more): organization level; mission/business process-level; system-level] risk assessment policy that: (a) addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance; and (b) is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines; and 2. procedures to facilitate the implementation of the risk assessment policy and the associated risk assessment controls; \n\nB. Designate an [assignment: organization-defined official] to manage the development, documentation, and dissemination of the risk assessment policy and procedures; and \n\nC. Review and update the current risk assessment: 1. policy [assignment: organization-defined frequency] and following [assignment: organization-defined events]; and 2. procedures [assignment: organization-defined frequency] and following [assignment: organization-defined events].\n\nRisk assessment policy and procedures address the controls in the RA family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of risk assessment policy and procedures. Security and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies reflecting the complex nature of organizations. Procedures can be established for security and privacy programs, for mission or business processes, and for systems, if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents. Events that may precipitate an update to risk assessment policy and procedures include assessment or audit findings, security incidents or breaches, or changes in laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Audit and accountability. Audit record reduction and report generation | automatic processing. Provide and implement the capability to process, sort, and search audit records for events of interest based on the following content: [assignment: organization-defined fields within audit records]. \n\nEvents of interest can be identified by the content of audit records, including system resources involved, information objects accessed, identities of individuals, event types, event locations, event dates and times, internet protocol addresses involved, or event success or failure. \n\nOrganizations may define event criteria to any degree of granularity required, such as locations selectable by a general networking location or by specific system component.",
          "Audit and accountability. Policy and procedures. A. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]:\n1. [Selection (one or more): organization level; mission/business process-level; system-level] audit and accountability policy that:\n(a) Addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance; and\n(b) Is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines; and\n2. Procedures to facilitate the implementation of the audit and accountability policy and the associated audit and accountability controls.\n\nB. Designate an [assignment: organization-defined official] to manage the development, documentation, and dissemination of the audit and accountability policy and procedures.\n\nC. Review and update the current audit and accountability:\n1. Policy [assignment: organization-defined frequency] and following [assignment: organization-defined events]; and\n2. Procedures [assignment: organization-defined frequency] and following [assignment: organization-defined events].\n\nAudit and accountability policy and procedures address the controls in the AU family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of audit and accountability policy and procedures.\n\nSecurity and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations.\n\nProcedures can be established for security and privacy programs, for mission or business processes, and for systems if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents.\n\nEvents that may precipitate an update to audit and accountability policy and procedures include assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "System and services acquisition. Developer configuration management. Require the developer of the system, system component, or system service to: \na. Perform configuration management during system, component, or service [selection (one or more): design; development; implementation; operation; disposal]. \nb. Document, manage, and control the integrity of changes to [assignment: organization-defined configuration items under configuration management]. \nc. Implement only organization-approved changes to the system, component, or service. \nd. Document approved changes to the system, component, or service and the potential security and privacy impacts of such changes. \ne. Track security flaws and flaw resolution with the system, component, or service and report findings to [assignment: organization-defined personnel]. \n\nOrganizations consider the quality and completeness of configuration management activities conducted by developers as direct evidence of applying effective security controls. \n\nControls include protecting the master copies of material used to generate security-relevant portions of the system hardware, software, and firmware from unauthorized modification or destruction. \n\nMaintaining the integrity of changes to the system, system component, or system service requires strict configuration control throughout the system development life cycle to track authorized changes and prevent unauthorized changes. \n\nThe configuration items that are placed under configuration management include the formal model, the functional, high-level, and low-level design specifications, other design data, implementation documentation, source code and hardware schematics, the current running version of the object code, tools for comparing new versions of security-relevant hardware descriptions and source code with previous versions, and test fixtures and documentation. \n\nDepending on the mission and business needs of organizations and the nature of the contractual relationships in place, developers may provide configuration management support during the operations and maintenance stage of the system development life cycle.",
          "Incident response. Incident response training. a. Provide incident response training to system users consistent with assigned roles and responsibilities:\n\n1. Within [assignment: organization-defined time period] of assuming an incident response role or responsibility or acquiring system access.\n2. When required by system changes.\n3. [Assignment: organization-defined frequency] thereafter.\n\nb. Review and update incident response training content [assignment: organization-defined frequency] and following [assignment: organization-defined events].\n\nIncident response training is associated with the assigned roles and responsibilities of organizational personnel to ensure that the appropriate content and level of detail are included in such training. For example, users may only need to know who to call or how to recognize an incident; system administrators may require additional training on how to handle incidents; and incident responders may receive more specific training on forensics, data collection techniques, reporting, system recovery, and system restoration. Incident response training includes user training in identifying and reporting suspicious activities from external and internal sources. Incident response training for users may be provided as part of AT-2 or AT-3.\n\nEvents that may precipitate an update to incident response training content include, but are not limited to, incident response plan testing or response to an actual incident (lessons learned), assessment or audit findings, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines.",
          "Media protection. Media sanitization | nondestructive techniques. Apply nondestructive sanitization techniques to portable storage devices prior to connecting such devices to the system under the following circumstances: [assignment: organization-defined circumstances requiring sanitization of portable storage devices]. Portable storage devices include external or removable hard disk drives (e.g., solid-state, magnetic), optical discs, magnetic or optical tapes, flash memory devices, flash memory cards, and other external or removable disks. Portable storage devices can be obtained from untrustworthy sources and contain malicious code that can be inserted into or transferred to organizational systems through USB ports or other entry portals. While scanning storage devices is recommended, sanitization provides additional assurance that such devices are free of malicious code. Organizations consider nondestructive sanitization of portable storage devices when the devices are purchased from manufacturers or vendors prior to initial use or when organizations cannot maintain a positive chain of custody for the devices.",
          "Personnel security. Personnel transfer. a. Review and confirm the ongoing operational need for current logical and physical access authorizations to systems and facilities when individuals are reassigned or transferred to other positions within the organization. \nb. Initiate [assignment: organization-defined transfer or reassignment actions] within [assignment: organization-defined time period following the formal transfer action]. \nc. Modify access authorization as needed to correspond with any changes in operational need due to reassignment or transfer. \nd. Notify [assignment: organization-defined personnel or roles] within [assignment: organization-defined time period]. \nPersonnel transfer applies when reassignments or transfers of individuals are permanent or of such extended duration as to make the actions warranted. Organizations define actions appropriate for the types of reassignments or transfers, whether permanent or extended. Actions that may be required for personnel transfers or reassignments to other positions within organizations include returning old and issuing new keys, identification cards, and building passes; closing system accounts and establishing new accounts; changing system access authorizations (i.e., privileges); and providing for access to official records to which individuals had access at previous work locations and in previous system accounts.",
          "Incident response. Policy and procedures. A. Develop, document, and disseminate to organization-defined personnel or roles:\n1. Organization level incident response policy that addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance. The policy should be consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines.\n2. Procedures to facilitate the implementation of the incident response policy and the associated incident response controls.\n\nB. Designate an organization-defined official to manage the development, documentation, and dissemination of the incident response policy and procedures.\n\nC. Review and update the current incident response:\n1. Policy organization-defined frequency and following organization-defined events.\n2. Procedures organization-defined frequency and following organization-defined events.\n\nThe incident response policy and procedures address the controls in the IR family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures.\n\nPolicies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of incident response policy and procedures. Security and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures.\n\nThe policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations. Procedures can be established for security and privacy programs, mission or business processes, and systems if needed.\n\nProcedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents.\n\nEvents that may precipitate an update to incident response policy and procedures include assessment or audit findings, security incidents or breaches, or changes in laws, executive orders, directives, regulations, policies, standards, and guidelines.\n\nSimply restating controls does not constitute an organizational policy or procedure.",
          "Maintenance. Policy and procedures. A. Develop, document, and disseminate to organization-defined personnel or roles:\n\n1. Organization-level maintenance policy that addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance. The policy should be consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines.\n\n2. Procedures to facilitate the implementation of the maintenance policy and the associated maintenance controls.\n\nB. Designate an organization-defined official to manage the development, documentation, and dissemination of the maintenance policy and procedures.\n\nC. Review and update the current maintenance:\n\n1. Policy organization-defined frequency and following organization-defined events.\n\n2. Procedures organization-defined frequency and following organization-defined events.\n\nMaintenance policy and procedures address the controls in the MA family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of maintenance policy and procedures.\n\nSecurity and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations. Procedures can be established for security and privacy programs, for mission or business processes, and for systems if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents.\n\nEvents that may precipitate an update to maintenance policy and procedures include assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "System and services acquisition. Policy and procedures. a. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]: \n1. [Selection (one or more): organization-level; mission/business process-level; system-level] system and services acquisition policy that: \n(a) Addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance.\n(b) Is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. \n2. Procedures to facilitate the implementation of the system and services acquisition policy and the associated system and services acquisition controls. \n\nb. Designate an [assignment: organization-defined official] to manage the development, documentation, and dissemination of the system and services acquisition policy and procedures. \n\nc. Review and update the current system and services acquisition: \n1. Policy [assignment: organization-defined frequency] and following [assignment: organization-defined events]. \n2. Procedures [assignment: organization-defined frequency] and following [assignment: organization-defined events]. \n\nSystem and services acquisition policy and procedures address the controls in the SA family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of system and services acquisition policy and procedures. \n\nSecurity and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations. Procedures can be established for security and privacy programs, for mission or business processes, and for systems if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents. \n\nEvents that may precipitate an update to system and services acquisition policy and procedures include assessment or audit findings, security incidents or breaches, or changes in laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Access control. Policy and procedures. A. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]: 1. [Selection (one or more): organization-level; mission/business process-level; system-level] access control policy that:\n(a) Addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance.\n(b) Is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines.\n2. Procedures to facilitate the implementation of the access control policy and the associated access controls.\n\nB. Designate an [assignment: organization-defined official] to manage the development, documentation, and dissemination of the access control policy and procedures.\n\nC. Review and update the current access control:\n1. Policy [assignment: organization-defined frequency] and following [assignment: organization-defined events].\n2. Procedures [assignment: organization-defined frequency] and following [assignment: organization-defined events].\n\nAccess control policy and procedures address the controls in the AC family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of access control policy and procedures. Security and privacy program policies and procedures at the organization level are preferable in general and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies reflecting the complex nature of organizations. Procedures can be established for security and privacy programs, for mission or business processes, and for systems if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents. Events that may precipitate an update to access control policy and procedures include assessment or audit findings, security incidents or breaches, or changes in laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Physical and environmental protection. Physical access authorizations. a. Develop, approve, and maintain a list of individuals with authorized access to the facility where the system resides. \nb. Issue authorization credentials for facility access. \nc. Review the access list detailing authorized facility access by individuals [assignment: organization-defined frequency]. \nd. Remove individuals from the facility access list when access is no longer required. \nPhysical access authorizations apply to employees and visitors. Individuals with permanent physical access authorization credentials are not considered visitors. Authorization credentials include ID badges, identification cards, and smart cards. Organizations determine the strength of authorization credentials needed consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Physical access authorizations may not be necessary to access certain areas within facilities that are designated as publicly accessible.",
          "Access control. Least privilege | review of user privileges. (a) Review [assignment: organization-defined frequency] the privileges assigned to [assignment: organization-defined roles or classes of users] to validate the need for such privileges; and (b) reassign or remove privileges, if necessary, to correctly reflect organizational mission and business needs. The need for certain assigned user privileges may change over time to reflect changes in organizational mission and business functions, environments of operation, technologies, or threats. A periodic review of assigned user privileges is necessary to determine if the rationale for assigning such privileges remains valid. If the need cannot be revalidated, organizations take appropriate corrective actions.",
          "Incident response. Incident handling. a. Implement an incident handling capability for incidents that is consistent with the incident response plan and includes preparation, detection and analysis, containment, eradication, and recovery. \nb. Coordinate incident handling activities with contingency planning activities. \nc. Incorporate lessons learned from ongoing incident handling activities into incident response procedures, training, and testing, and implement the resulting changes accordingly. \nd. Ensure the rigor, intensity, scope, and results of incident handling activities are comparable and predictable across the organization. \n\nOrganizations recognize that incident response capabilities are dependent on the capabilities of organizational systems and the mission and business processes being supported by those systems. Organizations consider incident response as part of the definition, design, and development of mission and business processes and systems. Incident-related information can be obtained from a variety of sources, including audit monitoring, physical access monitoring, and network monitoring; user or administrator reports; and reported supply chain events. \n\nAn effective incident handling capability includes coordination among many organizational entities (e.g., mission or business owners, system owners, authorizing officials, human resources offices, physical security offices, personnel security offices, legal departments, risk executive [function], operations personnel, procurement offices). \n\nSuspected security incidents include the receipt of suspicious email communications that can contain malicious code. Suspected supply chain incidents include the insertion of counterfeit hardware or malicious code into organizational systems or system components. \n\nFor federal agencies, an incident that involves personally identifiable information is considered a breach. A breach results in unauthorized disclosure, the loss of control, unauthorized acquisition, compromise, or a similar occurrence where a person other than an authorized user accesses or potentially accesses personally identifiable information or an authorized user accesses or potentially accesses such information for other than authorized purposes.",
          "Contingency planning. System backup | separate storage for critical information. Store backup copies of [assignment: organization-defined critical system software and other security-related information] in a separate facility or in a fire-rated container that is not collocated with the operational system. Separate storage for critical information applies to all critical information regardless of the type of backup storage media. Critical system software includes operating systems, middleware, cryptographic key management systems, and intrusion detection systems. Security-related information includes inventories of system hardware, software, and firmware components. Alternate storage sites, including geographically distributed architectures, serve as separate storage facilities for organizations. Organizations may provide separate storage by implementing automated backup processes at alternative storage sites (e.g., data centers). The General Services Administration (GSA) establishes standards and specifications for security and fire-rated containers.",
          "Security assessment and authorization. Control assessments | leveraging results from external organizations. Leverage the results of control assessments performed by [assignment: organization-defined external organization] on [assignment: organization-defined system] when the assessment meets [assignment: organization-defined requirements]. Organizations may rely on control assessments of organizational systems by other (external) organizations. Using such assessments and reusing existing assessment evidence can decrease the time and resources required for assessments by limiting the independent assessment activities that organizations need to perform. The factors that organizations consider in determining whether to accept assessment results from external organizations can vary. Such factors include the organization's past experience with the organization that conducted the assessment, the reputation of the assessment organization, the level of detail of supporting assessment evidence provided, and mandates imposed by applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Accredited testing laboratories that support the Common Criteria program ISO 15408-1, the NIST Cryptographic Module Validation Program (CMVP), or the NIST Cryptographic Algorithm Validation Program (CAVP) can provide independent assessment results that organizations can leverage.",
          "Media protection. Media sanitization. a. Sanitize [assignment: organization-defined system media] prior to disposal, release out of organizational control, or release for reuse using [assignment: organization-defined sanitization techniques and procedures]. b. Employ sanitization mechanisms with the strength and integrity commensurate with the security category or classification of the information. Media sanitization applies to all digital and non-digital system media subject to disposal or reuse, whether or not the media is considered removable. Examples include digital media in scanners, copiers, printers, notebook computers, workstations, network components, mobile devices, and non-digital media (e.g., paper and microfilm). The sanitization process removes information from system media such that the information cannot be retrieved or reconstructed. Sanitization techniques — including clearing, purging, cryptographic erase, de-identification of personally identifiable information, and destruction — prevent the disclosure of information to unauthorized individuals when such media is reused or released for disposal. Organizations determine the appropriate sanitization methods, recognizing that destruction is sometimes necessary when other methods cannot be applied to media requiring sanitization. Organizations use discretion on the employment of approved sanitization techniques and procedures for media that contains information deemed to be in the public domain or publicly releasable or information deemed to have no adverse impact on organizations or individuals if released for reuse or disposal. Sanitization of non-digital media includes destruction, removing a classified appendix from an otherwise unclassified document, or redacting selected sections or words from a document by obscuring the redacted sections or words in a manner equivalent in effectiveness to removing them from the document. NSA standards and policies control the sanitization process for media that contains classified information. NARA policies control the sanitization process for controlled unclassified information.",
          "Access control. Permitted actions without identification or authentication. a. Identify [assignment: organization-defined user actions] that can be performed on the system without identification or authentication consistent with organizational mission and business functions. \nB. Document and provide supporting rationale in the security plan for the system, user actions not requiring identification or authentication. \nSpecific user actions may be permitted without identification or authentication if organizations determine that identification and authentication are not required for the specified user actions. \nOrganizations may allow a limited number of user actions without identification or authentication, including when individuals access public websites or other publicly accessible federal systems, when individuals use mobile phones to receive calls, or when facsimiles are received. \nOrganizations identify actions that normally require identification or authentication but may, under certain circumstances, allow identification or authentication mechanisms to be bypassed. \nSuch bypasses may occur, for example, via a software-readable physical switch that commands bypass of the login functionality and is protected from accidental or unmonitored use. \nPermitting actions without identification or authentication does not apply to situations where identification and authentication have already occurred and are not repeated, but rather to situations where identification and authentication have not yet occurred. \nOrganizations may decide that there are no user actions that can be performed on organizational systems without identification and authentication, and therefore, the value for the assignment operation can be none.",
          "System and services acquisition. External system services | processing, storage, and service location. Restrict the location of information processing, information or data, or system services to organization-defined locations based on organization-defined requirements or conditions. The location of information processing, information and data storage, or system services can have a direct impact on the ability of organizations to successfully execute their mission and business functions. The impact occurs when external providers control the location of processing, storage, or services. The criteria that external providers use for the selection of processing, storage, or service locations may be different from the criteria that organizations use. For example, organizations may desire that data or information storage locations be restricted to certain locations to help facilitate incident response activities in case of information security incidents or breaches. Incident response activities, including forensic analyses and after-the-fact investigations, may be adversely affected by the governing laws, policies, or protocols in the locations where processing and storage occur and/or the locations from which system services emanate.",
          "Media protection. Policy and procedures. A. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]: 1. [Selection (one or more): organization level; mission/business process-level; system-level] media protection policy that: (a) addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance; and (b) is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines; and 2. procedures to facilitate the implementation of the media protection policy and the associated media protection controls. \n\nB. Designate an [assignment: organization-defined official] to manage the development, documentation, and dissemination of the media protection policy and procedures.\n\nC. Review and update the current media protection: 1. policy [assignment: organization-defined frequency] and following [assignment: organization-defined events]; and 2. procedures [assignment: organization-defined frequency] and following [assignment: organization-defined events]. \n\nMedia protection policy and procedures address the controls in the MP family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of media protection policy and procedures. Security and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations. Procedures can be established for security and privacy programs, for mission or business processes, and for systems, if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents. Events that may precipitate an update to media protection policy and procedures include assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Planning. Policy and procedures. A. Develop, document, and disseminate to organization-defined personnel or roles: 1. Organization level planning policy that addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance. The policy should be consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. 2. Procedures to facilitate the implementation of the planning policy and the associated planning controls. \n\nB. Designate an organization-defined official to manage the development, documentation, and dissemination of the planning policy and procedures. \n\nC. Review and update the current planning: 1. Policy organization-defined frequency and following organization-defined events. 2. Procedures organization-defined frequency and following organization-defined events. \n\nPlanning policy and procedures are essential for the controls in the PL family implemented within systems and organizations. The risk management strategy plays a crucial role in establishing such policies and procedures. Security and privacy programs should collaborate on their development as they contribute to security and privacy assurance. Preferably, security and privacy program policies and procedures should be established at the organization level, which may eliminate the need for mission level or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or represented by multiple policies that reflect the complex nature of organizations. Procedures can be established for security and privacy programs, mission/business processes, and systems, if necessary. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents. Events that may require an update to planning policy and procedures include, but are not limited to, assessment or audit findings, security incidents or breaches, or changes in laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Contingency planning. Contingency plan. A. Develop a contingency plan for the system that:\n1. Identifies essential mission and business functions and associated contingency requirements.\n2. Provides recovery objectives, restoration priorities, and metrics.\n3. Addresses contingency roles, responsibilities, assigned individuals with contact information.\n4. Addresses maintaining essential mission and business functions despite a system disruption, compromise, or failure.\n5. Addresses eventual, full system restoration without deterioration of the controls originally planned and implemented.\n6. Addresses the sharing of contingency information.\n7. Is reviewed and approved by [Assignment: organization-defined personnel or roles].\n\nB. Distribute copies of the contingency plan to [Assignment: organization-defined key contingency personnel (identified by name and/or by role) and organizational elements].\n\nC. Coordinate contingency planning activities with incident handling activities.\n\nD. Review the contingency plan for the system [Assignment: organization-defined frequency].\n\nE. Update the contingency plan to address changes to the organization, system, or environment of operation and problems encountered during contingency plan implementation, execution, or testing.\n\nF. Communicate contingency plan changes to [Assignment: organization-defined key contingency personnel (identified by name and/or by role) and organizational elements].\n\nG. Incorporate lessons learned from contingency plan testing, training, or actual contingency activities into contingency testing and training.\n\nH. Protect the contingency plan from unauthorized disclosure and modification.\n\nContingency planning for systems is part of an overall program for achieving continuity of operations for organizational mission and business functions. Contingency planning addresses system restoration and implementation of alternative mission or business processes when systems are compromised or breached. Contingency planning is considered throughout the system development life cycle and is a fundamental part of the system design. Systems can be designed for redundancy, to provide backup capabilities, and for resilience. \n\nContingency plans reflect the degree of restoration required for organizational systems since not all systems need to fully recover to achieve the level of continuity of operations desired. System recovery objectives reflect applicable laws, executive orders, directives, regulations, policies, standards, guidelines, organizational risk tolerance, and system impact level. Actions addressed in contingency plans include orderly system degradation, system shutdown, fallback to a manual mode, alternate information flows, and operating in modes reserved for when systems are under attack. \n\nBy coordinating contingency planning with incident handling activities, organizations ensure that the necessary planning activities are in place and activated in the event of an incident. Organizations consider whether continuity of operations during an incident conflicts with the capability to automatically disable the system, as specified in IR-4 (5). Incident response planning is part of contingency planning for organizations and is addressed in the IR (incident response) family.",
          "Risk assessment. Risk assessment. A. Conduct a risk assessment, including: 1. identifying threats to and vulnerabilities in the system; 2. determining the likelihood and magnitude of harm from unauthorized access, use, disclosure, disruption, modification, or destruction of the system, the information it processes, stores, or transmits, and any related information; and 3. determining the likelihood and impact of adverse effects on individuals arising from the processing of personally identifiable information. B. Integrate risk assessment results and risk management decisions from the organization and mission or business process perspectives with system-level risk assessments. C. Document risk assessment results in [selection: security and privacy plans; risk assessment report; [assignment: organization-defined document]]. D. Review risk assessment results [assignment: organization-defined frequency]. E. Disseminate risk assessment results to [assignment: organization-defined personnel or roles]. F. Update the risk assessment [assignment: organization-defined frequency] or when there are significant changes to the system, its environment of operation, or other conditions that may impact the security or privacy state of the system. Risk assessments consider threats, vulnerabilities, likelihood, and impact to organizational operations and assets, individuals, other organizations, and the nation. Risk assessments also consider risk from external parties, including contractors who operate systems on behalf of the organization, individuals who access organizational systems, service providers, and outsourcing entities. Organizations can conduct risk assessments at all three levels in the risk management hierarchy (i.e., organization level, mission/business process level, or information system level) and at any stage in the system development life cycle. Risk assessments can also be conducted at various steps in the risk management framework, including preparation, categorization, control selection, control implementation, control assessment, authorization, and control monitoring. Risk assessment is an ongoing activity carried out throughout the system development life cycle. Risk assessments can also address information related to the system, including system design, the intended use of the system, testing results, and supply chain-related information or artifacts. Risk assessments can play an important role in control selection processes, particularly during the application of tailoring guidance and in the earliest phases of capability determination.",
          "Audit and accountability. Audit record review, analysis, and reporting | integrated analysis of audit records. Integrate analysis of audit records with analysis of [selection (one or more): vulnerability scanning information; performance data; system monitoring information; [assignment: organization-defined data/information collected from other sources]] to further enhance the ability to identify inappropriate or unusual activity. Integrated analysis of audit records does not require vulnerability scanning, the generation of performance data, or system monitoring. Rather, integrated analysis requires that the analysis of information generated by scanning, monitoring, or other data collection activities is integrated with the analysis of audit record information. Security information and event management tools can facilitate audit record aggregation or consolidation from multiple system components, as well as audit record correlation and analysis. The use of standardized audit record analysis scripts developed by organizations (with localized script adjustments, as necessary) provides more cost-effective approaches for analyzing audit record information collected. The correlation of audit record information with vulnerability scanning information is important in determining the veracity of vulnerability scans of the system and in correlating attack detection events with scanning results. Correlation with performance data can uncover denial-of-service attacks or other types of attacks that result in the unauthorized use of resources. Correlation with system monitoring information can assist in uncovering attacks and in better relating audit information to operational situations.",
          "Awareness and training. Literacy training and awareness. a. Provide security and privacy literacy training to system users (including managers, senior executives, and contractors): 1. As part of initial training for new users and [assignment: organization-defined frequency] thereafter; and 2. When required by system changes or following [assignment: organization-defined events]. \nb. Employ the following techniques to increase the security and privacy awareness of system users [assignment: organization-defined awareness techniques]. \nc. Update literacy training and awareness content [assignment: organization-defined frequency] and following [assignment: organization-defined events]. \nd. Incorporate lessons learned from internal or external security incidents or breaches into literacy training and awareness techniques. \n\nOrganizations provide basic and advanced levels of literacy training to system users, including measures to test the knowledge level of users. Organizations determine the content of literacy training and awareness based on specific organizational requirements, the systems to which personnel have authorized access, and work environments (e.g., telework). The content includes an understanding of the need for security and privacy as well as actions by users to maintain security and personal privacy and to respond to suspected incidents. The content addresses the need for operations security and the handling of personally identifiable information. Awareness techniques include displaying posters, offering supplies inscribed with security and privacy reminders, displaying logon screen messages, generating email advisories or notices from organizational officials, and conducting awareness events. \n\nLiteracy training after the initial training described in at-2a.1 is conducted at a minimum frequency consistent with applicable laws, directives, regulations, and policies. Subsequent literacy training may be satisfied by one or more short ad hoc sessions and include topical information on recent attack schemes, changes to organizational security and privacy policies, revised security and privacy expectations, or a subset of topics from the initial training. Updating literacy training and awareness content on a regular basis helps to ensure that the content remains relevant. Events that may precipitate an update to literacy training and awareness content include, but are not limited to, assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines.",
          "Physical and environmental protection. Physical access control. A. Enforce physical access authorizations at [assignment: organization-defined entry and exit points to the facility where the system resides] by:\n\n1. Verifying individual access authorizations before granting access to the facility.\n2. Controlling ingress and egress to the facility using [selection (one or more): [assignment: organization-defined physical access control systems or devices] or guards].\n\nB. Maintain physical access audit logs for [assignment: organization-defined entry or exit points].\n\nC. Control access to areas within the facility designated as publicly accessible by implementing the following controls: [assignment: organization-defined physical access controls].\n\nD. Escort visitors and control visitor activity [assignment: organization-defined circumstances requiring visitor escorts and control of visitor activity].\n\nE. Secure keys, combinations, and other physical access devices.\n\nF. Inventory [assignment: organization-defined physical access devices] every [assignment: organization-defined frequency].\n\nG. Change combinations and keys [assignment: organization-defined frequency] and/or when keys are lost, combinations are compromised, or when individuals possessing the keys or combinations are transferred or terminated.\n\nPhysical access control applies to employees and visitors. Individuals with permanent physical access authorizations are not considered visitors.\n\nPhysical access controls for publicly accessible areas may include physical access control logs/records, guards, or physical access devices and barriers to prevent movement from publicly accessible areas to non-public areas.\n\nOrganizations determine the types of guards needed, including professional security staff, system users, or administrative staff. Physical access devices include keys, locks, combinations, biometric readers, and card readers.\n\nPhysical access control systems comply with applicable laws, executive orders, directives, policies, regulations, standards, and guidelines. Organizations have flexibility in the types of audit logs employed. Audit logs can be procedural, automated, or some combination thereof.\n\nPhysical access points can include facility access points, interior access points to systems that require supplemental access controls, or both. Components of systems may be in areas designated as publicly accessible with organizations controlling access to the components.",
          "Audit and accountability. Protection of audit information | store on separate physical systems or components. Store audit records [assignment: organization-defined frequency] in a repository that is part of a physically different system or system component than the system or component being audited. Storing audit records in a repository separate from the audited system or system component helps to ensure that a compromise of the system being audited does not also result in a compromise of the audit records. Storing audit records on separate physical systems or components also preserves the confidentiality and integrity of audit records and facilitates the management of audit records as an organization-wide activity. Storing audit records on separate systems or components applies to initial generation as well as backup or long-term storage of audit records.",
          "Access control. Session termination. Automatically terminate a user session after [assignment: organization-defined conditions or trigger events requiring session disconnect]. Session termination addresses the termination of user-initiated logical sessions. In contrast to SC-10, which addresses the termination of network connections associated with communications sessions (i.e., network disconnect). A logical session (for local, network, and remote access) is initiated whenever a user (or process acting on behalf of a user) accesses an organizational system. Such user sessions can be terminated without terminating network sessions. Session termination ends all processes associated with a user's logical session, except for those processes that are specifically created by the user (i.e., session owner) to continue after the session is terminated. Conditions or trigger events that require automatic termination of the session include organization-defined periods of user inactivity, targeted responses to certain types of incidents, or time-of-day restrictions on system use.",
          "System and services acquisition. Security and privacy engineering principles. Apply the following systems security and privacy engineering principles in the specification, design, development, implementation, and modification of the system and system components: [Assignment: organization-defined systems security and privacy engineering principles]. Systems security and privacy engineering principles are closely related to and implemented throughout the system development life cycle (see SA-3). Organizations can apply systems security and privacy engineering principles to new systems under development or to systems undergoing upgrades. For existing systems, organizations apply systems security and privacy engineering principles to system upgrades and modifications to the extent feasible, given the current state of hardware, software, and firmware components within those systems.\n\nThe application of systems security and privacy engineering principles helps organizations develop trustworthy, secure, and resilient systems and reduces the susceptibility to disruptions, hazards, threats, and the creation of privacy problems for individuals. Examples of system security engineering principles include: developing layered protections; establishing security and privacy policies, architecture, and controls as the foundation for design and development; incorporating security and privacy requirements into the system development life cycle; delineating physical and logical security boundaries; ensuring that developers are trained on how to build secure software; tailoring controls to meet organizational needs; and performing threat modeling to identify use cases, threat agents, attack vectors, and patterns, design patterns, and compensating controls needed to mitigate risk.\n\nOrganizations that apply systems security and privacy engineering concepts and principles can facilitate the development of trustworthy, secure systems, system components, and system services; reduce risk to acceptable levels; and make informed risk management decisions. System security engineering principles can also be used to protect against certain supply chain risks, including incorporating tamper-resistant hardware into a design.",
          "Physical and environmental protection. Visitor access records | automated records maintenance and review. Maintain and review visitor access records using [assignment: organization-defined automated mechanisms]. Visitor access records may be stored and maintained in a database management system that is accessible by organizational personnel. Automated access to such records facilitates record reviews on a regular basis to determine if access authorizations are current and still required to support organizational mission and business functions.",
          "Physical and environmental protection. Alternate work site. a. Determine and document the [assignment: organization-defined alternate work sites] allowed for use by employees. \nb. Employ the following controls at alternate work sites: [assignment: organization-defined controls]. \nc. Assess the effectiveness of controls at alternate work sites. \nd. Provide a means for employees to communicate with information security and privacy personnel in case of incidents. \n\nAlternate work sites include government facilities or the private residences of employees. While distinct from alternative processing sites, alternate work sites can provide readily available alternate locations during contingency operations. Organizations can define different sets of controls for specific alternate work sites or types of sites depending on the work-related activities conducted at the sites. Implementing and assessing the effectiveness of organization-defined controls and providing a means to communicate incidents at alternate work sites support the contingency planning activities of organizations.",
          "Risk assessment. Vulnerability monitoring and scanning. a. Monitor and scan for vulnerabilities in the system and hosted applications. [Assignment: Organization-defined frequency and/or randomly in accordance with organization-defined process]. When new vulnerabilities potentially affecting the system are identified and reported.\nb. Employ vulnerability monitoring tools and techniques that facilitate interoperability among tools and automate parts of the vulnerability management process. Use standards for: \n1. Enumerating platforms, software flaws, and improper configurations.\n2. Formatting checklists and test procedures.\n3. Measuring vulnerability impact.\nc. Analyze vulnerability scan reports and results from vulnerability monitoring.\nd. Remediate legitimate vulnerabilities. [Assignment: Organization-defined response times]. In accordance with an organizational assessment of risk.\ne. Share information obtained from the vulnerability monitoring process and control assessments with [Assignment: Organization-defined personnel or roles] to help eliminate similar vulnerabilities in other systems.\nf. Employ vulnerability monitoring tools that include the capability to readily update the vulnerabilities to be scanned. \n\nThe security categorization of information and systems guides the frequency and comprehensiveness of vulnerability monitoring (including scans). Organizations determine the required vulnerability monitoring for system components, ensuring that the potential sources of vulnerabilities such as infrastructure components (e.g., switches, routers, guards, sensors), networked printers, scanners, and copiers are not overlooked. The capability to readily update vulnerability monitoring tools as new vulnerabilities are discovered and announced and as new scanning methods are developed helps to ensure that new vulnerabilities are not missed by employed vulnerability monitoring tools. The vulnerability monitoring tool update process helps to ensure that potential vulnerabilities in the system are identified and addressed as quickly as possible. Vulnerability monitoring and analyses for custom software may require additional approaches such as static analysis, dynamic analysis, binary analysis, or a hybrid of the three approaches. Organizations can use these analysis approaches in source code reviews and in a variety of tools including web-based application scanners, static analysis tools, and binary analyzers. Vulnerability monitoring includes scanning for patch levels, scanning for functions, ports, protocols, and services that should not be accessible to users or devices, and scanning for flow control mechanisms that are improperly configured or operating incorrectly. Vulnerability monitoring may also include continuous vulnerability monitoring tools that use instrumentation to continuously analyze components. Instrumentation-based tools may improve accuracy and may be run throughout an organization without scanning. Vulnerability monitoring tools that facilitate interoperability include tools that are Security Content Automated Protocol (SCAP)-validated. Thus, organizations consider using scanning tools that express vulnerabilities in the Common Vulnerabilities and Exposures (CVE) naming convention and that employ the Open Vulnerability Assessment Language (OVAL) to determine the presence of vulnerabilities. Sources for vulnerability information include the Common Weakness Enumeration (CWE) listing and the National Vulnerability Database (NVD). Control assessments such as red team exercises provide additional sources of potential vulnerabilities for which to scan. Organizations also consider using scanning tools that express vulnerability impact by the Common Vulnerability Scoring System (CVSS). Vulnerability monitoring includes a channel and process for receiving reports of security vulnerabilities from the public at-large. Vulnerability disclosure programs can be as simple as publishing a monitored email address or web form that can receive reports, including notification authorizing good-faith research and disclosure of security vulnerabilities. Organizations generally expect that such research is happening with or without their authorization and can use public vulnerability disclosure channels to increase the likelihood that discovered vulnerabilities are reported directly to the organization for remediation. Organizations may also employ the use of financial incentives (also known as bug bounties) to further encourage external security researchers to report discovered vulnerabilities. Bug bounty programs can be tailored to the organization’s needs. Bounties can be operated indefinitely or over a defined period of time and can be offered to the general public or to a curated group. Organizations may run public and private bounties simultaneously and could choose to offer partially credentialed access to certain participants in order to evaluate security vulnerabilities from privileged vantage points.",
          "Personnel security. Personnel screening. a. Screen individuals prior to authorizing access to the system.\nb. Rescreen individuals in accordance with [assignment: organization-defined conditions requiring rescreening and, where rescreening is so indicated, the frequency of rescreening].\nPersonnel screening and rescreening activities reflect applicable laws, executive orders, directives, regulations, policies, standards, guidelines, and specific criteria established for the risk designations of assigned positions. Examples of personnel screening include background investigations and agency checks. Organizations may define different rescreening conditions and frequencies for personnel accessing systems based on types of information processed, stored, or transmitted by the systems.",
          "Configuration management. Configuration management plan. Develop, document, and implement a configuration management plan for the system that:\n\na. Addresses roles, responsibilities, and configuration management processes and procedures.\nb. Establishes a process for identifying configuration items throughout the system development life cycle and for managing the configuration of the configuration items.\nc. Defines the configuration items for the system and places the configuration items under configuration management.\nd. Is reviewed and approved by [assignment: organization-defined personnel or roles].\ne. Protects the configuration management plan from unauthorized disclosure and modification.\n\nConfiguration management activities occur throughout the system development life cycle. As such, there are developmental configuration management activities (e.g., the control of code and software libraries) and operational configuration management activities (e.g., control of installed components and how the components are configured). Configuration management plans satisfy the requirements in configuration management policies while being tailored to individual systems.\n\nConfiguration management plans define processes and procedures for how configuration management is used to support system development life cycle activities. Configuration management plans are generated during the development and acquisition stage of the system development life cycle. The plans describe how to advance changes through change management processes, update configuration settings and baselines, maintain component inventories, control development, test, and operational environments, and develop, release, and update key documents.\n\nOrganizations can employ templates to help ensure the consistent and timely development and implementation of configuration management plans. Templates can represent a configuration management plan for the organization with subsets of the plan implemented on a system by system basis.\n\nConfiguration management approval processes include the designation of key stakeholders responsible for reviewing and approving proposed changes to systems and personnel who conduct security and privacy impact analyses prior to the implementation of changes to the systems.\n\nConfiguration items are the system components, such as the hardware, software, firmware, and documentation to be configuration-managed. As systems continue through the system development life cycle, new configuration items may be identified, and some existing configuration items may no longer need to be under configuration control.",
          "System and services acquisition. System development life cycle. A. Acquire, develop, and manage the system using [assignment: organization-defined system development life cycle] that incorporates information security and privacy considerations. \nB. Define and document information security and privacy roles and responsibilities throughout the system development life cycle. \nC. Identify individuals having information security and privacy roles and responsibilities. \nD. Integrate the organizational information security and privacy risk management process into system development life cycle activities. \n\nA system development life cycle process provides the foundation for the successful development, implementation, and operation of organizational systems. The integration of security and privacy considerations early in the system development life cycle is a foundational principle of systems security engineering and privacy engineering. To apply the required controls within the system development life cycle requires a basic understanding of information security and privacy, threats, vulnerabilities, adverse impacts, and risk to critical mission and business functions. The security engineering principles in SA-8 help individuals properly design, code, and test systems and system components. \n\nOrganizations include qualified personnel (e.g., senior agency information security officers, senior agency officials for privacy, security and privacy architects, and security and privacy engineers) in system development life cycle processes to ensure that established security and privacy requirements are incorporated into organizational systems. Role-based security and privacy training programs can ensure that individuals with key security and privacy roles and responsibilities have the experience, skills, and expertise to conduct assigned system development life cycle activities. The effective integration of security and privacy requirements into enterprise architecture also helps to ensure that important security and privacy considerations are addressed throughout the system life cycle and that those considerations are directly related to organizational mission and business processes. This process also facilitates the integration of the information security and privacy architectures into the enterprise architecture, consistent with the risk management strategy of the organization. \n\nBecause the system development life cycle involves multiple organizations (e.g., external suppliers, developers, integrators, service providers), acquisition and supply chain risk management functions and controls play significant roles in the effective management of the system during the life cycle.",
          "Product safety and security (pss). Identification of vulnerabilities of the cloud service. Basic criterion: The cloud service provider applies appropriate measures to check the cloud service for vulnerabilities that might have been integrated into the cloud service during the software development process. The procedures for identifying such vulnerabilities are part of the software development process and, depending on a risk assessment, include the following activities: static application security testing; dynamic application security testing; code reviews by the cloud service provider’s subject matter experts; and obtaining information about confirmed vulnerabilities in software libraries provided by third parties and used in their own cloud service. The severity of identified vulnerabilities is assessed according to defined criteria, and measures are taken to immediately eliminate or mitigate them.\n\nAdditional criterion: The procedures for identifying such vulnerabilities also include annual code reviews or security penetration tests by qualified external third parties.\n\nSupplementary information about the criterion: Known vulnerabilities in externally related system components (e.g., operating systems) used for the development and provision of the cloud service but not going through the cloud service provider’s software development process are the subject of Criteria OPS-23 (Management of vulnerabilities, malfunctions, and errors – open vulnerability assessment).\n\nComplementary customer criterion: Notes on continuous auditing feasibility: Yes, the cloud service provider automatically checks its cloud services for vulnerabilities. This check is documented in a standardized digital form. By auditing this documentation, the auditor verifies whether the cloud service provider has performed a vulnerability scan. In addition, the severity of the identified vulnerabilities can be integrated into this continuous audit if the defined criteria and their application are standardized and machine-readable. The information on identified and/or repaired vulnerabilities can also be transferred directly to the affected customer, increasing transparency.",
          "Contingency planning. Alternate processing site. a. Establish an alternate processing site, including necessary agreements to permit the transfer and resumption of [assignment: organization-defined system operations] for essential mission and business functions within [assignment: organization-defined time period consistent with recovery time and recovery point objectives], when the primary processing capabilities are unavailable. \nb. Make available at the alternate processing site, the equipment and supplies required to transfer and resume operations or put contracts in place to support delivery to the site within the organization-defined time period for transfer and resumption. \nc. Provide controls at the alternate processing site that are equivalent to those at the primary site. \n\nAlternate processing sites are geographically distinct from primary processing sites and provide processing capability if the primary processing site is not available. The alternate processing capability may be addressed using a physical processing site or other alternatives, such as failover to a cloud-based service provider or other internally or externally provided processing service. Geographically distributed architectures that support contingency requirements may also be considered alternate processing sites. \n\nControls that are covered by alternate processing site agreements include the environmental conditions at alternate sites, access rules, physical and environmental protection requirements, and the coordination for the transfer and assignment of personnel. Requirements are allocated to alternate processing sites that reflect the requirements in contingency plans to maintain essential mission and business functions despite disruption, compromise, or failure in organizational systems.",
          "Audit and accountability. Audit record generation. a. Provide audit record generation capability for the event types the system is capable of auditing as defined in au-2a on [assignment: organization-defined system components].\nb. Allow [assignment: organization-defined personnel or roles] to select the event types that are to be logged by specific components of the system.\nc. Generate audit records for the event types defined in au-2c that include the audit record content defined in au-3. Audit records can be generated from many different system components. The event types specified in au-2d are the event types for which audit logs are to be generated and are a subset of all event types for which the system can generate audit records.",
          "Personnel security. Personnel sanctions. a. Employ a formal sanctions process for individuals failing to comply with established information security and privacy policies and procedures. \n\nb. Notify [assignment: organization-defined personnel or roles] within [assignment: organization-defined time period] when a formal employee sanctions process is initiated, identifying the individual sanctioned and the reason for the sanction. \n\nOrganizational sanctions reflect applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Sanctions processes are described in access agreements and can be included as part of general personnel policies for organizations and/or specified in security and privacy policies. \n\nOrganizations consult with the Office of the General Counsel regarding matters of employee sanctions.",
          "Incident response. Incident response plan. A. Develop an incident response plan that:\n\n1. Provides the organization with a roadmap for implementing its incident response capability.\n2. Describes the structure and organization of the incident response capability.\n3. Provides a high-level approach for how the incident response capability fits into the overall organization.\n4. Meets the unique requirements of the organization, which relate to mission, size, structure, and functions.\n5. Defines reportable incidents.\n6. Provides metrics for measuring the incident response capability within the organization.\n7. Defines the resources and management support needed to effectively maintain and mature an incident response capability.\n8. Addresses the sharing of incident information.\n9. Is reviewed and approved by [assignment: organization-defined personnel or roles] [assignment: organization-defined frequency].\n10. Explicitly designates responsibility for incident response to [assignment: organization-defined entities, personnel, or roles].\n\nB. Distribute copies of the incident response plan to [assignment: organization-defined incident response personnel (identified by name and/or role) and organizational elements].\n\nC. Update the incident response plan to address system and organizational changes or problems encountered during plan implementation, execution, or testing.\n\nD. Communicate incident response plan changes to [assignment: organization-defined incident response personnel (identified by name and/or role) and organizational elements].\n\nE. Protect the incident response plan from unauthorized disclosure and modification.\n\nIt is important that organizations develop and implement a coordinated approach to incident response. Organizational mission and business functions determine the structure of incident response capabilities. As part of the incident response capabilities, organizations consider the coordination and sharing of information with external organizations, including external service providers and other organizations involved in the supply chain. For incidents involving personally identifiable information (i.e., breaches), include a process to determine whether notice to oversight organizations or affected individuals is appropriate and provide that notice accordingly.",
          "Configuration management. User-installed software. a. Establish [assignment: organization-defined policies] governing the installation of software by users. \nb. Enforce software installation policies through the following methods: [assignment: organization-defined methods]. \nc. Monitor policy compliance [assignment: organization-defined frequency]. \n\nIf provided the necessary privileges, users can install software in organizational systems. To maintain control over the software installed, organizations identify permitted and prohibited actions regarding software installation. \n\nPermitted software installations include updates and security patches to existing software and downloading new applications from organization-approved app stores. Prohibited software installations include software with unknown or suspect pedigrees or software that organizations consider potentially malicious. \n\nPolicies selected for governing user-installed software are organization-developed or provided by some external entity. Policy enforcement methods can include procedural methods and automated methods.",
          "Incident response. Information spillage response | post-spill operations. Implement the following procedures to ensure that organizational personnel impacted by information spills can continue to carry out assigned tasks while contaminated systems are undergoing corrective actions:\n\n[Assignment: Organization-defined procedures]. Corrective actions for systems contaminated due to information spillages may be time-consuming. Personnel may not have access to the contaminated systems while corrective actions are being taken, which may potentially affect their ability to conduct organizational business.",
          "Supply chain risk management family. Supply chain controls and processes. a. Establish a process or processes to identify and address weaknesses or deficiencies in the supply chain elements and processes of [assignment: organization-defined system or system component] in coordination with [assignment: organization-defined supply chain personnel]. \nB. Employ the following controls to protect against supply chain risks to the system, system component, or system service and to limit the harm or consequences from supply chain-related events: [assignment: organization-defined supply chain controls]. \nC. Document the selected and implemented supply chain processes and controls in [Selection: security and privacy plans; supply chain risk management plan; [assignment: organization-defined document]]. \n\nSupply chain elements include organizations, entities, or tools employed for the research and development, design, manufacturing, acquisition, delivery, integration, operations and maintenance, and disposal of systems and system components. \nSupply chain processes include hardware, software, and firmware development processes; shipping and handling procedures; personnel security and physical security programs; configuration management tools, techniques, and measures to maintain provenance; or other programs, processes, or procedures associated with the development, acquisition, maintenance, and disposal of systems and system components. \nSupply chain elements and processes may be provided by organizations, system integrators, or external providers. \nWeaknesses or deficiencies in supply chain elements or processes represent potential vulnerabilities that can be exploited by adversaries to cause harm to the organization and affect its ability to carry out its core missions or business functions. \nSupply chain personnel are individuals with roles and responsibilities in the supply chain.",
          "Security assessment and authorization. Internal system connections. a. Authorize internal connections of [assignment: organization-defined system components or classes of components] to the system.\nb. Document, for each internal connection, the interface characteristics, security and privacy requirements, and the nature of the information communicated.\nc. Terminate internal system connections after [assignment: organization-defined conditions].\nd. Review [assignment: organization-defined frequency] the continued need for each internal connection.\n\nInternal system connections are connections between organizational systems and separate constituent system components. These include connections between components that are part of the same system, as well as components used for system development. Intra-system connections encompass connections with mobile devices, notebook and desktop computers, tablets, printers, copiers, facsimile machines, scanners, sensors, and servers.\n\nInstead of authorizing each internal system connection individually, organizations have the option to authorize internal connections for a class of system components with common characteristics and/or configurations. For example, printers, scanners, and copiers with a specified processing, transmission, and storage capability, or smart phones and tablets with a specific baseline configuration.\n\nThe continued need for an internal system connection should be reviewed from the perspective of whether it provides support for organizational missions or business functions.",
          "Identification and authentication. Identity proofing | identity evidence validation and verification. Require that the presented identity evidence be validated and verified through [assignment: organizational defined methods of validation and verification]. Validation and verification of identity evidence increases the assurance that accounts and identifiers are being established for the correct user and authenticators are being bound to that user. Validation refers to the process of confirming that the evidence is genuine and authentic, and the data contained in the evidence is correct, current, and related to an individual. Verification confirms and establishes a linkage between the claimed identity and the actual existence of the user presenting the evidence. Acceptable methods for validating and verifying identity evidence are consistent with the risks to the systems, roles, and privileges associated with the user's account.",
          "Contingency planning. Telecommunications services | provider contingency plan. (a) Require primary and alternate telecommunications service providers to have contingency plans. \n(b) Review provider contingency plans to ensure that the plans meet organizational contingency requirements. \n(c) Obtain evidence of contingency testing and training by providers [assignment: organization-defined frequency]. Reviews of provider contingency plans consider the proprietary nature of such plans. In some situations, a summary of provider contingency plans may be sufficient evidence for organizations to satisfy the review requirement. Telecommunications service providers may also participate in ongoing disaster recovery exercises in coordination with the Department of Homeland Security and state and local governments. Organizations may use these types of activities to satisfy evidentiary requirements related to service provider contingency plan reviews, testing, and training.",
          "Media protection. Media sanitization | review, approve, track, document, and verify. Review, approve, track, document, and verify media sanitization and disposal actions. Organizations review and approve media to be sanitized to ensure compliance with records retention policies. Tracking and documenting actions include listing personnel who reviewed and approved sanitization and disposal actions, types of media sanitized, files stored on the media, sanitization methods used, date and time of the sanitization actions, personnel who performed the sanitization, verification actions taken and personnel who performed the verification, and the disposal actions taken. Organizations verify that the sanitization of the media was effective prior to disposal.",
          "Identification and authentication. Policy and procedures. A. Develop, document, and disseminate to organization-defined personnel or roles: \n\n1. Organization level identification and authentication policy that addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance. The policy should be consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines.\n\n2. Procedures to facilitate the implementation of the identification and authentication policy and the associated identification and authentication controls.\n\nB. Designate an organization-defined official to manage the development, documentation, and dissemination of the identification and authentication policy and procedures.\n\nC. Review and update the current identification and authentication:\n\n1. Policy organization-defined frequency and following organization-defined events.\n\n2. Procedures organization-defined frequency and following organization-defined events.\n\nThe identification and authentication policy and procedures address the controls in the IA family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of identification and authentication policy and procedures. \n\nSecurity and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations. Procedures can be established for security and privacy programs, for mission or business processes, and for systems, if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents.\n\nEvents that may precipitate an update to identification and authentication policy and procedures include assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Contingency planning. Alternate storage site. a. Establish an alternate storage site, including necessary agreements to permit the storage and retrieval of system backup information; and b. Ensure that the alternate storage site provides controls equivalent to those of the primary site. Alternate storage sites are geographically distinct from primary storage sites and maintain duplicate copies of information and data if the primary storage site is not available. Similarly, alternate processing sites provide processing capability if the primary processing site is not available. Geographically distributed architectures that support contingency requirements may be considered as alternate storage sites. Items covered by alternate storage site agreements include environmental conditions at the alternate sites, access rules for systems and facilities, physical and environmental protection requirements, and coordination of delivery and retrieval of backup media. Alternate storage sites reflect the requirements in contingency plans so that organizations can maintain essential mission and business functions despite compromise, failure, or disruption in organizational systems.",
          "Supply chain risk management family. Policy and procedures. A. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]: 1. [Selection (one or more): organization level; mission/business process-level; system-level] supply chain risk management policy that: (a) addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance; and (b) is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines; and 2. Procedures to facilitate the implementation of the supply chain risk management policy and the associated supply chain risk management controls. \n\nB. Designate an [assignment: organization-defined official] to manage the development, documentation, and dissemination of the supply chain risk management policy and procedures. \n\nC. Review and update the current supply chain risk management: 1. Policy [assignment: organization-defined frequency] and following [assignment: organization-defined events]; and 2. Procedures [assignment: organization-defined frequency] and following [assignment: organization-defined events]. \n\nSupply chain risk management policy and procedures address the controls in the SR family as well as supply chain-related controls in other families that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of supply chain risk management policy and procedures. Security and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations. Procedures can be established for security and privacy programs, for mission or business processes, and for systems, if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents. Events that may precipitate an update to supply chain risk management policy and procedures include assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Operations (ops). Testing and documentation of known vulnerabilities. Basic criterion: System components in the area of responsibility of the cloud service provider for the provision of the cloud service are automatically checked for known vulnerabilities at least once a month in accordance with the policies for handling vulnerabilities (cf. ops-18). The severity is assessed in accordance with defined criteria, and measures for timely remediation or mitigation are initiated within defined time windows. \n\nAdditional criterion: Available security patches are applied depending on the severity of the vulnerabilities, as determined based on the latest version of the Common Vulnerability Scoring System (CVSS): \n- Critical (CVSS = 9.0 – 10.0): 3 hours.\n- High (CVSS = 7.0 – 8.9): 3 days.\n- Average (CVSS = 4.0 – 6.9): 1 month.\n- Low (CVSS = 0.1 – 3.9): 3 months. \n\nSupplementary information about the criterion: \nIn contrast to penetration tests (cf. ops-20), which are carried out manually and according to an individual scheme, the check for open vulnerabilities is performed automatically, using so-called vulnerability scanners. \n\nComplementary customer criterion: \nCloud customers ensure through suitable controls that system components under their responsibility are regularly checked for vulnerabilities and mitigated by appropriate measures. \n\nNotes on continuous auditing feasibility: \nYes, the periodic check for vulnerabilities and the corresponding results, as well as the analysis and remediation of identified vulnerabilities, are documented by the cloud service provider. An automated and continuous audit of this procedure can be implemented by the auditor by automatically evaluating the documented results.",
          "Contingency planning. Telecommunications services. Establish alternate telecommunications services, including necessary agreements to permit the resumption of [assignment: organization-defined system operations] for essential mission and business functions within [assignment: organization-defined time period], when the primary telecommunications capabilities are unavailable at either the primary or alternate processing or storage sites. \n\nTelecommunications services (for data and voice) for primary and alternate processing and storage sites are in scope for CP-8. Alternate telecommunications services reflect the continuity requirements in contingency plans to maintain essential mission and business functions despite the loss of primary telecommunications services. \n\nOrganizations may specify different time periods for primary or alternate sites. Alternate telecommunications services include additional organizational or commercial ground-based circuits or lines, network-based approaches to telecommunications, or the use of satellites. Organizations consider factors such as availability, quality of service, and access when entering into alternate telecommunications agreements.",
          "Planning. Rules of behavior | social media and external site/application usage restrictions. Include in the rules of behavior restrictions on:\n\n(a) Use of social media, social networking sites, and external sites/applications.\n\n(b) Posting organizational information on public websites.\n\n(c) Use of organization-provided identifiers (e.g., email addresses) and authentication secrets (e.g., passwords) for creating accounts on external sites/applications.\n\nSocial media, social networking, and external site/application usage restrictions address rules of behavior related to the use of social media, social networking, and external sites when organizational personnel are using such sites for official duties or in the conduct of official business. It also applies when organizational information is involved in social media and social networking transactions, and when personnel access social media and networking sites from organizational systems.\n\nOrganizations should also address specific rules that prevent unauthorized entities from obtaining non-public organizational information from social media and networking sites, either directly or through inference. Non-public information includes personally identifiable information and system account information.",
          "Configuration management. Policy and procedures. a. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]: 1. [Selection (one or more): organization level; mission/business process-level; system-level] configuration management policy that: (a) addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance; and (b) is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines; and 2. Procedures to facilitate the implementation of the configuration management policy and the associated configuration management controls. \n\nb. Designate an [assignment: organization-defined official] to manage the development, documentation, and dissemination of the configuration management policy and procedures.\n\nc. Review and update the current configuration management: \n1. Policy [assignment: organization-defined frequency] and following [assignment: organization-defined events].\n2. Procedures [assignment: organization-defined frequency] and following [assignment: organization-defined events].\n\nConfiguration management policy and procedures address the controls in the CM family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of configuration management policy and procedures.\n\nSecurity and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations. Procedures can be established for security and privacy programs, for mission/business processes, and for systems, if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents. \n\nEvents that may precipitate an update to configuration management policy and procedures include, but are not limited to, assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Security assessment and authorization. Control assessments | independent assessors. Employ independent assessors or assessment teams to conduct control assessments. Independent assessors or assessment teams are individuals or groups who conduct impartial assessments of systems. Impartiality means that assessors are free from any perceived or actual conflicts of interest regarding the development, operation, sustainment, or management of the systems under assessment or the determination of control effectiveness. To achieve impartiality, assessors do not create a mutual or conflicting interest with the organizations where the assessments are being conducted, assess their own work, act as management or employees of the organizations they are serving, or place themselves in positions of advocacy for the organizations acquiring their services.\n\nIndependent assessments can be obtained from elements within organizations or be contracted to public or private sector entities outside of organizations. Authorizing officials determine the required level of independence based on the security categories of systems and/or the risk to organizational operations, organizational assets, or individuals. Authorizing officials also determine if the level of assessor independence provides sufficient assurance that the results are sound and can be used to make credible, risk-based decisions. Assessor independence determination includes whether contracted assessment services have sufficient independence, such as when system owners are not directly involved in contracting processes or cannot influence the impartiality of the assessors conducting the assessments.\n\nDuring the system design and development phase, having independent assessors is analogous to having independent SMEs involved in design reviews. When organizations that own the systems are small or the structures of the organizations require that assessments be conducted by individuals that are in the developmental, operational, or management chain of the system owners, independence in assessment processes can be achieved by ensuring that assessment results are carefully reviewed and analyzed by independent teams of experts to validate the completeness, accuracy, integrity, and reliability of the results. Assessments performed for purposes other than to support authorization decisions are more likely to be usable for such decisions when performed by assessors with sufficient independence, thereby reducing the need to repeat assessments.",
          "Contingency planning. System backup | cryptographic protection. Implement cryptographic mechanisms to prevent unauthorized disclosure and modification of [assignment: organization-defined backup information]. The selection of cryptographic mechanisms is based on the need to protect the confidentiality and integrity of backup information. The strength of the mechanisms selected is commensurate with the security category or classification of the information. Cryptographic protection applies to system backup information in storage at both primary and alternate locations. Organizations that implement cryptographic mechanisms to protect information at rest also consider cryptographic key management solutions.",
          "Security assessment and authorization. Policy and procedures. A. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]: 1. [Selection (one or more): organization-level; mission/business process-level; system-level] assessment, authorization, and monitoring policy that: (a) addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance; and (b) is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines; and 2. Procedures to facilitate the implementation of the assessment, authorization, and monitoring policy and the associated assessment, authorization, and monitoring controls. \n\nB. Designate an [assignment: organization-defined official] to manage the development, documentation, and dissemination of the assessment, authorization, and monitoring policy and procedures. \n\nC. Review and update the current assessment, authorization, and monitoring: 1. Policy [assignment: organization-defined frequency] and following [assignment: organization-defined events]; and 2. Procedures [assignment: organization-defined frequency] and following [assignment: organization-defined events]. \n\nAssessment, authorization, and monitoring policy and procedures address the controls in the CA family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of assessment, authorization, and monitoring policy and procedures. Security and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. \n\nThe policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations. Procedures can be established for security and privacy programs, for mission or business processes, and for systems, if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents. \n\nEvents that may precipitate an update to assessment, authorization, and monitoring policy and procedures include assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "2_and_the_or",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "2_and_the_or"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          9.473983764648438,
          10.399503707885742,
          9.452746391296387,
          9.688994407653809,
          9.520442008972168,
          9.372076034545898,
          10.151632308959961,
          10.127416610717773,
          9.348061561584473,
          10.337641716003418,
          9.648388862609863,
          8.897439956665039,
          9.836983680725098,
          9.697278022766113,
          9.97485637664795,
          11.152085304260254,
          9.743496894836426,
          9.327303886413574,
          10.111806869506836,
          9.471198081970215,
          10.833686828613281,
          9.580780029296875,
          11.150717735290527,
          9.998311996459961,
          9.798787117004395,
          9.304377555847168,
          9.224818229675293,
          9.689516067504883,
          9.626941680908203,
          9.719680786132812,
          10.423111915588379,
          10.468301773071289,
          9.53370475769043,
          10.347304344177246,
          10.384194374084473,
          9.33307933807373,
          9.021660804748535,
          9.277937889099121,
          9.480558395385742,
          9.385869026184082,
          9.498327255249023,
          10.086709976196289,
          9.479670524597168,
          10.403902053833008,
          10.294946670532227,
          9.27448558807373,
          9.397388458251953,
          10.109230995178223,
          8.999979972839355,
          9.443947792053223,
          9.902069091796875,
          9.592314720153809,
          9.815842628479004,
          10.143033981323242,
          10.352005958557129,
          10.483741760253906,
          9.406840324401855,
          9.421747207641602,
          9.524468421936035,
          9.665599822998047,
          11.143287658691406,
          10.210752487182617,
          9.443746566772461,
          8.86953067779541,
          9.291871070861816,
          10.27171802520752,
          10.375872611999512,
          9.965211868286133,
          9.26914119720459,
          10.365943908691406,
          9.811715126037598
         ],
         "y": [
          9.359138488769531,
          9.878508567810059,
          8.970803260803223,
          10.45762825012207,
          10.277901649475098,
          8.93729019165039,
          9.106449127197266,
          9.51743221282959,
          10.428080558776855,
          8.850143432617188,
          10.489808082580566,
          9.683357238769531,
          9.197267532348633,
          9.687304496765137,
          9.510467529296875,
          9.736480712890625,
          9.829117774963379,
          9.31067180633545,
          9.165820121765137,
          9.966811180114746,
          9.832005500793457,
          10.434377670288086,
          9.733251571655273,
          9.581619262695312,
          9.345962524414062,
          9.35654354095459,
          8.652493476867676,
          8.98193073272705,
          9.074830055236816,
          9.435341835021973,
          8.931586265563965,
          8.863388061523438,
          10.30104923248291,
          9.575634002685547,
          9.000890731811523,
          9.04504680633545,
          9.027142524719238,
          9.336797714233398,
          10.2657470703125,
          10.543910026550293,
          10.009147644042969,
          9.26650619506836,
          9.41392707824707,
          8.922465324401855,
          9.093810081481934,
          9.088553428649902,
          10.463560104370117,
          9.267162322998047,
          11.028764724731445,
          10.526309967041016,
          9.839550971984863,
          9.647335052490234,
          9.88675308227539,
          9.127760887145996,
          9.747090339660645,
          9.7786226272583,
          9.132608413696289,
          10.486836433410645,
          9.95663833618164,
          10.474333763122559,
          9.777036666870117,
          9.190783500671387,
          10.470602035522461,
          11.116792678833008,
          9.162496566772461,
          9.713909149169922,
          9.830560684204102,
          9.230034828186035,
          9.090656280517578,
          9.727550506591797,
          9.630688667297363
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Access control. Least privilege | log use of privileged functions. Log the execution of privileged functions. The misuse of privileged functions, either intentionally or unintentionally, by authorized users or by unauthorized external entities that have compromised system accounts, is a serious and ongoing concern and can have significant adverse impacts on organizations. Logging and analyzing the use of privileged functions is one way to detect such misuse and, in doing so, help mitigate the risk from insider threats and the advanced persistent threat.",
          "Contingency planning. Contingency plan | resume mission and business functions. Plan for the resumption of [selection: all; essential] mission and business functions within [assignment: organization-defined time period] of contingency plan activation. Organizations may choose to conduct contingency planning activities to resume mission and business functions as part of business continuity planning or as part of business impact analyses. Organizations prioritize the resumption of mission and business functions. The time period for resuming mission and business functions may be dependent on the severity and extent of the disruptions to the system and its supporting infrastructure.",
          "System and communications protection. Transmission confidentiality and integrity. Protect the confidentiality and integrity of transmitted information. Protecting the confidentiality and integrity of transmitted information applies to internal and external networks as well as any system components that can transmit information, including servers, notebook computers, desktop computers, mobile devices, printers, copiers, scanners, facsimile machines, and radios. Unprotected communication paths are exposed to the possibility of interception and modification. Protecting the confidentiality and integrity of information can be accomplished by physical or logical means. Physical protection can be achieved by using protected distribution systems. A protected distribution system is a wireline or fiber-optics telecommunications system that includes terminals and adequate electromagnetic, acoustical, electrical, and physical controls to permit its use for the unencrypted transmission of classified information. Logical protection can be achieved by employing encryption techniques. Organizations that rely on commercial providers who offer transmission services as commodity services rather than as fully dedicated services may find it difficult to obtain the necessary assurances regarding the implementation of needed controls for transmission confidentiality and integrity. In such situations, organizations determine what types of confidentiality or integrity services are available in standard, commercial telecommunications service packages. If it is not feasible to obtain the necessary controls and assurances of control effectiveness through appropriate contracting vehicles, organizations can implement appropriate compensating controls.",
          "Physical and environmental protection. Fire protection | suppression systems — automatic activation and notification. (a) Employ fire suppression systems that activate automatically and notify [assignment: organization-defined personnel or roles] and [assignment: organization-defined emergency responders]. (b) Employ an automatic fire suppression capability when the facility is not staffed on a continuous basis. Organizations can identify specific personnel, roles, and emergency responders if individuals on the notification list need to have appropriate access authorizations and/or clearances (e.g., to enter facilities where access is restricted due to the impact level or classification of information within the facility). Notification mechanisms may require independent energy sources to ensure that the notification capability is not adversely affected by the fire.",
          "Supply chain risk management family. Supplier assessments and reviews. Assess and review the supply chain-related risks associated with suppliers or contractors and the system, system component, or system service they provide [assignment: organization-defined frequency]. An assessment and review of supplier risk includes security and supply chain risk management processes, foreign ownership, control or influence (FOCI), and the ability of the supplier to effectively assess subordinate second-tier and third-tier suppliers and contractors. The reviews may be conducted by the organization or by an independent third party. The reviews consider documented processes, documented controls, all-source intelligence, and publicly available information related to the supplier or contractor. Organizations can use open-source information to monitor for indications of stolen information, poor development and quality control practices, information spillage, or counterfeits. In some cases, it may be appropriate or required to share assessment and review results with other organizations in accordance with any applicable rules, policies, or inter-organizational agreements or contracts.",
          "Access control. Wireless access | restrict configurations by users. Identify and explicitly authorize users allowed to independently configure wireless networking capabilities. Organizational authorizations to allow selected users to configure wireless networking capabilities are enforced, in part, by the access enforcement mechanisms employed within organizational systems.",
          "System and services acquisition. Acquisition process | system, component, and service configurations. Require the developer of the system, system component, or system service to: (a) deliver the system, component, or service with organization-defined security configurations implemented; and (b) use the configurations as the default for any subsequent system, component, or service reinstallation or upgrade. Examples of security configurations include the U.S. Government Configuration Baseline (USGCB), Security Technical Implementation Guides (STIGs), and any limitations on functions, ports, protocols, and services. Security characteristics can include requiring that default passwords have been changed.",
          "Identification and authentication. Identification and authentication (non-organizational users) | acceptance of piv credentials from other agencies. Accept and electronically verify Personal Identity Verification (PIV)-compliant credentials from other federal agencies. Acceptance of PIV credentials from other federal agencies applies to both logical and physical access control systems. PIV credentials are those credentials issued by federal agencies that conform to FIPS Publication 201 and supporting guidelines. The adequacy and reliability of PIV card issuers are addressed and authorized using SP 800-79-2.",
          "Risk assessment. Risk assessment | supply chain risk assessment. (a) Assess supply chain risks associated with [assignment: organization-defined systems, system components, and system services]; and (b) update the supply chain risk assessment [assignment: organization-defined frequency], when there are significant changes to the relevant supply chain or when changes to the system, environments of operation, or other conditions may necessitate a change in the supply chain. Supply chain-related events include disruption, use of defective components, insertion of counterfeits, theft, malicious development practices, improper delivery practices, and insertion of malicious code. These events can have a significant impact on the confidentiality, integrity, or availability of a system and its information and therefore can also adversely impact organizational operations (including mission, functions, image, or reputation), organizational assets, individuals, other organizations, and the nation. The supply chain-related events may be unintentional or malicious and can occur at any point during the system life cycle. An analysis of supply chain risk can help an organization identify systems or components for which additional supply chain risk mitigations are required.",
          "Contingency planning. Contingency plan | capacity planning. Conduct capacity planning so that necessary capacity for information processing, telecommunications, and environmental support exists during contingency operations. Capacity planning is needed because different threats can result in a reduction of the available processing, telecommunications, and support services intended to support essential mission and business functions. Organizations anticipate degraded operations during contingency operations and factor the degradation into capacity planning. For capacity planning, environmental support refers to any environmental factor for which the organization determines that it needs to provide support in a contingency situation, even if in a degraded state. Such determinations are based on an organizational assessment of risk, system categorization (impact level), and organizational risk tolerance.",
          "System and information integrity. Software, firmware, and information integrity | automated response to integrity violations. Automatically [selection: shut the system down; restart the system; implement [assignment: organization-defined controls]] when integrity violations are discovered. Organizations may define different integrity checking responses by type of information, specific information, or a combination of both. Types of information include firmware, software, and user data. Specific information includes boot firmware for certain types of machines. The automatic implementation of controls within organizational systems includes reversing the changes, halting the system, or triggering audit alerts when unauthorized modifications to critical security files occur.",
          "System and communications protection. Cryptographic key establishment and management. Establish and manage cryptographic keys when cryptography is employed within the system in accordance with the following key management requirements: [assignment: organization-defined requirements for key generation, distribution, storage, access, and destruction]. Cryptographic key management and establishment can be performed using manual procedures or automated mechanisms with supporting manual procedures. Organizations define key management requirements in accordance with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines and specify appropriate options, parameters, and levels. Organizations manage trust stores to ensure that only approved trust anchors are part of such trust stores. This includes certificates with visibility external to organizational systems and certificates related to the internal operations of systems. NIST CMVP and NIST CAVP provide additional information on validated cryptographic modules and algorithms that can be used in cryptographic key management and establishment.",
          "Access control. Unsuccessful logon attempts. a. Enforce a limit of [assignment: organization-defined number] consecutive invalid logon attempts by a user during a [assignment: organization-defined time period]. \nb. Automatically [selection (one or more): lock the account or node for an [assignment: organization-defined time period]; lock the account or node until released by an administrator; delay next logon prompt per [assignment: organization-defined delay algorithm]; notify system administrator; take other [assignment: organization-defined action]] when the maximum number of unsuccessful attempts is exceeded. The need to limit unsuccessful logon attempts and take subsequent action when the maximum number of attempts is exceeded applies regardless of whether the logon occurs via a local or network connection. Due to the potential for denial of service, automatic lockouts initiated by systems are usually temporary and automatically release after a predetermined, organization-defined time period. If a delay algorithm is selected, organizations may employ different algorithms for different components of the system based on the capabilities of those components. Responses to unsuccessful logon attempts may be implemented at the operating system and the application levels. Organization-defined actions that may be taken when the number of allowed consecutive invalid logon attempts is exceeded include prompting the user to answer a secret question in addition to the username and password, invoking a lockdown mode with limited user capabilities (instead of full lockout), allowing users to only logon from specified internet protocol (IP) addresses, requiring a captcha to prevent automated attacks, or applying user profiles such as location, time of day, IP address, device, or media access control (MAC) address. If automatic system lockout or execution of a delay algorithm is not implemented in support of the availability objective, organizations consider a combination of other actions to help prevent brute force attacks. In addition to the above, organizations can prompt users to respond to a secret question before the number of allowed unsuccessful logon attempts is exceeded. Automatically unlocking an account after a specified period of time is generally not permitted. However, exceptions may be required based on operational mission or need.",
          "Access control. Information flow enforcement | physical or logical separation of information flows. Separate information flows logically or physically using [assignment: organization-defined mechanisms and/or techniques] to accomplish [assignment: organization-defined required separations by types of information]. Enforcing the separation of information flows associated with defined types of data can enhance protection by ensuring that information is not commingled while in transit and by enabling flow control by transmission paths that are not otherwise achievable. Types of separable information include inbound and outbound communications traffic, service requests and responses, and information of differing security impact or classification levels.",
          "System and communications protection. Protection of information at rest | cryptographic protection. Implement cryptographic mechanisms to prevent unauthorized disclosure and modification of the following information at rest on [assignment: organization-defined system components or media]: [assignment: organization-defined information]. The selection of cryptographic mechanisms is based on the need to protect the confidentiality and integrity of organizational information. The strength of the mechanism is commensurate with the security category or classification of the information. Organizations have the flexibility to encrypt information on system components or media or encrypt data structures, including files, records, or fields.",
          "System and communications protection. Boundary protection | deny by default — allow by exception. Deny network communications traffic by default and allow network communications traffic by exception. Denying by default and allowing by exception applies to inbound and outbound network communications traffic. A deny-all, permit-by-exception network communications traffic policy ensures that only those system connections that are essential and approved are allowed. Deny by default, allow by exception also applies to a system that is connected to an external system.",
          "Physical and environmental protection. Fire protection | detection systems — automatic activation and notification. Employ fire detection systems that activate automatically and notify [organization-defined personnel or roles] and [organization-defined emergency responders] in the event of a fire. Organizations can identify personnel, roles, and emergency responders. If individuals on the notification list need access authorizations or clearances (e.g., to enter facilities where access is restricted due to the classification or impact level of information within the facility), organizations can include them. Notification mechanisms may require independent energy sources to ensure that the notification capability is not adversely affected by the fire.",
          "Identification and authentication. Cryptographic module authentication. Implement mechanisms for authentication to a cryptographic module that meet the requirements of applicable laws, executive orders, directives, policies, regulations, standards, and guidelines for such authentication. Authentication mechanisms may be required within a cryptographic module to authenticate an operator accessing the module and to verify that the operator is authorized to assume the requested role and perform services within that role.",
          "Risk assessment. Vulnerability monitoring and scanning | review historic audit logs. Review historic audit logs to determine if a vulnerability identified in an organization-defined system has been previously exploited within an organization-defined time period. Reviewing historic audit logs to determine if a recently detected vulnerability in a system has been previously exploited by an adversary can provide important information for forensic analyses. Such analyses can help identify, for example, the extent of a previous intrusion, the tradecraft employed during the attack, organizational information exfiltrated or modified, mission or business capabilities affected, and the duration of the attack.",
          "Security assessment and authorization. Information exchange. a. Approve and manage the exchange of information between the system and other systems using [selection (one or more): interconnection security agreements; information exchange security agreements; memoranda of understanding or agreement; service level agreements; user agreements; nondisclosure agreements; [assignment: organization-defined type of agreement]].\n\nb. Document, as part of each exchange agreement, the interface characteristics, security and privacy requirements, controls, and responsibilities for each system, and the impact level of the information communicated.\n\nc. Review and update the agreements [assignment: organization-defined frequency].\n\nSystem information exchange requirements apply to information exchanges between two or more systems. System information exchanges include connections via leased lines or virtual private networks, connections to internet service providers, database sharing or exchanges of database transaction information, connections and exchanges with cloud services, exchanges via web-based services, or exchanges of files via file transfer protocols, network protocols (e.g., IPv4, IPv6), email, or other organization-to-organization communications.\n\nOrganizations consider the risk related to new or increased threats that may be introduced when systems exchange information with other systems that may have different security and privacy requirements and controls. This includes systems within the same organization and systems that are external to the organization.\n\nA joint authorization of the systems exchanging information, as described in CA-6 (1) or CA-6 (2), may help to communicate and reduce risk. Authorizing officials determine the risk associated with system information exchange and the controls needed for appropriate risk mitigation.\n\nThe types of agreements selected are based on factors such as the impact level of the information being exchanged, the relationship between the organizations exchanging information (e.g., government to government, government to business, business to business, government or business to service provider, government or business to individual), or the level of access to the organizational system by users of the other system.\n\nIf systems that exchange information have the same authorizing official, organizations need not develop agreements. Instead, the interface characteristics between the systems (e.g., how the information is being exchanged, how the information is protected) are described in the respective security and privacy plans.\n\nIf the systems that exchange information have different authorizing officials within the same organization, the organizations can develop agreements or provide the same information that would be provided in the appropriate agreement type from CA-3a in the respective security and privacy plans for the systems.\n\nOrganizations may incorporate agreement information into formal contracts, especially for information exchanges established between federal agencies and nonfederal organizations (including service providers, contractors, system developers, and system integrators). Risk considerations include systems that share the same networks.",
          "Identification and authentication. Re-authentication. Require users to re-authenticate when [assignment: organization-defined circumstances or situations requiring re-authentication]. In addition to the re-authentication requirements associated with device locks, organizations may require re-authentication of individuals in certain situations, including when roles, authenticators, or credentials change, when security categories of systems change, when the execution of privileged functions occurs, after a fixed time period, or periodically.",
          "Supply chain risk management family. Component disposal. Dispose of [assignment: organization-defined data, documentation, tools, or system components] using the following techniques and methods: [assignment: organization-defined techniques and methods]. Data, documentation, tools, or system components can be disposed of at any time during the system development life cycle (not only in the disposal or retirement phase of the life cycle). For example, disposal can occur during research and development, design, prototyping, or operations/maintenance and include methods such as disk cleaning, removal of cryptographic keys, partial reuse of components. Opportunities for compromise during disposal affect physical and logical data, including system documentation in paper-based or digital files; shipping and delivery documentation; memory sticks with software code; or complete routers or servers that include permanent media, which contain sensitive or proprietary information. Additionally, proper disposal of system components helps to prevent such components from entering the gray market.",
          "Incident response. Incident handling | dynamic reconfiguration. Include the following types of dynamic reconfiguration for organization-defined system components as part of the incident response capability: organization-defined types of dynamic reconfiguration. Dynamic reconfiguration includes changes to router rules, access control lists, intrusion detection or prevention system parameters, and filter rules for guards or firewalls. Organizations may perform dynamic reconfiguration of systems to stop attacks, misdirect attackers, and isolate components of systems, thus limiting the extent of the damage from breaches or compromises. Organizations should include specific time frames for achieving the reconfiguration of systems in the definition of the reconfiguration capability, considering the potential need for rapid response to effectively address cyber threats.",
          "Configuration management. Configuration change control | testing, validation, and documentation of changes. Test, validate, and document changes to the system before finalizing the implementation of the changes. Changes to systems include modifications to hardware, software, or firmware components and configuration settings defined in CM-6. Organizations ensure that testing does not interfere with system operations that support organizational mission and business functions. Individuals or groups conducting tests understand security and privacy policies and procedures, system security and privacy policies and procedures, and the health, safety, and environmental risks associated with specific facilities or processes. Operational systems may need to be taken offline, or replicated to the extent feasible, before testing can be conducted. If systems must be taken offline for testing, the tests are scheduled to occur during planned system outages whenever possible. If the testing cannot be conducted on operational systems, organizations employ compensating controls.",
          "Media protection. Media marking. a. Mark system media indicating the distribution limitations, handling caveats, and applicable security markings (if any) of the information; and b. Exempt [assignment: organization-defined types of system media] from marking if the media remain within [assignment: organization-defined controlled areas]. Security marking refers to the application or use of human-readable security attributes. Digital media includes diskettes, magnetic tapes, external or removable hard disk drives (e.g., solid state, magnetic), flash drives, compact discs, and digital versatile discs. Non-digital media includes paper and microfilm. Controlled Unclassified Information (CUI) is defined by the National Archives and Records Administration along with the appropriate safeguarding and dissemination requirements for such information and is codified in 32 CFR 2002. Security markings are generally not required for media that contains information determined by organizations to be in the public domain or to be publicly releasable. Some organizations may require markings for public information indicating that the information is publicly releasable. System media marking reflects applicable laws, executive orders, directives, policies, regulations, standards, and guidelines.",
          "Incident response. Incident monitoring. Track and document incidents. Documenting incidents includes maintaining records about each incident, the status of the incident, and other pertinent information necessary for forensics, as well as evaluating incident details, trends, and handling. Incident information can be obtained from a variety of sources, including network monitoring, incident reports, incident response teams, user complaints, supply chain partners, audit monitoring, physical access monitoring, and user and administrator reports. IR-4 provides information on the types of incidents that are appropriate for monitoring.",
          "Access control. Device lock. a. Prevent further access to the system by [selection (one or more): initiating a device lock after [assignment: organization-defined time period] of inactivity; requiring the user to initiate a device lock before leaving the system unattended]. \nb. Retain the device lock until the user reestablishes access using established identification and authentication procedures. Device locks are temporary actions taken to prevent logical access to organizational systems when users stop work and move away from the immediate vicinity of those systems but do not want to log out because of the temporary nature of their absences. Device locks can be implemented at the operating system level or at the application level. A proximity lock may be used to initiate the device lock (e.g., via a Bluetooth-enabled device or dongle). User-initiated device locking is behavior or policy-based and, as such, requires users to take physical action to initiate the device lock. Device locks are not an acceptable substitute for logging out of systems, such as when organizations require users to log out at the end of workdays.",
          "System and communications protection. System time synchronization | synchronization with authoritative time source. (a) Compare the internal system clocks. [Assignment: organization-defined frequency].  \n(b) Synchronize the internal system clocks to the authoritative time source when the time difference is greater than [Assignment: organization-defined time period]. \n\nSynchronization of internal system clocks with an authoritative source provides uniformity of timestamps for systems with multiple system clocks and systems connected over a network.",
          "Security assessment and authorization. Control assessments | specialized assessments. Include as part of control assessments, [assignment: organization-defined frequency]. [Selection: Announced; Unannounced]. [Selection (one or more): In-depth monitoring; Security instrumentation; Automated security test cases; Vulnerability scanning; Malicious user testing; Insider threat assessment; Performance and load testing; Data leakage or data loss assessment; [assignment: organization-defined other forms of assessment]]. Organizations can conduct specialized assessments, including verification and validation, system monitoring, insider threat assessments, malicious user testing, and other forms of testing. These assessments can improve readiness by exercising organizational capabilities and indicating current levels of performance as a means of focusing actions to improve security and privacy. Organizations conduct specialized assessments in accordance with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Authorizing officials approve the assessment methods in coordination with the organizational risk executive function. Organizations can include vulnerabilities uncovered during assessments into vulnerability remediation processes. Specialized assessments can also be conducted early in the system development life cycle (e.g., during initial design, development, and unit testing).",
          "System and information integrity. Software, firmware, and information integrity | code authentication. Implement cryptographic mechanisms to authenticate the following software or firmware components prior to installation: [assignment: organization-defined software or firmware components]. Cryptographic authentication includes verifying that software or firmware components have been digitally signed using certificates recognized and approved by organizations. Code signing is an effective method to protect against malicious code. Organizations that employ cryptographic mechanisms also consider cryptographic key management solutions.",
          "Contingency planning. Alternate processing site | accessibility. Identify potential accessibility problems to alternate processing sites in the event of an area-wide disruption or disaster and outline explicit mitigation actions. Area-wide disruptions refer to those types of disruptions that are broad in geographic scope, with such determinations made by organizations based on organizational assessments of risk.",
          "System and communications protection. Mobile code. a. Define acceptable and unacceptable mobile code and mobile code technologies; and b. Authorize, monitor, and control the use of mobile code within the system. Mobile code includes any program, application, or content that can be transmitted across a network (e.g., embedded in an email, document, or website) and executed on a remote system. Decisions regarding the use of mobile code within organizational systems are based on the potential for the code to cause damage to the systems if used maliciously. Mobile code technologies include Java applets, JavaScript, HTML5, WebGL, and VBScript. Usage restrictions and implementation guidelines apply to both the selection and use of mobile code installed on servers and mobile code downloaded and executed on individual workstations and devices, including notebook computers and smartphones. Mobile code policy and procedures address specific actions taken to prevent the development, acquisition, and introduction of unacceptable mobile code within organizational systems, including requiring mobile code to be digitally signed by a trusted source.",
          "System and communications protection. Boundary protection | external telecommunications services. (a) Implement a managed interface for each external telecommunication service. \n(b) Establish a traffic flow policy for each managed interface. \n(c) Protect the confidentiality and integrity of the information being transmitted across each interface. \n(d) Document each exception to the traffic flow policy with a supporting mission or business need and duration of that need. \n(e) Review exceptions to the traffic flow policy [assignment: organization-defined frequency] and remove exceptions that are no longer supported by an explicit mission or business need. \n(f) Prevent unauthorized exchange of control plane traffic with external networks. \n(g) Publish information to enable remote networks to detect unauthorized control plane traffic from internal networks. \n(h) Filter unauthorized control plane traffic from external networks. External telecommunication services can provide data and/or voice communications services. Examples of control plane traffic include Border Gateway Protocol (BGP) routing, Domain Name System (DNS), and management protocols. See SP 800-189 for additional information on the use of the Resource Public Key Infrastructure (RPKI) to protect BGP routes and detect unauthorized BGP announcements.",
          "Contingency planning. Alternate processing site | priority of service. Develop alternate processing site agreements that contain priority-of-service provisions in accordance with availability requirements (including recovery time objectives). Priority of service agreements refer to negotiated agreements with service providers that ensure organizations receive priority treatment consistent with their availability requirements and the availability of information resources for logical alternate processing and/or at the physical alternate processing site. Organizations establish recovery time objectives as part of contingency planning.",
          "Identification and authentication. Identification and authentication (organizational users) | multi-factor authentication to privileged accounts. Implement multi-factor authentication for access to privileged accounts. Multi-factor authentication requires the use of two or more different factors to achieve authentication. The authentication factors are defined as follows: something you know (e.g., a personal identification number [PIN]), something you have (e.g., a physical authenticator such as a cryptographic private key), or something you are (e.g., a biometric). \n\nMulti-factor authentication solutions that feature physical authenticators include hardware authenticators that provide time-based or challenge-response outputs and smart cards such as the U.S. government Personal Identity Verification (PIV) card or the Department of Defense (DoD) Common Access Card (CAC). In addition to authenticating users at the system level (i.e., at logon), organizations may employ authentication mechanisms at the application level, at their discretion, to provide increased security.\n\nRegardless of the type of access (i.e., local, network, remote), privileged accounts are authenticated using multi-factor options appropriate for the level of risk. Organizations can add additional security measures, such as additional or more rigorous authentication mechanisms, for specific types of access.",
          "System and communications protection. Protection of information at rest. Protect the confidentiality and integrity of the following information at rest: Organization-defined information at rest. Information at rest refers to the state of information when it is not in process or in transit and is located on system components. Such components include internal or external hard disk drives, storage area network devices, or databases. However, the focus of protecting information at rest is not on the type of storage device or frequency of access but rather on the state of the information. Information at rest addresses the confidentiality and integrity of information and covers user information and system information.\n\nSystem-related information that requires protection includes configurations or rule sets for firewalls, intrusion detection and prevention systems, filtering routers, and authentication information. Organizations may employ different mechanisms to achieve confidentiality and integrity protections, including the use of cryptographic mechanisms and file share scanning. Integrity protection can be achieved, for example, by implementing write-once-read-many (WORM) technologies. When adequate protection of information at rest cannot otherwise be achieved, organizations may employ other controls, including frequent scanning to identify malicious code at rest and secure offline storage in lieu of online storage.",
          "Configuration management. Least functionality. a. Configure the system to provide only [assignment: organization-defined mission essential capabilities]. \nb. Prohibit or restrict the use of the following functions, ports, protocols, software, and/or services: [assignment: organization-defined prohibited or restricted functions, system ports, protocols, software, and/or services].\n\nSystems provide a wide variety of functions and services. Some of the functions and services routinely provided by default may not be necessary to support essential organizational missions, functions, or operations. Additionally, it is sometimes convenient to provide multiple services from a single system component, but doing so increases risk over limiting the services provided by that single component.\n\nWhere feasible, organizations limit component functionality to a single function per component. Organizations consider removing unused or unnecessary software and disabling unused or unnecessary physical and logical ports and protocols to prevent unauthorized connection of components, transfer of information, and tunneling. Organizations employ network scanning tools, intrusion detection and prevention systems, and end-point protection technologies, such as firewalls and host-based intrusion detection systems, to identify and prevent the use of prohibited functions, protocols, ports, and services.\n\nLeast functionality can also be achieved as part of the fundamental design and development of the system (see SA-8, SC-2, and SC-3).",
          "System and information integrity. Security and privacy function verification. a. Verify the correct operation of [assignment: organization-defined security and privacy functions]. \nb. Perform the verification of the functions specified in si-6a. [Selection (one or more): [assignment: organization-defined system transitional states]; upon command by a user with appropriate privilege; [assignment: organization-defined frequency]].\nc. Alert [assignment: organization-defined personnel or roles] to failed security and privacy verification tests.\nd. [Selection (one or more): Shut the system down; restart the system; [assignment: organization-defined alternative action(s)]] when anomalies are discovered.\n\nTransitional states for systems include system startup, restart, shutdown, and abort. System notifications include hardware indicator lights, electronic alerts to system administrators, and messages to local computer consoles.\n\nIn contrast to security function verification, privacy function verification ensures that privacy functions operate as expected and are approved by the senior agency official for privacy or that privacy attributes are applied or used as expected.",
          "System and communications protection. Cryptographic key establishment and management | availability. Maintain availability of information in the event of the loss of cryptographic keys by users. Escrowing of encryption keys is a common practice for ensuring availability in the event of key loss. A forgotten passphrase is an example of losing a cryptographic key.",
          "Access control. Use of external systems | limits on authorized use. Permit authorized individuals to use an external system to access the system or to process, store, or transmit organization-controlled information only after: (a) verification of the implementation of controls on the external system as specified in the organization's security and privacy policies and security and privacy plans; or (b) retention of approved system connection or processing agreements with the organizational entity hosting the external system. Limiting authorized use recognizes circumstances where individuals using external systems may need to access organizational systems. Organizations need assurance that the external systems contain the necessary controls so as not to compromise, damage, or otherwise harm organizational systems. Verification that the required controls have been implemented can be achieved by external, independent assessments, attestations, or other means, depending on the confidence level required by organizations.",
          "Security assessment and authorization. Information exchange | transfer authorizations. Verify that individuals or systems transferring data between interconnecting systems have the requisite authorizations (i.e., write permissions or privileges) prior to accepting such data. To prevent unauthorized individuals and systems from making information transfers to protected systems, the protected system verifies - via independent means - whether the individual or system attempting to transfer information is authorized to do so. Verification of the authorization to transfer information also applies to control plane traffic (e.g., routing and DNS) and services (e.g., authenticated SMTP relays).",
          "System and information integrity. Software, firmware, and information integrity | integration of detection and response. Incorporate the detection of the following unauthorized changes into the organizational incident response capability: [assignment: organization-defined security-relevant changes to the system]. Integrating detection and response helps to ensure that detected events are tracked, monitored, corrected, and available for historical purposes. Maintaining historical records is important for being able to identify and discern adversary actions over an extended time period and for possible legal actions. Security-relevant changes include unauthorized changes to established configuration settings or the unauthorized elevation of system privileges.",
          "Contingency planning. System backup | test restoration using sampling. Use a sample of backup information in the restoration of selected system functions as part of contingency plan testing. Organizations need assurance that system functions can be restored correctly and can support established organizational missions. \n\nTo ensure that the selected system functions are thoroughly exercised during contingency plan testing, a sample of backup information is retrieved to determine whether the functions are operating as intended. \n\nOrganizations can determine the sample size for the functions and backup information based on the level of assurance needed.",
          "System and communications protection. Boundary protection | prevent exfiltration. (a) Prevent the exfiltration of information; and (b) conduct exfiltration tests [assignment: organization-defined frequency]. Prevention of exfiltration applies to both intentional and unintentional exfiltration of information. Techniques used to prevent the exfiltration of information from systems may be implemented at internal endpoints, external boundaries, and across managed interfaces. These techniques include adherence to protocol formats, monitoring for beaconing activity from systems, disconnecting external network interfaces except when explicitly needed, employing traffic profile analysis to detect deviations from the volume and types of traffic expected, call backs to command and control centers, conducting penetration testing, monitoring for steganography, disassembling and reassembling packet headers, and using data loss and data leakage prevention tools. Devices that enforce strict adherence to protocol formats include deep packet inspection firewalls and extensible markup language (XML) gateways. These devices verify adherence to protocol formats and specifications at the application layer and identify vulnerabilities that cannot be detected by devices that operate at the network or transport layers. The prevention of exfiltration is similar to data loss prevention or data leakage prevention and is closely associated with cross-domain solutions and system guards that enforce information flow requirements.",
          "Identification and authentication. Identification and authentication (organizational users) | multi-factor authentication to non-privileged accounts. Implement multi-factor authentication for access to non-privileged accounts. Multi-factor authentication requires the use of two or more different factors to achieve authentication. The authentication factors are defined as follows: something you know (e.g., a personal identification number [PIN]), something you have (e.g., a physical authenticator such as a cryptographic private key), or something you are (e.g., a biometric). \n\nMulti-factor authentication solutions that feature physical authenticators include hardware authenticators that provide time-based or challenge-response outputs and smart cards such as the U.S. government personal identity verification card or the DoD common access card. \n\nIn addition to authenticating users at the system level, organizations may also employ authentication mechanisms at the application level, at their discretion, to provide increased information security. Regardless of the type of access (i.e., local, network, remote), non-privileged accounts are authenticated using multi-factor options appropriate for the level of risk. \n\nOrganizations can provide additional security measures, such as additional or more rigorous authentication mechanisms, for specific types of access.",
          "System and information integrity. System monitoring | host-based devices. Implement the following host-based monitoring mechanisms at [assignment: organization-defined system components]: [assignment: organization-defined host-based monitoring mechanisms]. Host-based monitoring collects information about the host (or system in which it resides). System components in which host-based monitoring can be implemented include servers, notebook computers, and mobile devices. Organizations may consider employing host-based monitoring mechanisms from multiple product developers or vendors.",
          "Supply chain risk management family. Inspection of systems or components. Inspect the following systems or system components [selection (one or more): at random; at [assignment: organization-defined frequency], upon [assignment: organization-defined indications of need for inspection]] to detect tampering: [assignment: organization-defined systems or system components]. The inspection of systems or system components for tamper resistance and detection addresses physical and logical tampering and is applied to systems and system components removed from organization-controlled areas. Indications of a need for inspection include changes in packaging, specifications, factory location, or entity in which the part is purchased, and when individuals return from travel to high-risk locations.",
          "Configuration management. Impact analyses | verification of controls. After system changes, verify that the impacted controls are implemented correctly, operating as intended, and producing the desired outcome with regard to meeting the security and privacy requirements for the system. Implementation in this context refers to installing changed code in the operational system that may have an impact on security or privacy controls.",
          "System and information integrity. System monitoring. A. Monitor the system to detect:\n1. Attacks and indicators of potential attacks in accordance with the following monitoring objectives: [Assignment: organization-defined monitoring objectives].\n2. Unauthorized local, network, and remote connections.\n\nB. Identify unauthorized use of the system through the following techniques and methods: [Assignment: organization-defined techniques and methods].\n\nC. Invoke internal monitoring capabilities or deploy monitoring devices:\n1. Strategically within the system to collect organization-determined essential information.\n2. At ad hoc locations within the system to track specific types of transactions of interest to the organization.\n\nD. Analyze detected events and anomalies.\n\nE. Adjust the level of system monitoring activity when there is a change in risk to organizational operations and assets, individuals, other organizations, or the nation.\n\nF. Obtain a legal opinion regarding system monitoring activities.\n\nG. Provide [Assignment: organization-defined system monitoring information] to [Assignment: organization-defined personnel or roles] [Selection (one or more): as needed; [Assignment: organization-defined frequency]].\n\nSystem monitoring includes external and internal monitoring. External monitoring includes the observation of events occurring at external interfaces to the system. Internal monitoring includes the observation of events occurring within the system. Organizations monitor systems by observing audit activities in real-time or by observing other system aspects such as access patterns, characteristics of access, and other actions. The monitoring objectives guide and inform the determination of the events.\n\nSystem monitoring capabilities are achieved through a variety of tools and techniques, including intrusion detection and prevention systems, malicious code protection software, scanning tools, audit record monitoring software, and network monitoring software. Depending on the security architecture, the distribution and configuration of monitoring devices may impact throughput at key internal and external boundaries as well as at other locations across a network due to the introduction of network throughput latency. If throughput management is needed, such devices are strategically located and deployed as part of an established organization-wide security architecture. Strategic locations for monitoring devices include selected perimeter locations and near key servers and server farms that support critical applications. Monitoring devices are typically employed at the managed interfaces associated with controls SC-7 and AC-17.\n\nThe information collected is a function of the organizational monitoring objectives and the capability of systems to support such objectives. Specific types of transactions of interest include Hypertext Transfer Protocol (HTTP) traffic that bypasses HTTP proxies. System monitoring is an integral part of organizational continuous monitoring and incident response programs, and output from system monitoring serves as input to those programs.\n\nSystem monitoring requirements, including the need for specific types of system monitoring, may be referenced in other controls (e.g., AC-2g, AC-2 (7), AC-2 (12) (a), AC-17 (1), AU-13, AU-13 (1), AU-13 (2), CM-3f, CM-6d, MA-3a, MA-4a, SC-5 (3) (b), SC-7a, SC-7 (24) (b), SC-18b, SC-43b). Adjustments to levels of system monitoring are based on law enforcement information, intelligence information, or other sources of information.\n\nThe legality of system monitoring activities is based on applicable laws, executive orders, directives, regulations, policies, standards, and guidelines.",
          "Identification and authentication. Identification and authentication (non-organizational users). Uniquely identify and authenticate non-organizational users or processes acting on behalf of non-organizational users. Non-organizational users include system users other than organizational users explicitly covered by IA-2. Non-organizational users are uniquely identified and authenticated for accesses other than those explicitly identified and documented in AC-14. Identification and authentication of non-organizational users accessing federal systems may be required to protect federal, proprietary, or privacy-related information (with exceptions noted for national security systems).\n\nOrganizations consider many factors – including security, privacy, scalability, and practicality – when balancing the need to ensure ease of use for access to federal information and systems with the need to protect and adequately mitigate risk.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "3_and_of_the",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "3_and_of_the"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          8.590103149414062,
          9.388113021850586,
          8.718092918395996,
          8.506542205810547,
          8.995674133300781,
          8.618535041809082,
          8.775341033935547,
          9.151071548461914,
          8.171541213989258,
          8.190810203552246,
          8.89806842803955,
          9.25512409210205,
          8.699479103088379,
          8.966900825500488,
          9.22960090637207,
          8.63099479675293,
          8.658367156982422,
          9.485932350158691,
          9.162612915039062,
          9.178544044494629,
          8.573213577270508,
          8.543000221252441,
          8.49796199798584,
          8.419573783874512,
          9.108988761901855,
          9.541739463806152,
          8.778115272521973,
          9.342711448669434,
          8.906537055969238,
          9.14127254486084,
          9.295510292053223,
          8.817384719848633,
          8.534219741821289,
          9.805641174316406,
          8.677420616149902,
          8.750046730041504,
          8.344464302062988,
          8.51187515258789,
          9.138565063476562,
          8.599534034729004,
          8.548585891723633,
          8.56545639038086,
          9.537894248962402,
          7.965007781982422,
          8.722536087036133,
          9.293928146362305,
          9.49044418334961,
          8.242486953735352,
          8.893948554992676,
          8.96339225769043,
          8.856457710266113
         ],
         "y": [
          6.878695011138916,
          6.753416061401367,
          6.734012603759766,
          7.2702107429504395,
          7.614005088806152,
          7.193661212921143,
          6.713754177093506,
          7.545133590698242,
          7.42270040512085,
          6.953901290893555,
          6.614383220672607,
          7.435398578643799,
          7.7457804679870605,
          6.856729984283447,
          7.205946445465088,
          7.140892505645752,
          7.551512718200684,
          7.421236515045166,
          7.772249221801758,
          7.1486334800720215,
          6.936097621917725,
          6.869762420654297,
          7.496157169342041,
          7.488683700561523,
          7.6035237312316895,
          6.77260684967041,
          7.704648494720459,
          6.845179080963135,
          7.697448253631592,
          7.666213035583496,
          6.425282001495361,
          7.634327411651611,
          7.125762462615967,
          6.968886852264404,
          7.773719310760498,
          7.804479122161865,
          7.506827354431152,
          7.877782821655273,
          6.350473880767822,
          6.817863464355469,
          7.252464294433594,
          7.088747978210449,
          6.76041316986084,
          7.32454252243042,
          7.764920234680176,
          6.98149299621582,
          7.340899467468262,
          6.902570724487305,
          6.637447357177734,
          6.664646148681641,
          7.201122283935547
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Contingency planning. System backup | transfer to alternate storage site. Transfer system backup information to the alternate storage site. [Assignment: Organization-defined time period and transfer rate consistent with the recovery time and recovery point objectives.] System backup information can be transferred to alternate storage sites either electronically or by the physical shipment of storage media.",
          "Configuration management. Configuration settings. A. Establish and document configuration settings for components employed within the system that reflect the most restrictive mode consistent with operational requirements using [assignment: organization-defined common secure configurations].\nB. Implement the configuration settings.\nC. Identify, document, and approve any deviations from established configuration settings for [assignment: organization-defined system components] based on [assignment: organization-defined operational requirements].\nD. Monitor and control changes to the configuration settings in accordance with organizational policies and procedures.\n\nConfiguration settings are the parameters that can be changed in the hardware, software, or firmware components of the system that affect the security and privacy posture or functionality of the system. Information technology products for which configuration settings can be defined include mainframe computers, servers, workstations, operating systems, mobile devices, input/output devices, protocols, and applications. Parameters that impact the security posture of systems include registry settings; account, file, or directory permission settings; and settings for functions, protocols, ports, services, and remote connections. Privacy parameters are parameters impacting the privacy posture of systems, including the parameters required to satisfy other privacy controls. Privacy parameters include settings for access controls, data processing preferences, and processing and retention permissions.\n\nOrganizations establish organization-wide configuration settings and subsequently derive specific configuration settings for systems. The established settings become part of the configuration baseline for the system. Common secure configurations (also known as security configuration checklists, lockdown and hardening guides, and security reference guides) provide recognized, standardized, and established benchmarks that stipulate secure configuration settings for information technology products and platforms as well as instructions for configuring those products or platforms to meet operational requirements. Common secure configurations can be developed by a variety of organizations, including information technology product developers, manufacturers, vendors, federal agencies, consortia, academia, industry, and other organizations in the public and private sectors.\n\nImplementation of a common secure configuration may be mandated at the organization level, mission and business process level, system level, or at a higher level, including by a regulatory agency. Common secure configurations include the United States Government Configuration Baseline (USGCB) and Security Technical Implementation Guides (STIGs), which affect the implementation of CM-6 and other controls such as AC-19 and CM-7. The Security Content Automation Protocol (SCAP) and the defined standards within the protocol provide an effective method to uniquely identify, track, and control configuration settings.",
          "Maintenance. Maintenance tools. a. Approve, control, and monitor the use of system maintenance tools; and b. Review previously approved system maintenance tools [assignment: organization-defined frequency]. Approving, controlling, monitoring, and reviewing maintenance tools address security-related issues associated with maintenance tools that are not within system authorization boundaries and are used specifically for diagnostic and repair actions on organizational systems. Organizations have flexibility in determining roles for the approval of maintenance tools and how that approval is documented. A periodic review of maintenance tools facilitates the withdrawal of approval for outdated, unsupported, irrelevant, or no-longer-used tools. Maintenance tools can include hardware, software, and firmware items and may be pre-installed, brought in with maintenance personnel on media, cloud-based or downloaded from a website. Such tools can be vehicles for transporting malicious code, either intentionally or unintentionally, into a facility and subsequently into systems. Maintenance tools can include hardware and software diagnostic test equipment and packet sniffers. The hardware and software components that support maintenance and are part of the system (including the software implementing utilities such as ping, ls, ipconfig, or the hardware and software implementing the monitoring port of an Ethernet switch) are not addressed by maintenance tools.",
          "Configuration management. Signed components. Prevent the installation of [assignment: organization-defined software and firmware components] without verification that the component has been digitally signed using a certificate that is recognized and approved by the organization. Software and firmware components should not be installed unless signed with recognized and approved certificates. These components include software and firmware version updates, patches, service packs, device drivers, and basic input/output system updates. Organizations can identify applicable software and firmware components by type, specific items, or a combination of both. Digital signatures and organizational verification of such signatures are methods of code authentication.",
          "Access control. Least privilege | privileged accounts. Restrict privileged accounts on the system to [assignment: organization-defined personnel or roles]. Privileged accounts, including super user accounts, are typically described as a system administrator for various types of commercial off-the-shelf operating systems. Restricting privileged accounts to specific personnel or roles prevents day-to-day users from accessing privileged information or privileged functions. Organizations may differentiate in the application of restricting privileged accounts between allowed privileges for local accounts and for domain accounts, provided that they retain the ability to control system configurations for key parameters and as otherwise necessary to sufficiently mitigate risk.",
          "System and services acquisition. Acquisition process | functional properties of controls. Require the developer of the system, system component, or system service to provide a description of the functional properties of the controls to be implemented. Functional properties of security and privacy controls describe the functionality (i.e., security or privacy capability, functions, or mechanisms) visible at the interfaces of the controls and specifically exclude functionality and data structures internal to the operation of the controls.",
          "Identification and authentication. Device identification and authentication. Uniquely identify and authenticate [assignment: organization-defined devices and/or types of devices] before establishing a [selection (one or more): local; remote; network] connection. Devices that require unique device-to-device identification and authentication are defined by type, device, or a combination of type and device. Organization-defined device types include devices that are not owned by the organization. Systems use shared known information (e.g., media access control [MAC], Transmission Control Protocol/Internet Protocol [TCP/IP] addresses) for device identification or organizational authentication solutions (e.g., Institute of Electrical and Electronics Engineers (IEEE) 802.1X and Extensible Authentication Protocol [EAP], RADIUS server with EAP-Transport Layer Security [TLS] authentication, Kerberos) to identify and authenticate devices on local and wide area networks. Organizations determine the required strength of authentication mechanisms based on the security categories of systems and mission or business requirements. Because of the challenges of implementing device authentication on a large scale, organizations can restrict the application of the control to a limited number/type of devices based on mission or business needs.",
          "Configuration management. Information location. A. Identify and document the location of [assignment: organization-defined information] and the specific system components on which the information is processed and stored.\nB. Identify and document the users who have access to the system and system components where the information is processed and stored.\nC. Document changes to the location (i.e., system or system components) where the information is processed and stored.\n\nInformation location addresses the need to understand where information is being processed and stored. Information location includes identifying where specific information types and information reside in system components and how information is being processed so that information flow can be understood and adequate protection and policy management provided for such information and system components. The security category of the information is also a factor in determining the controls necessary to protect the information and the system component where the information resides (see FIPS 199). The location of the information and system components is also a factor in the architecture and design of the system (see SA-4, SA-8, SA-17).",
          "Configuration management. Baseline configuration. a. Develop, document, and maintain under configuration control a current baseline configuration of the system. \n\nb. Review and update the baseline configuration of the system as follows:\n1. [Assignment: organization-defined frequency].\n2. When required due to [Assignment: organization-defined circumstances].\n3. When system components are installed or upgraded.\n\nBaseline configurations for systems and system components include connectivity, operational, and communications aspects of systems. Baseline configurations are documented, formally reviewed, and agreed-upon specifications for systems or configuration items within those systems. Baseline configurations serve as a basis for future builds, releases, or changes to systems and include security and privacy control implementations, operational procedures, information about system components, network topology, and logical placement of components in the system architecture. \n\nMaintaining baseline configurations requires creating new baselines as organizational systems change over time. Baseline configurations of systems reflect the current enterprise architecture.",
          "Audit and accountability. Time stamps. a. Use internal system clocks to generate time stamps for audit records; and b. Record time stamps for audit records that meet [assignment: organization-defined granularity of time measurement] and that use Coordinated Universal Time, have a fixed local time offset from Coordinated Universal Time, or that include the local time offset as part of the time stamp. Time stamps generated by the system include date and time. Time is commonly expressed in Coordinated Universal Time (UTC), a modern continuation of Greenwich Mean Time (GMT), or local time with an offset from UTC. Granularity of time measurements refers to the degree of synchronization between system clocks and reference clocks (e.g., clocks synchronizing within hundreds of milliseconds or tens of milliseconds). Organizations may define different time granularities for different system components. Time service can be critical to other security capabilities such as access control and identification and authentication, depending on the nature of the mechanisms used to support those capabilities.",
          "System and services acquisition. Development process, standards, and tools | criticality analysis. Require the developer of the system, system component, or system service to perform a criticality analysis: (a) at the following decision points in the system development life cycle: [assignment: organization-defined decision points in the system development life cycle]; and (b) at the following level of rigor: [assignment: organization-defined breadth and depth of criticality analysis]. Criticality analysis performed by the developer provides input to the criticality analysis performed by organizations. Developer input is essential to organizational criticality analysis because organizations may not have access to detailed design documentation for system components that are developed as commercial off-the-shelf products. Such design documentation includes functional specifications, high-level designs, low-level designs, source code, and hardware schematics. Criticality analysis is important for organizational systems that are designated as high-value assets. High-value assets can be moderate or high-impact systems due to heightened adversarial interest or potential adverse effects on the federal enterprise. Developer input is especially important when organizations conduct supply chain criticality analyses.",
          "Contingency planning. Contingency plan | identify critical assets. Identify critical system assets supporting [SELECTION: all; essential] mission and business functions. Organizations may choose to identify critical assets as part of a criticality analysis, business continuity planning, or business impact analyses. Organizations identify critical system assets so that additional controls can be employed (beyond the controls routinely implemented) to help ensure that organizational mission and business functions can continue to be conducted during contingency operations. The identification of critical information assets also facilitates the prioritization of organizational resources. Critical system assets include technical and operational aspects. Technical aspects include system components, information technology services, information technology products, and mechanisms. Operational aspects include procedures (i.e., manually executed operations) and personnel (i.e., individuals operating technical controls and/or executing manual procedures). Organizational program protection plans can assist in identifying critical assets. If critical assets are resident within or supported by external service providers, organizations consider implementing CP-2 (7) as a control enhancement.",
          "Audit and accountability. Non-repudiation. Provide irrefutable evidence that an individual (or process acting on behalf of an individual) has performed [assignment: organization-defined actions to be covered by non-repudiation]. Types of individual actions covered by non-repudiation include creating information, sending and receiving messages, and approving information. Non-repudiation protects against claims by authors of not having authored certain documents, senders of not having transmitted messages, receivers of not having received messages, and signatories of not having signed documents. Non-repudiation services can be used to determine if information originated from an individual or if an individual took specific actions (e.g., sending an email, signing a contract, approving a procurement request, or receiving specific information). Organizations obtain non-repudiation services by employing various techniques or mechanisms, including digital signatures and digital message receipts.",
          "Identification and authentication. Authenticator management | expiration of cached authenticators. Prohibit the use of cached authenticators after [assignment: organization-defined time period]. Cached authenticators are used to authenticate to the local machine when the network is not available. If cached authentication information is out of date, the validity of the authentication information may be questionable.",
          "Operations (ops). Logging and monitoring – access, storage and deletion. Basic criterion: The requirements for the logging and monitoring of events and for the secure handling of metadata are implemented by technically supported procedures with regard to the following restrictions: access only for authorized users and systems; retention for the specified period; and deletion when further retention is no longer necessary for the purpose of collection.\n\nNotes on continuous auditing feasibility: No, a continuous check is only of limited use here, since the primary purpose of checking the handling of metadata is to check the guidelines and the associated configurations of the tools for securing, processing, and deleting metadata. In addition, the contractual basis for the use of metadata may also need to be considered. A continuous audit could include the configuration for deleting or anonymizing the metadata and automatically recording whether the configuration still exists and is implemented correctly. In this case, there would be a partial possibility for continuous auditing.",
          "System and communications protection. Boundary protection | route traffic to authenticated proxy servers. Route [assignment: organization-defined internal communications traffic] to [assignment: organization-defined external networks] through authenticated proxy servers at managed interfaces. External networks are networks outside of organizational control. A proxy server is a server (i.e., system or application) that acts as an intermediary for clients requesting system resources from non-organizational or other organizational servers. System resources that may be requested include files, connections, web pages, or services. Client requests established through a connection to a proxy server are assessed to manage complexity and provide additional protection by limiting direct connectivity. Web content filtering devices are one of the most common proxy servers that provide access to the internet. Proxy servers can support the logging of Transmission Control Protocol (TCP) sessions and the blocking of specific Uniform Resource Locators (URLs), Internet Protocol (IP) addresses, and domain names. Web proxies can be configured with organization-defined lists of authorized and unauthorized websites. Note that proxy servers may inhibit the use of virtual private networks (VPNs) and create the potential for man-in-the-middle attacks (depending on the implementation).",
          "Awareness and training. Training records. a. Document and monitor information security and privacy training activities, including security and privacy awareness training and specific role-based security and privacy training. \n\nb. Retain individual training records for [assignment: organization-defined time period]. \n\nDocumentation for specialized training may be maintained by individual supervisors at the discretion of the organization. \n\nThe National Archives and Records Administration provides guidance on records retention for federal agencies.",
          "System and information integrity. Flaw remediation | automated flaw remediation status. Determine if system components have applicable security-relevant software and firmware updates installed using [assignment: organization-defined automated mechanisms]. [Assignment: Organization-defined frequency]. Automated mechanisms can track and determine the status of known flaws for system components.",
          "System and services acquisition. Acquisition process. Include the following requirements, descriptions, and criteria, explicitly or by reference, using standardized contract language in the acquisition contract for the system, system component, or system service:\n\na. Security and privacy functional requirements.\nb. Strength of mechanism requirements.\nc. Security and privacy assurance requirements.\nd. Controls needed to satisfy the security and privacy requirements.\ne. Security and privacy documentation requirements.\nf. Requirements for protecting security and privacy documentation.\ng. Description of the system development environment and environment in which the system is intended to operate.\nh. Allocation of responsibility or identification of parties responsible for information security, privacy, and supply chain risk management.\ni. Acceptance criteria.\n\nSecurity and privacy functional requirements are typically derived from the high-level security and privacy requirements described in SA-2. The derived requirements include security and privacy capabilities, functions, and mechanisms. Strength requirements associated with such capabilities, functions, and mechanisms include the degree of correctness, completeness, resistance to tampering or bypass, and resistance to direct attack. Assurance requirements include development processes, procedures, and methodologies, as well as the evidence from development and assessment activities that provide grounds for confidence that the required functionality is implemented and possesses the required strength of the mechanism. SP 800-160-1 describes the process of requirements engineering as part of the system development life cycle.\n\nControls can be viewed as descriptions of the safeguards and protection capabilities appropriate for achieving the particular security and privacy objectives of the organization and for reflecting the security and privacy requirements of stakeholders. Controls are selected and implemented to satisfy system requirements and include developer and organizational responsibilities. Controls can include technical, administrative, and physical aspects. In some cases, the selection and implementation of a control may necessitate additional specification by the organization in the form of derived requirements or instantiated control parameter values. The derived requirements and control parameter values may be necessary to provide the appropriate level of implementation detail for controls within the system development life cycle.\n\nSecurity and privacy documentation requirements address all stages of the system development life cycle. Documentation provides user and administrator guidance for the implementation and operation of controls. The level of detail required in such documentation is based on the security categorization or classification level of the system and the degree to which organizations depend on the capabilities, functions, or mechanisms to meet risk response expectations. Requirements can include mandated configuration settings that specify allowed functions, ports, protocols, and services. Acceptance criteria for systems, system components, and system services are defined in the same manner as the criteria for any organizational acquisition or procurement.",
          "Physical and environmental protection. Delivery and removal. a. Authorize and control [assignment: organization-defined types of system components] entering and exiting the facility; and b. Maintain records of the system components. Enforcing authorizations for entry and exit of system components may require restricting access to delivery areas and isolating the areas from the system and media libraries.",
          "Configuration management. Impact analyses | separate test environments. Analyze changes to the system in a separate test environment before implementation in an operational environment, looking for security and privacy impacts due to flaws, weaknesses, incompatibility, or intentional malice. A separate test environment requires an environment that is physically or logically separate and distinct from the operational environment. The separation is sufficient to ensure that activities in the test environment do not impact activities in the operational environment and that information in the operational environment is not inadvertently transmitted to the test environment. Separate environments can be achieved by physical or logical means. If physically separate test environments are not implemented, organizations determine the strength of the mechanism required when implementing logical separation.",
          "System and communications protection. Boundary protection | dynamic isolation and segregation. Provide the capability to dynamically isolate [assignment: organization-defined system components] from other system components. The capability to dynamically isolate certain internal system components is useful when it is necessary to partition or separate system components of questionable origin from components that possess greater trustworthiness. Component isolation reduces the attack surface of organizational systems. Isolating selected system components can also limit the damage from successful attacks when such attacks occur.",
          "Media protection. Media storage. A. Physically control and securely store [assignment: organization-defined types of digital and/or non-digital media] within [assignment: organization-defined controlled areas]. \nB. Protect system media types defined in MP-4A until the media are destroyed or sanitized using approved equipment, techniques, and procedures. System media includes digital and non-digital media. Digital media includes flash drives, diskettes, magnetic tapes, external or removable hard disk drives (e.g., solid state, magnetic), compact discs, and digital versatile discs. Non-digital media includes paper and microfilm. \nPhysically controlling stored media includes conducting inventories, ensuring procedures are in place to allow individuals to check out and return media to the library, and maintaining accountability for stored media. \nSecure storage includes a locked drawer, desk, or cabinet or a controlled media library. The type of media storage is commensurate with the security category or classification of the information on the media. \nControlled areas are spaces that provide physical and procedural controls to meet the requirements established for protecting information and systems. Fewer controls may be needed for media that contains information determined to be in the public domain, publicly releasable, or have limited adverse impacts on organizations, operations, or individuals if accessed by other than authorized personnel. In these situations, physical access controls provide adequate protection.",
          "Access control. Access enforcement. Enforce approved authorizations for logical access to information and system resources in accordance with applicable access control policies. Access control policies control access between active entities or subjects (i.e., users or processes acting on behalf of users) and passive entities or objects (i.e., devices, files, records, domains) in organizational systems. In addition to enforcing authorized access at the system level and recognizing that systems can host many applications and services in support of mission and business functions, access enforcement mechanisms can also be employed at the application and service level to provide increased information security and privacy. In contrast to logical access controls that are implemented within the system, physical access controls are addressed by the controls in the Physical and Environmental Protection (PE) family.",
          "System and communications protection. Boundary protection | fail secure. Prevent systems from entering insecure states in the event of an operational failure of a boundary protection device. Fail-secure is a condition achieved by employing mechanisms to ensure that, in the event of operational failures of boundary protection devices at managed interfaces, systems do not enter unsecure states where intended security properties no longer hold. Managed interfaces include routers, firewalls, and application gateways that reside on protected subnetworks (commonly referred to as demilitarized zones). Failures of boundary protection devices cannot lead to or cause information external to the devices to enter the devices, nor can failures permit unauthorized information releases.",
          "System and services acquisition. Acquisition process | design and implementation information for controls. Require the developer of the system, system component, or system service to provide design and implementation information for the controls that includes: [selection (one or more): security-relevant external system interfaces; high-level design; low-level design; source code or hardware schematics; [assignment: organization-defined design and implementation information]] at [assignment: organization-defined level of detail]. Organizations may require different levels of detail in the documentation for the design and implementation of controls in organizational systems, system components, or system services based on mission and business requirements, requirements for resiliency and trustworthiness, and requirements for analysis and testing. Systems can be partitioned into multiple subsystems. Each subsystem within the system can contain one or more modules. The high-level design for the system is expressed in terms of subsystems and the interfaces between subsystems providing security-relevant functionality. The low-level design for the system is expressed in terms of modules and the interfaces between modules providing security-relevant functionality. Design and implementation documentation can include manufacturer, version, serial number, verification hash signature, software libraries used, date of purchase or download, and the vendor or download source. Source code and hardware schematics are referred to as the implementation representation of the system.",
          "Identification and authentication. Identification and authentication (organizational users) | access to accounts —separate device. Implement multi-factor authentication for [selection (one or more): local; network; remote] access to [selection (one or more): privileged accounts; non-privileged accounts]. Ensure that: \n(a) one of the factors is provided by a device separate from the system gaining access; and \n(b) the device meets [assignment: organization-defined strength of mechanism requirements]. \n\nThe purpose of requiring a device that is separate from the system to which the user is attempting to gain access for one of the factors during multi-factor authentication is to reduce the likelihood of compromising authenticators or credentials stored on the system. Adversaries may be able to compromise such authenticators or credentials and subsequently impersonate authorized users. Implementing one of the factors on a separate device (e.g., a hardware token) provides a greater strength of mechanism and an increased level of assurance in the authentication process.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "4_and_the_system",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "4_and_the_system"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          7.378952980041504,
          7.452214241027832,
          7.15250301361084,
          7.379349708557129,
          7.331433296203613,
          7.351921558380127,
          7.075958251953125,
          7.2334113121032715,
          7.393858909606934,
          7.032440185546875,
          7.5726318359375,
          7.423788070678711,
          7.345486164093018,
          7.433244228363037,
          7.400285243988037,
          7.528531074523926,
          7.3922438621521,
          7.2778849601745605,
          7.152300834655762,
          7.284757614135742,
          7.419235706329346,
          7.410729885101318,
          7.148396015167236,
          7.183862209320068,
          7.422628879547119,
          7.202152729034424,
          7.426090717315674,
          7.3261590003967285
         ],
         "y": [
          6.984966278076172,
          7.855653285980225,
          7.7183709144592285,
          7.745065689086914,
          7.722984313964844,
          7.163640975952148,
          7.900961399078369,
          7.289067268371582,
          7.588577747344971,
          7.454041004180908,
          7.375581741333008,
          7.7872514724731445,
          7.848271369934082,
          6.993288516998291,
          7.0336503982543945,
          7.397063732147217,
          7.94394588470459,
          7.067375659942627,
          7.7639923095703125,
          7.046305179595947,
          7.1563239097595215,
          7.031123161315918,
          7.66758918762207,
          7.78991174697876,
          7.2599968910217285,
          7.341585636138916,
          7.02538537979126,
          7.442666053771973
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "System and services acquisition. Developer testing and evaluation. Require the developer of the system, system component, or system service, at all post-design stages of the system development life cycle, to: a. develop and implement a plan for ongoing security and privacy control assessments; b. perform [selection (one or more): unit; integration; system; regression] testing/evaluation [assignment: organization-defined frequency] at [assignment: organization-defined depth and coverage]; c. produce evidence of the execution of the assessment plan and the results of the testing and evaluation; d. implement a verifiable flaw remediation process; and e. correct flaws identified during testing and evaluation. Developmental testing and evaluation confirms that the required controls are implemented correctly, operating as intended, enforcing the desired security and privacy policies, and meeting established security and privacy requirements. Security properties of systems and the privacy of individuals may be affected by the interconnection of system components or changes to those components. The interconnections or changes—including upgrading or replacing applications, operating systems, and firmware—may adversely affect previously implemented controls. Ongoing assessment during development allows for additional types of testing and evaluation that developers can conduct to reduce or eliminate potential flaws. Testing custom software applications may require approaches such as manual code review, security architecture review, and penetration testing, as well as static analysis, dynamic analysis, binary analysis, or a hybrid of the three analysis approaches. Developers can use the analysis approaches, along with security instrumentation and fuzzing, in a variety of tools and in source code reviews. The security and privacy assessment plans include the specific activities that developers plan to carry out, including the types of analyses, testing, evaluation, and reviews of software and firmware components; the degree of rigor to be applied; the frequency of the ongoing testing and evaluation; and the types of artifacts produced during those processes. The depth of testing and evaluation refers to the rigor and level of detail associated with the assessment process. The coverage of testing and evaluation refers to the scope (i.e., number and type) of the artifacts included in the assessment process. Contracts specify the acceptance criteria for security and privacy assessment plans, flaw remediation processes, and the evidence that the plans and processes have been diligently applied. Methods for reviewing and protecting assessment plans, evidence, and documentation are commensurate with the security category or classification level of the system. Contracts may specify protection requirements for documentation.",
          "Security assessment and authorization. Penetration testing | independent penetration testing agent or team. Employ an independent penetration testing agent or team to perform penetration testing on the system or system components. Independent penetration testing agents or teams are individuals or groups who conduct impartial penetration testing of organizational systems. Impartiality implies that penetration testing agents or teams are free from perceived or actual conflicts of interest with respect to the development, operation, or management of the systems that are the targets of the penetration testing. CA-2 (1) provides additional information on independent assessments that can be applied to penetration testing.",
          "Access control. Separation of duties. A. Identify and document [Assignment: organization-defined duties of individuals requiring separation]. \n\nB. Define system access authorizations to support separation of duties. Separation of duties addresses the potential for abuse of authorized privileges and helps to reduce the risk of malevolent activity without collusion. Separation of duties includes dividing mission or business functions and support functions among different individuals or roles. It also involves conducting system support functions with different individuals and ensuring that security personnel who administer access control functions do not also administer audit functions. \n\nBecause separation of duty violations can span systems and application domains, organizations consider the entirety of systems and system components when developing policy on separation of duties. Separation of duties is enforced through the account management activities in AC-2, access control mechanisms in AC-3, and identity management activities in IA-2, IA-4, and IA-12.",
          "Security assessment and authorization. Authorization. a. Assign a senior official as the authorizing official for the system. \nb. Assign a senior official as the authorizing official for common controls available for inheritance by organizational systems. \nc. Ensure that the authorizing official for the system, before commencing operations: \n   1. Accepts the use of common controls inherited by the system. \n   2. Authorizes the system to operate. \nd. Ensure that the authorizing official for common controls authorizes the use of those controls for inheritance by organizational systems. \ne. Update the authorizations [assignment: organization-defined frequency]. Authorizations are official management decisions by senior officials to authorize the operation of systems, authorize the use of common controls for inheritance by organizational systems, and explicitly accept the risk to organizational operations and assets, individuals, other organizations, and the nation based on the implementation of agreed-upon controls. \nAuthorizing officials provide budgetary oversight for organizational systems and common controls or assume responsibility for the mission and business functions supported by those systems or common controls. The authorization process is a federal responsibility, and therefore, authorizing officials must be federal employees. \nAuthorizing officials are both responsible and accountable for security and privacy risks associated with the operation and use of organizational systems. Nonfederal organizations may have similar processes to authorize systems and senior officials that assume the authorization role and associated responsibilities. \nAuthorizing officials issue ongoing authorizations of systems based on evidence produced from implemented continuous monitoring programs. Robust continuous monitoring programs reduce the need for separate reauthorization processes. Through the employment of comprehensive continuous monitoring processes, the information contained in authorization packages (i.e., security and privacy plans, assessment reports, and plans of action and milestones) is updated on an ongoing basis. This provides authorizing officials, common control providers, and system owners with an up-to-date status of the security and privacy posture of their systems, controls, and operating environments. To reduce the cost of reauthorization, authorizing officials can leverage the results of continuous monitoring processes to the maximum extent possible as the basis for rendering reauthorization decisions.",
          "Contingency planning. Contingency plan testing | coordinate with related plans. Coordinate contingency plan testing with organizational elements responsible for related plans. Plans related to contingency planning for organizational systems include:\n\n1. Business continuity plans\n2. Disaster recovery plans\n3. Continuity of operations plans\n4. Crisis communications plans\n5. Critical infrastructure plans\n6. Cyber incident response plans\n7. Occupant emergency plans \n\nCoordination of contingency plan testing does not require organizations to create organizational elements to handle related plans or to align such elements with specific plans. However, it does require that if such organizational elements are responsible for related plans, organizations coordinate with those elements.",
          "Contingency planning. Telecommunications services | separation of primary and alternate providers. Obtain alternate telecommunications services from providers that are separated from primary service providers to reduce susceptibility to the same threats. Threats that affect telecommunications services are defined in organizational assessments of risk and include natural disasters, structural failures, cyber or physical attacks, and errors of omission or commission. Organizations can reduce common susceptibilities by minimizing shared infrastructure among telecommunications service providers and achieving sufficient geographic separation between services. Organizations may consider using a single service provider in situations where the service provider can provide alternate telecommunications services that meet the separation needs addressed in the risk assessment.",
          "Identification and authentication. Authenticator management | public key-based authentication. (a) For public key-based authentication: (1) Enforce authorized access to the corresponding private key. (2) Map the authenticated identity to the account of the individual or group. (b) When Public Key Infrastructure (PKI) is used: (1) Validate certificates by constructing and verifying a certification path to an accepted trust anchor, including checking certificate status information. (2) Implement a local cache of revocation data to support path discovery and validation. Public key cryptography is a valid authentication mechanism for individuals, machines, and devices. For PKI solutions, status information for certification paths includes certificate revocation lists or certificate status protocol responses. For PIV cards, certificate validation involves the construction and verification of a certification path to the Common Policy root trust anchor, which includes certificate policy processing. Implementing a local cache of revocation data to support path discovery and validation also supports system availability in situations where organizations are unable to access revocation information via the network.",
          "Access control. Least privilege | non-privileged access for nonsecurity functions. Require that users of system accounts (or roles) with access to [assignment: organization-defined security functions or security-relevant information] use non-privileged accounts or roles when accessing non-security functions. Requiring the use of non-privileged accounts when accessing non-security functions limits exposure when operating from within privileged accounts or roles. The inclusion of roles addresses situations where organizations implement access control policies, such as role-based access control, and where a change of role provides the same degree of assurance in the change of access authorizations for the user and the processes acting on behalf of the user as would be provided by a change between a privileged and non-privileged account.",
          "Identification and authentication. Identifier management. Manage system identifiers by: a. receiving authorization from [assignment: organization-defined personnel or roles] to assign an individual, group, role, service, or device identifier; b. selecting an identifier that identifies an individual, group, role, service, or device; c. assigning the identifier to the intended individual, group, role, service, or device; and d. preventing reuse of identifiers for [assignment: organization-defined time period]. Common device identifiers include Media Access Control (MAC) addresses, Internet Protocol (IP) addresses, or device-unique token identifiers. The management of individual identifiers is not applicable to shared system accounts. Typically, individual identifiers are the usernames of the system accounts assigned to those individuals. In such instances, the account management activities of AC-2 use account names provided by IA-4. Identifier management also addresses individual identifiers not necessarily associated with system accounts. Preventing the reuse of identifiers implies preventing the assignment of previously used individual, group, role, service, or device identifiers to different individuals, groups, roles, services, or devices.",
          "Identification and authentication. Identifier management | identify user status. Manage individual identifiers by uniquely identifying each individual as [assignment: organization-defined characteristic identifying individual status]. Characteristics that identify the status of individuals include contractors, foreign nationals, and non-organizational users. Identifying the status of individuals by these characteristics provides additional information about the people with whom organizational personnel are communicating. For example, it might be useful for a government employee to know that one of the individuals on an email message is a contractor.",
          "System and information integrity. Information management and retention. Manage and retain information within the system and information output from the system in accordance with applicable laws, executive orders, directives, regulations, policies, standards, guidelines, and operational requirements. Information management and retention requirements cover the full life cycle of information, in some cases extending beyond system disposal. Information to be retained may also include policies, procedures, plans, reports, data output from control implementation, and other types of administrative information.\n\nThe National Archives and Records Administration (NARA) provides federal policy and guidance on records retention and schedules. If organizations have a records management office, consider coordinating with records management personnel. Records produced from the output of implemented controls that may require management and retention include, but are not limited to: all XX-1, AC-6 (9), AT-4, AU-12, CA-2, CA-3, CA-5, CA-6, CA-7, CA-8, CA-9, CM-2, CM-3, CM-4, CM-6, CM-8, CM-9, CM-12, CM-13, CP-2, IR-6, IR-8, MA-2, MA-4, PE-2, PE-8, PE-16, PE-17, PL-2, PL-4, PL-7, PL-8, PM-5, PM-8, PM-9, PM-18, PM-21, PM-27, PM-28, PM-30, PM-31, PS-2, PS-6, PS-7, PT-2, PT-3, PT-7, RA-2, RA-3, RA-5, RA-8, SA-4, SA-5, SA-8, SA-10, SI-4, SR-2, SR-4, SR-8.",
          "Access control. System use notification. a. Display [assignment: organization-defined system use notification message or banner] to users before granting access to the system that provides privacy and security notices consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines, and state that users are accessing a U.S. government system. System usage may be monitored, recorded, and subject to audit. Unauthorized use of the system is prohibited and subject to criminal and civil penalties. Use of the system indicates consent to monitoring and recording.\n\nb. Retain the notification message or banner on the screen until users acknowledge the usage conditions and take explicit actions to log on to or further access the system.\n\nc. For publicly accessible systems:\n\n1. Display system use information [assignment: organization-defined conditions] before granting further access to the publicly accessible system.\n\n2. Display references, if any, to monitoring, recording, or auditing that are consistent with privacy accommodations for such systems that generally prohibit those activities.\n\n3. Include a description of the authorized uses of the system.\n\nSystem use notifications can be implemented using messages or warning banners displayed before individuals log in to systems. System use notifications are used only for access via logon interfaces with human users. Notifications are not required when human interfaces do not exist.\n\nBased on an assessment of risk, organizations consider whether or not a secondary system use notification is needed to access applications or other system resources after the initial network logon.\n\nOrganizations consider system use notification messages or banners displayed in multiple languages based on organizational needs and the demographics of system users. Organizations consult with the privacy office for input regarding privacy messaging and the Office of the General Counsel or organizational equivalent for legal review and approval of warning banner content.",
          "System and communications protection. Secure name/address resolution service (recursive or caching resolver). Request and perform data origin authentication and data integrity verification on the name/address resolution responses the system receives from authoritative sources. Each client of name resolution services either performs this validation on its own or has authenticated channels to trusted validation providers. \n\nSystems that provide name and address resolution services for local clients include recursive resolving or caching Domain Name System (DNS) servers. DNS client resolvers either perform validation of DNSSEC signatures, or clients use authenticated channels to recursive resolvers that perform such validations. \n\nSystems that use technologies other than the DNS to map between host and service names and network addresses provide some other means to enable clients to verify the authenticity and integrity of response data.",
          "Identification and authentication. Authenticator management | multiple system accounts. Implement [assignment: organization-defined security controls] to manage the risk of compromise due to individuals having accounts on multiple systems. When individuals have accounts on multiple systems and use the same authenticators, such as passwords, there is the risk that a compromise of one account may lead to the compromise of other accounts. Alternative approaches include having different authenticators (passwords) on all systems, employing a single sign-on or federation mechanism, or using some form of one-time passwords on all systems. Organizations can also use rules of behavior (see PL-4) and access agreements (see PS-6) to mitigate the risk of multiple system accounts.",
          "Contingency planning. Contingency plan | continue mission and business functions. Plan for the continuance of [selection: all; essential] mission and business functions with minimal or no loss of operational continuity and sustain that continuity until full system restoration at primary processing and/or storage sites. Organizations may choose to conduct the contingency planning activities to continue mission and business functions as part of business continuity planning or business impact analyses. Primary processing and/or storage sites defined by organizations as part of contingency planning may change depending on the circumstances associated with the contingency.",
          "Incident response. Incident reporting | supply chain coordination. Provide incident information to the provider of the product or service and other organizations involved in the supply chain or supply chain governance for systems or system components related to the incident. Organizations involved in supply chain activities include product developers, system integrators, manufacturers, packagers, assemblers, distributors, vendors, and resellers. Entities that provide supply chain governance include the Federal Acquisition Security Council (FASC). Supply chain incidents include compromises or breaches that involve information technology products, system components, development processes or personnel, distribution processes, or warehousing facilities. Organizations determine the appropriate information to share and consider the value gained from informing external organizations about supply chain incidents, including the ability to improve processes or to identify the root cause of an incident.",
          "Configuration management. Configuration change control | security and privacy representatives. Require organization-defined security and privacy representatives to be members of the organization-defined configuration change control element. Information security and privacy representatives include system security officers, senior agency information security officers, senior agency officials for privacy, or system privacy officers. Representation by personnel with information security and privacy expertise is important because changes to system configurations can have unintended side effects, some of which may be security- or privacy-relevant. Detecting such changes early in the process can help avoid unintended, negative consequences that could ultimately affect the security and privacy posture of systems. The configuration change control element referred to in the second organization-defined parameter reflects the change control elements defined by organizations in CM-3g.",
          "Security assessment and authorization. Penetration testing. Conduct penetration testing [assignment: organization-defined frequency] on [assignment: organization-defined systems or system components]. Penetration testing is a specialized type of assessment conducted on systems or individual system components to identify vulnerabilities that could be exploited by adversaries. Penetration testing goes beyond automated vulnerability scanning and is conducted by agents and teams with demonstrable skills and experience that include technical expertise in network, operating system, and/or application-level security. Penetration testing can be used to validate vulnerabilities or determine the degree of penetration resistance of systems to adversaries within specified constraints. Such constraints include time, resources, and skills. Penetration testing attempts to duplicate the actions of adversaries and provides a more in-depth analysis of security- and privacy-related weaknesses or deficiencies. Penetration testing is especially important when organizations are transitioning from older technologies to newer technologies (e.g., transitioning from IPv4 to IPv6 network protocols). Organizations can use the results of vulnerability analyses to support penetration testing activities. Penetration testing can be conducted internally or externally on the hardware, software, or firmware components of a system and can exercise both physical and technical controls. A standard method for penetration testing includes a pretest analysis based on full knowledge of the system, pretest identification of potential vulnerabilities based on the pretest analysis, and testing designed to determine the exploitability of vulnerabilities. All parties agree to the rules of engagement before commencing penetration testing scenarios. Organizations correlate the rules of engagement for the penetration tests with the tools, techniques, and procedures that are anticipated to be employed by adversaries. Penetration testing may result in the exposure of information that is protected by laws or regulations to individuals conducting the testing. Rules of engagement, contracts, or other appropriate mechanisms can be used to communicate expectations for how to protect this information. Risk assessments guide the decisions on the level of independence required for the personnel conducting penetration testing.",
          "Security assessment and authorization. Control assessments. a. Select the appropriate assessor or assessment team for the type of assessment to be conducted. \nb. Develop a control assessment plan that describes the scope of the assessment, including: \n1. Controls and control enhancements under assessment. \n2. Assessment procedures to be used to determine control effectiveness. \n3. Assessment environment, assessment team, and assessment roles and responsibilities. \nc. Ensure the control assessment plan is reviewed and approved by the authorizing official or designated representative prior to conducting the assessment. \nd. Assess the controls in the system and its environment of operation [assignment: organization-defined frequency] to determine the extent to which the controls are implemented correctly, operating as intended, and producing the desired outcome with respect to meeting established security and privacy requirements. \ne. Produce a control assessment report that documents the results of the assessment. \nf. Provide the results of the control assessment to [assignment: organization-defined individuals or roles]. \nOrganizations ensure that control assessors possess the required skills and technical expertise to develop effective assessment plans and to conduct assessments of system-specific, hybrid, common, and program management controls, as appropriate. The required skills include general knowledge of risk management concepts and approaches as well as comprehensive knowledge of and experience with the hardware, software, and firmware system components implemented. Organizations assess controls in systems and the environments in which those systems operate as part of initial and ongoing authorizations, continuous monitoring, FISMA annual assessments, system design and development, systems security engineering, privacy engineering, and the system development life cycle. Assessments help to ensure that organizations meet information security and privacy requirements, identify weaknesses and deficiencies in the system design and development process, provide essential information needed to make risk-based decisions as part of authorization processes, and comply with vulnerability mitigation procedures. Organizations conduct assessments on the implemented controls as documented in security and privacy plans. Assessments can also be conducted throughout the system development life cycle as part of systems engineering and systems security engineering processes. The design for controls can be assessed as RFPs are developed, responses assessed, and design reviews conducted. If a design to implement controls and subsequent implementation in accordance with the design are assessed during development, the final control testing can be a simple confirmation utilizing previously completed control assessment and aggregating the outcomes. Organizations may develop a single, consolidated security and privacy assessment plan for the system or maintain separate plans. A consolidated assessment plan clearly delineates the roles and responsibilities for control assessment. If multiple organizations participate in assessing a system, a coordinated approach can reduce redundancies and associated costs. Organizations can use other types of assessment activities, such as vulnerability scanning and system monitoring, to maintain the security and privacy posture of systems during the system life cycle. Assessment reports document assessment results in sufficient detail, as deemed necessary by organizations, to determine the accuracy and completeness of the reports and whether the controls are implemented correctly, operating as intended, and producing the desired outcome with respect to meeting requirements. Assessment results are provided to the individuals or roles appropriate for the types of assessments being conducted. For example, assessments conducted in support of authorization decisions are provided to authorizing officials, senior agency officials for privacy, senior agency information security officers, and authorizing official designated representatives. To satisfy annual assessment requirements, organizations can use assessment results from the following sources: initial or ongoing system authorizations, continuous monitoring, systems engineering processes, or system development life cycle activities. Organizations ensure that assessment results are current, relevant to the determination of control effectiveness, and obtained with the appropriate level of assessor independence. Existing control assessment results can be reused to the extent that the results are still valid and can also be supplemented with additional assessments as needed. After the initial authorizations, organizations assess controls during continuous monitoring. Organizations also establish the frequency for ongoing assessments in accordance with organizational continuous monitoring strategies. External audits, including audits by external entities such as regulatory agencies, are outside the scope of CA-2.",
          "Planning. Baseline selection. Select a control baseline for the system. Control baselines are predefined sets of controls specifically assembled to address the protection needs of a group, organization, or community of interest. Controls are chosen for baselines to either satisfy mandates imposed by laws, executive orders, directives, regulations, policies, standards, and guidelines or address threats common to all users of the baseline under the assumptions specific to the baseline. Baselines represent a starting point for the protection of individuals' privacy, information, and information systems with subsequent tailoring actions to manage risk in accordance with mission, business, or other constraints (see PL-11). Federal control baselines are provided in SP 800-53b. The selection of a control baseline is determined by the needs of stakeholders. Stakeholder needs consider mission and business requirements as well as mandates imposed by applicable laws, executive orders, directives, policies, regulations, standards, and guidelines. For example, the control baselines in SP 800-53b are based on the requirements from FISMA and privacy. The requirements, along with the NIST standards and guidelines implementing the legislation, direct organizations to select one of the control baselines after reviewing the information types and the information that is processed, stored, and transmitted on the system; analyzing the potential adverse impact of the loss or compromise of the information or system on the organization's operations and assets, individuals, other organizations, or the nation; and considering the results from system and organizational risk assessments. CNSSI 1253 provides guidance on control baselines for national security systems.",
          "Media protection. Media transport. a. Protect and control [assignment: organization-defined types of system media] during transport outside of controlled areas using [assignment: organization-defined controls]. b. Maintain accountability for system media during transport outside of controlled areas. c. Document activities associated with the transport of system media. d. Restrict the activities associated with the transport of system media to authorized personnel.\n\nSystem media includes digital and non-digital media. Digital media includes flash drives, diskettes, magnetic tapes, external or removable hard disk drives (e.g., solid state and magnetic), compact discs, and digital versatile discs. Non-digital media includes microfilm and paper.\n\nControlled areas are spaces for which organizations provide physical or procedural controls to meet requirements established for protecting information and systems. Controls to protect media during transport include cryptography and locked containers. Cryptographic mechanisms can provide confidentiality and integrity protections depending on the mechanisms implemented.\n\nActivities associated with media transport include releasing media for transport, ensuring that media enters the appropriate transport processes, and the actual transport. Authorized transport and courier personnel may include individuals external to the organization.\n\nMaintaining accountability of media during transport includes restricting transport activities to authorized personnel and tracking and/or obtaining records of transport activities as the media moves through the transportation system to prevent and detect loss, destruction, or tampering.\n\nOrganizations establish documentation requirements for activities associated with the transport of system media in accordance with organizational assessments of risk. Organizations maintain the flexibility to define record-keeping methods for the different types of media transport as part of a system of transport-related records.",
          "Security assessment and authorization. Continuous monitoring. Develop a system-level continuous monitoring strategy and implement continuous monitoring in accordance with the organization-level continuous monitoring strategy. This includes:\n\na. Establishing the following system-level metrics to be monitored: [assignment: organization-defined system-level metrics].\n\nb. Establishing [assignment: organization-defined frequencies] for monitoring and [assignment: organization-defined frequencies] for assessment of control effectiveness.\n\nc. Conducting ongoing control assessments in accordance with the continuous monitoring strategy.\n\nd. Performing ongoing monitoring of system and organization-defined metrics based on the continuous monitoring strategy.\n\ne. Correlating and analyzing information generated by control assessments and monitoring.\n\nf. Taking response actions to address results of the analysis of control assessment and monitoring information.\n\ng. Reporting the security and privacy status of the system to [assignment: organization-defined personnel or roles] [assignment: organization-defined frequency].\n\nContinuous monitoring at the system level enables ongoing awareness of the system's security and privacy posture, supporting organizational risk management decisions. The terms \"continuous\" and \"ongoing\" imply that organizations assess and monitor their controls and risks at a frequency sufficient to support risk-based decisions. Different types of controls may require different monitoring frequencies.\n\nThe results of continuous monitoring generate risk response actions by organizations. When monitoring the effectiveness of multiple controls grouped into capabilities, a root-cause analysis may be necessary to determine the specific control that has failed. Continuous monitoring programs enable organizations to maintain authorizations of systems and common controls in highly dynamic operational environments with changing mission and business needs, threats, vulnerabilities, and technologies.\n\nHaving access to security and privacy information on a continuous basis through reports and dashboards provides organizational officials with the ability to make effective and timely risk management decisions, including ongoing authorization decisions. Automation supports more frequent updates to hardware, software, and firmware inventories, authorization packages, and other system information.\n\nEffectiveness is further enhanced when continuous monitoring outputs are formatted to provide specific, measurable, actionable, relevant, and timely information.\n\nContinuous monitoring activities are scaled based on the security categories of systems. Monitoring requirements, including the need for specific monitoring, may be referenced in other controls and control enhancements, such as AC-2g, AC-2 (7), AC-2 (12) (a), AC-2 (7) (b), AC-2 (7) (c), AC-17 (1), AT-4a, AU-13, AU-13 (1), AU-13 (2), CM-3f, CM-6d, CM-11c, IR-5, MA-2b, MA-3a, MA-4a, PE-3d, PE-6, PE-14b, PE-16, PE-20, PM-6, PM-23, PM-31, PS-7e, SA-9c, SR-4, SC-5 (3) (b), SC-7a, SC-7 (24) (b), SC-18b, SC-43b, and SI-4.",
          "Identification and authentication. Identification and authentication (organizational users). Uniquely identify and authenticate organizational users and associate that unique identification with processes acting on behalf of those users. Organizations can satisfy the identification and authentication requirements by complying with the requirements in HSPD 12. Organizational users include employees or individuals who organizations consider to have an equivalent status to employees (e.g., contractors and guest researchers). \n\nUnique identification and authentication of users applies to all accesses other than those that are explicitly identified in AC-14 and that occur through the authorized use of group authenticators without individual authentication. Since processes execute on behalf of groups and roles, organizations may require unique identification of individuals in group accounts or for detailed accountability of individual activity. \n\nOrganizations employ passwords, physical authenticators, or biometrics to authenticate user identities or, in the case of multi-factor authentication, some combination thereof. Access to organizational systems is defined as either local access or network access. Local access is any access to organizational systems by users or processes acting on behalf of users, where access is obtained through direct connections without the use of networks. \n\nNetwork access is access to organizational systems by users (or processes acting on behalf of users) where access is obtained through network connections (i.e., nonlocal accesses). Remote access is a type of network access that involves communication through external networks. Internal networks include local area networks and wide area networks. \n\nThe use of encrypted virtual private networks for network connections between organization-controlled endpoints and non-organization-controlled endpoints may be treated as internal networks with respect to protecting the confidentiality and integrity of information traversing the network. Identification and authentication requirements for non-organizational users are described in IA-8.",
          "Incident response. Incident handling | integrated incident response team. Establish and maintain an integrated incident response team that can be deployed to any location identified by the organization in [assignment: organization-defined time period]. An integrated incident response team is a team of experts that assesses, documents, and responds to incidents so that organizational systems and networks can recover quickly and implement the necessary controls to avoid future incidents. Incident response team personnel include forensic and malicious code analysts, tool developers, systems security and privacy engineers, and real-time operations personnel. The incident handling capability includes performing rapid forensic preservation of evidence and analysis of and response to intrusions. For some organizations, the incident response team can be a cross-organizational entity. \n\nAn integrated incident response team facilitates information sharing and allows organizational personnel (e.g., developers, implementers, and operators) to leverage team knowledge of the threat and implement defensive measures that enable organizations to deter intrusions more effectively. Moreover, integrated teams promote the rapid detection of intrusions, the development of appropriate mitigations, and the deployment of effective defensive measures. \n\nFor example, when an intrusion is detected, the integrated team can rapidly develop an appropriate response for operators to implement, correlate the new incident with information on past intrusions, and augment ongoing cyber intelligence development. Integrated incident response teams are better able to identify adversary tactics, techniques, and procedures that are linked to the operations tempo or specific mission and business functions and to define responsive actions in a way that does not disrupt those mission and business functions. Incident response teams can be distributed within organizations to make the capability resilient.",
          "Identification and authentication. Authenticator management | no embedded unencrypted static authenticators. Ensure that unencrypted static authenticators are not embedded in applications or other forms of static storage. In addition to applications, other forms of static storage include access scripts and function keys. Organizations should exercise caution when determining whether embedded or stored authenticators are in encrypted or unencrypted form. If authenticators are used in the manner stored, then those representations are considered unencrypted authenticators.",
          "Audit and accountability. Audit record generation | changes by authorized individuals. Provide and implement the capability for (assignment: organization-defined individuals or roles) to change the logging to be performed on (assignment: organization-defined system components) based on (assignment: organization-defined selectable event criteria) within (assignment: organization-defined time thresholds). Permitting authorized individuals to make changes to system logging enables organizations to extend or limit logging as necessary to meet organizational requirements. Logging that is limited to conserve system resources may be extended (either temporarily or permanently) to address certain threat situations. In addition, logging may be limited to a specific set of event types to facilitate audit reduction, analysis, and reporting. Organizations can establish time thresholds in which logging actions are changed (e.g., near real-time, within minutes, or within hours).",
          "Configuration management. Configuration change control. A. Determine and document the types of changes to the system that are configuration-controlled.\nB. Review proposed configuration-controlled changes to the system and approve or disapprove such changes with explicit consideration for security and privacy impact analyses.\nC. Document configuration change decisions associated with the system.\nD. Implement approved configuration-controlled changes to the system.\nE. Retain records of configuration-controlled changes to the system for [assignment: organization-defined time period].\nF. Monitor and review activities associated with configuration-controlled changes to the system.\nG. Coordinate and provide oversight for configuration change control activities through [assignment: organization-defined configuration change control element] that convenes [selection (one or more): [assignment: organization-defined frequency]; when [assignment: organization-defined configuration change conditions]].\n\nConfiguration change control for organizational systems involves the systematic proposal, justification, implementation, testing, review, and disposition of system changes, including system upgrades and modifications. Configuration change control includes changes to baseline configurations, configuration items of systems, operational procedures, configuration settings for system components, remediate vulnerabilities, and unscheduled or unauthorized changes. Processes for managing configuration changes to systems include configuration control boards or change advisory boards that review and approve proposed changes. For changes that impact privacy risk, the senior agency official for privacy updates privacy impact assessments and system of records notices. For new systems or major upgrades, organizations consider including representatives from the development organizations on the configuration control boards or change advisory boards. Auditing of changes includes activities before and after changes are made to systems and the auditing activities required to implement such changes. See also SA-10.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "5_and_the_of",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "5_and_the_of"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          7.494183540344238,
          7.718514919281006,
          7.555552959442139,
          7.5828166007995605,
          7.869657039642334,
          7.61395788192749,
          8.121368408203125,
          7.64052677154541,
          8.141922950744629,
          7.72064733505249,
          7.528336524963379,
          7.611112117767334,
          6.893303394317627,
          7.648326873779297,
          7.850076198577881,
          6.825395107269287,
          7.977609634399414,
          6.746827602386475,
          7.78400993347168,
          7.432539939880371,
          7.623303413391113,
          7.704678058624268,
          7.56710958480835,
          8.01084041595459,
          7.710371971130371,
          7.744290351867676,
          7.64607048034668,
          7.620865345001221
         ],
         "y": [
          8.863102912902832,
          9.624378204345703,
          9.087672233581543,
          8.906708717346191,
          9.537017822265625,
          9.223852157592773,
          9.291881561279297,
          9.252727508544922,
          9.32738971710205,
          9.290656089782715,
          8.263867378234863,
          8.792263984680176,
          9.16232967376709,
          9.20607852935791,
          9.600786209106445,
          9.197781562805176,
          9.449823379516602,
          9.141278266906738,
          8.887089729309082,
          8.959809303283691,
          8.512412071228027,
          8.965879440307617,
          9.062882423400879,
          9.060641288757324,
          9.239245414733887,
          8.623045921325684,
          9.239747047424316,
          9.102605819702148
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Cryptography and key management (cry). Encryption of data for transmission (transport encryption). Basic criterion: The cloud service provider has established procedures and technical measures for strong encryption and authentication for the transmission of data of cloud customers over public networks.\n\nAdditional criterion: The cloud service provider has established procedures and technical measures for strong encryption and authentication for the transmission of all data.\n\nSupplementary information about the criterion: When transmitting data with normal protection requirements within the cloud service provider's infrastructure, encryption is not mandatory, provided that the data is not transmitted via public networks. In this case, the non-public environment of the cloud service provider can generally be deemed trusted. The protocols TLS 1.2 and TLS 1.3 are currently regarded as strong, state-of-the-art transport encryptions, in each case in combination with perfect forward secrecy. The specific configuration should comply with the recommendations of the (current) version of the BSI Technical Guideline TR-02102-2 \"Cryptographic Procedures: Recommendations and Key Lengths - Part 2: Use of Transport Layer Security (TLS)\". Generally, the use of wildcard certificates is not considered a secure procedure.\n\nThe basic criterion for the transmission of cloud customers' data relates to, for example, the sending of electronic messages via public networks.\n\nComplementary customer criterion: Cloud customers ensure, through suitable controls for those parts of the cloud service under their responsibility, that their data is transmitted over encrypted connections in accordance with the respective protection requirements.\n\nNotes on continuous auditing feasibility: Partially, the procedures and technical measures for encrypting data during transmission are configured centrally. This configuration rarely changes. Therefore, a continuous audit would not be sensible, as only changes to this configuration would have to be checked. However, the system status can be audited continuously. This also applies to the additional criterion.",
          "Product safety and security (pss). Locations of data processing and storage. Basic criterion: The cloud customer is able to specify the locations (location/country) of the data processing and storage, including data backups, according to the contractually available options. This must be ensured by the cloud architecture.\n\nAdditional criterion: Supplementary information about the criterion. This criterion supplements the general condition BC-01. The cloud architecture must exist in such a way that it enables the technical design of the IT infrastructure to provide the cloud service in accordance with the data location specifications agreed with the customer.\n\nComplementary customer criterion: Cloud customers ensure, through suitable controls, that when selecting service providers and configuring the cloud service, they are informed about the available data processing and storage locations. If there is a choice between different locations, they select those that meet their own requirements. Depending on the use case and especially when using services of a cloud service provider based in another country, cloud customers take the laws applicable to them into account when making their selection (e.g., when processing personal data; compliance with legal retention obligations for business documents, etc.).\n\nNotes on continuous auditing feasibility: Yes, a continuous survey of the location of the data and the country from which the service is provided can be carried out automatically by the cloud service provider. This information can then be made available to the customer, for example, on their dashboard or on request.",
          "Contingency planning. System backup | testing for reliability and integrity. Test backup information [assignment: organization-defined frequency] to verify media reliability and information integrity. Organizations need assurance that backup information can be reliably retrieved. Reliability pertains to the systems and system components where the backup information is stored, the operations used to retrieve the information, and the integrity of the information being retrieved. Independent and specialized tests can be used for each of the aspects of reliability. For example, decrypting and transporting (or transmitting) a random sample of backup files from the alternate storage or backup site and comparing the information to the same information at the primary processing site can provide such assurance.",
          "Security incident management (sim). Duty of the users to report security incidents to a central body. Basic criterion: The cloud service provider informs employees and external business partners of their obligations. If necessary, they agree to, or are contractually obliged to, report all security events that become known to them and are directly related to the cloud service provided by the cloud service provider to a previously designated central office of the cloud service provider promptly. In addition, the cloud service provider communicates that \"false reports\" of events that do not subsequently turn out to be incidents do not have any negative consequences.\n\nAdditional criterion: Supplementary information about the criterion complementary customer criterion cloud customers ensure, through suitable controls, that identified security events which the cloud service provider is required to process are communicated promptly to previously designated responsible personnel. The identification of such security events is supported by suitable controls (cf. complementary criterion for ops-10).\n\nNotes on continuous auditing feasibility: Partially, the cloud service provider should inform its employees and external business partners about their obligations in a standardized and digital format. This obligation usually occurs when the employee joins the company or the business relationship. This enables the auditor to automatically and continuously audit whether all employees and external business partners are notified of their obligations by automatically testing whether the clause, if any, is included in the contract when the contract is signed.",
          "Communication security (cos). Cross-network access. Basic criterion: Each network perimeter is controlled by security gateways. The system access authorization for cross-network access is based on a security assessment, considering the requirements of the cloud customers.\n\nAdditional criterion: Each network perimeter is controlled by redundant and highly-available security gateways.\n\nSupplementary information about the criterion: Cross-network access refers to access from one network to another network through a defined network perimeter.\n\nComplementary customer criterion: Cloud customers ensure, through suitable controls, that access to their virtual networks within the cloud service is controlled according to their protection needs. This is achieved by using security gateways on the perimeters of the virtual networks for which they are responsible.\n\nNotes on continuous auditing feasibility: Yes, if the control of the network perimeters is documented (e.g., by logs), these logs can be automatically evaluated. This provides the possibility of a continuous audit for this part of the criterion. If the security evaluation for access authorizations is conducted in a standardized form by the cloud service provider, it can also be automatically evaluated. In such a case, a continuous audit for the second part of the criterion would also be possible.",
          "Communication security (cos). Segregation of data traffic in jointly used network environments. Basic criterion: Data traffic of cloud customers in jointly used network environments is segregated on network level according to a documented concept to ensure the confidentiality and integrity of the data transmitted. \nAdditional criterion: In the case of IaaS/PaaS, secure segregation is ensured by physically separated networks or by means of strongly encrypted VLANs. For the definition of strong encryption, the BSI technical guideline TR-02102 must be considered. \nSupplementary information about the criterion: If the suitability and effectiveness of the logical segmentation cannot be assessed with sufficient certainty (e.g. due to a complex implementation), evidence can also be provided based on audit results of expert third parties (e.g. security audits to validate the concept). The segregation of stored and processed data is subject to the criterion OPS-24. After successful authentication via an insecure communication channel (HTTP), a secure communication channel (HTTPS) is to be used. \nWith IaaS/PaaS, secure segregation is ensured by physically separated networks or strong encryption of the networks. For the definition of strong encryption, the BSI technical guideline TR-02102 must be considered (cf. CRY-01). \nIf the cloud service provider does not use shared network environments for cloud customers and instead uses a physical segregation, the basic criterion is not applicable. \nComplementary customer criterion: Through suitable controls, cloud customers ensure that, for parts of the cloud service under their responsibility, virtual networks are designed, configured, and documented in accordance with their network security requirements (e.g. logical segmentation of organizational units). \nNotes on continuous auditing feasibility: No. The logical segregation of cloud customer network traffic at the network level is centrally configured and rarely changed. Thus, a continuous audit is not beneficial since no highly frequented automated query can be performed to support the continuous audit.",
          "Security incident management (sim). Documentation and reporting of security incidents. Basic criterion: After a security incident has been processed, the solution is documented in accordance with the contractual agreements, and the report is sent to the affected customers for final acknowledgement or, if applicable, as confirmation. \n\nAdditional criterion: The customer can either actively approve solutions, or the solution is automatically approved after a certain period. Information on security incidents or confirmed security breaches is made available to all affected customers. The contract between the cloud service provider and the cloud customer regulates which data is made available to the cloud customer for their own analysis in the event of security incidents. \n\nSupplementary information about the criterion: Complementary customer criterion. Cloud customers ensure through suitable controls that they receive notifications from the cloud service provider about security incidents that affect them and their resolution, and that these notifications are forwarded promptly to the entity responsible for handling them so that an appropriate response can be made. \n\nNotes on continuous auditing feasibility: Yes. In the logs or tickets that document the security incidents (cf. sim-03), the cloud service provider also describes the solution pursued to eliminate the incident. Additionally, the cloud service provider also documents the confirmation to the customer. The auditor can then automatically and continuously read out whether the documented security incidents have been resolved and whether a solution has been documented. The same applies to the communication of the resolution of the incidents to affected customers. If this is not the case, the unresolved security incident can be documented as the output value of the continuous audit.",
          "Operations (ops). Capacity management – planning. Basic criterion: The planning of capacities and resources (personnel and IT resources) follows an established procedure in order to avoid possible capacity bottlenecks. The procedures include forecasting future capacity requirements to identify usage trends and manage system overload. Cloud service providers take appropriate measures to ensure they continue to meet the requirements agreed with cloud customers for the provision of the cloud service in the event of capacity bottlenecks or outages, particularly those related to the dedicated use of system components, in accordance with the respective agreements.\n\nAdditional criterion: The forecasts are considered in accordance with the service level agreement for planning and preparing the provisioning.\n\nSupplementary information about the criterion: For economic reasons, cloud service providers typically strive for high utilization of IT resources (CPU, RAM, storage space, network). In multi-tenant environments, existing resources must still be shared between cloud users (clients) in a way that adheres to service level agreements. Proper planning and monitoring of IT resources are critical to the availability and competitiveness of the cloud service. If the procedures are not documented or are subject to a higher degree of confidentiality as a trade secret of the cloud service provider, the cloud service provider must be able to explain the procedures at least orally within the scope of this audit. Cloud customers must use appropriate controls to ensure that the capacity and resource requirements to be covered by the cloud service provider are planned and reflected in the SLA with the cloud service provider. The requirements can also be reviewed regularly through appropriate controls, and the SLA can be adjusted accordingly.\n\nComplementary customer criterion notes on continuous auditing feasibility: No. An audit of the planning of capacities and resources requires an assessment of the plausibility or meaningfulness of the content. At present, this can hardly be audited automatically and continuously.",
          "Configuration management. System component inventory. a. Develop and document an inventory of system components that: 1. accurately reflects the system; 2. includes all components within the system; 3. does not include duplicate accounting of components or components assigned to any other system; 4. is at the level of granularity deemed necessary for tracking and reporting; and 5. includes the following information to achieve system component accountability: [Assignment: organization-defined information deemed necessary to achieve effective system component accountability]. And b. Review and update the system component inventory [Assignment: organization-defined frequency]. \n\nSystem components are discrete, identifiable information technology assets that include hardware, software, and firmware. Organizations may choose to implement centralized system component inventories that include components from all organizational systems. In such situations, organizations ensure that the inventories include system-specific information required for component accountability. The information necessary for effective accountability of system components includes the system name, software owners, software version numbers, hardware inventory specifications, software license information, and for networked components, the machine names and network addresses across all implemented protocols (e.g., IPv4, IPv6). \n\nInventory specifications include date of receipt, cost, model, serial number, manufacturer, supplier information, component type, and physical location. Preventing duplicate accounting of system components addresses the lack of accountability that occurs when component ownership and system association is not known, especially in large or complex connected systems. Effective prevention of duplicate accounting of system components necessitates use of a unique identifier for each component. \n\nFor software inventory, centrally managed software that is accessed via other systems is addressed as a component of the system on which it is installed and managed. Software installed on multiple organizational systems and managed at the system level is addressed for each individual system and may appear more than once in a centralized component inventory, necessitating a system association for each software instance in the centralized inventory to avoid duplicate accounting of components. \n\nScanning systems implementing multiple network protocols (e.g., IPv4 and IPv6) can result in duplicate components being identified in different address spaces. The implementation of CM-8 (7) can help to eliminate duplicate accounting of components.",
          "Product safety and security (pss). Software defined networking. Basic criterion: If the cloud service offers functions for software-defined networking (SDN), the confidentiality of the data of the cloud user is ensured by suitable SDN procedures. The cloud service provider validates the functionality of the SDN functions before providing new SDN features to cloud users or modifying existing SDN features. Identified defects are assessed and corrected in a risk-oriented manner.\n\nAdditional criterion: Supplementary information about the criterion: This criterion is typically not applicable to the SaaS service model. Suitable SDN methods for increasing confidentiality are, for example, L2 overlay networking (tagging) or tunneling/encapsulation.\n\nComplementary customer criterion: Notes on continuous auditing feasibility: Yes. Validation during provision and modification of SDN functions and identification of defects can be documented in a standardized manner by the cloud service provider. This documentation can be audited continuously and automatically by the auditor. The \"marking\" of the data is carried out by a configuration that has to be tested centrally. A continuous audit of all transmitted data packets would not be effective here. The status of the configuration can be continuously audited against a target value, and a content evaluation must be carried out manually.",
          "Operations (ops). Involvement of cloud customers in the event of incidents. Basic criterion: The cloud service provider periodically informs the cloud customer on the status of incidents affecting the cloud customer, or, where appropriate and necessary, involves the customer in the resolution, in a manner consistent with the contractual agreements. As soon as an incident has been resolved from the cloud service provider’s perspective, the cloud customer is informed according to the contractual agreements about the actions taken.\n\nAdditional criterion: Supplementary information about the criterion complementary customer criterion. Cloud customers ensure through suitable controls that they receive notifications from the cloud service provider regarding incidents that affect them, and that these notifications are forwarded in a timely manner to the department responsible for processing them so that appropriate action can be taken.\n\nNotes on continuous auditing feasibility: Yes, a continuous audit is possible if customers are informed about incidents via a standardized communication channel and this is documented (e-mails, logs). The auditor can then evaluate the compiled documentation automatically and continuously. However, it seems more effective to combine the evaluation of the communication of incidents to cloud customers with the evaluation of the elimination of the incidents. As soon as the incidents have been resolved automatically, in the best case, an automatic message is generated and sent to the cloud customer. This message is to be documented. This makes it possible for the auditor to evaluate whether the cloud customer has been properly informed on a regular basis about all incidents affecting them but not beyond.",
          "Security incident management (sim). Policy for security incident management. Basic Criterion: Policies and instructions with technical and organizational safeguards are documented, communicated, and provided in accordance with SP-01 to ensure a fast, effective, and proper response to all known security incidents. The cloud service provider defines guidelines for the classification, prioritization, and escalation of security incidents and creates interfaces to the incident management and business continuity management. In addition, the cloud service provider has set up a \"Computer Emergency Response Team\" (CERT), which contributes to the coordinated resolution of occurring security incidents. Customers affected by security incidents are informed in a timely and appropriate manner.\n\nAdditional Criterion: There are instructions on how to collect the data of a suspicious system conclusively in the event of a security incident. Additionally, there are analysis plans for typical security incidents and an evaluation methodology to ensure that the collected information does not lose its evidential value in any subsequent legal assessment.\n\nSupplementary Information about the Criterion: Complementary Customer Criterion: Cloud customers ensure, through suitable controls, that they receive notifications from the cloud service provider about security incidents that affect them and that these notifications are forwarded in a timely manner to the responsible departments for handling so that an appropriate response can be triggered.\n\nNotes on Continuous Auditing Feasibility: Partially, a continuous audit of the documented policies and instructions is not effective because they are not subject to high-frequency changes. Thus, the audit of the policies and instructions can be performed in the recurring audit. Similarly, setting up a CERT is not suitable for continuous auditing as it is an organizational body and does not require continuous monitoring. The timely communication of security incidents to affected customers can be covered by a continuous audit approach. In addition, the cloud service provider can document not only the security incidents by means of logs but also that they have been communicated to the customer via email, for example. The fact that there was communication to affected customers for every security incident can thus be evaluated automatically and continuously by the auditor. However, this procedure can be combined with the audit approach of further requirements of security incident management.",
          "Identity and access management (idm). Access to cloud customer data. Basic criterion: The cloud customer is informed by the cloud service provider whenever internal or external employees of the cloud service provider read or write to the cloud customer’s data processed, stored, or transmitted in the cloud service or have accessed it without the prior consent of the cloud customer. The information is provided whenever data of the cloud customer is/was not encrypted, the encryption is/was disabled for access, or the contractual agreements do not explicitly exclude such information. The information contains the cause, time, duration, type, and scope of the access. The information is sufficiently detailed to enable subject matter experts of the cloud customer to assess the risks of the access. The information is provided in accordance with the contractual agreements or within 72 hours after the access.\n\nAdditional criterion: Access to the data processed, stored, or transmitted in the cloud service by internal or external employees of the cloud service provider requires the prior consent of an authorized department of the cloud customer, provided that the cloud customer's data is not encrypted, encryption is disabled for access, or contractual agreements do not explicitly exclude such consent. For the consent, the cloud customer's department is provided with meaningful information about the cause, time, duration, type, and scope of the access supporting assessing the risks associated with the access.\n\nSupplementary information about the criterion: Subject matter experts, in the sense of this basic criterion, are personnel from e.g. IT, compliance, or internal audit.\n\nComplementary customer criterion notes on continuous auditing feasibility: Yes, a continuous audit of the notifications carried out only appears practical if the accesses mentioned are also logged and classified automatically. The content of the notifications can only be audited if the content is specified by the cloud service provider according to a specific scheme. Then, a comparison and plausibility check can take place. A continuous audit would test all notifications after they have been received and thus check whether the process has been executed correctly in all cases.",
          "Physical security (ps). Redundancy model. Basic criterion: The cloud service is provided from two locations that are redundant to each other. The locations meet the security requirements of the cloud service provider (cf. ps-01 security concept) and are located in an adequate distance from each other to achieve operational redundancy. Operational redundancy is designed in a way that ensures the availability requirements specified in the service level agreement are met. The functionality of the redundancy is checked at least annually by suitable tests and exercises (cf. bcm-04 - verification, updating, and testing of business continuity). \n\nAdditional criterion: The cloud service is provided from more than two locations that provide redundancy to each other. The locations are sufficiently far apart to achieve georedundancy. If two locations fail at the same time, at least one third location is still available to prevent a total service failure. The georedundancy is designed in a way that ensures the availability requirements specified in the service level agreement are met. The functionality of the redundancy is checked at least annually by suitable tests and exercises (cf. bcm-04 - verification, updating, and testing of business continuity).\n\nSupplementary information about the criterion: Operational redundancy of the sites to each other, in the sense of the basic requirement, is given if based on the assessment of elementary risks at the site, corresponding distances of the premises and buildings to these risks are maintained. Very extensive events which, due to their extent, could affect several sites of the same redundancy group simultaneously or in a timely manner (e.g. floods, earthquakes) are not considered. A georedundancy of the sites to each other, in the sense of the optional, more far-reaching requirement, is given if a very extensive event at a site under no circumstances affects several sites of the same redundancy group simultaneously or promptly. The BSI publication \"Kriterien für die Standortwahl höchstverfügbarer und georedun-danter Rechenzentren\" provides assistance in this regard.\n\nThere are cloud providers who no longer address the issue of reliability of the cloud service on a physical level through redundancy from two independent locations but through resilience. The cloud service is provided simultaneously from more than two locations. The underlying distributed data center architecture ensures that the failure of a location or components of a location does not violate the defined availability criteria of the cloud service. Such an architecture can represent an alternative fulfillment (cf. chapter 3.4.7) of the criterion. The tests and exercises on functionality required in the criterion also apply analogously to resilient architectures.\n\nComplementary customer criterion: By means of suitable controls, cloud customers ensure that the existing redundancy model of the cloud provider and the evidence for the verification of the model comply with their own requirements for the availability and reliability of the cloud service.\n\nNotes on continuous auditing feasibility: Partially an annual audit of the effectiveness of the redundancy is only partially suitable for a continuous audit. A continuous audit could return the date of the last transaction to bring about redundancy. In addition, it would be possible to document every transaction that contributes to redundancy by means of logs and to evaluate these logs automatically and continuously. In addition, the status of the redundancy could be continuously queried.",
          "Access control. Concurrent session control. Limit the number of concurrent sessions for each organization-defined account and/or account type to the organization-defined number. Organizations may define the maximum number of concurrent sessions for system accounts globally, by account type, by account, or any combination thereof. For example, organizations may limit the number of concurrent sessions for system administrators or other individuals working in particularly sensitive domains or mission-critical applications. Concurrent session control addresses concurrent sessions for system accounts. It does not, however, address concurrent sessions by single users via multiple system accounts.",
          "Organisation of information security (ois). Information security management system (isms). Basic criterion: The cloud service provider operates an Information Security Management System (ISMS) in accordance with ISO/IEC 27001. The scope of the ISMS covers the cloud service provider's organizational units, locations, and procedures for providing the cloud service. The measures for setting up, implementing, maintaining, and continuously improving the ISMS are documented. The documentation includes: scope of the ISMS (Section 4.3 of ISO/IEC 27001), declaration of applicability (Section 6.1.3), and results of the last management review (Section 9.3).\n\nAdditional criterion: The Information Security Management System (ISMS) has a valid certification according to ISO/IEC 27001 or ISO 27001 based on IT-Grundschutz.\n\nSupplementary information about the criterion: The basic criterion can also be fulfilled without a valid certification of the ISMS according to ISO/IEC 27001 or ISO 27001 based on IT-Grundschutz if the submitted documentation meets the requirements of ISO/IEC 27001.\n\nComplementary customer criterion: Notes on continuous auditing feasibility: Partially, a continuous audit of the ISO 27001 certificate is partially feasible because the existence of a certificate can be continuously verified through the creation date of the certificate and passing an authenticity check. However, the certificate is usually issued for three years, and there will be no dynamic changes as a rule.",
          "Product safety and security (pss). Error handling and logging mechanisms. Basic criterion: The cloud service provided is equipped with error handling and logging mechanisms. These enable cloud users to obtain security-related information about the security status of the cloud service as well as the data, services, or functions it provides. The information is detailed enough to allow cloud users to check the following aspects, insofar as they are applicable to the cloud service: which data, services, or functions available to the cloud user within the cloud service have been accessed by whom and when (audit logs); malfunctions during the processing of automatic or manual actions; and changes to security-relevant configuration parameters, error handling and logging mechanisms, user authentication, action authorization, cryptography, and communication security. The logged information is protected from unauthorized access and modification and can be deleted by the cloud customer. If the cloud customer is responsible for the activation or type and scope of logging, the cloud service provider must provide appropriate logging capabilities. \n\nAdditional criterion: Cloud users can retrieve security-related information via documented interfaces which are suitable for further processing this information as part of their security information and event management (SIEM). \n\nSupplementary information about the criterion: In the case of a SaaS service for secure data exchange, the terms data, services, or functions would mean, for example, the logging of all read or write accesses to the stored files and their metadata. \n\nComplementary customer criterion: If the cloud service is equipped with error handling and logging mechanisms, cloud customers must activate these and configure them according to defined requirements. The cloud customer must incorporate their own information security management for this purpose. \n\nNotes on continuous auditing feasibility: Yes, the information about the security status of cloud services and further data provided can be read automatically and continuously, as these must be made available to cloud users in digital form. This enables continuous auditing.",
          "Product safety and security (pss). Authentication mechanisms. Basic criterion: The cloud service provider provides authentication mechanisms that can enforce strong authentication (e.g., two or more factors) for users, IT components, or applications within the cloud users' area of responsibility. These authentication mechanisms are set up at all access points that allow users, IT components, or applications to interact with the cloud service. For privileged users, IT components, or applications, these authentication mechanisms are enforced.\n\nAdditional criterion: The cloud service offers out-of-band authentication (OOB), in which the factors are transmitted via different channels (e.g., internet and mobile network).\n\nSupplementary information about the criterion: IT components, in the sense of this criterion, are independently usable objects with external interfaces that can be connected with other IT components. Access points, in the sense of this criterion, are those that can be accessed by users, IT components, or applications via networks (for users, for example, the login screen on the publicly accessible website of the cloud service provider). Multi-factor authentication can be performed with cryptographic certificates, smart cards, or tokens, for example.\n\nComplementary customer criterion: Cloud customers ensure, through suitable controls, that the authentication mechanisms offered by the cloud service are used in accordance with the customer's identity and authorization management requirements.\n\nNotes on continuous auditing feasibility: Partially, the implementation of authentication mechanisms for users takes place via configurations that are only adapted at a low frequency. Thus, continuous auditing is only partially effective here. Nevertheless, it is conceivable to monitor the status of the underlying authentication system, but only deviations from target configurations can be checked. Whether these deviations are desired or not must still be recorded in a manual audit.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "6_the_cloud_of",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "6_the_cloud_of"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          5.972567558288574,
          5.734075546264648,
          5.969104766845703,
          6.0125250816345215,
          5.894079685211182,
          5.938411712646484,
          5.998533248901367,
          5.767136573791504,
          6.052338600158691,
          5.826740264892578,
          6.186958312988281,
          5.943981170654297,
          5.948462963104248,
          5.993259906768799,
          5.879744052886963,
          5.73638916015625,
          5.878992557525635,
          5.8938069343566895,
          5.923727989196777
         ],
         "y": [
          10.679219245910645,
          10.615572929382324,
          10.186574935913086,
          10.739490509033203,
          10.653024673461914,
          10.703886985778809,
          10.705796241760254,
          10.614022254943848,
          10.001705169677734,
          10.776589393615723,
          10.772459030151367,
          10.062220573425293,
          10.661775588989258,
          10.696490287780762,
          10.00855827331543,
          10.658935546875,
          10.63860034942627,
          10.652922630310059,
          10.545990943908691
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Security incident management (sim). Evaluation and learning process. Basic criterion: Mechanisms are in place to measure and monitor the type and scope of security incidents and to report them to support agencies. The information obtained from the evaluation is used to identify recurrent or significant incidents and to identify the need for further protection.\n\nAdditional criterion: Supplementary information about the criterion supporting bodies may be external service providers or government agencies such as the BSI.\n\nComplementary customer criterion: Cloud customers ensure, through suitable controls, that they include into their ISMS the findings and measures related to previous security incidents reported by the cloud service provider. The cloud customers evaluate whether and which supporting measures they might take on their side.\n\nNotes on continuous auditing feasibility: No, the existing mechanisms for measuring the type and scope of security incidents are rarely changed. As a result, continuous auditing is not effective. In addition, in some cases, it can be a manual task carried out by employees to identify recurring incidents or incidents with significant consequences and to develop associated protective measures.\n\n5.14 Business Continuity Management (BCM) Objective: Plan, implement, maintain, and test procedures and measures for business continuity and emergency management.",
          "Operations (ops). Capacity management – monitoring. Basic criterion: Technical and organizational safeguards for the monitoring and provisioning and de-provisioning of cloud services are defined. Thus, the cloud service provider ensures that resources are provided and/or services are rendered according to the contractual agreements and that compliance with the service level agreements is ensured. \n\nAdditional criterion: To monitor capacity and availability, the relevant information is available to the cloud customer in a self-service portal. \n\nSupplementary information about the criterion: Technical and organizational measures typically include the use of monitoring tools with an alarm function when defined threshold values are exceeded, a process for correlating events and an interface to incident management, continuous monitoring of the systems by qualified personnel, and redundancies in the IT systems. \n\nComplementary customer criterion: Cloud customers ensure through suitable controls that the contractual agreements made with the cloud service provider for the provision of resources or services can be monitored. In case of deviations, appropriate controls ensure that the cloud service provider is informed so that the cloud service provider can take appropriate action. \n\nNotes on continuous auditing feasibility: Yes, the part of resource monitoring can be continuously audited by checking capacity forecasts and monitoring the resource management tool. Furthermore, the logs of provisioning and de-provisioning and their impact on resource management can be continuously audited by the changes in resource management.",
          "Control and monitoring of service providers and suppliers (sso). Risk assessment of service providers and suppliers. Basic criterion: Service providers and suppliers of the cloud service provider undergo a risk assessment in accordance with the policies and instructions for the control and monitoring of third parties prior to contributing to the delivery of the cloud service. The adequacy of the risk assessment is reviewed regularly, at least annually, by qualified personnel of the cloud service provider during service usage. The risk assessment includes the identification, analysis, evaluation, handling, and documentation of risks with regard to the following aspects: protection needs regarding the confidentiality, integrity, availability, and authenticity of information processed, stored, or transmitted by the third party; impact of a protection breach on the provision of the cloud service; the cloud service provider's dependence on the service provider or supplier for the scope, complexity, and uniqueness of the service purchased, including the consideration of possible alternatives.\n\nAdditional criterion: Supplementary information about the criterion complementary customer criterion notes on continuous auditing feasibility: No continuous auditing of the risk assessment is not effective, as only its regular execution could be audited automatically, but not the content. In addition, the specified frequency of at least one year is covered by the recurring audit. Risk assessments are rarely carried out dynamically and therefore do not often change during the year.",
          "Compliance (com). Identification of applicable legal, regulatory, self-imposed or contractual requirements. Basic criterion: The legal, regulatory, self-imposed, and contractual requirements relevant to the information security of the cloud service, as well as the cloud service provider's procedures for complying with these requirements, are explicitly defined and documented.\n\nAdditional criterion: Supplementary information about the criterion. The cloud service provider's documentation may refer to the following requirements, among others: requirements for the protection of personal data (e.g., EU General Data Protection Regulation); compliance requirements based on contractual obligations with cloud customers (e.g., ISO/IEC 27001, SOC 2, PCI-DSS); generally accepted accounting principles (e.g., in accordance with HGB or IFRS); requirements regarding access to data and auditability of digital documents (e.g., according to GDPDU); and other laws (e.g., according to BSIG or AktG).\n\nComplementary customer criterion: Notes on continuous auditing feasibility. No, a continuous audit of contract specifications, regulations, and their documentation does not seem to be effective. In this case, the test within the recurring audit is sufficient. A continuous audit could assist in giving the date of the last audit of the criteria.",
          "Operations (ops). Managing vulnerabilities, malfunctions and errors – concept. Basic criterion: Guidelines and instructions with technical and organizational measures are documented, communicated, and provided in accordance with SP-01 to ensure the timely identification and addressing of vulnerabilities in the system components used to provide the cloud service. These guidelines and instructions contain specifications regarding the following aspects: regular identification of vulnerabilities; assessment of the severity of identified vulnerabilities; prioritization and implementation of actions to promptly remediate or mitigate identified vulnerabilities based on severity and according to defined timelines; and handling of system components for which no measures are initiated for the timely remediation or mitigation of vulnerabilities. \n\nAdditional criterion: Supplementary information about the criterion identified vulnerabilities can be classified according to established metrics such as CVSS or OWASP. The decision not to remediate or mitigate identified vulnerabilities must be made by the cloud service provider based on a risk assessment. If necessary, risk-compensating measures must be taken. \n\nComplementary customer criterion: Cloud customers ensure, through suitable controls, that they check system components in their area of responsibility for vulnerabilities on a regular basis and mitigate these with appropriate measures. \n\nNotes on continuous auditing feasibility: No, a policy can change ad-hoc. However, the continuous audit of policies is only partially feasible as the only attributes that can be tested are the last change date and the status of review or approval, as far as this information is stored in a system. The content of a policy can hardly be tested automatically.",
          "Portability and interoperability (pi). Secure deletion of data. Basic criterion: The cloud service provider's procedures for deleting the cloud customers' data upon termination of the contractual relationship ensure compliance with the contractual agreements (cf. pi-02). The deletion includes data in the cloud customer's environment, metadata, and data stored in the data backups. The deletion procedures prevent recovery by forensic means.\n\nAdditional criterion supplementary information about the criterion suitable methods for data deletion are, e.g., multiple overwriting or deletion of the encryption key.\n\nComplementary customer criterion: Cloud customers ensure through suitable controls that the legal and regulatory framework (e.g., legal requirements for storage and deletion) is identified and that the deletion of their data is initiated accordingly.\n\nNotes on continuous auditing feasibility: Yes, the complete deletion of the data is documented by the cloud service provider using logs. The logs should include which data has been deleted so that it can be tracked whether data has been deleted in the cloud customer's environment, metadata, and data in the backup. The auditor can then perform an automated evaluation of these logs. The auditor can also check the system status of the procedure for deleting the data. The fact that the deletion procedures prevent recovery by forensic means does not have to be audited continuously. The deletion procedures used can be tested as part of the recurring audit.\n\n5.11 Procurement, development, and modification of information systems (dev) objective: Ensure information security in the development cycle of information systems.",
          "Identity and access management (idm). Regular review of access rights. Basic criterion: Access rights of internal and external employees of the cloud service provider, as well as system components that play a role in automated authorization processes of the cloud service provider, are reviewed at least once a year to ensure that they still correspond to the actual area of use. The review is carried out by authorized persons from the cloud service provider’s organizational units, who can assess the appropriateness of the assigned access rights based on their knowledge of the task areas of the employees or system components. Identified deviations will be dealt with promptly, but no later than 7 days after their detection, by appropriate modification or withdrawal of the access rights.\n\nAdditional criterion: Privileged access rights are reviewed at least every six months.\n\nSupplementary information about the criterion: Complementary customer criterion notes on continuous auditing feasibility: Yes, the review audit cannot be recorded automatically. A registration of documents used for documentary purposes could take place (e.g., confirmation that the assignment of the access rights has been reviewed). A continuous audit could indicate when this review was last carried out. The cloud service provider must automate the review process (in particular, the confirmation that the review has been performed) so that the auditor can audit the steps to be performed in case deviations are detected.",
          "Procurement, development and modification of information systems (dev). Outsourcing of the development. Basic criterion: In the case of outsourced development of the cloud service (or individual system components), specifications regarding the following aspects are contractually agreed between the cloud service provider and the outsourced development contractor: security in software development (requirements, design, implementation, tests and verifications) in accordance with recognized standards and methods; acceptance testing of the quality of the services provided in accordance with the agreed functional and non-functional requirements; and providing evidence that sufficient verifications have been carried out to rule out the existence of known vulnerabilities.\n\nAdditional criterion: Supplementary information about the criterion outsourced development in the sense of the basic criterion: refers to the development of system components used specifically for the cloud service by a contractor of the cloud service provider. The development takes place according to the processes of the contractor. The purchase of software available on the market as well as the integration of external employees into the processes of the cloud service provider do not constitute outsourcing in the sense of this basic criterion.\n\nComplementary customer criterion: Notes on continuous auditing feasibility: No. An outsourced development of a cloud service provider’s cloud services and the associated contract creation and signing will not be performed with high frequency. Changes in contract structures are also rare. Therefore, a continuous audit in these cases is not effective.",
          "Procurement, development and modification of information systems (dev). Logging of changes. Basic criterion: System components and tools for source code management and software deployment that are used to make changes to system components of the cloud service in the production environment are subject to a role and rights concept, according to IDM-01, and authorization mechanisms. They must be configured in such a way that all changes are logged and can, therefore, be traced back to the individuals or system components executing them.\n\nAdditional criterion: Supplementary information about the criterion complementary customer criterion notes on continuous auditing feasibility: Yes, the changes to the role and rights concept according to IDM-01 are documented in logs by the cloud service provider. Thus, an automatic and continuous evaluation of these logs can be carried out. Irregularities are detected and logged. The auditor can perform a continuous audit by automatically evaluating the logs and logged irregularities.",
          "Physical security (ps). Perimeter protection. Basic criterion: The structural shell of premises and buildings related to the cloud service provided are physically solid and protected by adequate security measures that meet the security requirements of the cloud service provider (cf. PS-01 Security Concept). The security measures are designed to detect and prevent unauthorized access so that the information security of the cloud service is not compromised. The outer doors, windows, and other construction elements exhibit an appropriate security level and withstand a burglary attempt for at least 10 minutes. The surrounding wall constructions as well as the locking mechanisms meet the associated requirements.\n\nAdditional criterion: The security measures installed at the site include permanently present security personnel (at least 2 individuals), video surveillance, and anti-burglary systems. Supplementary information about the criterion security measures for detecting unauthorized access can be security personnel, video surveillance, or burglar alarm systems. \n\nThe resistance class RC4 according to DIN EN 1627 stipulates that doors, windows, and other components must withstand a break-in attempt for at least 10 minutes. The US standard SD-STD-01.01 Rev.G. is an international equivalent to this standard.\n\nComplementary customer criterion notes on continuous auditing feasibility: \n\nPartially, a continuous inspection of the structural shell of buildings is only partially feasible. Only the protection against unauthorized access can provide evaluable data in the form of access logs that are stored.",
          "Control and monitoring of service providers and suppliers (sso). Exit strategy for the receipt of benefits. Basic criterion: The cloud service provider has defined and documented exit strategies for the purchase of services where the risk assessment of the service providers and suppliers regarding the scope, complexity, and uniqueness of the purchased service resulted in a very high dependency (cf. supplementary information). Exit strategies are aligned with operational continuity plans and include the following aspects: analysis of the potential costs, impacts, resources, and timing of the transition of a purchased service to an alternative service provider or supplier; definition and allocation of roles, responsibilities, and sufficient resources to perform the activities for a transition; definition of success criteria for the transition; and definition of indicators for monitoring the performance of services, which should initiate the withdrawal from the service if the results are unacceptable. \n\nAdditional criterion: Supplementary information about the criterion - a very high dependency can be assumed in the following situations, in particular: the purchased service is absolutely required for the provision of the cloud service. This situation is given when the cloud service provider provides the cloud service from data centers operated by third parties and provides a SaaS service and uses the IaaS or PaaS of another cloud service provider. The service cannot be obtained within one month from an alternative service provider or supplier, as: it is unique on the market and no other supplier can deliver it; it is strongly individualized by the service provider or supplier and/or the cloud service provider; it cannot be supplied by any other provider in the required quality of service; and it requires specific knowledge that is only/mainly available to the current service provider or supplier and not to the cloud service provider. \n\nComplementary customer criterion: Notes on continuous auditing feasibility - No, the existence of individual exit strategies is not a practical test item for continuous audit. \n\n5.13 Security Incident Management (SIM) \n\nObjective: Ensure a consistent and comprehensive approach to the capture, assessment, communication, and escalation of security incidents.",
          "Compliance (com). Information on information security performance and management assessment of the isms. Basic criterion: The top management of the cloud service provider is regularly informed about the information security performance within the scope of the ISMS in order to ensure its continued suitability, adequacy, and effectiveness. The information is included in the management review of the ISMS, which is performed at least once a year.\n\nAdditional criterion: Supplementary information about the criterion is that the top management is a natural person or group of people who make final decisions for the institution and are responsible for these. The aspects to be dealt with in the management review of the ISMS are listed in Section 9.3 of ISO/IEC 27001.\n\nComplementary customer criterion: Notes on continuous auditing feasibility - partially, the actual transmission of information to the cloud service provider's management can be logged and automated. However, the testing of the contents of the communication and the fact that these have also been included in the management assessment must still be carried out within the regular audit.\n\n5.16 Dealing with investigation requests from government agencies (INQ)\n\nObjective: Ensure appropriate handling of government investigation requests for legal review, information to cloud customers, and limitation of access to or disclosure of data.",
          "Physical security (ps). Physical security and environmental control requirements. Basic criterion: Security requirements for premises and buildings related to the cloud service provided are based on the security objectives of the information security policy, identified protection requirements for the cloud service, and the assessment of risks to physical and environmental security. The security requirements are documented, communicated, and provided in a policy or concept according to SP-01. The security requirements for data centers are based on criteria that comply with established rules of technology. They are suitable for addressing the following risks in accordance with the applicable legal and contractual requirements: faults in planning, unauthorized access, insufficient surveillance, insufficient air conditioning, fire and smoke, water, power failure, and air ventilation and filtration. If the cloud service provider uses premises or buildings operated by third parties to provide the cloud service, the document describes which security requirements the cloud service provider places on these third parties. The appropriate and effective verification of implementation is carried out in accordance with the criteria for controlling and monitoring subcontractors (cf. SSO-01, SSO-02).\n\nAdditional criterion: The security requirements include time constraints for self-sufficient operation in the event of exceptional events (e.g., prolonged power outage, heat waves, low water in cold river water supply) and maximum tolerable utility downtime. The time limits for self-sufficient operation provide for at least 48 hours in the event of a failure of the external power supply. For self-sufficient operation during a heat period, the highest outside temperatures measured to date within a radius of at least 50 km around the locations of the premises and buildings have been determined with a safety margin of 3 K. The security requirements stipulate that the permissible operating and environmental parameters of the cooling supply must also be observed on at least five consecutive days with these outside temperatures, including the safety margin (cf. PS-06 Protection against Failure of the Supply Facilities). If water is taken from a river for air conditioning, it is determined at which water levels and water temperatures the air conditioning can be maintained for how long. The maximum tolerable downtimes of utility facilities are suitable for meeting the availability requirements contained in the service level agreement.\n\nSupplementary information about the criterion: Premises and buildings related to the cloud service provided include data centers and server rooms housing system components used to process cloud customer data and the technical utilities required to operate these system components (e.g., power supply, refrigeration, fire-fighting, telecommunications, security, etc.). Backup or redundancy computer centers. Premises and buildings operated by third parties are e.g., server housing, colocation, IaaS. Premises and buildings in which no data from cloud customers is processed or stored (e.g., offices of the cloud service provider, server rooms with system components for internal development and test systems) are not subject to this criteria area. The recognized rules of technology are defined in relevant standards, e.g., EN 50600 (Facilities and Infrastructures of Data Centers). Incorrect planning can endanger the operational safety and availability of the premises or buildings. This can result from an incorrect assessment of elementary hazards at the site (e.g., air traffic, earthquakes, floods, hazardous substances) as well as an incorrect conception of the bandwidth or energy supply. Time specifications for self-sustaining operation as well as maximum tolerable downtimes of utility facilities are typically collected during the business impact analysis (cf. BCM-02, BCM-03).\n\nComplementary customer criterion notes on continuous auditing feasibility: Partially, a policy can change ad-hoc. However, the continuous audit of policies is only partially feasible as the only attributes that can be tested are the last change date and the status of review or approval, as far as this information is stored in a system. The content of a policy can hardly be tested automatically.",
          "Product safety and security (pss). Authorisation mechanisms. Basic criterion: Access to the functions provided by the cloud service is restricted by access controls (authorization mechanisms) that verify whether users, IT components, or applications are authorized to perform certain actions. The cloud service provider validates the functionality of the authorization mechanisms before new functions are made available to cloud users and in the event of changes to the authorization mechanisms of existing functions (cf. dev-06). The severity of identified vulnerabilities is assessed according to defined criteria based on industry-standard metrics (e.g., Common Vulnerability Scoring System), and measures for timely resolution or mitigation are initiated. Vulnerabilities that have not been fixed are listed in the online register of known vulnerabilities (cf. pss-02).\n\nAdditional criterion: Access controls are attribute-based to enable granular and contextual checks against multiple attributes of a user, IT component, or application (e.g., role, location, authentication method).\n\nSupplementary information about the criterion: Complementary customer criterion notes on continuous auditing feasibility: Yes, the changes to authorization mechanisms and the identification of vulnerabilities are documented in a standardized manner by the cloud service provider. This documentation can be automated and continuously audited. If the elimination of the vulnerabilities and their prioritization also takes place in a standardized form (according to standardized criteria), these points can be integrated into the continuous audit.",
          "Procurement, development and modification of information systems (dev). Testing changes. Basic criterion: Changes to the cloud service are subject to appropriate testing during software development and deployment. The type and scope of the tests correspond to the risk assessment. The tests are carried out by appropriately qualified personnel of the cloud service provider or by automated test procedures that comply with the state-of-the-art. Cloud customers are involved in the tests in accordance with the contractual requirements. The severity of the errors and vulnerabilities identified in the tests, which are relevant for the deployment decision, is determined according to defined criteria and actions for timely remediation or mitigation are initiated. \n\nAdditional criterion: Supplementary information about the criterion. The errors and vulnerabilities identified in tests can be assessed, for example, according to the Common Vulnerability Scoring System (CVSS). \n\nComplementary customer criterion: Where changes are to be tested by the cloud customers in accordance with the contractual agreements prior to deployment in the production environment, the cloud customers ensure through suitable controls that the tests are performed appropriately to identify errors. In particular, this includes timely execution of the tests by qualified personnel in accordance with the conditions specified by the cloud service provider. \n\nNotes on continuous auditing feasibility: Yes, if the tests are carried out automatically, the execution and associated results can be documented in logs. These logs can then be read continuously by the auditor. Measures for the elimination of identified vulnerabilities can also be documented and carried out in a standardized manner, so that continuous auditing is possible.",
          "Operations (ops). Protection against malware – implementation. Basic criterion: System components under the cloud service provider's responsibility that are used to deploy the cloud service in the production environment are configured with malware protection according to the policies and instructions. If protection programs are set up with signature and behavior-based malware detection and removal, these protection programs are updated at least daily.\n\nAdditional criterion: The configuration of the protection mechanisms is monitored automatically. Deviations from the specifications are automatically reported to the subject matter experts so that the deviations are immediately assessed and the necessary measures taken.\n\nSupplementary information about the criterion: Protection against malicious programs can be implemented by operating system-specific protection mechanisms or explicit protection programs (e.g., for signature- and behavior-based detection and removal of malicious programs).\n\nComplementary customer criterion: Cloud customers ensure, through suitable controls, that the layers of the cloud service for which they are responsible have security products in place to detect and remove malware.\n\nNotes on continuous auditing feasibility: Yes, the first step should be to check whether all systems are covered. This should be monitored by continuously checking a tool, including the additions and deletions of entries. In the second step, the log files for the updates of the individual servers and the regular scans should be audited continuously. Identified malware or irregularities should be marked and tracked as part of the continuous scan.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "7_the_of_service",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "7_the_of_service"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          7.458475589752197,
          7.747735023498535,
          7.800865173339844,
          7.73793888092041,
          7.886588096618652,
          7.925027370452881,
          7.751289367675781,
          7.921878337860107,
          7.501453876495361,
          7.718118190765381,
          7.588413715362549,
          7.746891975402832,
          7.679973125457764,
          7.741386890411377,
          8.51601505279541,
          7.7347092628479,
          7.778547286987305
         ],
         "y": [
          11.23072624206543,
          11.544248580932617,
          11.510095596313477,
          11.562446594238281,
          11.431112289428711,
          11.509382247924805,
          11.613245964050293,
          11.344695091247559,
          11.314804077148438,
          11.546539306640625,
          11.279671669006348,
          11.560351371765137,
          11.619725227355957,
          11.553208351135254,
          11.268342971801758,
          11.562047004699707,
          11.465665817260742
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "text": "D1",
          "x": 1.2802203118801116,
          "y": 8.824368238449097,
          "yshift": 10
         },
         {
          "showarrow": false,
          "text": "D2",
          "x": 8.764980313181876,
          "xshift": 10,
          "y": 13.36268401145935
         }
        ],
        "height": 750,
        "legend": {
         "bordercolor": "Black",
         "borderwidth": 1
        },
        "shapes": [
         {
          "line": {
           "color": "#CFD8DC",
           "width": 2
          },
          "type": "line",
          "x0": 8.764980313181876,
          "x1": 8.764980313181876,
          "y0": 4.286052465438843,
          "y1": 13.36268401145935
         },
         {
          "line": {
           "color": "#9E9E9E",
           "width": 2
          },
          "type": "line",
          "x0": 1.2802203118801116,
          "x1": 16.249740314483642,
          "y0": 8.824368238449097,
          "y1": 8.824368238449097
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.6
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(237,237,237)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(217,217,217)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 1,
            "tickcolor": "rgb(36,36,36)",
            "ticks": "outside"
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "rgb(103,0,31)"
            ],
            [
             0.1,
             "rgb(178,24,43)"
            ],
            [
             0.2,
             "rgb(214,96,77)"
            ],
            [
             0.3,
             "rgb(244,165,130)"
            ],
            [
             0.4,
             "rgb(253,219,199)"
            ],
            [
             0.5,
             "rgb(247,247,247)"
            ],
            [
             0.6,
             "rgb(209,229,240)"
            ],
            [
             0.7,
             "rgb(146,197,222)"
            ],
            [
             0.8,
             "rgb(67,147,195)"
            ],
            [
             0.9,
             "rgb(33,102,172)"
            ],
            [
             1,
             "rgb(5,48,97)"
            ]
           ],
           "sequential": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ]
          },
          "colorway": [
           "#1F77B4",
           "#FF7F0E",
           "#2CA02C",
           "#D62728",
           "#9467BD",
           "#8C564B",
           "#E377C2",
           "#7F7F7F",
           "#BCBD22",
           "#17BECF"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           }
          },
          "shapedefaults": {
           "fillcolor": "black",
           "line": {
            "width": 0
           },
           "opacity": 0.3
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "baxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          }
         }
        },
        "title": {
         "text": "Topic clusters (BERT)"
        },
        "width": 1200,
        "xaxis": {
         "visible": false
        },
        "yaxis": {
         "visible": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize Topics\n",
    "fig = topic_model.visualize_documents(docs, embeddings=embeddings)\n",
    "fig.update_layout(\n",
    "    title=\"Topic clusters (BERT)\",\n",
    "    legend=dict(bordercolor=\"Black\", borderwidth=1),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuned BERT topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train topic model using embeddings from BERT (pre-calculated)\n",
    "embeddings = np.array(list(df['finetuned_embeddings'].values))\n",
    "topic_model = BERTopic()\n",
    "topics, probs = topic_model.fit_transform(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>296</td>\n",
       "      <td>0_and_the_of_to</td>\n",
       "      <td>[and, the, of, to, system, or, information, for, access, that]</td>\n",
       "      <td>[System and services acquisition. External system services | processing, storage, and service location. Restrict the location of information processing, information or data, or system services to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>1_the_of_cloud_and</td>\n",
       "      <td>[the, of, cloud, and, criterion, service, to, in, for, are]</td>\n",
       "      <td>[Control and monitoring of service providers and suppliers (sso). Monitoring of compliance with requirements. Basic criterion: The cloud service provider monitors compliance with information secur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>109</td>\n",
       "      <td>2_and_the_or_of</td>\n",
       "      <td>[and, the, or, of, to, system, security, for, that, privacy]</td>\n",
       "      <td>[Access control. Policy and procedures. A. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]: 1. [Selection (one or more): organization-level; mission/bus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  ...                                                                                                                                                                                      Representative_Docs\n",
       "0      0  ...  [System and services acquisition. External system services | processing, storage, and service location. Restrict the location of information processing, information or data, or system services to ...\n",
       "1      1  ...  [Control and monitoring of service providers and suppliers (sso). Monitoring of compliance with requirements. Basic criterion: The cloud service provider monitors compliance with information secur...\n",
       "2      2  ...  [Access control. Policy and procedures. A. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]: 1. [Selection (one or more): organization-level; mission/bus...\n",
       "\n",
       "[3 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show summary of topics\n",
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "text",
         "hovertext": [
          null
         ],
         "marker": {
          "color": "#CFD8DC",
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "other",
         "showlegend": false,
         "type": "scattergl",
         "x": [
          null
         ],
         "y": [
          null
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Audit and accountability. Audit record review, analysis, and reporting | automated process integration. Integrate audit record review, analysis, and reporting processes using [assignment: organization-defined automated mechanisms]. Organizational processes that benefit from integrated audit record review, analysis, and reporting include incident response, continuous monitoring, contingency planning, investigation, and response to suspicious activities, and Inspector General audits.",
          "Access control. Least privilege | network access to privileged commands. Authorize network access to [assignment: organization-defined privileged commands] only for [assignment: organization-defined compelling operational needs] and document the rationale for such access in the security plan for the system. Network access is any access across a network connection, in lieu of local access (i.e., the user being physically present at the device).",
          "Physical and environmental protection. Emergency power. Provide an uninterruptible power supply to facilitate an orderly shutdown of the system or transition of the system to long-term alternate power in the event of a primary power source loss. An uninterruptible power supply (UPS) is an electrical system or mechanism that provides emergency power when there is a failure of the main power source. A UPS is typically used to protect computers, data centers, telecommunication equipment, or other electrical equipment where an unexpected power disruption could cause injuries, fatalities, serious mission or business disruption, or loss of data or information. A UPS differs from an emergency power system or backup generator in that the UPS provides near-instantaneous protection from unanticipated power interruptions from the main power source by providing energy stored in batteries, supercapacitors, or flywheels. The battery duration of a UPS is relatively short but provides sufficient time to start a standby power source, such as a backup generator, or properly shut down the system.",
          "Awareness and training. Literacy training and awareness | insider threat. Provide literacy training on recognizing and reporting potential indicators of insider threat. Potential indicators and possible precursors of insider threat can include behaviors such as inordinate, long-term job dissatisfaction; attempts to gain access to information not required for job performance; unexplained access to financial resources; bullying or harassment of fellow employees; workplace violence; and other serious violations of policies, procedures, directives, regulations, rules, or practices. Literacy training includes how to communicate the concerns of employees and management regarding potential indicators of insider threat through channels established by the organization and in accordance with established policies and procedures. Organizations may consider tailoring insider threat awareness topics to the role. For example, training for managers may be focused on changes in the behavior of team members, while training for employees may be focused on more general observations.",
          "Physical and environmental protection. Environmental controls | monitoring with alarms and notifications. Employ environmental control monitoring that provides an alarm or notification of changes potentially harmful to personnel or equipment to [assignment: organization-defined personnel or roles]. The alarm or notification may be an audible alarm or a visual message in real-time to personnel or roles defined by the organization. Such alarms and notifications can help minimize harm to individuals and damage to organizational assets by facilitating a timely incident response.",
          "System and communications protection. Cryptographic key establishment and management. Establish and manage cryptographic keys when cryptography is employed within the system in accordance with the following key management requirements: [assignment: organization-defined requirements for key generation, distribution, storage, access, and destruction]. Cryptographic key management and establishment can be performed using manual procedures or automated mechanisms with supporting manual procedures. Organizations define key management requirements in accordance with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines and specify appropriate options, parameters, and levels. Organizations manage trust stores to ensure that only approved trust anchors are part of such trust stores. This includes certificates with visibility external to organizational systems and certificates related to the internal operations of systems. NIST CMVP and NIST CAVP provide additional information on validated cryptographic modules and algorithms that can be used in cryptographic key management and establishment.",
          "Contingency planning. Contingency plan | continue mission and business functions. Plan for the continuance of [selection: all; essential] mission and business functions with minimal or no loss of operational continuity and sustain that continuity until full system restoration at primary processing and/or storage sites. Organizations may choose to conduct the contingency planning activities to continue mission and business functions as part of business continuity planning or business impact analyses. Primary processing and/or storage sites defined by organizations as part of contingency planning may change depending on the circumstances associated with the contingency.",
          "Identification and authentication. Identity proofing | identity evidence validation and verification. Require that the presented identity evidence be validated and verified through [assignment: organizational defined methods of validation and verification]. Validation and verification of identity evidence increases the assurance that accounts and identifiers are being established for the correct user and authenticators are being bound to that user. Validation refers to the process of confirming that the evidence is genuine and authentic, and the data contained in the evidence is correct, current, and related to an individual. Verification confirms and establishes a linkage between the claimed identity and the actual existence of the user presenting the evidence. Acceptable methods for validating and verifying identity evidence are consistent with the risks to the systems, roles, and privileges associated with the user's account.",
          "Audit and accountability. Audit record generation | system-wide and time-correlated audit trail. Compile audit records from [assignment: organization-defined system components] into a system-wide (logical or physical) audit trail that is time-correlated to within [assignment: organization-defined level of tolerance for the relationship between time stamps of individual records in the audit trail]. Audit trails are time-correlated if the time stamps in the individual audit records can be reliably related to the time stamps in other audit records to achieve a time ordering of the records within organizational tolerances.",
          "Physical and environmental protection. Emergency lighting. Employ and maintain automatic emergency lighting for the system that activates in the event of a power outage or disruption and that covers emergency exits and evacuation routes within the facility. The provision of emergency lighting applies primarily to organizational facilities that contain concentrations of system resources, including data centers, server rooms, and mainframe computer rooms. Emergency lighting provisions for the system are described in the contingency plan for the organization. If emergency lighting for the system fails or cannot be provided, organizations should consider alternate processing sites for power-related contingencies.",
          "Media protection. Media sanitization | review, approve, track, document, and verify. Review, approve, track, document, and verify media sanitization and disposal actions. Organizations review and approve media to be sanitized to ensure compliance with records retention policies. Tracking and documenting actions include listing personnel who reviewed and approved sanitization and disposal actions, types of media sanitized, files stored on the media, sanitization methods used, date and time of the sanitization actions, personnel who performed the sanitization, verification actions taken and personnel who performed the verification, and the disposal actions taken. Organizations verify that the sanitization of the media was effective prior to disposal.",
          "Physical and environmental protection. Physical access authorizations. a. Develop, approve, and maintain a list of individuals with authorized access to the facility where the system resides. \nb. Issue authorization credentials for facility access. \nc. Review the access list detailing authorized facility access by individuals [assignment: organization-defined frequency]. \nd. Remove individuals from the facility access list when access is no longer required. \nPhysical access authorizations apply to employees and visitors. Individuals with permanent physical access authorization credentials are not considered visitors. Authorization credentials include ID badges, identification cards, and smart cards. Organizations determine the strength of authorization credentials needed consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Physical access authorizations may not be necessary to access certain areas within facilities that are designated as publicly accessible.",
          "Access control. Remote access | protection of confidentiality and integrity using encryption. Implement cryptographic mechanisms to protect the confidentiality and integrity of remote access sessions. Virtual private networks can be used to protect the confidentiality and integrity of remote access sessions. Transport Layer Security (TLS) is an example of a cryptographic protocol that provides end-to-end communication security over networks and is used for internet communications and online transactions.",
          "Configuration management. Configuration settings | respond to unauthorized changes. Take the following actions in response to unauthorized changes to organization-defined configuration settings: alerting designated organizational personnel, restoring established configuration settings, or halting affected system processing in extreme cases.",
          "Identification and authentication. Identity proofing | address confirmation. Require that a [selection: registration code. Notice of proofing] be delivered through an out-of-band channel to verify the user's address (physical or digital) of record. To make it more difficult for adversaries to pose as legitimate users during the identity proofing process, organizations can use out-of-band methods to ensure that the individual associated with an address of record is the same individual that participated in the registration. Confirmation can take the form of a temporary enrollment code or a notice of proofing. The delivery address for these artifacts is obtained from records and not self-asserted by the user. The address can include a physical or digital address. A home address is an example of a physical address. Email addresses and telephone numbers are examples of digital addresses.",
          "Media protection. Media sanitization | equipment testing. Test sanitization equipment and procedures [assignment: organization-defined frequency] to ensure that the intended sanitization is being achieved. Testing of sanitization equipment and procedures may be conducted by qualified and authorized external entities, including federal agencies or external service providers.",
          "Contingency planning. System recovery and reconstitution | transaction recovery. Implement transaction recovery for systems that are transaction-based. Transaction-based systems include database management systems and transaction processing systems. Mechanisms supporting transaction recovery include transaction rollback and transaction journaling.",
          "System and information integrity. System monitoring | system-wide intrusion detection system. Connect and configure individual intrusion detection tools into a system-wide intrusion detection system. Linking individual intrusion detection tools into a system-wide intrusion detection system provides additional coverage and effective detection capabilities. The information contained in one intrusion detection tool can be shared widely across the organization, making the system-wide detection capability more robust and powerful.",
          "Access control. Access control for mobile devices | full device or container-based encryption. Employ full-device encryption or container-based encryption to protect the confidentiality and integrity of information on organization-defined mobile devices. Container-based encryption provides a more fine-grained approach to data and information encryption on mobile devices, including encrypting selected data structures such as files, records, or fields.",
          "Incident response. Incident monitoring | automated tracking, data collection, and analysis. Track incidents and collect and analyze incident information using [assignment: organization-defined automated mechanisms]. Automated mechanisms for tracking incidents and collecting and analyzing incident information include computer incident response centers or other electronic databases of incidents and network monitoring devices.",
          "Identification and authentication. Identification and authentication (non-organizational users) | use of defined profiles. Conform to the following profiles for identity management. [Assignment: Organization-defined identity management profiles.] Organizations define profiles for identity management based on open identity management standards. To ensure that open identity management standards are viable, robust, reliable, sustainable, and interoperable as documented, the federal government assesses and scopes the standards and technology implementations against applicable laws, executive orders, directives, policies, regulations, standards, and guidelines.",
          "Configuration management. Information location | automated tools to support information location. Use automated tools to identify organization-defined information by information type on organization-defined system components to ensure controls are in place to protect organizational information and individual privacy. The use of automated tools helps to increase the effectiveness and efficiency of the information location capability implemented within the system. Automation also helps organizations manage the data produced during information location activities and share such information across the organization. The output of automated information location tools can be used to guide and inform system architecture and design decisions.",
          "Personnel security. Personnel screening. a. Screen individuals prior to authorizing access to the system.\nb. Rescreen individuals in accordance with [assignment: organization-defined conditions requiring rescreening and, where rescreening is so indicated, the frequency of rescreening].\nPersonnel screening and rescreening activities reflect applicable laws, executive orders, directives, regulations, policies, standards, guidelines, and specific criteria established for the risk designations of assigned positions. Examples of personnel screening include background investigations and agency checks. Organizations may define different rescreening conditions and frequencies for personnel accessing systems based on types of information processed, stored, or transmitted by the systems.",
          "Access control. Information flow enforcement | physical or logical separation of information flows. Separate information flows logically or physically using [assignment: organization-defined mechanisms and/or techniques] to accomplish [assignment: organization-defined required separations by types of information]. Enforcing the separation of information flows associated with defined types of data can enhance protection by ensuring that information is not commingled while in transit and by enabling flow control by transmission paths that are not otherwise achievable. Types of separable information include inbound and outbound communications traffic, service requests and responses, and information of differing security impact or classification levels.",
          "Configuration management. Configuration change control | automated documentation, notification, and prohibition of changes. Use [assignment: organization-defined automated mechanisms] to:\n(a) document proposed changes to the system.\n(b) notify [assignment: organization-defined approval authorities] of proposed changes to the system and request change approval.\n(c) highlight proposed changes to the system that have not been approved or disapproved within [assignment: organization-defined time period].\n(d) prohibit changes to the system until designated approvals are received.\n(e) document all changes to the system.\n(f) notify [assignment: organization-defined personnel] when approved changes to the system are completed.\nNone.",
          "System and services acquisition. Acquisition process | functions, ports, protocols, and services in use. Require the developer of the system, system component, or system service to identify the functions, ports, protocols, and services intended for organizational use. The identification of functions, ports, protocols, and services early in the system development life cycle (e.g., during the initial requirements definition and design stages) allows organizations to influence the design of the system, system component, or system service. This early involvement in the system development life cycle helps organizations avoid or minimize the use of functions, ports, protocols, or services that pose unnecessarily high risks and understand the trade-offs involved in blocking specific ports, protocols, or services or requiring system service providers to do so. Early identification of functions, ports, protocols, and services avoids costly retrofitting of controls after the system, component, or system service has been implemented. SA-9 describes the requirements for external system services. Organizations identify which functions, ports, protocols, and services are provided from external sources.",
          "System and services acquisition. Development process, standards, and tools | criticality analysis. Require the developer of the system, system component, or system service to perform a criticality analysis: (a) at the following decision points in the system development life cycle: [assignment: organization-defined decision points in the system development life cycle]; and (b) at the following level of rigor: [assignment: organization-defined breadth and depth of criticality analysis]. Criticality analysis performed by the developer provides input to the criticality analysis performed by organizations. Developer input is essential to organizational criticality analysis because organizations may not have access to detailed design documentation for system components that are developed as commercial off-the-shelf products. Such design documentation includes functional specifications, high-level designs, low-level designs, source code, and hardware schematics. Criticality analysis is important for organizational systems that are designated as high-value assets. High-value assets can be moderate or high-impact systems due to heightened adversarial interest or potential adverse effects on the federal enterprise. Developer input is especially important when organizations conduct supply chain criticality analyses.",
          "Audit and accountability. Protection of audit information | store on separate physical systems or components. Store audit records [assignment: organization-defined frequency] in a repository that is part of a physically different system or system component than the system or component being audited. Storing audit records in a repository separate from the audited system or system component helps to ensure that a compromise of the system being audited does not also result in a compromise of the audit records. Storing audit records on separate physical systems or components also preserves the confidentiality and integrity of audit records and facilitates the management of audit records as an organization-wide activity. Storing audit records on separate systems or components applies to initial generation as well as backup or long-term storage of audit records.",
          "Access control. Wireless access | disable wireless networking. Disable, when not intended for use, wireless networking capabilities embedded within system components prior to issuance and deployment. Wireless networking capabilities that are embedded within system components represent a significant potential vulnerability that can be exploited by adversaries. Disabling wireless capabilities when not needed for essential organizational missions or functions can reduce susceptibility to threats by adversaries involving wireless technologies.",
          "Identification and authentication. Identity proofing | in-person validation and verification. Require that the validation and verification of identity evidence be conducted in person, before a designated registration authority. In-person proofing reduces the likelihood of fraudulent credentials being issued because it requires the physical presence of individuals, the presentation of physical identity documents, and actual face-to-face interactions with designated registration authorities.",
          "Identification and authentication. Authenticator management | no embedded unencrypted static authenticators. Ensure that unencrypted static authenticators are not embedded in applications or other forms of static storage. In addition to applications, other forms of static storage include access scripts and function keys. Organizations should exercise caution when determining whether embedded or stored authenticators are in encrypted or unencrypted form. If authenticators are used in the manner stored, then those representations are considered unencrypted authenticators.",
          "Physical and environmental protection. Physical access control | system access. Enforce physical access authorizations to the system, in addition to the physical access controls for the facility at [assignment: organization-defined physical spaces containing one or more components of the system]. Control of physical access to the system provides additional physical security for those areas within facilities where there is a concentration of system components.",
          "Personnel security. Personnel sanctions. a. Employ a formal sanctions process for individuals failing to comply with established information security and privacy policies and procedures. \n\nb. Notify [assignment: organization-defined personnel or roles] within [assignment: organization-defined time period] when a formal employee sanctions process is initiated, identifying the individual sanctioned and the reason for the sanction. \n\nOrganizational sanctions reflect applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Sanctions processes are described in access agreements and can be included as part of general personnel policies for organizations and/or specified in security and privacy policies. \n\nOrganizations consult with the Office of the General Counsel regarding matters of employee sanctions.",
          "Incident response. Incident reporting | supply chain coordination. Provide incident information to the provider of the product or service and other organizations involved in the supply chain or supply chain governance for systems or system components related to the incident. Organizations involved in supply chain activities include product developers, system integrators, manufacturers, packagers, assemblers, distributors, vendors, and resellers. Entities that provide supply chain governance include the Federal Acquisition Security Council (FASC). Supply chain incidents include compromises or breaches that involve information technology products, system components, development processes or personnel, distribution processes, or warehousing facilities. Organizations determine the appropriate information to share and consider the value gained from informing external organizations about supply chain incidents, including the ability to improve processes or to identify the root cause of an incident.",
          "System and communications protection. Secure name/address resolution service (recursive or caching resolver). Request and perform data origin authentication and data integrity verification on the name/address resolution responses the system receives from authoritative sources. Each client of name resolution services either performs this validation on its own or has authenticated channels to trusted validation providers. \n\nSystems that provide name and address resolution services for local clients include recursive resolving or caching Domain Name System (DNS) servers. DNS client resolvers either perform validation of DNSSEC signatures, or clients use authenticated channels to recursive resolvers that perform such validations. \n\nSystems that use technologies other than the DNS to map between host and service names and network addresses provide some other means to enable clients to verify the authenticity and integrity of response data.",
          "Audit and accountability. Response to audit logging process failures | storage capacity warning. Provide a warning to organization-defined personnel, roles, and/or locations within the organization-defined time period, when the allocated audit log storage volume reaches the organization-defined percentage of the repository's maximum audit log storage capacity. Please note that organizations may have multiple audit log storage repositories distributed across multiple system components. Each repository may have different storage volume capacities.",
          "Supply chain risk management family. Tamper resistance and detection | multiple stages of system development life cycle. Employ anti-tamper technologies, tools, and techniques throughout the system development life cycle. The system development life cycle includes research and development, design, manufacturing, acquisition, delivery, integration, operations and maintenance, and disposal. Organizations use a combination of hardware and software techniques for tamper resistance and detection. Organizations use obfuscation and self-checking to make reverse engineering and modifications more difficult, time-consuming, and expensive for adversaries. The customization of systems and system components can make substitutions easier to detect and, therefore, limit damage.",
          "Audit and accountability. Audit record generation. a. Provide audit record generation capability for the event types the system is capable of auditing as defined in au-2a on [assignment: organization-defined system components].\nb. Allow [assignment: organization-defined personnel or roles] to select the event types that are to be logged by specific components of the system.\nc. Generate audit records for the event types defined in au-2c that include the audit record content defined in au-3. Audit records can be generated from many different system components. The event types specified in au-2d are the event types for which audit logs are to be generated and are a subset of all event types for which the system can generate audit records.",
          "System and information integrity. Memory protection. Implement the following controls to protect the system memory from unauthorized code execution: [assignment: organization-defined controls]. Some adversaries launch attacks with the intent of executing code in non-executable regions of memory or in memory locations that are prohibited. Controls employed to protect memory include data execution prevention and address space layout randomization. Data execution prevention controls can either be hardware-enforced or software-enforced, with hardware enforcement providing the greater strength of mechanism.",
          "Audit and accountability. Non-repudiation. Provide irrefutable evidence that an individual (or process acting on behalf of an individual) has performed [assignment: organization-defined actions to be covered by non-repudiation]. Types of individual actions covered by non-repudiation include creating information, sending and receiving messages, and approving information. Non-repudiation protects against claims by authors of not having authored certain documents, senders of not having transmitted messages, receivers of not having received messages, and signatories of not having signed documents. Non-repudiation services can be used to determine if information originated from an individual or if an individual took specific actions (e.g., sending an email, signing a contract, approving a procurement request, or receiving specific information). Organizations obtain non-repudiation services by employing various techniques or mechanisms, including digital signatures and digital message receipts.",
          "Configuration management. Configuration change control | cryptography management. Ensure that cryptographic mechanisms used to provide the following controls are under configuration management: [assignment: organization-defined controls]. The controls referenced in the control enhancement refer to security and privacy controls from the control catalog. Regardless of the cryptographic mechanisms employed, processes and procedures are in place to manage those mechanisms. For example, if system components use certificates for identification and authentication, a process is implemented to address the expiration of those certificates.",
          "Access control. Account management | inactivity logout. Require that users log out when [assignment: organization-defined time period of expected inactivity or description of when to log out]. Inactivity logout is behavior- or policy-based and requires users to take physical action to log out when they are expecting inactivity longer than the defined period. Automatic enforcement of inactivity logout is addressed by AC-11.",
          "Access control. Wireless access. a. Establish configuration requirements, connection requirements, and implementation guidance for each type of wireless access; and b. Authorize each type of wireless access to the system prior to allowing such connections. Wireless technologies include microwave, packet radio (ultra-high frequency or very high frequency), 802.11x, and Bluetooth. Wireless networks use authentication protocols that provide authenticator protection and mutual authentication.",
          "Access control. Information flow enforcement | flow control of encrypted information. Prevent encrypted information from bypassing [assignment: organization-defined information flow control mechanisms] by [selection (one or more): decrypting the information; blocking the flow of the encrypted information; terminating communication sessions attempting to pass encrypted information; [assignment: organization-defined procedure or method]]. Flow control mechanisms include content checking, security policy filters, and data type identifiers. The term encryption is extended to cover encoded data not recognized by filtering mechanisms.",
          "Contingency planning. Contingency plan testing | coordinate with related plans. Coordinate contingency plan testing with organizational elements responsible for related plans. Plans related to contingency planning for organizational systems include:\n\n1. Business continuity plans\n2. Disaster recovery plans\n3. Continuity of operations plans\n4. Crisis communications plans\n5. Critical infrastructure plans\n6. Cyber incident response plans\n7. Occupant emergency plans \n\nCoordination of contingency plan testing does not require organizations to create organizational elements to handle related plans or to align such elements with specific plans. However, it does require that if such organizational elements are responsible for related plans, organizations coordinate with those elements.",
          "System and services acquisition. Allocation of resources. A. Determine the high-level information security and privacy requirements for the system or system service in mission and business process planning. \nB. Determine, document, and allocate the resources required to protect the system or system service as part of the organizational capital planning and investment control process. \nC. Establish a discrete line item for information security and privacy in organizational programming and budgeting documentation.\n\nResource allocation for information security and privacy includes funding for system and services acquisition, sustainment, and supply chain-related risks throughout the system development life cycle.",
          "Physical and environmental protection. Location of system components. Position system components within the facility to minimize potential damage from physical and environmental hazards, such as floods, fires, tornadoes, earthquakes, hurricanes, terrorism, vandalism, an electromagnetic pulse, electrical interference, and other forms of incoming electromagnetic radiation. Also, consider the location of entry points where unauthorized individuals may be near systems, even if they are not granted access. Such proximity can increase the risk of unauthorized access to organizational communications using wireless packet sniffers or microphones, or unauthorized disclosure of information.",
          "Identification and authentication. Identity proofing | identity evidence. Require evidence of individual identification be presented to the registration authority. Identity evidence, such as documentary evidence or a combination of documents and biometrics, reduces the likelihood of individuals using fraudulent identification to establish an identity or, at least, increases the work factor of potential adversaries. The forms of acceptable evidence are consistent with the risks to the systems, roles, and privileges associated with the user's account.",
          "Incident response. Information spillage response | exposure to unauthorized personnel. Employ the following controls for personnel exposed to information not within assigned access authorizations: [assignment: organization-defined controls]. Controls include ensuring that personnel who are exposed to spilled information are made aware of the laws, executive orders, directives, regulations, policies, standards, and guidelines regarding the information and the restrictions imposed based on exposure to such information.",
          "Risk assessment. Vulnerability monitoring and scanning | discoverable information. Determine information about the system that is discoverable and take [assignment: organization-defined corrective actions]. Discoverable information includes information that adversaries could obtain without compromising or breaching the system, such as by collecting information that the system is exposing or by conducting extensive web searches. Corrective actions include notifying appropriate organizational personnel, removing designated information, or changing the system to make the designated information less relevant or attractive to adversaries. This enhancement excludes intentionally discoverable information that may be part of a decoy capability (e.g., honeypots, honeynets, or deception nets) deployed by the organization.",
          "Contingency planning. System backup | test restoration using sampling. Use a sample of backup information in the restoration of selected system functions as part of contingency plan testing. Organizations need assurance that system functions can be restored correctly and can support established organizational missions. \n\nTo ensure that the selected system functions are thoroughly exercised during contingency plan testing, a sample of backup information is retrieved to determine whether the functions are operating as intended. \n\nOrganizations can determine the sample size for the functions and backup information based on the level of assurance needed.",
          "System and communications protection. Boundary protection | access points. Limit the number of external network connections to the system. Limiting the number of external network connections facilitates monitoring of inbound and outbound communications traffic. The Trusted Internet Connection (TIC) Initiative, mandated by the Department of Homeland Security (DHS), is an example of a federal guideline that requires limits on the number of external network connections. Limiting the number of external network connections to the system is important during transition periods from older to newer technologies (e.g., transitioning from IPv4 to IPv6 network protocols). Such transitions may require implementing the older and newer technologies simultaneously during the transition period and thus increase the number of access points to the system.",
          "System and information integrity. Spam protection. a. Employ spam protection mechanisms at system entry and exit points to detect and act on unsolicited messages; and b. Update spam protection mechanisms when new releases are available in accordance with organizational configuration management policy and procedures. \n\nSystem entry and exit points include firewalls, remote-access servers, electronic mail servers, web servers, proxy servers, workstations, notebook computers, and mobile devices. Spam can be transported by different means, including email, email attachments, and web accesses. \n\nSpam protection mechanisms include signature definitions.",
          "System and communications protection. Boundary protection | route traffic to authenticated proxy servers. Route [assignment: organization-defined internal communications traffic] to [assignment: organization-defined external networks] through authenticated proxy servers at managed interfaces. External networks are networks outside of organizational control. A proxy server is a server (i.e., system or application) that acts as an intermediary for clients requesting system resources from non-organizational or other organizational servers. System resources that may be requested include files, connections, web pages, or services. Client requests established through a connection to a proxy server are assessed to manage complexity and provide additional protection by limiting direct connectivity. Web content filtering devices are one of the most common proxy servers that provide access to the internet. Proxy servers can support the logging of Transmission Control Protocol (TCP) sessions and the blocking of specific Uniform Resource Locators (URLs), Internet Protocol (IP) addresses, and domain names. Web proxies can be configured with organization-defined lists of authorized and unauthorized websites. Note that proxy servers may inhibit the use of virtual private networks (VPNs) and create the potential for man-in-the-middle attacks (depending on the implementation).",
          "Access control. Least privilege | review of user privileges. (a) Review [assignment: organization-defined frequency] the privileges assigned to [assignment: organization-defined roles or classes of users] to validate the need for such privileges; and (b) reassign or remove privileges, if necessary, to correctly reflect organizational mission and business needs. The need for certain assigned user privileges may change over time to reflect changes in organizational mission and business functions, environments of operation, technologies, or threats. A periodic review of assigned user privileges is necessary to determine if the rationale for assigning such privileges remains valid. If the need cannot be revalidated, organizations take appropriate corrective actions.",
          "System and communications protection. System time synchronization. Synchronize system clocks within and between systems and system components. Time synchronization of system clocks is essential for the correct execution of many system services, including identification and authentication processes that involve certificates and time-of-day restrictions as part of access control. Denial of service or failure to deny expired credentials may result without properly synchronized clocks within and between systems and system components. Time is commonly expressed in Coordinated Universal Time (UTC), a modern continuation of Greenwich Mean Time (GMT), or local time with an offset from UTC. The granularity of time measurements refers to the degree of synchronization between system clocks and reference clocks, such as clocks synchronizing within hundreds of milliseconds or tens of milliseconds. Organizations may define different time granularities for system components. Time service can be critical to other security capabilities—such as access control and identification and authentication—depending on the nature of the mechanisms used to support the capabilities.",
          "Audit and accountability. Content of audit records | additional audit information. Generate audit records containing the following additional information: [assignment: organization-defined additional information]. The ability to add information generated in audit records is dependent on system functionality to configure the audit record content. Organizations may consider additional information in audit records, including, but not limited to, access control or flow control rules invoked, and individual identities of group account users. Organizations may also consider limiting additional audit record information to only information that is explicitly needed for audit requirements. This facilitates the use of audit trails and audit logs by not including information in audit records that could potentially be misleading, make it more difficult to locate information of interest, or increase the risk to individuals' privacy.",
          "Personnel security. Access agreements. a. Develop and document access agreements for organizational systems.\nb. Review and update the access agreements [assignment: organization-defined frequency].\nc. Verify that individuals requiring access to organizational information and systems:\n1. Sign appropriate access agreements prior to being granted access.\n2. Re-sign access agreements to maintain access to organizational systems when access agreements have been updated or [assignment: organization-defined frequency].\nAccess agreements include nondisclosure agreements, acceptable use agreements, rules of behavior, and conflict-of-interest agreements. Signed access agreements include an acknowledgement that individuals have read, understand, and agree to abide by the constraints associated with organizational systems to which access is authorized. Organizations can use electronic signatures to acknowledge access agreements unless specifically prohibited by organizational policy.",
          "System and information integrity. Software, firmware, and information integrity | integration of detection and response. Incorporate the detection of the following unauthorized changes into the organizational incident response capability: [assignment: organization-defined security-relevant changes to the system]. Integrating detection and response helps to ensure that detected events are tracked, monitored, corrected, and available for historical purposes. Maintaining historical records is important for being able to identify and discern adversary actions over an extended time period and for possible legal actions. Security-relevant changes include unauthorized changes to established configuration settings or the unauthorized elevation of system privileges.",
          "Configuration management. Signed components. Prevent the installation of [assignment: organization-defined software and firmware components] without verification that the component has been digitally signed using a certificate that is recognized and approved by the organization. Software and firmware components should not be installed unless signed with recognized and approved certificates. These components include software and firmware version updates, patches, service packs, device drivers, and basic input/output system updates. Organizations can identify applicable software and firmware components by type, specific items, or a combination of both. Digital signatures and organizational verification of such signatures are methods of code authentication.",
          "Contingency planning. Contingency plan | capacity planning. Conduct capacity planning so that necessary capacity for information processing, telecommunications, and environmental support exists during contingency operations. Capacity planning is needed because different threats can result in a reduction of the available processing, telecommunications, and support services intended to support essential mission and business functions. Organizations anticipate degraded operations during contingency operations and factor the degradation into capacity planning. For capacity planning, environmental support refers to any environmental factor for which the organization determines that it needs to provide support in a contingency situation, even if in a degraded state. Such determinations are based on an organizational assessment of risk, system categorization (impact level), and organizational risk tolerance.",
          "Audit and accountability. Audit record review, analysis, and reporting | correlate audit record repositories. Analyze and correlate audit records across different repositories to gain organization-wide situational awareness. Organization-wide situational awareness includes awareness across all three levels of risk management (i.e., organizational level, mission/business process level, and information system level) and supports cross-organization awareness.",
          "Audit and accountability. Audit record review, analysis, and reporting | central review and analysis. Provide and implement the capability to centrally review and analyze audit records from multiple components within the system. Automated mechanisms for centralized reviews and analyses include Security Information and Event Management (SIEM) products.",
          "System and information integrity. Software, firmware, and information integrity | integrity checks. Perform an integrity check of organization-defined software, firmware, and information at startup. At organization-defined transitional states or security-relevant events, perform an integrity check. Perform an integrity check at organization-defined frequency. Security-relevant events include the identification of new threats to which organizational systems are susceptible and the installation of new hardware, software, or firmware. Transitional states include system startup, restart, shutdown, and abort.",
          "System and information integrity. System monitoring | host-based devices. Implement the following host-based monitoring mechanisms at [assignment: organization-defined system components]: [assignment: organization-defined host-based monitoring mechanisms]. Host-based monitoring collects information about the host (or system in which it resides). System components in which host-based monitoring can be implemented include servers, notebook computers, and mobile devices. Organizations may consider employing host-based monitoring mechanisms from multiple product developers or vendors.",
          "Access control. Device lock | pattern-hiding displays. Conceal, via the device lock, information previously visible on the display with a publicly viewable image. The pattern-hiding display can include static or dynamic images, such as patterns used with screen savers, photographic images, solid colors, clock, battery life indicator, or a blank screen. Controlled unclassified information is not displayed.",
          "Access control. Account management | usage conditions. Enforce [assignment: organization-defined circumstances and/or usage conditions] for [assignment: organization-defined system accounts]. Specifying and enforcing usage conditions helps to enforce the principle of least privilege, increase user accountability, and enable effective account monitoring. Account monitoring includes alerts generated if the account is used in violation of organizational parameters. Organizations can describe specific conditions or circumstances under which system accounts can be used, such as by restricting usage to certain days of the week, time of day, or specific durations of time.",
          "Personnel security. Position descriptions. Incorporate security and privacy roles and responsibilities into organizational position descriptions. Specification of security and privacy roles in individual organizational position descriptions facilitates clarity in understanding the security or privacy responsibilities associated with the roles and the role-based security and privacy training requirements for the roles.",
          "Maintenance. Maintenance personnel. a. Establish a process for maintenance personnel authorization and maintain a list of authorized maintenance organizations or personnel. \nb. Verify that non-escorted personnel performing maintenance on the system possess the required access authorizations. \nc. Designate organizational personnel with required access authorizations and technical competence to supervise the maintenance activities of personnel who do not possess the required access authorizations. \n\nMaintenance personnel refers to individuals who perform hardware or software maintenance on organizational systems, while PE-2 addresses physical access for individuals whose maintenance duties place them within the physical protection perimeter of the systems. \n\nTechnical competence of supervising individuals relates to the maintenance performed on the systems, while having required access authorizations refers to maintenance on and near the systems. \n\nIndividuals not previously identified as authorized maintenance personnel—such as information technology manufacturers, vendors, systems integrators, and consultants—may require privileged access to organizational systems, such as when they are required to conduct maintenance activities with little or no notice. \n\nBased on organizational assessments of risk, organizations may issue temporary credentials to these individuals. Temporary credentials may be for one-time use or for very limited time periods.",
          "System and services acquisition. Developer testing and evaluation | threat modeling and vulnerability analyses. Require the developer of the system, system component, or system service to perform threat modeling and vulnerability analyses during development and the subsequent testing and evaluation of the system, component, or service. This should include the following: \n\n(a) Use the following contextual information: [assignment: organization-defined information concerning impact, environment of operations, known or assumed threats, and acceptable risk levels]. \n\n(b) Employ the following tools and methods: [assignment: organization-defined tools and methods]. \n\n(c) Conduct the modeling and analyses at the following level of rigor: [assignment: organization-defined breadth and depth of modeling and analyses]. \n\n(d) Produce evidence that meets the following acceptance criteria: [assignment: organization-defined acceptance criteria]. \n\nSystems, system components, and system services may deviate significantly from the functional and design specifications created during the requirements and design stages of the system development life cycle. Therefore, updates to threat modeling and vulnerability analyses of those systems, system components, and system services during development and prior to delivery are critical to the effective operation of those systems, components, and services. \n\nThreat modeling and vulnerability analyses at this stage of the system development life cycle ensure that design and implementation changes have been accounted for and that vulnerabilities created because of those changes have been reviewed and mitigated.",
          "Contingency planning. Contingency plan | identify critical assets. Identify critical system assets supporting [SELECTION: all; essential] mission and business functions. Organizations may choose to identify critical assets as part of a criticality analysis, business continuity planning, or business impact analyses. Organizations identify critical system assets so that additional controls can be employed (beyond the controls routinely implemented) to help ensure that organizational mission and business functions can continue to be conducted during contingency operations. The identification of critical information assets also facilitates the prioritization of organizational resources. Critical system assets include technical and operational aspects. Technical aspects include system components, information technology services, information technology products, and mechanisms. Operational aspects include procedures (i.e., manually executed operations) and personnel (i.e., individuals operating technical controls and/or executing manual procedures). Organizational program protection plans can assist in identifying critical assets. If critical assets are resident within or supported by external service providers, organizations consider implementing CP-2 (7) as a control enhancement.",
          "Configuration management. Impact analyses | separate test environments. Analyze changes to the system in a separate test environment before implementation in an operational environment, looking for security and privacy impacts due to flaws, weaknesses, incompatibility, or intentional malice. A separate test environment requires an environment that is physically or logically separate and distinct from the operational environment. The separation is sufficient to ensure that activities in the test environment do not impact activities in the operational environment and that information in the operational environment is not inadvertently transmitted to the test environment. Separate environments can be achieved by physical or logical means. If physically separate test environments are not implemented, organizations determine the strength of the mechanism required when implementing logical separation.",
          "System and information integrity. System monitoring | unauthorized network services. (a) Detect network services that have not been authorized or approved by [assignment: organization-defined authorization or approval processes]; and (b) [selection (one or more): audit; alert [assignment: organization-defined personnel or roles]] when detected. Unauthorized or unapproved network services include services in service-oriented architectures that lack organizational verification or validation and may therefore be unreliable or serve as malicious rogues for valid services.",
          "Security assessment and authorization. Penetration testing | red team exercises. Employ the following red-team exercises to simulate attempts by adversaries to compromise organizational systems in accordance with applicable rules of engagement: [assignment: organization-defined red team exercises]. Red team exercises extend the objectives of penetration testing by examining the security and privacy posture of organizations and the capability to implement effective cyber defenses. Red team exercises simulate attempts by adversaries to compromise mission and business functions and provide a comprehensive assessment of the security and privacy posture of systems and organizations. Such attempts may include technology-based attacks and social engineering-based attacks. Technology-based attacks include interactions with hardware, software, or firmware components and/or mission and business processes. Social engineering-based attacks include interactions via email, telephone, shoulder surfing, or personal conversations. Red team exercises are most effective when conducted by penetration testing agents and teams with knowledge of and experience with current adversarial tactics, techniques, procedures, and tools. While penetration testing may be primarily laboratory-based testing, organizations can use red team exercises to provide more comprehensive assessments that reflect real-world conditions. The results from red team exercises can be used by organizations to improve security and privacy awareness and training and to assess control effectiveness.",
          "Access control. Access enforcement. Enforce approved authorizations for logical access to information and system resources in accordance with applicable access control policies. Access control policies control access between active entities or subjects (i.e., users or processes acting on behalf of users) and passive entities or objects (i.e., devices, files, records, domains) in organizational systems. In addition to enforcing authorized access at the system level and recognizing that systems can host many applications and services in support of mission and business functions, access enforcement mechanisms can also be employed at the application and service level to provide increased information security and privacy. In contrast to logical access controls that are implemented within the system, physical access controls are addressed by the controls in the Physical and Environmental Protection (PE) family.",
          "Access control. Account management | automated temporary and emergency account management. Automatically remove temporary and emergency accounts after an organization-defined time period for each type of account. Management of temporary and emergency accounts includes the removal or disabling of such accounts automatically after a predefined time period, rather than at the convenience of the system administrator. Automatic removal or disabling of accounts provides a more consistent implementation.",
          "Maintenance. Controlled maintenance | automated maintenance activities. (a) Schedule, conduct, and document maintenance, repair, and replacement actions for the system using [assignment: organization-defined automated mechanisms]. \n(b) Produce up-to-date, accurate, and complete records of all maintenance, repair, and replacement actions requested, scheduled, in process, and completed. \nThe use of automated mechanisms to manage and control system maintenance programs and activities helps to ensure the generation of timely, accurate, complete, and consistent maintenance records.",
          "Contingency planning. System backup | transfer to alternate storage site. Transfer system backup information to the alternate storage site. [Assignment: Organization-defined time period and transfer rate consistent with the recovery time and recovery point objectives.] System backup information can be transferred to alternate storage sites either electronically or by the physical shipment of storage media.",
          "Maintenance. Timely maintenance. Obtain maintenance support and/or spare parts for [assignment: organization-defined system components] within [assignment: organization-defined time period] of failure. Organizations specify the system components that result in increased risk to organizational operations and assets, individuals, other organizations, or the nation when the functionality provided by those components is not operational. Organizational actions to obtain maintenance support include having appropriate contracts in place.",
          "Configuration management. User-installed software. a. Establish [assignment: organization-defined policies] governing the installation of software by users. \nb. Enforce software installation policies through the following methods: [assignment: organization-defined methods]. \nc. Monitor policy compliance [assignment: organization-defined frequency]. \n\nIf provided the necessary privileges, users can install software in organizational systems. To maintain control over the software installed, organizations identify permitted and prohibited actions regarding software installation. \n\nPermitted software installations include updates and security patches to existing software and downloading new applications from organization-approved app stores. Prohibited software installations include software with unknown or suspect pedigrees or software that organizations consider potentially malicious. \n\nPolicies selected for governing user-installed software are organization-developed or provided by some external entity. Policy enforcement methods can include procedural methods and automated methods.",
          "Access control. Least privilege | non-privileged access for nonsecurity functions. Require that users of system accounts (or roles) with access to [assignment: organization-defined security functions or security-relevant information] use non-privileged accounts or roles when accessing non-security functions. Requiring the use of non-privileged accounts when accessing non-security functions limits exposure when operating from within privileged accounts or roles. The inclusion of roles addresses situations where organizations implement access control policies, such as role-based access control, and where a change of role provides the same degree of assurance in the change of access authorizations for the user and the processes acting on behalf of the user as would be provided by a change between a privileged and non-privileged account.",
          "Risk assessment. Vulnerability monitoring and scanning | update vulnerabilities to be scanned. Update the system vulnerabilities to be scanned [selection (one or more): [assignment: organization-defined frequency]; prior to a new scan; when new vulnerabilities are identified and reported]. Due to the complexity of modern software, systems, and other factors, new vulnerabilities are discovered on a regular basis. It is important that newly discovered vulnerabilities are added to the list of vulnerabilities to be scanned to ensure that the organization can take steps to mitigate those vulnerabilities in a timely manner.",
          "System and services acquisition. Developer testing and evaluation | static code analysis. Require the developer of the system, system component, or system service to employ static code analysis tools to identify common flaws and document the results of the analysis. Static code analysis provides a technology and methodology for security reviews and includes checking for weaknesses in the code as well as for the incorporation of libraries or other included code with known vulnerabilities or that is out-of-date and not supported. Static code analysis can be used to identify vulnerabilities and enforce secure coding practices. It is most effective when used early in the development process, when each code change can automatically be scanned for potential weaknesses. Static code analysis can provide clear remediation guidance and identify defects for developers to fix. Evidence of the correct implementation of static analysis can include aggregate defect density for critical defect types, evidence that defects were inspected by developers or security professionals, and evidence that defects were remediated. A high density of ignored findings, commonly referred to as false positives, indicates a potential problem with the analysis process or the analysis tool. In such cases, organizations weigh the validity of the evidence against evidence from other sources.",
          "Awareness and training. Training records. a. Document and monitor information security and privacy training activities, including security and privacy awareness training and specific role-based security and privacy training. \n\nb. Retain individual training records for [assignment: organization-defined time period]. \n\nDocumentation for specialized training may be maintained by individual supervisors at the discretion of the organization. \n\nThe National Archives and Records Administration provides guidance on records retention for federal agencies.",
          "Access control. Wireless access | authentication and encryption. Protect wireless access to the system using authentication of users and encryption. Wireless networking capabilities represent a significant potential vulnerability that can be exploited by adversaries. To protect systems with wireless access points, strong authentication of users and devices, along with strong encryption, can reduce susceptibility to threats by adversaries involving wireless technologies.",
          "Personnel security. Personnel screening | information requiring special protective measures. Verify that individuals accessing a system processing, storing, or transmitting information requiring special protection. (a) Have valid access authorizations that are demonstrated by assigned official government duties. And (b) Satisfy [assignment: organization-defined additional personnel screening criteria]. \n\nOrganizational information that requires special protection includes controlled unclassified information. Personnel security criteria include position sensitivity background screening requirements.",
          "Identification and authentication. Identification and authentication (non-organizational users) | acceptance of piv credentials from other agencies. Accept and electronically verify Personal Identity Verification (PIV)-compliant credentials from other federal agencies. Acceptance of PIV credentials from other federal agencies applies to both logical and physical access control systems. PIV credentials are those credentials issued by federal agencies that conform to FIPS Publication 201 and supporting guidelines. The adequacy and reliability of PIV card issuers are addressed and authorized using SP 800-79-2.",
          "Supply chain risk management family. Tamper resistance and detection. Implement a tamper protection program for the system, system component, or system service. Anti-tamper technologies, tools, and techniques provide a level of protection for systems, system components, and services against many threats, including reverse engineering, modification, and substitution. Strong identification, combined with tamper resistance and/or tamper detection, is essential to protecting systems and components during distribution and when in use.",
          "Physical and environmental protection. Delivery and removal. a. Authorize and control [assignment: organization-defined types of system components] entering and exiting the facility; and b. Maintain records of the system components. Enforcing authorizations for entry and exit of system components may require restricting access to delivery areas and isolating the areas from the system and media libraries.",
          "Configuration management. System component inventory | accountability information. Include in the system component inventory information a means for identifying, by name, position, or role, the individuals responsible and accountable for administering those components. Identifying the individuals who are responsible and accountable for administering system components ensures that the assigned components are properly administered. Additionally, it allows organizations to contact those individuals if any action is required, such as when the component is determined to be the source of a breach, needs to be recalled or replaced, or needs to be relocated.",
          "Physical and environmental protection. Alternate work site. a. Determine and document the [assignment: organization-defined alternate work sites] allowed for use by employees. \nb. Employ the following controls at alternate work sites: [assignment: organization-defined controls]. \nc. Assess the effectiveness of controls at alternate work sites. \nd. Provide a means for employees to communicate with information security and privacy personnel in case of incidents. \n\nAlternate work sites include government facilities or the private residences of employees. While distinct from alternative processing sites, alternate work sites can provide readily available alternate locations during contingency operations. Organizations can define different sets of controls for specific alternate work sites or types of sites depending on the work-related activities conducted at the sites. Implementing and assessing the effectiveness of organization-defined controls and providing a means to communicate incidents at alternate work sites support the contingency planning activities of organizations.",
          "Incident response. Incident handling | automated incident handling processes. Support the incident handling process using organization-defined automated mechanisms. Automated mechanisms that support incident handling processes include online incident management systems and tools that support the collection of live response data, full network packet capture, and forensic analysis.",
          "Access control. Use of external systems | portable storage devices — restricted use. Restrict the use of organization-controlled portable storage devices by authorized individuals on external systems using [assignment: organization-defined restrictions]. \n\nLimits on the use of organization-controlled portable storage devices in external systems include restrictions on how the devices may be used and under what conditions the devices may be used.",
          "Contingency planning. Telecommunications services | priority of service provisions. (a) Develop primary and alternate telecommunications service agreements that contain priority-of-service provisions in accordance with availability requirements (including recovery time objectives). (b) Request telecommunications service priority for all telecommunications services used for national security emergency preparedness if the primary and/or alternate telecommunications services are provided by a common carrier. Organizations should consider the potential mission or business impact in situations where telecommunications service providers are servicing other organizations with similar priority of service provisions.\n\nTelecommunications Service Priority (TSP) is a Federal Communications Commission (FCC) program that directs telecommunications service providers (e.g., wireline and wireless phone companies) to give preferential treatment to users enrolled in the program when they need to add new lines or have their lines restored following a disruption of service, regardless of the cause. The FCC sets the rules and policies for the TSP program, and the Department of Homeland Security manages the TSP program. The TSP program is always in effect and not contingent on a major disaster or attack taking place. Federal sponsorship is required to enroll in the TSP program.",
          "Risk assessment. Vulnerability monitoring and scanning | breadth and depth of coverage. Define the breadth and depth of vulnerability scanning coverage. The breadth of vulnerability scanning coverage can be expressed as a percentage of components within the system, by the particular types of systems, by the criticality of systems, or by the number of vulnerabilities to be checked. Conversely, the depth of vulnerability scanning coverage can be expressed as the level of the system design that the organization intends to monitor (e.g., component, module, subsystem, element). Organizations can determine the sufficiency of vulnerability scanning coverage with regard to its risk tolerance and other factors. Scanning tools and how the tools are configured may affect the depth and coverage. Multiple scanning tools may be needed to achieve the desired depth and coverage. SP 800-53a provides additional information on the breadth and depth of coverage.",
          "Physical and environmental protection. Access control for output devices. Control physical access to output from [assignment: organization-defined output devices] to prevent unauthorized individuals from obtaining the output. Controlling physical access to output devices includes placing output devices in locked rooms or other secured areas with keypad or card reader access controls and allowing access to authorized individuals only. Also, placing output devices in locations that can be monitored by personnel, installing monitor or screen filters, and using headphones. Examples of output devices include monitors, printers, scanners, audio devices, facsimile machines, and copiers.",
          "System and information integrity. System monitoring | wireless intrusion detection. Employ a wireless intrusion detection system to identify rogue wireless devices and to detect attack attempts and potential compromises or breaches to the system. Wireless signals may radiate beyond organizational facilities. Organizations proactively search for unauthorized wireless connections, including the conduct of thorough scans for unauthorized wireless access points. Wireless scans are not limited to those areas within facilities containing systems but also include areas outside of facilities to verify that unauthorized wireless access points are not connected to organizational systems.",
          "Access control. Account management | automated system account management. Support the management of system accounts using [assignment: organization-defined automated mechanisms]. Automated system account management includes using automated mechanisms to create, enable, modify, disable, and remove accounts. Notify account managers when an account is created, enabled, modified, disabled, or removed, or when users are terminated or transferred. Monitor system account usage. Report atypical system account usage. Automated mechanisms can include internal system functions and email, telephonic, and text messaging notifications.",
          "Security assessment and authorization. Control assessments | leveraging results from external organizations. Leverage the results of control assessments performed by [assignment: organization-defined external organization] on [assignment: organization-defined system] when the assessment meets [assignment: organization-defined requirements]. Organizations may rely on control assessments of organizational systems by other (external) organizations. Using such assessments and reusing existing assessment evidence can decrease the time and resources required for assessments by limiting the independent assessment activities that organizations need to perform. The factors that organizations consider in determining whether to accept assessment results from external organizations can vary. Such factors include the organization's past experience with the organization that conducted the assessment, the reputation of the assessment organization, the level of detail of supporting assessment evidence provided, and mandates imposed by applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Accredited testing laboratories that support the Common Criteria program ISO 15408-1, the NIST Cryptographic Module Validation Program (CMVP), or the NIST Cryptographic Algorithm Validation Program (CAVP) can provide independent assessment results that organizations can leverage.",
          "Contingency planning. Alternate processing site | preparation for use. Prepare the alternate processing site so that the site can serve as the operational site supporting essential mission and business functions. Site preparation includes establishing configuration settings for systems at the alternate processing site consistent with the requirements for such settings at the primary site and ensuring that essential supplies and logistical considerations are in place.",
          "System and communications protection. Collaborative computing devices and applications. a. Prohibit remote activation of collaborative computing devices and applications with the following exceptions: [assignment: organization-defined exceptions where remote activation is to be allowed]. \n\nb. Provide an explicit indication of use to users physically present at the devices. Collaborative computing devices and applications include remote meeting devices and applications, networked whiteboards, cameras, and microphones. The explicit indication of use includes signals to users when collaborative computing devices and applications are activated.",
          "Audit and accountability. Protection of audit information | access by subset of privileged users. Authorize access to management of audit logging functionality to only [assignment: organization-defined subset of privileged users or roles]. Individuals or roles with privileged access to a system and who are also the subject of an audit by that system may affect the reliability of the audit information by inhibiting audit activities or modifying audit records. Requiring privileged access to be further defined between audit-related privileges and other privileges limits the number of users or roles with audit-related privileges.",
          "Maintenance. Nonlocal maintenance. a. Approve and monitor non-local maintenance and diagnostic activities.\nb. Allow the use of non-local maintenance and diagnostic tools only as consistent with organizational policy and documented in the security plan for the system.\nc. Employ strong authentication in the establishment of non-local maintenance and diagnostic sessions.\nd. Maintain records for non-local maintenance and diagnostic activities.\ne. Terminate session and network connections when non-local maintenance is completed.\n\nNon-local maintenance and diagnostic activities are conducted by individuals who communicate through either an external or internal network. Local maintenance and diagnostic activities are carried out by individuals who are physically present at the system location and not communicating across a network connection. Authentication techniques used to establish non-local maintenance and diagnostic sessions reflect the network access requirements in IA-2. Strong authentication requires authenticators that are resistant to replay attacks and employ multi-factor authentication. Strong authenticators include PKI where certificates are stored on a token protected by a password, passphrase, or biometric. \n\nEnforcing requirements in MA-4 is accomplished, in part, by other controls. SP 800-63b provides additional guidance on strong authentication and authenticators.",
          "Security assessment and authorization. Information exchange | transfer authorizations. Verify that individuals or systems transferring data between interconnecting systems have the requisite authorizations (i.e., write permissions or privileges) prior to accepting such data. To prevent unauthorized individuals and systems from making information transfers to protected systems, the protected system verifies - via independent means - whether the individual or system attempting to transfer information is authorized to do so. Verification of the authorization to transfer information also applies to control plane traffic (e.g., routing and DNS) and services (e.g., authenticated SMTP relays).",
          "System and communications protection. Session authenticity. Protect the authenticity of communication sessions. Protecting session authenticity addresses communication protection at the session level, not at the packet level. Such protection establishes grounds for confidence at both ends of communication sessions in the ongoing identities of other parties and the validity of transmitted information. Authenticity protection includes protecting against man-in-the-middle attacks, session hijacking, and the insertion of false information into sessions.",
          "Incident response. Incident handling | dynamic reconfiguration. Include the following types of dynamic reconfiguration for organization-defined system components as part of the incident response capability: organization-defined types of dynamic reconfiguration. Dynamic reconfiguration includes changes to router rules, access control lists, intrusion detection or prevention system parameters, and filter rules for guards or firewalls. Organizations may perform dynamic reconfiguration of systems to stop attacks, misdirect attackers, and isolate components of systems, thus limiting the extent of the damage from breaches or compromises. Organizations should include specific time frames for achieving the reconfiguration of systems in the definition of the reconfiguration capability, considering the potential need for rapid response to effectively address cyber threats.",
          "System and communications protection. Network disconnect. Terminate the network connection associated with a communications session at the end of the session or after [assignment: organization-defined time period] of inactivity. Network disconnect applies to internal and external networks. Terminating network connections associated with specific communications sessions includes de-allocating TCP/IP address or port pairs at the operating system level and de-allocating the networking assignments at the application level if multiple application sessions are using a single operating system-level network connection. Periods of inactivity may be established by organizations and include time periods by type of network access or for specific network accesses.",
          "Audit and accountability. Audit record retention. Retain audit records for [assignment: organization-defined time period consistent with records retention policy] to provide support for after-the-fact investigations of incidents and to meet regulatory and organizational information retention requirements. Organizations retain audit records until it is determined that the records are no longer needed for administrative, legal, audit, or other operational purposes. This includes the retention and availability of audit records relative to Freedom of Information Act (FOIA) requests, subpoenas, and law enforcement actions. Organizations develop standard categories of audit records relative to such types of actions and standard response processes for each type of action. The National Archives and Records Administration (NARA) General Records Schedules provide federal policy on records retention.",
          "Supply chain risk management family. Component authenticity | anti-counterfeit training. Train organization-defined personnel or roles to detect counterfeit system components (including hardware, software, and firmware). None.",
          "Access control. Remote access | privileged commands and access. (a) Authorize the execution of privileged commands and access to security-relevant information via remote access only in a format that provides accessible evidence and for the following needs: [assignment: organization-defined needs]. \n\n(b) Document the rationale for remote access in the security plan for the system. Remote access to systems represents a significant potential vulnerability that can be exploited by adversaries. As such, restricting the execution of privileged commands and access to security-relevant information via remote access reduces the exposure of the organization and the susceptibility to threats by adversaries to the remote access capability.",
          "Incident response. Incident response training | automated training environments. Provide an incident response training environment using [assignment: organization-defined automated mechanisms]. Automated mechanisms can provide a more thorough and realistic incident response training environment. This can be accomplished, for example, by providing more complete coverage of incident response issues, selecting more realistic training scenarios and environments, and stressing the response capability.",
          "Personnel security. Personnel termination | automated actions. Use organization-defined automated mechanisms to notify organization-defined personnel or roles of individual termination actions or disable access to system resources. In organizations with many employees, not all personnel who need to know about termination actions receive the appropriate notifications. Even if such notifications are received, they may not occur in a timely manner. Automated mechanisms can be used to send automatic alerts or notifications to organizational personnel or roles when individuals are terminated. Such automatic alerts or notifications can be conveyed in a variety of ways, including via telephone, electronic mail, text message, or websites. Automated mechanisms can also be employed to quickly and thoroughly disable access to system resources after an employee is terminated.",
          "Security assessment and authorization. Continuous monitoring | risk monitoring. Ensure risk monitoring is an integral part of the continuous monitoring strategy that includes the following: (a) effectiveness monitoring; (b) compliance monitoring; and (c) change monitoring. Risk monitoring is informed by the established organizational risk tolerance. Effectiveness monitoring determines the ongoing effectiveness of the implemented risk response measures. Compliance monitoring verifies that required risk response measures are implemented. It also verifies that security and privacy requirements are satisfied. Change monitoring identifies changes to organizational systems and environments of operation that may affect security and privacy risk.",
          "Audit and accountability. Audit record reduction and report generation. Provide and implement an audit record reduction and report generation capability that: \n\na. Supports on-demand audit record review, analysis, and reporting requirements, as well as after-the-fact investigations of incidents. \n\nb. Does not alter the original content or time ordering of audit records. \n\nAudit record reduction is a process that manipulates collected audit log information and organizes it into a summary format that is more meaningful to analysts. \n\nAudit record reduction and report generation capabilities do not always emanate from the same system or the same organizational entities that conduct audit logging activities. \n\nThe audit record reduction capability includes modern data mining techniques with advanced data filters to identify anomalous behavior in audit records. \n\nThe report generation capability provided by the system can generate customizable reports. \n\nTime ordering of audit records can be an issue if the granularity of the timestamp in the record is insufficient.",
          "Audit and accountability. Protection of audit information. A. Protect audit information and audit logging tools from unauthorized access, modification, and deletion.\nB. Alert [assignment: organization-defined personnel or roles] upon detection of unauthorized access, modification, or deletion of audit information.\nAudit information includes all information needed to successfully audit system activity, such as audit records, audit log settings, audit reports, and personally identifiable information. Audit logging tools are those programs and devices used to conduct system audit and logging activities.\nProtection of audit information focuses on technical protection and limits the ability to access and execute audit logging tools to authorized individuals. Physical protection of audit information is addressed by both media protection controls and physical and environmental protection controls.",
          "System and communications protection. Protection of information at rest | cryptographic protection. Implement cryptographic mechanisms to prevent unauthorized disclosure and modification of the following information at rest on [assignment: organization-defined system components or media]: [assignment: organization-defined information]. The selection of cryptographic mechanisms is based on the need to protect the confidentiality and integrity of organizational information. The strength of the mechanism is commensurate with the security category or classification of the information. Organizations have the flexibility to encrypt information on system components or media or encrypt data structures, including files, records, or fields.",
          "Contingency planning. Alternate storage site. a. Establish an alternate storage site, including necessary agreements to permit the storage and retrieval of system backup information; and b. Ensure that the alternate storage site provides controls equivalent to those of the primary site. Alternate storage sites are geographically distinct from primary storage sites and maintain duplicate copies of information and data if the primary storage site is not available. Similarly, alternate processing sites provide processing capability if the primary processing site is not available. Geographically distributed architectures that support contingency requirements may be considered as alternate storage sites. Items covered by alternate storage site agreements include environmental conditions at the alternate sites, access rules for systems and facilities, physical and environmental protection requirements, and coordination of delivery and retrieval of backup media. Alternate storage sites reflect the requirements in contingency plans so that organizations can maintain essential mission and business functions despite compromise, failure, or disruption in organizational systems.",
          "Contingency planning. Telecommunications services | separation of primary and alternate providers. Obtain alternate telecommunications services from providers that are separated from primary service providers to reduce susceptibility to the same threats. Threats that affect telecommunications services are defined in organizational assessments of risk and include natural disasters, structural failures, cyber or physical attacks, and errors of omission or commission. Organizations can reduce common susceptibilities by minimizing shared infrastructure among telecommunications service providers and achieving sufficient geographic separation between services. Organizations may consider using a single service provider in situations where the service provider can provide alternate telecommunications services that meet the separation needs addressed in the risk assessment.",
          "Personnel security. Personnel transfer. a. Review and confirm the ongoing operational need for current logical and physical access authorizations to systems and facilities when individuals are reassigned or transferred to other positions within the organization. \nb. Initiate [assignment: organization-defined transfer or reassignment actions] within [assignment: organization-defined time period following the formal transfer action]. \nc. Modify access authorization as needed to correspond with any changes in operational need due to reassignment or transfer. \nd. Notify [assignment: organization-defined personnel or roles] within [assignment: organization-defined time period]. \nPersonnel transfer applies when reassignments or transfers of individuals are permanent or of such extended duration as to make the actions warranted. Organizations define actions appropriate for the types of reassignments or transfers, whether permanent or extended. Actions that may be required for personnel transfers or reassignments to other positions within organizations include returning old and issuing new keys, identification cards, and building passes; closing system accounts and establishing new accounts; changing system access authorizations (i.e., privileges); and providing for access to official records to which individuals had access at previous work locations and in previous system accounts.",
          "Configuration management. Access restrictions for change | privilege limitation for production and operation. (a) Limit privileges to change system components and system-related information within a production or operational environment; and (b) review and reevaluate privileges [assignment: organization-defined frequency]. In many organizations, systems support multiple mission and business functions. Limiting privileges to change system components with respect to operational systems is necessary because changes to a system component may have far-reaching effects on mission and business processes supported by the system. The relationships between systems and mission/business processes are, in some cases, unknown to developers. System-related information includes operational procedures.",
          "System and services acquisition. External system services | processing, storage, and service location. Restrict the location of information processing, information or data, or system services to organization-defined locations based on organization-defined requirements or conditions. The location of information processing, information and data storage, or system services can have a direct impact on the ability of organizations to successfully execute their mission and business functions. The impact occurs when external providers control the location of processing, storage, or services. The criteria that external providers use for the selection of processing, storage, or service locations may be different from the criteria that organizations use. For example, organizations may desire that data or information storage locations be restricted to certain locations to help facilitate incident response activities in case of information security incidents or breaches. Incident response activities, including forensic analyses and after-the-fact investigations, may be adversely affected by the governing laws, policies, or protocols in the locations where processing and storage occur and/or the locations from which system services emanate.",
          "System and communications protection. Boundary protection | isolation of system components. Employ boundary protection mechanisms to isolate [assignment: organization-defined system components] supporting [assignment: organization-defined missions and/or business functions]. Organizations can isolate system components that perform different mission or business functions. Such isolation limits unauthorized information flows among system components and provides the opportunity to deploy greater levels of protection for selected system components. Isolating system components with boundary protection mechanisms provides the capability for increased protection of individual system components and to more effectively control information flows between those components. Isolating system components provides enhanced protection that limits the potential harm from hostile cyber-attacks and errors. The degree of isolation varies depending upon the mechanisms chosen. Boundary protection mechanisms include routers, gateways, and firewalls that separate system components into physically separate networks or subnetworks; cross-domain devices that separate subnetworks; virtualization techniques; and the encryption of information flows among system components using distinct encryption keys.",
          "Planning. Rules of behavior | social media and external site/application usage restrictions. Include in the rules of behavior restrictions on:\n\n(a) Use of social media, social networking sites, and external sites/applications.\n\n(b) Posting organizational information on public websites.\n\n(c) Use of organization-provided identifiers (e.g., email addresses) and authentication secrets (e.g., passwords) for creating accounts on external sites/applications.\n\nSocial media, social networking, and external site/application usage restrictions address rules of behavior related to the use of social media, social networking, and external sites when organizational personnel are using such sites for official duties or in the conduct of official business. It also applies when organizational information is involved in social media and social networking transactions, and when personnel access social media and networking sites from organizational systems.\n\nOrganizations should also address specific rules that prevent unauthorized entities from obtaining non-public organizational information from social media and networking sites, either directly or through inference. Non-public information includes personally identifiable information and system account information.",
          "Incident response. Incident reporting | automated reporting. Report incidents using [Assignment: organization-defined automated mechanisms]. The recipients of incident reports are specified in IR-6b. Automated reporting mechanisms include email, posting on websites (with automatic updates), and automated incident response tools and programs.",
          "Configuration management. Configuration change control | security and privacy representatives. Require organization-defined security and privacy representatives to be members of the organization-defined configuration change control element. Information security and privacy representatives include system security officers, senior agency information security officers, senior agency officials for privacy, or system privacy officers. Representation by personnel with information security and privacy expertise is important because changes to system configurations can have unintended side effects, some of which may be security- or privacy-relevant. Detecting such changes early in the process can help avoid unintended, negative consequences that could ultimately affect the security and privacy posture of systems. The configuration change control element referred to in the second organization-defined parameter reflects the change control elements defined by organizations in CM-3g.",
          "Physical and environmental protection. Fire protection | suppression systems — automatic activation and notification. (a) Employ fire suppression systems that activate automatically and notify [assignment: organization-defined personnel or roles] and [assignment: organization-defined emergency responders]. (b) Employ an automatic fire suppression capability when the facility is not staffed on a continuous basis. Organizations can identify specific personnel, roles, and emergency responders if individuals on the notification list need to have appropriate access authorizations and/or clearances (e.g., to enter facilities where access is restricted due to the impact level or classification of information within the facility). Notification mechanisms may require independent energy sources to ensure that the notification capability is not adversely affected by the fire.",
          "Contingency planning. Alternate processing site | accessibility. Identify potential accessibility problems to alternate processing sites in the event of an area-wide disruption or disaster and outline explicit mitigation actions. Area-wide disruptions refer to those types of disruptions that are broad in geographic scope, with such determinations made by organizations based on organizational assessments of risk.",
          "Audit and accountability. Protection of audit information | cryptographic protection. Implement cryptographic mechanisms to protect the integrity of audit information and audit tools. Cryptographic mechanisms used for protecting the integrity of audit information include signed hash functions using asymmetric cryptography. This enables the distribution of the public key to verify the hash information while maintaining the confidentiality of the secret key used to generate the hash.",
          "Contingency planning. Alternate storage site | recovery time and recovery point objectives. Configure the alternate storage site to facilitate recovery operations in accordance with recovery time and recovery point objectives. Organizations establish recovery time and recovery point objectives as part of contingency planning. Configuration of the alternate storage site includes physical facilities and the systems supporting recovery operations that ensure accessibility and correct execution.",
          "Incident response. Incident response testing. Test the effectiveness of the incident response capability for the system [assignment: organization-defined frequency] using the following tests: [assignment: organization-defined tests]. Organizations test incident response capabilities to determine their effectiveness and identify potential weaknesses or deficiencies. Incident response testing includes the use of checklists, walk-through or tabletop exercises, and simulations (parallel or full interrupt). Incident response testing can include a determination of the effects on organizational operations and assets and individuals due to incident response. The use of qualitative and quantitative data aids in determining the effectiveness of incident response processes.",
          "Access control. Use of external systems | limits on authorized use. Permit authorized individuals to use an external system to access the system or to process, store, or transmit organization-controlled information only after: (a) verification of the implementation of controls on the external system as specified in the organization's security and privacy policies and security and privacy plans; or (b) retention of approved system connection or processing agreements with the organizational entity hosting the external system. Limiting authorized use recognizes circumstances where individuals using external systems may need to access organizational systems. Organizations need assurance that the external systems contain the necessary controls so as not to compromise, damage, or otherwise harm organizational systems. Verification that the required controls have been implemented can be achieved by external, independent assessments, attestations, or other means, depending on the confidence level required by organizations.",
          "Configuration management. Access restrictions for change. Define, document, approve, and enforce physical and logical access restrictions associated with changes to the system. Changes to the hardware, software, or firmware components of systems or the operational procedures related to the system can potentially have significant effects on the security of the systems or individuals' privacy. Therefore, organizations permit only qualified and authorized individuals to access systems for purposes of initiating changes. Access restrictions include physical and logical access controls (see AC-3 and PE-3), software libraries, workflow automation, media libraries, abstract layers (i.e., changes implemented into external interfaces rather than directly into systems), and change windows (i.e., changes occur only during specified times).",
          "Physical and environmental protection. Environmental controls. a. Maintain [selection (one or more): temperature; humidity; pressure; radiation; [assignment: organization-defined environmental control]] levels within the facility where the system resides at [assignment: organization-defined acceptable levels]. \n\nb. Monitor environmental control levels [assignment: organization-defined frequency]. \n\nThe provision of environmental controls applies primarily to organizational facilities that contain concentrations of system resources (e.g., data centers, mainframe computer rooms, and server rooms). Insufficient environmental controls, especially in very harsh environments, can have a significant adverse impact on the availability of systems and system components that are needed to support organizational mission and business functions.",
          "Risk assessment. Vulnerability monitoring and scanning | privileged access. Implement privileged access authorization to [assignment: organization-defined system components] for [assignment: organization-defined vulnerability scanning activities]. In certain situations, the nature of the vulnerability scanning may be more intrusive, or the system component that is the subject of the scanning may contain classified or controlled unclassified information, such as personally identifiable information. Privileged access authorization to selected system components facilitates more thorough vulnerability scanning and protects the sensitive nature of such scanning.",
          "Configuration management. Access restrictions for change | automated access enforcement and audit records. (a) Enforce access restrictions using organization-defined automated mechanisms. \n(b) Automatically generate audit records of the enforcement actions. \nOrganizations log system accesses associated with applying configuration changes to ensure that configuration change control is implemented and to support after-the-fact actions should organizations discover any unauthorized changes.",
          "Security assessment and authorization. Plan of action and milestones. A. Develop a plan of action and milestones for the system to document the planned remediation actions of the organization. This will help to correct weaknesses or deficiencies noted during the assessment of the controls and to reduce or eliminate known vulnerabilities in the system. \n\nB. Update the existing plan of action and milestones, at a frequency determined by the organization, based on the findings from control assessments, independent audits or reviews, and continuous monitoring activities. \n\nPlans of action and milestones are useful for any type of organization to track planned remedial actions. They are required in authorization packages and are subject to federal reporting requirements established by the OMB.",
          "System and information integrity. Error handling. a. Generate error messages that provide information necessary for corrective actions without revealing information that could be exploited, and \nb. Reveal error messages only to organization-defined personnel or roles. Organizations should consider the structure and content of error messages. The extent to which systems can handle error conditions is guided and informed by organizational policy and operational requirements. Exploitable information includes stack traces and implementation details. Erroneous logon attempts with passwords mistakenly entered as the username, mission or business information that can be derived from, if not stated explicitly by, the information recorded, and personally identifiable information such as account numbers, social security numbers, and credit card numbers. Error messages may also provide a covert channel for transmitting information.",
          "System and communications protection. Boundary protection | fail secure. Prevent systems from entering insecure states in the event of an operational failure of a boundary protection device. Fail-secure is a condition achieved by employing mechanisms to ensure that, in the event of operational failures of boundary protection devices at managed interfaces, systems do not enter unsecure states where intended security properties no longer hold. Managed interfaces include routers, firewalls, and application gateways that reside on protected subnetworks (commonly referred to as demilitarized zones). Failures of boundary protection devices cannot lead to or cause information external to the devices to enter the devices, nor can failures permit unauthorized information releases.",
          "Security assessment and authorization. Control assessments | specialized assessments. Include as part of control assessments, [assignment: organization-defined frequency]. [Selection: Announced; Unannounced]. [Selection (one or more): In-depth monitoring; Security instrumentation; Automated security test cases; Vulnerability scanning; Malicious user testing; Insider threat assessment; Performance and load testing; Data leakage or data loss assessment; [assignment: organization-defined other forms of assessment]]. Organizations can conduct specialized assessments, including verification and validation, system monitoring, insider threat assessments, malicious user testing, and other forms of testing. These assessments can improve readiness by exercising organizational capabilities and indicating current levels of performance as a means of focusing actions to improve security and privacy. Organizations conduct specialized assessments in accordance with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Authorizing officials approve the assessment methods in coordination with the organizational risk executive function. Organizations can include vulnerabilities uncovered during assessments into vulnerability remediation processes. Specialized assessments can also be conducted early in the system development life cycle (e.g., during initial design, development, and unit testing).",
          "Access control. Account management | restrictions on use of shared and group accounts. Only permit the use of shared and group accounts that meet [assignment: organization-defined conditions for establishing shared and group accounts]. Before permitting the use of shared or group accounts, organizations should consider the increased risk due to the lack of accountability associated with such accounts.",
          "System and information integrity. Software, firmware, and information integrity | automated notifications of integrity violations. Employ automated tools that provide notification to [assignment: organization-defined personnel or roles] upon discovering discrepancies during integrity verification. The employment of automated tools to report system and information integrity violations and to notify organizational personnel in a timely manner is essential to effective risk response. Personnel with an interest in system and information integrity violations include mission and business owners, system owners, senior agency information security official, senior agency official for privacy, system administrators, software developers, systems integrators, information security officers, and privacy officers.",
          "Contingency planning. System recovery and reconstitution | restore within time period. Provide the capability to restore system components within [assignment: organization-defined restoration time periods] from configuration-controlled and integrity-protected information representing a known, operational state for the components. Restoration of system components includes reimaging, which restores the components to known, operational states.",
          "Access control. Least privilege | privilege levels for code execution. Prevent the following software from executing at higher privilege levels than users executing the software: [assignment: organization-defined software]. In certain situations, software applications or programs need to execute with elevated privileges to perform required functions. However, depending on the software functionality and configuration, if the privileges required for execution are at a higher level than the privileges assigned to organizational users invoking such applications or programs, those users may indirectly be provided with greater privileges than assigned.",
          "Physical and environmental protection. Visitor access records. a. Maintain visitor access records to the facility where the system resides for [assignment: organization- defined time period].\nb. Review visitor access records [assignment: organization-defined frequency].\nc. Report anomalies in visitor access records to [assignment: organization-defined personnel].\n\nVisitor access records include the names and organizations of individuals visiting, visitor signatures, forms of identification, dates of access, entry and departure times, purpose of visits, and the names and organizations of individuals visited. \n\nAccess record reviews determine if access authorizations are current and are still required to support the organizational mission and business functions. Access records are not required for publicly accessible areas.",
          "System and communications protection. Boundary protection | dynamic isolation and segregation. Provide the capability to dynamically isolate [assignment: organization-defined system components] from other system components. The capability to dynamically isolate certain internal system components is useful when it is necessary to partition or separate system components of questionable origin from components that possess greater trustworthiness. Component isolation reduces the attack surface of organizational systems. Isolating selected system components can also limit the damage from successful attacks when such attacks occur.",
          "Access control. Account management | account monitoring for atypical usage. (a) Monitor system accounts for [assignment: organization-defined atypical usage]; and (b) report atypical usage of system accounts to [assignment: organization-defined personnel or roles]. Atypical usage includes accessing systems at certain times of the day or from locations that are not consistent with the normal usage patterns of individuals. Monitoring for atypical usage may reveal rogue behavior by individuals or an attack in progress. Account monitoring may inadvertently create privacy risks since data collected to identify atypical usage may reveal previously unknown information about the behavior of individuals. Organizations assess and document privacy risks from monitoring accounts for atypical usage in their privacy impact assessment and make determinations that are in alignment with their privacy program plan.",
          "Identification and authentication. Cryptographic module authentication. Implement mechanisms for authentication to a cryptographic module that meet the requirements of applicable laws, executive orders, directives, policies, regulations, standards, and guidelines for such authentication. Authentication mechanisms may be required within a cryptographic module to authenticate an operator accessing the module and to verify that the operator is authorized to assume the requested role and perform services within that role.",
          "System and communications protection. Transmission confidentiality and integrity | cryptographic protection. Implement cryptographic mechanisms to prevent unauthorized disclosure of information during transmission. \nEncryption protects information from unauthorized disclosure and modification during transmission. \nCryptographic mechanisms that protect the confidentiality and integrity of information during transmission include TLS and IPsec. \nCryptographic mechanisms used to protect information integrity include cryptographic hash functions that have applications in digital signatures, checksums, and message authentication codes.",
          "System and information integrity. Software, firmware, and information integrity. a. Employ integrity verification tools to detect unauthorized changes to the following software, firmware, and information: [assignment: organization-defined software, firmware, and information]. \nb. Take the following actions when unauthorized changes to the software, firmware, and information are detected: [assignment: organization-defined actions]. Unauthorized changes to software, firmware, and information can occur due to errors or malicious activity. Software includes operating systems (with key internal components such as kernels or drivers), middleware, and applications. Firmware interfaces include Unified Extensible Firmware Interface (UEFI) and Basic Input/Output System (BIOS). Information includes personally identifiable information and metadata that contains security and privacy attributes associated with information. Integrity checking mechanisms, including parity checks, cyclical redundancy checks, cryptographic hashes, and associated tools, can automatically monitor the integrity of systems and hosted applications.",
          "System and services acquisition. External system services | identification of functions, ports, protocols, and services. Require providers of the following external system services to identify the functions, ports, protocols, and other services required for the use of such services: [assignment: organization-defined external system services]. Information from external service providers regarding the specific functions, ports, protocols, and services used in the provision of such services can be useful when the need arises to understand the trade-offs involved in restricting certain functions and services or blocking certain ports and protocols.",
          "Audit and accountability. Audit record review, analysis, and reporting | correlation with physical monitoring. Correlate information from audit records with information obtained from monitoring physical access to further enhance the ability to identify suspicious, inappropriate, unusual, or malevolent activity. The correlation of physical audit record information and the audit records from systems may assist organizations in identifying suspicious behavior or supporting evidence of such behavior. For example, the correlation of an individual's identity for logical access to certain systems with the additional physical security information that the individual was present at the facility when the logical access occurred may be useful in investigations.",
          "System and communications protection. Cryptographic key establishment and management | availability. Maintain availability of information in the event of the loss of cryptographic keys by users. Escrowing of encryption keys is a common practice for ensuring availability in the event of key loss. A forgotten passphrase is an example of losing a cryptographic key.",
          "Contingency planning. Telecommunications services. Establish alternate telecommunications services, including necessary agreements to permit the resumption of [assignment: organization-defined system operations] for essential mission and business functions within [assignment: organization-defined time period], when the primary telecommunications capabilities are unavailable at either the primary or alternate processing or storage sites. \n\nTelecommunications services (for data and voice) for primary and alternate processing and storage sites are in scope for CP-8. Alternate telecommunications services reflect the continuity requirements in contingency plans to maintain essential mission and business functions despite the loss of primary telecommunications services. \n\nOrganizations may specify different time periods for primary or alternate sites. Alternate telecommunications services include additional organizational or commercial ground-based circuits or lines, network-based approaches to telecommunications, or the use of satellites. Organizations consider factors such as availability, quality of service, and access when entering into alternate telecommunications agreements.",
          "System and information integrity. System monitoring | inbound and outbound communications traffic. (A) Determine criteria for unusual or unauthorized activities or conditions for inbound and outbound communications traffic.\n(B) Monitor inbound and outbound communications traffic [Assignment: organization-defined frequency] for [Assignment: organization-defined unusual or unauthorized activities or conditions].\n\nUnusual or unauthorized activities or conditions related to system inbound and outbound communications traffic include internal traffic that indicates the presence of malicious code or unauthorized use of legitimate code or credentials within organizational systems or propagating among system components, signaling to external systems, and the unauthorized exporting of information. Evidence of malicious code or unauthorized use of legitimate code or credentials is used to identify potentially compromised systems or system components.",
          "Incident response. Incident monitoring. Track and document incidents. Documenting incidents includes maintaining records about each incident, the status of the incident, and other pertinent information necessary for forensics, as well as evaluating incident details, trends, and handling. Incident information can be obtained from a variety of sources, including network monitoring, incident reports, incident response teams, user complaints, supply chain partners, audit monitoring, physical access monitoring, and user and administrator reports. IR-4 provides information on the types of incidents that are appropriate for monitoring.",
          "Identification and authentication. Authenticator management | protection of authenticators. Protect authenticators commensurate with the security category of the information to which the use of the authenticator permits access. For systems that contain multiple security categories of information without reliable physical or logical separation between categories, authenticators used to grant access to the systems are protected commensurate with the highest security category of information on the systems. Security categories of information are determined as part of the security categorization process.",
          "System and information integrity. Information management and retention. Manage and retain information within the system and information output from the system in accordance with applicable laws, executive orders, directives, regulations, policies, standards, guidelines, and operational requirements. Information management and retention requirements cover the full life cycle of information, in some cases extending beyond system disposal. Information to be retained may also include policies, procedures, plans, reports, data output from control implementation, and other types of administrative information.\n\nThe National Archives and Records Administration (NARA) provides federal policy and guidance on records retention and schedules. If organizations have a records management office, consider coordinating with records management personnel. Records produced from the output of implemented controls that may require management and retention include, but are not limited to: all XX-1, AC-6 (9), AT-4, AU-12, CA-2, CA-3, CA-5, CA-6, CA-7, CA-8, CA-9, CM-2, CM-3, CM-4, CM-6, CM-8, CM-9, CM-12, CM-13, CP-2, IR-6, IR-8, MA-2, MA-4, PE-2, PE-8, PE-16, PE-17, PL-2, PL-4, PL-7, PL-8, PM-5, PM-8, PM-9, PM-18, PM-21, PM-27, PM-28, PM-30, PM-31, PS-2, PS-6, PS-7, PT-2, PT-3, PT-7, RA-2, RA-3, RA-5, RA-8, SA-4, SA-5, SA-8, SA-10, SI-4, SR-2, SR-4, SR-8.",
          "System and communications protection. Separation of system and user functionality. Separate user functionality, including user interface services, from system management functionality. System management functionality includes functions that are necessary to administer databases, network components, workstations, or servers. These functions typically require privileged user access. \n\nThe separation of user functions from system management functions can be physical or logical. Organizations may choose to separate system management functions from user functions by utilizing different computers, instances of operating systems, central processing units, or network addresses. They can also employ virtualization techniques or a combination of other methods. \n\nThe separation of system management functions from user functions should also extend to web administrative interfaces. These interfaces should employ separate authentication methods compared to users accessing other system resources. \n\nIn addition, it is recommended to isolate administrative interfaces on different domains and implement additional access controls. \n\nAchieving the separation of system and user functionality can be accomplished by applying the systems security engineering design principles outlined in SA-8. This includes SA-8(1), SA-8(3), SA-8(4), SA-8(10), SA-8(12), SA-8(13), SA-8(14), and SA-8(18).",
          "Physical and environmental protection. Visitor access records | automated records maintenance and review. Maintain and review visitor access records using [assignment: organization-defined automated mechanisms]. Visitor access records may be stored and maintained in a database management system that is accessible by organizational personnel. Automated access to such records facilitates record reviews on a regular basis to determine if access authorizations are current and still required to support organizational mission and business functions.",
          "Access control. Account management | automated audit actions. Automatically audit account creation, modification, enabling, disabling, and removal actions. Account management audit records are defined in accordance with AU-2 and reviewed, analyzed, and reported in accordance with AU-6.",
          "Incident response. Incident reporting. a. Require personnel to report suspected incidents to the organizational incident response capability within [assignment: organization-defined time period]. \nb. Report incident information to [assignment: organization-defined authorities]. \n\nThe types of incidents reported, the content and timeliness of the reports, and the designated reporting authorities reflect applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Incident information can inform risk assessments, control effectiveness assessments, security requirements for acquisitions, and selection criteria for technology products.",
          "Maintenance. Maintenance tools | inspect tools. Inspect the maintenance tools used by maintenance personnel for improper or unauthorized modifications. Maintenance tools can be directly brought into a facility by maintenance personnel or downloaded from a vendor's website. If, upon inspection of the maintenance tools, organizations determine that the tools have been modified in an improper manner or the tools contain malicious code, the incident is handled consistent with organizational policies and procedures for incident handling.",
          "System and communications protection. Boundary protection | host-based protection. Implement organization-defined host-based boundary protection mechanisms at organization-defined system components. Host-based boundary protection mechanisms include host-based firewalls. System components that employ host-based boundary protection mechanisms include servers, workstations, notebook computers, and mobile devices.",
          "Access control. Least privilege | authorize access to security functions. Authorize access for an organization-defined individuals or roles to:\n(a) organization-defined security functions (deployed in hardware, software, and firmware).\n(b) organization-defined security-relevant information.\n\nSecurity functions include establishing system accounts, configuring access authorizations (i.e., permissions, privileges), configuring settings for events to be audited, and establishing intrusion detection parameters. \n\nSecurity-relevant information includes filtering rules for routers or firewalls, configuration parameters for security services, cryptographic key management information, and access control lists.\n\nAuthorized personnel include security administrators, system administrators, system security officers, system programmers, and other privileged users.",
          "Access control. Wireless access | antennas and transmission power levels. Select radio antennas and calibrate transmission power levels to reduce the probability that signals from wireless access points can be received outside of organization-controlled boundaries. Actions that may be taken to limit unauthorized use of wireless communications outside of organization-controlled boundaries include reducing the power of wireless transmissions so that the transmissions are less likely to emit a signal that can be captured outside of the physical perimeters of the organization, employing measures such as emissions security to control wireless emanations, and using directional or beamforming antennas that reduce the likelihood that unintended receivers will be able to intercept signals. Prior to taking such mitigating actions, organizations can conduct periodic wireless surveys to understand the radio frequency profile of organizational systems as well as other systems that may be operating in the area.",
          "Configuration management. Baseline configuration | configure systems and components for high-risk areas. (a) Issue [assignment: organization-defined systems or system components] with [assignment: organization-defined configurations] to individuals traveling to locations that the organization deems to be of significant risk; and (b) apply the following controls to the systems or components when the individuals return from travel: [assignment: organization-defined controls]. When it is known that systems or system components will be in high-risk areas external to the organization, additional controls may be implemented to counter the increased threat in such areas. For example, organizations can take actions for notebook computers used by individuals departing on and returning from travel. Actions include determining the locations that are of concern, defining the required configurations for the components, ensuring that components are configured as intended before travel is initiated, and applying controls to the components after travel is completed. Specially configured notebook computers include computers with sanitized hard drives, limited applications, and more stringent configuration settings. Controls applied to mobile devices upon return from travel include examining the mobile device for signs of physical tampering and purging and reimaging disk drives. Protecting information that resides on mobile devices is addressed in the MP (Media Protection) family.",
          "System and information integrity. Security alerts, advisories, and directives | automated alerts and advisories. Broadcast security alert and advisory information throughout the organization using organization-defined automated mechanisms. The significant number of changes to organizational systems and environments of operation requires the dissemination of security-related information to a variety of organizational entities that have a direct interest in the success of the organizational mission and business functions. Based on information provided by security alerts and advisories, changes may be required at one or more of the three levels related to the management of risk, including the governance level, mission and business process level, and the information system level.",
          "Risk assessment. Vulnerability monitoring and scanning | review historic audit logs. Review historic audit logs to determine if a vulnerability identified in an organization-defined system has been previously exploited within an organization-defined time period. Reviewing historic audit logs to determine if a recently detected vulnerability in a system has been previously exploited by an adversary can provide important information for forensic analyses. Such analyses can help identify, for example, the extent of a previous intrusion, the tradecraft employed during the attack, organizational information exfiltrated or modified, mission or business capabilities affected, and the duration of the attack.",
          "Identification and authentication. Authenticator management | expiration of cached authenticators. Prohibit the use of cached authenticators after [assignment: organization-defined time period]. Cached authenticators are used to authenticate to the local machine when the network is not available. If cached authentication information is out of date, the validity of the authentication information may be questionable.",
          "Identification and authentication. Authentication feedback. Obscure feedback of authentication information during the authentication process to protect the information from possible exploitation and use by unauthorized individuals. Authentication feedback from systems does not provide information that would allow unauthorized individuals to compromise authentication mechanisms. For some types of systems, such as desktops or notebooks with relatively large monitors, the threat (referred to as shoulder surfing) may be significant. For other types of systems, such as mobile devices with small displays, the threat may be less significant and is balanced against the increased likelihood of typographic input errors due to small keyboards. Thus, the means for obscuring authentication feedback is selected accordingly. Obscuring authentication feedback includes displaying asterisks when users type passwords into input devices or displaying feedback for a very limited time before obscuring it.",
          "System and information integrity. System monitoring | analyze traffic and covert exfiltration. Analyze outbound communications traffic at external interfaces to the system and at the following interior points to detect covert exfiltration of information: [assignment: organization-defined interior points within the system]. Organization-defined interior points include subnetworks and subsystems. Covert means that can be used to exfiltrate information include steganography.",
          "Access control. Least privilege | prohibit non-privileged users from executing privileged functions. Prevent non-privileged users from executing privileged functions. Privileged functions include disabling, circumventing, or altering implemented security or privacy controls, establishing system accounts, performing system integrity checks, and administering cryptographic key management activities. Non-privileged users are individuals who do not possess appropriate authorizations. Privileged functions that require protection from non-privileged users include circumventing intrusion detection and prevention mechanisms or malicious code protection mechanisms. Preventing non-privileged users from executing privileged functions is enforced by AC-3.",
          "Identification and authentication. Identification and authentication (organizational users) | acceptance of piv credentials. Accept and electronically verify personal identity verification-compliant credentials. Acceptance of personal identity verification (PIV)-compliant credentials applies to organizations implementing logical access control and physical access control systems. PIV-compliant credentials are those credentials issued by federal agencies that conform to FIPS Publication 201 and supporting guidance documents. The adequacy and reliability of PIV card issuers are authorized using SP 800-79-2. Acceptance of PIV-compliant credentials includes derived PIV credentials, the use of which is addressed in SP 800-166. The DoD Common Access Card (CAC) is an example of a PIV credential.",
          "Contingency planning. Contingency plan testing | alternate processing site. Test the contingency plan at the alternate processing site: (a) to familiarize contingency personnel with the facility and available resources; and (b) to evaluate the capabilities of the alternate processing site to support contingency operations. Conditions at the alternate processing site may be significantly different than the conditions at the primary site. Having the opportunity to visit the alternate site and experience the actual capabilities available at the site can provide valuable information on potential vulnerabilities that could affect essential organizational mission and business functions. The on-site visit can also provide an opportunity to refine the contingency plan to address the vulnerabilities discovered during testing.",
          "Contingency planning. System backup | cryptographic protection. Implement cryptographic mechanisms to prevent unauthorized disclosure and modification of [assignment: organization-defined backup information]. The selection of cryptographic mechanisms is based on the need to protect the confidentiality and integrity of backup information. The strength of the mechanisms selected is commensurate with the security category or classification of the information. Cryptographic protection applies to system backup information in storage at both primary and alternate locations. Organizations that implement cryptographic mechanisms to protect information at rest also consider cryptographic key management solutions.",
          "Incident response. Incident handling. a. Implement an incident handling capability for incidents that is consistent with the incident response plan and includes preparation, detection and analysis, containment, eradication, and recovery. \nb. Coordinate incident handling activities with contingency planning activities. \nc. Incorporate lessons learned from ongoing incident handling activities into incident response procedures, training, and testing, and implement the resulting changes accordingly. \nd. Ensure the rigor, intensity, scope, and results of incident handling activities are comparable and predictable across the organization. \n\nOrganizations recognize that incident response capabilities are dependent on the capabilities of organizational systems and the mission and business processes being supported by those systems. Organizations consider incident response as part of the definition, design, and development of mission and business processes and systems. Incident-related information can be obtained from a variety of sources, including audit monitoring, physical access monitoring, and network monitoring; user or administrator reports; and reported supply chain events. \n\nAn effective incident handling capability includes coordination among many organizational entities (e.g., mission or business owners, system owners, authorizing officials, human resources offices, physical security offices, personnel security offices, legal departments, risk executive [function], operations personnel, procurement offices). \n\nSuspected security incidents include the receipt of suspicious email communications that can contain malicious code. Suspected supply chain incidents include the insertion of counterfeit hardware or malicious code into organizational systems or system components. \n\nFor federal agencies, an incident that involves personally identifiable information is considered a breach. A breach results in unauthorized disclosure, the loss of control, unauthorized acquisition, compromise, or a similar occurrence where a person other than an authorized user accesses or potentially accesses personally identifiable information or an authorized user accesses or potentially accesses such information for other than authorized purposes.",
          "System and information integrity. System monitoring | automated tools and mechanisms for real-time analysis. Employ automated tools and mechanisms to support near real-time analysis of events. Automated tools and mechanisms include host-based, network-based, transport-based, or storage-based event monitoring tools and mechanisms or security information and event management (SIEM) technologies that provide real-time analysis of alerts and notifications generated by organizational systems. Automated monitoring techniques can create unintended privacy risks because automated controls may connect to external or otherwise unrelated systems. The matching of records between these systems may create linkages with unintended consequences. Organizations assess and document these risks in their Privacy Impact Assessment and make determinations that are in alignment with their privacy program plan.",
          "System and communications protection. Boundary protection | deny by default — allow by exception. Deny network communications traffic by default and allow network communications traffic by exception. Denying by default and allowing by exception applies to inbound and outbound network communications traffic. A deny-all, permit-by-exception network communications traffic policy ensures that only those system connections that are essential and approved are allowed. Deny by default, allow by exception also applies to a system that is connected to an external system.",
          "Audit and accountability. Audit record review, analysis, and reporting | integrated analysis of audit records. Integrate analysis of audit records with analysis of [selection (one or more): vulnerability scanning information; performance data; system monitoring information; [assignment: organization-defined data/information collected from other sources]] to further enhance the ability to identify inappropriate or unusual activity. Integrated analysis of audit records does not require vulnerability scanning, the generation of performance data, or system monitoring. Rather, integrated analysis requires that the analysis of information generated by scanning, monitoring, or other data collection activities is integrated with the analysis of audit record information. Security information and event management tools can facilitate audit record aggregation or consolidation from multiple system components, as well as audit record correlation and analysis. The use of standardized audit record analysis scripts developed by organizations (with localized script adjustments, as necessary) provides more cost-effective approaches for analyzing audit record information collected. The correlation of audit record information with vulnerability scanning information is important in determining the veracity of vulnerability scans of the system and in correlating attack detection events with scanning results. Correlation with performance data can uncover denial-of-service attacks or other types of attacks that result in the unauthorized use of resources. Correlation with system monitoring information can assist in uncovering attacks and in better relating audit information to operational situations.",
          "System and communications protection. Public key infrastructure certificates. a. Issue public key certificates under an [assignment: organization-defined certificate policy] or obtain public key certificates from an approved service provider; and b. Include only approved trust anchors in trust stores or certificate stores managed by the organization. Public Key Infrastructure (PKI) certificates are certificates with visibility external to organizational systems and certificates related to the internal operations of systems, such as application-specific time services. In cryptographic systems with a hierarchical structure, a trust anchor is an authoritative source (i.e., a certificate authority) for which trust is assumed and not derived. A root certificate for a PKI system is an example of a trust anchor. A trust store or certificate store maintains a list of trusted root certificates.",
          "Risk assessment. Risk response. Respond to findings from security and privacy assessments, monitoring, and audits in accordance with organizational risk tolerance. Organizations have many options for responding to risk, including mitigating risk by implementing new controls or strengthening existing controls, accepting risk with appropriate justification or rationale, sharing or transferring risk, or avoiding risk. The risk tolerance of the organization influences risk response decisions and actions. Risk response addresses the need to determine an appropriate response to risk before generating a Plan of Action and Milestones (POA&M) entry. For example, the response may be to accept risk or reject risk, or it may be possible to mitigate the risk immediately so that a POA&M entry is not needed. However, if the risk response is to mitigate the risk and the mitigation cannot be completed immediately, a POA&M entry is generated.",
          "Access control. Least privilege. Employ the principle of least privilege, allowing only authorized accesses for users (or processes acting on behalf of users) that are necessary to accomplish assigned organizational tasks. Organizations employ least privilege for specific duties and systems. The principle of least privilege is also applied to system processes, ensuring that the processes have access to systems and operate at privilege levels no higher than necessary to accomplish organizational missions or business functions. Organizations consider the creation of additional processes, roles, and accounts as necessary to achieve least privilege. Organizations apply least privilege to the development, implementation, and operation of organizational systems.",
          "Physical and environmental protection. Monitoring physical access | intrusion alarms and surveillance equipment. Monitor physical access to the facility where the system resides using physical intrusion alarms and surveillance equipment. Physical intrusion alarms can be employed to alert security personnel when unauthorized access to the facility is attempted. Alarm systems work in conjunction with physical barriers, physical access control systems, and security guards by triggering a response when these other forms of security have been compromised or breached. Physical intrusion alarms can include different types of sensor devices, such as motion sensors, contact sensors, and broken glass sensors. Surveillance equipment includes video cameras installed at strategic locations throughout the facility.",
          "System and communications protection. Cryptographic protection. a. Determine the organization-defined cryptographic uses; and b. Implement the following types of cryptography required for each specified cryptographic use: organization-defined types of cryptography for each specified cryptographic use. Cryptography can be employed to support a variety of security solutions, including the protection of classified information and controlled unclassified information, the provision and implementation of digital signatures, and the enforcement of information separation when authorized individuals have the necessary clearances but lack the necessary formal access approvals. Cryptography can also be used to support random number and hash generation. Generally applicable cryptographic standards include FIPS-validated cryptography and NSA-approved cryptography. For example, organizations that need to protect classified information may specify the use of NSA-approved cryptography. Organizations that need to provision and implement digital signatures may specify the use of FIPS-validated cryptography. Cryptography is implemented in accordance with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines.",
          "Identification and authentication. Identification and authentication (non-organizational users). Uniquely identify and authenticate non-organizational users or processes acting on behalf of non-organizational users. Non-organizational users include system users other than organizational users explicitly covered by IA-2. Non-organizational users are uniquely identified and authenticated for accesses other than those explicitly identified and documented in AC-14. Identification and authentication of non-organizational users accessing federal systems may be required to protect federal, proprietary, or privacy-related information (with exceptions noted for national security systems).\n\nOrganizations consider many factors – including security, privacy, scalability, and practicality – when balancing the need to ensure ease of use for access to federal information and systems with the need to protect and adequately mitigate risk.",
          "Access control. Remote access | monitoring and control. Employ automated mechanisms to monitor and control remote access methods. Monitoring and control of remote access methods allows organizations to detect attacks and help ensure compliance with remote access policies by auditing the connection activities of remote users on a variety of system components, including servers, notebook computers, workstations, smartphones, and tablets. Audit logging for remote access is enforced by AU-2. Audit events are defined in AU-2a.",
          "System and services acquisition. Acquisition process | use of approved piv products. Employ only information technology products on the FIPS 201-approved products list for Personal Identity Verification (PIV) capability implemented within organizational systems. Products on the FIPS 201-approved products list meet NIST requirements for Personal Identity Verification (PIV) of federal employees and contractors. PIV cards are used for multi-factor authentication in systems and organizations.",
          "Configuration management. Configuration change control | testing, validation, and documentation of changes. Test, validate, and document changes to the system before finalizing the implementation of the changes. Changes to systems include modifications to hardware, software, or firmware components and configuration settings defined in CM-6. Organizations ensure that testing does not interfere with system operations that support organizational mission and business functions. Individuals or groups conducting tests understand security and privacy policies and procedures, system security and privacy policies and procedures, and the health, safety, and environmental risks associated with specific facilities or processes. Operational systems may need to be taken offline, or replicated to the extent feasible, before testing can be conducted. If systems must be taken offline for testing, the tests are scheduled to occur during planned system outages whenever possible. If the testing cannot be conducted on operational systems, organizations employ compensating controls.",
          "Incident response. Information spillage response | post-spill operations. Implement the following procedures to ensure that organizational personnel impacted by information spills can continue to carry out assigned tasks while contaminated systems are undergoing corrective actions:\n\n[Assignment: Organization-defined procedures]. Corrective actions for systems contaminated due to information spillages may be time-consuming. Personnel may not have access to the contaminated systems while corrective actions are being taken, which may potentially affect their ability to conduct organizational business.",
          "Identification and authentication. Identity proofing. a. Identity proof users that require accounts for logical access to systems, based on appropriate identity assurance level requirements as specified in applicable standards and guidelines. \nb. Resolve user identities to a unique individual. \nc. Collect, validate, and verify identity evidence. \n\nIdentity proofing is the process of collecting, validating, and verifying a user’s identity information for the purposes of establishing credentials for accessing a system. Identity proofing is intended to mitigate threats to the registration of users and the establishment of their accounts. \n\nStandards and guidelines specifying identity assurance levels for identity proofing include SP 800-63-3 and SP 800-63a. Organizations may be subject to laws, executive orders, directives, regulations, or policies that address the collection of identity evidence. \n\nOrganizational personnel consult with the senior agency official for privacy and legal counsel regarding such requirements.",
          "Physical and environmental protection. Emergency shutoff. a. Provide the capability of shutting off power to [assignment: organization-defined system or individual system components] in emergency situations. \nb. Place emergency shutoff switches or devices in [assignment: organization-defined location by system or system component] to facilitate access for authorized personnel. \nc. Protect emergency power shutoff capability from unauthorized activation. \n\nEmergency power shutoff primarily applies to organizational facilities that contain concentrations of system resources, including data centers, mainframe computer rooms, server rooms, and areas with computer-controlled machinery.",
          "Configuration management. System component inventory | automated maintenance. Maintain the currency, completeness, accuracy, and availability of the inventory of system components using [assignment: organization-defined automated mechanisms]. Organizations maintain system inventories to the extent feasible. For example, virtual machines can be difficult to monitor because such machines are not visible to the network when not in use. In such cases, organizations maintain as up-to-date, complete, and accurate an inventory as is deemed reasonable. Automated maintenance can be achieved by the implementation of CM-2 (2) for organizations that combine system component inventory and baseline configuration activities.",
          "Contingency planning. Contingency plan | resume mission and business functions. Plan for the resumption of [selection: all; essential] mission and business functions within [assignment: organization-defined time period] of contingency plan activation. Organizations may choose to conduct contingency planning activities to resume mission and business functions as part of business continuity planning or as part of business impact analyses. Organizations prioritize the resumption of mission and business functions. The time period for resuming mission and business functions may be dependent on the severity and extent of the disruptions to the system and its supporting infrastructure.",
          "Physical and environmental protection. Monitoring physical access. a. Monitor physical access to the facility where the system resides to detect and respond to physical security incidents. \nb. Review physical access logs [assignment: organization-defined frequency] and upon occurrence of [assignment: organization-defined events or potential indications of events].\nc. Coordinate results of reviews and investigations with the organizational incident response capability.\n\nPhysical access monitoring includes publicly accessible areas within organizational facilities. Examples of physical access monitoring include the employment of guards, video surveillance equipment (i.e., cameras), and sensor devices. \n\nReviewing physical access logs can help identify suspicious activity, anomalous events, or potential threats. The reviews can be supported by audit logging controls, such as AU-2, if the access logs are part of an automated system.\n\nOrganizational incident response capabilities include investigations of physical security incidents and responses to the incidents. Incidents include security violations or suspicious physical access activities. Suspicious physical access activities include accesses outside of normal work hours, repeated accesses to areas not normally accessed, accesses for unusual lengths of time, and out-of-sequence accesses.",
          "Configuration management. Baseline configuration | automation support for accuracy and currency. Maintain the currency, completeness, accuracy, and availability of the baseline configuration of the system using [assignment: organization-defined automated mechanisms]. Automated mechanisms that help organizations maintain consistent baseline configurations for systems include configuration management tools, hardware, software, firmware inventory tools, and network management tools. Automated tools can be used at the organization level, mission and business process level, or system level on workstations, servers, notebook computers, network components, or mobile devices. Tools can be used to track version numbers on operating systems, applications, types of software installed, and current patch levels. Automation support for accuracy and currency can be satisfied by the implementation of CM-8 (2) for organizations that combine system component inventory and baseline configuration activities.",
          "Physical and environmental protection. Access control for transmission. Control physical access to [assignment: organization-defined system distribution and transmission lines] within organizational facilities using [assignment: organization-defined security controls]. Security controls applied to system distribution and transmission lines prevent accidental damage, disruption, and physical tampering. Such controls may also be necessary to prevent eavesdropping or modification of unencrypted transmissions. Security controls used to control physical access to system distribution and transmission lines include disconnected or locked spare jacks, locked wiring closets, protection of cabling by conduit or cable trays, and wiretapping sensors.",
          "Identification and authentication. Authenticator management | multiple system accounts. Implement [assignment: organization-defined security controls] to manage the risk of compromise due to individuals having accounts on multiple systems. When individuals have accounts on multiple systems and use the same authenticators, such as passwords, there is the risk that a compromise of one account may lead to the compromise of other accounts. Alternative approaches include having different authenticators (passwords) on all systems, employing a single sign-on or federation mechanism, or using some form of one-time passwords on all systems. Organizations can also use rules of behavior (see PL-4) and access agreements (see PS-6) to mitigate the risk of multiple system accounts.",
          "Supply chain risk management family. Component authenticity | configuration control for component service and repair. Maintain configuration control over the following system components awaiting service or repair and serviced or repaired components awaiting return to service: [assignment: organization-defined system components]. None.",
          "Supply chain risk management family. Inspection of systems or components. Inspect the following systems or system components [selection (one or more): at random; at [assignment: organization-defined frequency], upon [assignment: organization-defined indications of need for inspection]] to detect tampering: [assignment: organization-defined systems or system components]. The inspection of systems or system components for tamper resistance and detection addresses physical and logical tampering and is applied to systems and system components removed from organization-controlled areas. Indications of a need for inspection include changes in packaging, specifications, factory location, or entity in which the part is purchased, and when individuals return from travel to high-risk locations.",
          "Configuration management. Software usage restrictions. a. Use software and associated documentation in accordance with contract agreements and copyright laws. \nb. Track the use of software and associated documentation protected by quantity licenses to control copying and distribution. \nc. Control and document the use of peer-to-peer file sharing technology to ensure that this capability is not used for the unauthorized distribution, display, performance, or reproduction of copyrighted work. \n\nSoftware license tracking can be accomplished by manual or automated methods, depending on organizational needs. Examples of contract agreements include software license agreements and non-disclosure agreements.",
          "Configuration management. Least functionality | prevent program execution. Prevent program execution in accordance with [selection (one or more): [assignment: organization-defined policies, rules of behavior, and/or access agreements regarding software program usage and restrictions]; rules authorizing the terms and conditions of software program usage]. Prevention of program execution addresses organizational policies, rules of behavior, and/or access agreements that restrict software usage and the terms and conditions imposed by the developer or manufacturer, including software licensing and copyrights. Restrictions include prohibiting auto-execute features, restricting roles allowed to approve program execution, permitting or prohibiting specific software programs, or restricting the number of program instances executed at the same time.",
          "Access control. Remote access | managed access control points. Route remote accesses through authorized and managed network access control points. Organizations consider the Trusted Internet Connections (TIC) initiative - DHS TIC requirements for external network connections, since limiting the number of access control points for remote access reduces attack surfaces.",
          "Security assessment and authorization. Continuous monitoring | independent assessment. Employ independent assessors or assessment teams to monitor the controls in the system on an ongoing basis. Organizations maximize the value of control assessments by requiring that assessments be conducted by assessors with appropriate levels of independence. The level of required independence is based on organizational continuous monitoring strategies. Assessor independence provides a degree of impartiality to the monitoring process. To achieve such impartiality, assessors do not create a mutual or conflicting interest with the organizations where the assessments are being conducted, assess their own work, act as management or employees of the organizations they are serving, or place themselves in advocacy positions for the organizations acquiring their services.",
          "System and information integrity. Spam protection | automatic updates. Automatically update spam protection mechanisms [assignment: organization-defined frequency]. Using automated mechanisms to update spam protection mechanisms helps to ensure that updates occur on a regular basis and provide the latest content and protection capabilities.",
          "System and communications protection. Process isolation. Maintain a separate execution domain for each executing system process. Systems can maintain separate execution domains for each executing process by assigning each process a separate address space. Each system process has a distinct address space so that communication between processes is performed in a manner controlled through the security functions, and one process cannot modify the executing code of another process. Maintaining separate execution domains for executing processes can be achieved, for example, by implementing separate address spaces. Process isolation technologies, including sandboxing or virtualization, logically separate software and firmware from other software, firmware, and data. Process isolation helps limit the access of potentially untrusted software to other system resources. The capability to maintain separate execution domains is available in commercial operating systems that employ multi-state processor technologies.",
          "Audit and accountability. Audit log storage capacity. Allocate audit log storage capacity to accommodate [assignment: organization-defined audit log retention requirements]. Organizations consider the types of audit logging to be performed and the audit log processing requirements when allocating audit log storage capacity. Allocating sufficient audit log storage capacity reduces the likelihood of such capacity being exceeded and resulting in the potential loss or reduction of audit logging capability.",
          "System and services acquisition. External system services | risk assessments and organizational approvals. (a) Conduct an organizational assessment of risk prior to the acquisition or outsourcing of information security services; and (b) verify that the acquisition or outsourcing of dedicated information security services is approved by [assignment: organization-defined personnel or roles]. Information security services include the operation of security devices, such as firewalls or key management services, as well as incident monitoring, analysis, and response. Risks assessed can include system, mission or business, security, privacy, or supply chain risks.",
          "Incident response. Incident handling | information correlation. Correlate incident information and individual incident responses to achieve an organization-wide perspective on incident awareness and response. Sometimes, a threat event, such as a hostile cyber-attack, can only be observed by bringing together information from different sources, including various reports and reporting procedures established by organizations.",
          "Configuration management. Impact analyses. Analyze changes to the system to determine potential security and privacy impacts prior to change implementation. Organizational personnel with security or privacy responsibilities conduct impact analyses. Individuals conducting impact analyses possess the necessary skills and technical expertise to analyze the changes to systems as well as the security or privacy ramifications.\n\nImpact analyses include:\n- Reviewing security and privacy plans, policies, and procedures to understand control requirements.\n- Reviewing system design documentation and operational procedures to understand control implementation and how specific system changes might affect the controls.\n- Reviewing the impact of changes on organizational supply chain partners with stakeholders.\n- Determining how potential changes to a system create new risks to the privacy of individuals and the ability of implemented controls to mitigate those risks.\n\nImpact analyses also include risk assessments to understand the impact of the changes and determine if additional controls are required.",
          "Identification and authentication. Identification and authentication (organizational users) | individual authentication with group authentication. When shared accounts or authenticators are employed, require users to be individually authenticated before granting access to the shared accounts or resources. Individual authentication prior to shared group authentication mitigates the risk of using group accounts or authenticators.",
          "Contingency planning. Telecommunications services | provider contingency plan. (a) Require primary and alternate telecommunications service providers to have contingency plans. \n(b) Review provider contingency plans to ensure that the plans meet organizational contingency requirements. \n(c) Obtain evidence of contingency testing and training by providers [assignment: organization-defined frequency]. Reviews of provider contingency plans consider the proprietary nature of such plans. In some situations, a summary of provider contingency plans may be sufficient evidence for organizations to satisfy the review requirement. Telecommunications service providers may also participate in ongoing disaster recovery exercises in coordination with the Department of Homeland Security and state and local governments. Organizations may use these types of activities to satisfy evidentiary requirements related to service provider contingency plan reviews, testing, and training.",
          "Media protection. Media access. Restrict access to [assignment: organization-defined types of digital and/or non-digital media] to [assignment: organization-defined personnel or roles]. System media includes digital and non-digital media. Digital media includes flash drives, diskettes, magnetic tapes, external or removable hard disk drives (e.g., solid state, magnetic), compact discs, and digital versatile discs. Non-digital media includes paper and microfilm. Denying access to patient medical records in a community hospital unless the individuals seeking access to such records are authorized healthcare providers is an example of restricting access to non-digital media. Limiting access to the design specifications stored on compact discs in the media library to individuals on the system development team is an example of restricting access to digital media.",
          "Audit and accountability. Audit record reduction and report generation | automatic processing. Provide and implement the capability to process, sort, and search audit records for events of interest based on the following content: [assignment: organization-defined fields within audit records]. \n\nEvents of interest can be identified by the content of audit records, including system resources involved, information objects accessed, identities of individuals, event types, event locations, event dates and times, internet protocol addresses involved, or event success or failure. \n\nOrganizations may define event criteria to any degree of granularity required, such as locations selectable by a general networking location or by specific system component.",
          "Contingency planning. Contingency plan | coordinate with related plans. Coordinate contingency plan development with organizational elements responsible for related plans. Plans that are related to contingency plans include:\n- Business continuity plans\n- Disaster recovery plans\n- Critical infrastructure plans\n- Continuity of operations plans\n- Crisis communications plans\n- Insider threat implementation plans\n- Data breach response plans\n- Cyber incident response plans\n- Breach response plans\n- Occupant emergency plans.",
          "Access control. Concurrent session control. Limit the number of concurrent sessions for each organization-defined account and/or account type to the organization-defined number. Organizations may define the maximum number of concurrent sessions for system accounts globally, by account type, by account, or any combination thereof. For example, organizations may limit the number of concurrent sessions for system administrators or other individuals working in particularly sensitive domains or mission-critical applications. Concurrent session control addresses concurrent sessions for system accounts. It does not, however, address concurrent sessions by single users via multiple system accounts.",
          "Awareness and training. Literacy training and awareness | social engineering and mining. Provide literacy training on recognizing and reporting potential and actual instances of social engineering and social mining. Social engineering is an attempt to trick an individual into revealing information or taking an action that can be used to breach, compromise, or otherwise adversely impact a system. Social engineering includes phishing, pretexting, impersonation, baiting, quid pro quo, thread-jacking, social media exploitation, and tailgating. Social mining is an attempt to gather information about the organization that may be used to support future attacks. Literacy training includes information on how to communicate the concerns of employees and management regarding potential and actual instances of social engineering and data mining through organizational channels based on established policies and procedures.",
          "Physical and environmental protection. Water damage protection | automation support. Detect the presence of water near the system and alert [assignment: organization-defined personnel or roles] using [assignment: organization-defined automated mechanisms]. Automated mechanisms include notification systems, water detection sensors, and alarms.",
          "Incident response. Incident response training | simulated events. Incorporate simulated events into incident response training to facilitate the required response by personnel in crisis situations. Organizations establish requirements for responding to incidents in incident response plans. Incorporating simulated events into incident response training helps to ensure that personnel understand their individual responsibilities and what specific actions to take in crisis situations.",
          "Supply chain risk management family. Notification agreements. Establish agreements and procedures with entities involved in the supply chain for the system, system component, or system service for the [selection (one or more): notification of supply chain compromises; results of assessments or audits; [assignment: organization-defined information]]. The establishment of agreements and procedures facilitates communications among supply chain entities. Early notification of compromises and potential compromises in the supply chain that can potentially adversely affect or have adversely affected organizational systems or system components is essential for organizations to effectively respond to such incidents. The results of assessments or audits may include open-source information that contributed to a decision or result, and could be used to help the supply chain entity resolve a concern or improve its processes.",
          "Physical and environmental protection. Power equipment and cabling. Protect power equipment and power cabling for the system from damage and destruction. Organizations determine the types of protection necessary for the power equipment and cabling employed at different locations that are both internal and external to organizational facilities and environments of operation. Types of power equipment and cabling include internal cabling and uninterruptible power sources in offices or data centers, generators and power cabling outside of buildings, and power sources for self-contained components such as satellites, vehicles, and other deployable systems.",
          "Supply chain risk management family. Component authenticity. a. Develop and implement an anti-counterfeit policy and procedures that include the means to detect and prevent counterfeit components from entering the system. \nb. Report counterfeit system components to the source of the counterfeit component; organization-defined external reporting organizations; organization-defined personnel or roles. \nSources of counterfeit components include manufacturers, developers, vendors, and contractors. \nAnti-counterfeiting policies and procedures support tamper resistance and provide a level of protection against the introduction of malicious code. \nExternal reporting organizations include CISA.",
          "Contingency planning. System backup | separate storage for critical information. Store backup copies of [assignment: organization-defined critical system software and other security-related information] in a separate facility or in a fire-rated container that is not collocated with the operational system. Separate storage for critical information applies to all critical information regardless of the type of backup storage media. Critical system software includes operating systems, middleware, cryptographic key management systems, and intrusion detection systems. Security-related information includes inventories of system hardware, software, and firmware components. Alternate storage sites, including geographically distributed architectures, serve as separate storage facilities for organizations. Organizations may provide separate storage by implementing automated backup processes at alternative storage sites (e.g., data centers). The General Services Administration (GSA) establishes standards and specifications for security and fire-rated containers.",
          "Contingency planning. Telecommunications services | single points of failure. Obtain alternate telecommunications services to reduce the likelihood of sharing a single point of failure with primary telecommunications services. In certain circumstances, telecommunications service providers or services may share the same physical lines, which increases the vulnerability of a single failure point. It is important to have provider transparency for the actual physical transmission capability for telecommunication services.",
          "Access control. Account management | privileged user accounts. (a) Establish and administer privileged user accounts in accordance with [selection: a role-based access scheme; an attribute-based access scheme]. \n(b) Monitor privileged role or attribute assignments. \n(c) Monitor changes to roles or attributes. \n(d) Revoke access when privileged role or attribute assignments are no longer appropriate. \n\nPrivileged roles are organization-defined roles assigned to individuals that allow those individuals to perform certain security-relevant functions that ordinary users are not authorized to perform. Privileged roles include key management, account management, database administration, system and network administration, and web administration. \n\nA role-based access scheme organizes permitted system access and privileges into roles. In contrast, an attribute-based access scheme specifies allowed system access and privileges based on attributes.",
          "Audit and accountability. Response to audit logging process failures | real-time alerts. Provide an alert within [assignment: organization-defined real-time period] to [assignment: organization-defined personnel, roles, and/or locations] when the following audit failure events occur: [assignment: organization-defined audit logging failure events requiring real-time alerts]. Alerts provide organizations with urgent messages. Real-time alerts provide these messages at information technology speed (i.e., the time from event detection to alert occurs in seconds or less).",
          "Contingency planning. System backup. a. Conduct backups of user-level information contained in [assignment: organization-defined system components] [assignment: organization-defined frequency consistent with recovery time and recovery point objectives].\nb. Conduct backups of system-level information contained in the system [assignment: organization-defined frequency consistent with recovery time and recovery point objectives].\nc. Conduct backups of system documentation, including security- and privacy-related documentation [assignment: organization-defined frequency consistent with recovery time and recovery point objectives].\nd. Protect the confidentiality, integrity, and availability of backup information. System-level information includes system state information, operating system software, middleware, application software, and licenses. User-level information includes information other than system-level information. Mechanisms employed to protect the integrity of system backups include digital signatures and cryptographic hashes. Protection of system backup information while in transit is addressed by mp-5 and sc-8. System backups reflect the requirements in contingency plans as well as other organizational requirements for backing up information. Organizations may be subject to laws, executive orders, directives, regulations, or policies with requirements regarding specific categories of information (e.g., personal health information). Organizational personnel consult with the senior agency official for privacy and legal counsel regarding such requirements.",
          "Personnel security. Personnel termination. Upon termination of individual employment: a. Disable system access within [assignment: organization-defined time period]. b. Terminate or revoke any authenticators and credentials associated with the individual. c. Conduct exit interviews that include a discussion of [assignment: organization-defined information security topics]. d. Retrieve all security-related organizational system-related property. e. Retain access to organizational information and systems formerly controlled by the terminated individual. \n\nSystem property includes hardware authentication tokens, system administration technical manuals, keys, identification cards, and building passes. Exit interviews ensure that terminated individuals understand the security constraints imposed by being former employees and that proper accountability is achieved for system-related property. Security topics at exit interviews include reminding individuals of nondisclosure agreements and potential limitations on future employment. Exit interviews may not always be possible for some individuals, including in cases related to the unavailability of supervisors, illnesses, or job abandonment. Exit interviews are important for individuals with security clearances. The timely execution of termination actions is essential for individuals who have been terminated for cause. In certain situations, organizations consider disabling the system accounts of individuals who are being terminated prior to the individuals being notified.",
          "System and information integrity. Software, firmware, and information integrity | automated response to integrity violations. Automatically [selection: shut the system down; restart the system; implement [assignment: organization-defined controls]] when integrity violations are discovered. Organizations may define different integrity checking responses by type of information, specific information, or a combination of both. Types of information include firmware, software, and user data. Specific information includes boot firmware for certain types of machines. The automatic implementation of controls within organizational systems includes reversing the changes, halting the system, or triggering audit alerts when unauthorized modifications to critical security files occur.",
          "Identification and authentication. Identifier management | identify user status. Manage individual identifiers by uniquely identifying each individual as [assignment: organization-defined characteristic identifying individual status]. Characteristics that identify the status of individuals include contractors, foreign nationals, and non-organizational users. Identifying the status of individuals by these characteristics provides additional information about the people with whom organizational personnel are communicating. For example, it might be useful for a government employee to know that one of the individuals on an email message is a contractor.",
          "System and services acquisition. Acquisition process | functional properties of controls. Require the developer of the system, system component, or system service to provide a description of the functional properties of the controls to be implemented. Functional properties of security and privacy controls describe the functionality (i.e., security or privacy capability, functions, or mechanisms) visible at the interfaces of the controls and specifically exclude functionality and data structures internal to the operation of the controls.",
          "Incident response. Information spillage response | training. Provide information spillage response training [assignment: organization-defined frequency]. Organizations establish requirements for responding to information spillage incidents in incident response plans. Incident response training on a regular basis helps to ensure that organizational personnel understand their individual responsibilities and what specific actions to take when spillage incidents occur.",
          "Identification and authentication. Identification and authentication (non-organizational users) | acceptance of external authenticators. (a) Accept only external authenticators that are NIST-compliant; and (b) document and maintain a list of accepted external authenticators. Acceptance of only NIST-compliant external authenticators applies to organizational systems that are accessible to the public (e.g., public-facing websites). External authenticators are issued by nonfederal government entities and are compliant with SP 800-63b. Approved external authenticators meet or exceed the minimum federal government-wide technical, security, privacy, and organizational maturity requirements. Meeting or exceeding federal requirements allows federal government relying parties to trust external authenticators in connection with an authentication transaction at a specified authenticator assurance level.",
          "Configuration management. Least functionality | periodic review. (A) Review the system [assignment: organization-defined frequency] to identify unnecessary and/or nonsecure functions, ports, protocols, software, and services; and (B) disable or remove [assignment: organization-defined functions, ports, protocols, software, and services within the system deemed to be unnecessary and/or nonsecure]. Organizations review functions, ports, protocols, and services provided by systems or system components to determine the functions and services that are candidates for elimination. Such reviews are especially important during transition periods from older technologies to newer technologies (e.g., transition from IPv4 to IPv6). These technology transitions may require implementing the older and newer technologies simultaneously during the transition period and returning to minimum essential functions, ports, protocols, and services at the earliest opportunity. Organizations can either decide the relative security of the function, port, protocol, and/or service or base the security decision on the assessment of other entities. Insecure protocols include Bluetooth, FTP, and peer-to-peer networking.",
          "System and communications protection. System time synchronization | synchronization with authoritative time source. (a) Compare the internal system clocks. [Assignment: organization-defined frequency].  \n(b) Synchronize the internal system clocks to the authoritative time source when the time difference is greater than [Assignment: organization-defined time period]. \n\nSynchronization of internal system clocks with an authoritative source provides uniformity of timestamps for systems with multiple system clocks and systems connected over a network.",
          "Access control. Least privilege | privileged accounts. Restrict privileged accounts on the system to [assignment: organization-defined personnel or roles]. Privileged accounts, including super user accounts, are typically described as a system administrator for various types of commercial off-the-shelf operating systems. Restricting privileged accounts to specific personnel or roles prevents day-to-day users from accessing privileged information or privileged functions. Organizations may differentiate in the application of restricting privileged accounts between allowed privileges for local accounts and for domain accounts, provided that they retain the ability to control system configurations for key parameters and as otherwise necessary to sufficiently mitigate risk.",
          "Configuration management. Information location. A. Identify and document the location of [assignment: organization-defined information] and the specific system components on which the information is processed and stored.\nB. Identify and document the users who have access to the system and system components where the information is processed and stored.\nC. Document changes to the location (i.e., system or system components) where the information is processed and stored.\n\nInformation location addresses the need to understand where information is being processed and stored. Information location includes identifying where specific information types and information reside in system components and how information is being processed so that information flow can be understood and adequate protection and policy management provided for such information and system components. The security category of the information is also a factor in determining the controls necessary to protect the information and the system component where the information resides (see FIPS 199). The location of the information and system components is also a factor in the architecture and design of the system (see SA-4, SA-8, SA-17).",
          "System and services acquisition. Acquisition process | system, component, and service configurations. Require the developer of the system, system component, or system service to: (a) deliver the system, component, or service with organization-defined security configurations implemented; and (b) use the configurations as the default for any subsequent system, component, or service reinstallation or upgrade. Examples of security configurations include the U.S. Government Configuration Baseline (USGCB), Security Technical Implementation Guides (STIGs), and any limitations on functions, ports, protocols, and services. Security characteristics can include requiring that default passwords have been changed.",
          "System and information integrity. System monitoring | privileged users. Implement the following additional monitoring of privileged users: [assignment: organization-defined additional monitoring]. Privileged users have access to more sensitive information, including security-related information, than the general user population. Access to such information means that privileged users can potentially do greater damage to systems and organizations than non-privileged users. Therefore, implementing additional monitoring on privileged users helps to ensure that organizations can identify malicious activity at the earliest possible time and take appropriate actions.",
          "System and information integrity. Software, firmware, and information integrity | code authentication. Implement cryptographic mechanisms to authenticate the following software or firmware components prior to installation: [assignment: organization-defined software or firmware components]. Cryptographic authentication includes verifying that software or firmware components have been digitally signed using certificates recognized and approved by organizations. Code signing is an effective method to protect against malicious code. Organizations that employ cryptographic mechanisms also consider cryptographic key management solutions.",
          "Configuration management. Baseline configuration | retention of previous configurations. Retain [assignment: organization-defined number] of previous versions of baseline configurations of the system to support rollback. Retaining previous versions of baseline configurations to support rollback includes hardware, software, firmware, configuration files, configuration records, and associated documentation.",
          "Physical and environmental protection. Monitoring physical access | monitoring physical access to systems. Monitor physical access to the system, in addition to the physical access monitoring of the facility, at [assignment: organization-defined physical spaces containing one or more components of the system]. Monitoring physical access to systems provides additional monitoring for those areas within facilities where there is a concentration of system components, including server rooms, media storage areas, and communications centers. Physical access monitoring can be coordinated with intrusion detection systems and system monitoring capabilities to provide comprehensive and integrated threat coverage for the organization.",
          "Access control. Account management | disable accounts for high-risk individuals. Disable accounts of individuals within [assignment: organization-defined time period] of discovery of [assignment: organization-defined significant risks]. Users who pose a significant security and/or privacy risk include individuals for whom reliable evidence indicates either the intention to use authorized access to systems to cause harm or through whom adversaries will cause harm. Such harm includes adverse impacts to organizational operations, organizational assets, individuals, other organizations, or the nation. Close coordination among system administrators, legal staff, human resource managers, and authorizing officials is essential when disabling system accounts for high-risk individuals.",
          "Audit and accountability. Audit record generation | changes by authorized individuals. Provide and implement the capability for (assignment: organization-defined individuals or roles) to change the logging to be performed on (assignment: organization-defined system components) based on (assignment: organization-defined selectable event criteria) within (assignment: organization-defined time thresholds). Permitting authorized individuals to make changes to system logging enables organizations to extend or limit logging as necessary to meet organizational requirements. Logging that is limited to conserve system resources may be extended (either temporarily or permanently) to address certain threat situations. In addition, logging may be limited to a specific set of event types to facilitate audit reduction, analysis, and reporting. Organizations can establish time thresholds in which logging actions are changed (e.g., near real-time, within minutes, or within hours).",
          "System and information integrity. System monitoring | correlate monitoring information. Correlating information from monitoring tools and mechanisms employed throughout the system is crucial. Doing so can provide a more comprehensive view of system activity. It allows for the identification of attack patterns that may otherwise go unnoticed. To achieve this, it is important to understand the capabilities and limitations of diverse monitoring tools and mechanisms. By maximizing the use of the information generated by these tools, organizations can develop, operate, and maintain effective monitoring programs. This correlation of monitoring information becomes even more critical during technology transitions, such as the shift from IPv4 to IPv6 network protocols.",
          "Identification and authentication. Re-authentication. Require users to re-authenticate when [assignment: organization-defined circumstances or situations requiring re-authentication]. In addition to the re-authentication requirements associated with device locks, organizations may require re-authentication of individuals in certain situations, including when roles, authenticators, or credentials change, when security categories of systems change, when the execution of privileged functions occurs, after a fixed time period, or periodically.",
          "Identification and authentication. Identification and authentication (organizational users) | access to accounts — replay resistant. Implement replay-resistant authentication mechanisms for access to privileged accounts and non-privileged accounts. Authentication processes resist replay attacks if it is impractical to achieve successful authentications by replaying previous authentication messages. Replay-resistant techniques include protocols that use nonces or challenges such as time synchronous or cryptographic authenticators.",
          "Identification and authentication. Identification and authentication (organizational users) | access to accounts —separate device. Implement multi-factor authentication for [selection (one or more): local; network; remote] access to [selection (one or more): privileged accounts; non-privileged accounts]. Ensure that: \n(a) one of the factors is provided by a device separate from the system gaining access; and \n(b) the device meets [assignment: organization-defined strength of mechanism requirements]. \n\nThe purpose of requiring a device that is separate from the system to which the user is attempting to gain access for one of the factors during multi-factor authentication is to reduce the likelihood of compromising authenticators or credentials stored on the system. Adversaries may be able to compromise such authenticators or credentials and subsequently impersonate authorized users. Implementing one of the factors on a separate device (e.g., a hardware token) provides a greater strength of mechanism and an increased level of assurance in the authentication process.",
          "Access control. Session termination. Automatically terminate a user session after [assignment: organization-defined conditions or trigger events requiring session disconnect]. Session termination addresses the termination of user-initiated logical sessions. In contrast to SC-10, which addresses the termination of network connections associated with communications sessions (i.e., network disconnect). A logical session (for local, network, and remote access) is initiated whenever a user (or process acting on behalf of a user) accesses an organizational system. Such user sessions can be terminated without terminating network sessions. Session termination ends all processes associated with a user's logical session, except for those processes that are specifically created by the user (i.e., session owner) to continue after the session is terminated. Conditions or trigger events that require automatic termination of the session include organization-defined periods of user inactivity, targeted responses to certain types of incidents, or time-of-day restrictions on system use.",
          "Contingency planning. Alternate storage site | separation from primary site. Identify an alternate storage site that is sufficiently separated from the primary storage site to reduce susceptibility to the same threats. Threats that affect alternate storage sites are defined in organizational risk assessments and include natural disasters, structural failures, hostile attacks, and errors of omission or commission. Organizations determine what is considered a sufficient degree of separation between primary and alternate storage sites based on the types of threats that are of concern. For threats such as hostile attacks, the degree of separation between sites is less relevant.",
          "Physical and environmental protection. Fire protection. Employ and maintain fire detection and suppression systems that are supported by an independent energy source. The provision of fire detection and suppression systems applies primarily to organizational facilities that contain concentrations of system resources, including data centers, server rooms, and mainframe computer rooms. Fire detection and suppression systems that may require an independent energy source include sprinkler systems and smoke detectors. An independent energy source is an energy source, such as a microgrid, that is separate or can be separated from the energy sources providing power for the other parts of the facility.",
          "System and communications protection. Information in shared system resources. Prevent unauthorized and unintended information transfer via shared system resources. Preventing unauthorized and unintended information transfer via shared system resources stops information produced by the actions of prior users or roles (or the actions of processes acting on behalf of prior users or roles) from being available to current users or roles (or current processes acting on behalf of current users or roles) that obtain access to shared system resources after those resources have been released back to the system. Information in shared system resources also applies to encrypted representations of information. In other contexts, control of information in shared system resources is referred to as object reuse and residual information protection. Information in shared system resources does not address information remanence, which refers to the residual representation of data that has been nominally deleted; covert channels (including storage and timing channels), where shared system resources are manipulated to violate information flow restrictions; or components within systems for which there are only single users or roles.",
          "System and services acquisition. Developer-provided training. Require the developer of the system, system component, or system service to provide the following training on the correct use and operation of the implemented security and privacy functions, controls, and/or mechanisms: [assignment: organization-defined training]. Developer-provided training applies to external and internal (in-house) developers. Training personnel is essential to ensuring the effectiveness of the controls implemented within organizational systems. Types of training include web-based and computer-based training, classroom-style training, and hands-on training (including micro-training). Organizations can also request training materials from developers to conduct in-house training or offer self-training to organizational personnel. Organizations determine the type of training necessary and may require different types of training for different security and privacy functions, controls, and mechanisms.",
          "Media protection. Media sanitization | nondestructive techniques. Apply nondestructive sanitization techniques to portable storage devices prior to connecting such devices to the system under the following circumstances: [assignment: organization-defined circumstances requiring sanitization of portable storage devices]. Portable storage devices include external or removable hard disk drives (e.g., solid-state, magnetic), optical discs, magnetic or optical tapes, flash memory devices, flash memory cards, and other external or removable disks. Portable storage devices can be obtained from untrustworthy sources and contain malicious code that can be inserted into or transferred to organizational systems through USB ports or other entry portals. While scanning storage devices is recommended, sanitization provides additional assurance that such devices are free of malicious code. Organizations consider nondestructive sanitization of portable storage devices when the devices are purchased from manufacturers or vendors prior to initial use or when organizations cannot maintain a positive chain of custody for the devices.",
          "Incident response. Incident response assistance | automation support for availability of information and support. Increase the availability of incident response information and support using [assignment: organization-defined automated mechanisms]. Automated mechanisms can provide a push or pull capability for users to obtain incident response assistance. For example, individuals may have access to a website to query the assistance capability, or the assistance capability can proactively send incident response information to users (general distribution or targeted) as part of increasing understanding of current response capabilities and support.",
          "Access control. Wireless access | restrict configurations by users. Identify and explicitly authorize users allowed to independently configure wireless networking capabilities. Organizational authorizations to allow selected users to configure wireless networking capabilities are enforced, in part, by the access enforcement mechanisms employed within organizational systems.",
          "Incident response. Incident response testing | coordination with related plans. Coordinate incident response testing with organizational elements responsible for related plans. Organizational plans related to incident response testing include:\n\n1. Business continuity plans.\n2. Disaster recovery plans.\n3. Continuity of operations plans.\n4. Contingency plans.\n5. Crisis communications plans.\n6. Critical infrastructure plans.\n7. Occupant emergency plans.",
          "Contingency planning. Alternate processing site | priority of service. Develop alternate processing site agreements that contain priority-of-service provisions in accordance with availability requirements (including recovery time objectives). Priority of service agreements refer to negotiated agreements with service providers that ensure organizations receive priority treatment consistent with their availability requirements and the availability of information resources for logical alternate processing and/or at the physical alternate processing site. Organizations establish recovery time objectives as part of contingency planning.",
          "Contingency planning. System recovery and reconstitution. Provide for the recovery and reconstitution of the system to a known state within [assignment: organization-defined time period consistent with recovery time and recovery point objectives] after a disruption, compromise, or failure. Recovery is executing contingency plan activities to restore organizational mission and business functions. Reconstitution takes place following recovery and includes activities for returning systems to fully operational states. Recovery and reconstitution operations reflect mission and business priorities; recovery point, recovery time, and reconstitution objectives; and organizational metrics consistent with contingency plan requirements. Reconstitution includes the deactivation of interim system capabilities that may have been needed during recovery operations. Reconstitution also includes assessments of fully restored system capabilities, reestablishment of continuous monitoring activities, system reauthorization (if required), and activities to prepare the system and organization for future disruptions, breaches, compromises, or failures. Recovery and reconstitution capabilities can include automated mechanisms and manual procedures. Organizations establish recovery time and recovery point objectives as part of contingency planning.",
          "Configuration management. Configuration settings | automated management, application, and verification. Manage, apply, and verify configuration settings for [assignment: organization-defined system components] using [assignment: organization-defined automated mechanisms]. Automated tools (e.g., hardening tools, baseline configuration tools) can improve the accuracy, consistency, and availability of configuration settings information. Automation can also provide data aggregation and data correlation capabilities, alerting mechanisms, and dashboards to support risk-based decision-making within the organization.",
          "System and services acquisition. Development process, standards, and tools. a. Require the developer of the system, system component, or system service to follow a documented development process that:\n1. Explicitly addresses security and privacy requirements.\n2. Identifies the standards and tools used in the development process.\n3. Documents the specific tool options and tool configurations used in the development process.\n4. Documents, manages, and ensures the integrity of changes to the process and/or tools used in development.\n\nb. Review the development process, standards, tools, tool options, and tool configurations [assignment: organization-defined frequency] to determine if the process, standards, tools, tool options, and tool configurations selected and employed can satisfy the following security and privacy requirements: [assignment: organization-defined security and privacy requirements]. \n\nDevelopment tools include programming languages and computer-aided design systems. Reviews of development processes include the use of maturity models to determine the potential effectiveness of such processes. Maintaining the integrity of changes to tools and processes facilitates effective supply chain risk assessment and mitigation. Such integrity requires configuration control throughout the system development life cycle to track authorized changes and prevent unauthorized changes.",
          "Access control. Least privilege | log use of privileged functions. Log the execution of privileged functions. The misuse of privileged functions, either intentionally or unintentionally, by authorized users or by unauthorized external entities that have compromised system accounts, is a serious and ongoing concern and can have significant adverse impacts on organizations. Logging and analyzing the use of privileged functions is one way to detect such misuse and, in doing so, help mitigate the risk from insider threats and the advanced persistent threat.",
          "Access control. Separation of duties. A. Identify and document [Assignment: organization-defined duties of individuals requiring separation]. \n\nB. Define system access authorizations to support separation of duties. Separation of duties addresses the potential for abuse of authorized privileges and helps to reduce the risk of malevolent activity without collusion. Separation of duties includes dividing mission or business functions and support functions among different individuals or roles. It also involves conducting system support functions with different individuals and ensuring that security personnel who administer access control functions do not also administer audit functions. \n\nBecause separation of duty violations can span systems and application domains, organizations consider the entirety of systems and system components when developing policy on separation of duties. Separation of duties is enforced through the account management activities in AC-2, access control mechanisms in AC-3, and identity management activities in IA-2, IA-4, and IA-12.",
          "Physical and environmental protection. Water damage protection. Protect the system from damage resulting from water leakage by providing master shutoff or isolation valves that are accessible, working properly, and known to key personnel. The provision of water damage protection primarily applies to organizational facilities that contain concentrations of system resources, including data centers, server rooms, and mainframe computer rooms. Isolation valves can be employed in addition to or in lieu of master shutoff valves to shut off water supplies in specific areas of concern without affecting the entire organization.",
          "Physical and environmental protection. Fire protection | detection systems — automatic activation and notification. Employ fire detection systems that activate automatically and notify [organization-defined personnel or roles] and [organization-defined emergency responders] in the event of a fire. Organizations can identify personnel, roles, and emergency responders. If individuals on the notification list need access authorizations or clearances (e.g., to enter facilities where access is restricted due to the classification or impact level of information within the facility), organizations can include them. Notification mechanisms may require independent energy sources to ensure that the notification capability is not adversely affected by the fire.",
          "Supply chain risk management family. Supplier assessments and reviews. Assess and review the supply chain-related risks associated with suppliers or contractors and the system, system component, or system service they provide [assignment: organization-defined frequency]. An assessment and review of supplier risk includes security and supply chain risk management processes, foreign ownership, control or influence (FOCI), and the ability of the supplier to effectively assess subordinate second-tier and third-tier suppliers and contractors. The reviews may be conducted by the organization or by an independent third party. The reviews consider documented processes, documented controls, all-source intelligence, and publicly available information related to the supplier or contractor. Organizations can use open-source information to monitor for indications of stolen information, poor development and quality control practices, information spillage, or counterfeits. In some cases, it may be appropriate or required to share assessment and review results with other organizations in accordance with any applicable rules, policies, or inter-organizational agreements or contracts.",
          "Contingency planning. Contingency training | simulated events. Incorporate simulated events into contingency training to facilitate effective response by personnel in crisis situations. The use of simulated events creates an environment for personnel to experience actual threat events, including cyber-attacks that disable websites, ransomware attacks that encrypt organizational data on servers, hurricanes that damage or destroy organizational facilities, or hardware or software failures.",
          "Configuration management. Baseline configuration. a. Develop, document, and maintain under configuration control a current baseline configuration of the system. \n\nb. Review and update the baseline configuration of the system as follows:\n1. [Assignment: organization-defined frequency].\n2. When required due to [Assignment: organization-defined circumstances].\n3. When system components are installed or upgraded.\n\nBaseline configurations for systems and system components include connectivity, operational, and communications aspects of systems. Baseline configurations are documented, formally reviewed, and agreed-upon specifications for systems or configuration items within those systems. Baseline configurations serve as a basis for future builds, releases, or changes to systems and include security and privacy control implementations, operational procedures, information about system components, network topology, and logical placement of components in the system architecture. \n\nMaintaining baseline configurations requires creating new baselines as organizational systems change over time. Baseline configurations of systems reflect the current enterprise architecture.",
          "System and information integrity. System monitoring | visibility of encrypted communications. Make provisions so that [assignment: organization-defined encrypted communications traffic] is visible to [assignment: organization-defined system monitoring tools and mechanisms]. Organizations balance the need to encrypt communications traffic to protect data confidentiality with the need to maintain visibility into such traffic from a monitoring perspective. Organizations determine whether the visibility requirement applies to internal encrypted traffic, encrypted traffic intended for external destinations, or a subset of the traffic types.",
          "Audit and accountability. Content of audit records. Ensure that audit records contain information that establishes the following: a. What type of event occurred; b. When the event occurred; c. Where the event occurred; d. Source of the event; e. Outcome of the event; and f. Identity of any individuals, subjects, or objects/entities associated with the event. Audit record content that may be necessary to support the auditing function includes event descriptions (item a), timestamps (item b), source and destination addresses (item c), user or process identifiers (items d and f), success or fail indications (item e), and filenames involved (items a, c, e, and f). Event outcomes include indicators of event success or failure and event-specific results, such as the system security and privacy posture after the event occurred. Organizations consider how audit records can reveal information about individuals that may give rise to privacy risks and how best to mitigate such risks. For example, there is the potential to reveal personally identifiable information in the audit trail, especially if the trail records inputs or is based on patterns or time of usage.",
          "Supply chain risk management family. Component disposal. Dispose of [assignment: organization-defined data, documentation, tools, or system components] using the following techniques and methods: [assignment: organization-defined techniques and methods]. Data, documentation, tools, or system components can be disposed of at any time during the system development life cycle (not only in the disposal or retirement phase of the life cycle). For example, disposal can occur during research and development, design, prototyping, or operations/maintenance and include methods such as disk cleaning, removal of cryptographic keys, partial reuse of components. Opportunities for compromise during disposal affect physical and logical data, including system documentation in paper-based or digital files; shipping and delivery documentation; memory sticks with software code; or complete routers or servers that include permanent media, which contain sensitive or proprietary information. Additionally, proper disposal of system components helps to prevent such components from entering the gray market.",
          "Risk assessment. Vulnerability monitoring and scanning | public disclosure program. Establish a public reporting channel for receiving reports of vulnerabilities in organizational systems and system components. The reporting channel is publicly discoverable and contains clear language authorizing good-faith research and the disclosure of vulnerabilities to the organization. The organization does not condition its authorization on an expectation of indefinite non-disclosure to the public by the reporting entity. However, the organization may request a specific time period to properly remediate the vulnerability.",
          "System and information integrity. System monitoring | automated organization-generated alerts. Alert [assignment: organization-defined personnel or roles] using [assignment: organization-defined automated mechanisms] when the following indications of inappropriate or unusual activities with security or privacy implications occur: [assignment: organization-defined activities that trigger alerts]. Organizational personnel on the system alert notification list include system administrators, mission or business owners, system owners, senior agency information security officer, senior agency official for privacy, system security officers, or privacy officers. Automated organization-generated alerts are the security alerts generated by organizations and transmitted using automated means. The sources for organization-generated alerts are focused on other entities such as suspicious activity reports and reports on potential insider threats. In contrast to alerts generated by the organization, alerts generated by the system in SI-4 (5) focus on information sources that are internal to the systems, such as audit records.",
          "Contingency planning. Contingency plan testing. a. Test the contingency plan for the system [assignment: organization-defined frequency] using the following tests to determine the effectiveness of the plan and the readiness to execute the plan: [assignment: organization-defined tests]. \nb. Review the contingency plan test results. \nc. Initiate corrective actions if needed. \n\nMethods for testing contingency plans to determine the effectiveness of the plans and identify potential weaknesses include checklists, walk-through, and tabletop exercises, simulations (parallel or full interrupt), and comprehensive exercises. Organizations conduct testing based on the requirements in contingency plans and include a determination of the effects on organizational operations, assets, and individuals due to contingency operations. Organizations have flexibility and discretion in the breadth, depth, and timelines of corrective actions.",
          "System and information integrity. System monitoring | analyze communications traffic anomalies. Analyze outbound communications traffic at the external interfaces to the system and selected (organization-defined interior points within the system) to discover anomalies. Organization-defined interior points include subnetworks and subsystems. Anomalies within organizational systems include large file transfers, long-time persistent connections, attempts to access information from unexpected locations, the use of unusual protocols and ports, the use of unmonitored network protocols (e.g., IPv6 usage during IPv4 transition), and attempted communications with suspected malicious external addresses.",
          "System and communications protection. Fail in known state. Failures to achieve a organization-defined known system state for the following failures on the indicated components while preserving organization-defined system state information in failure: (list of organization-defined types of system failures on organization-defined system components). Failure in a known state addresses security concerns in accordance with the mission and business needs of organizations. Failure in a known state prevents the loss of confidentiality, integrity, or availability of information in the event of failures of organizational systems or system components. Failure in a known safe state helps to prevent systems from failing to a state that may cause injury to individuals or destruction to property. Preserving system state information facilitates system restart and return to the operational mode with less disruption of mission and business processes.",
          "Configuration management. Impact analyses | verification of controls. After system changes, verify that the impacted controls are implemented correctly, operating as intended, and producing the desired outcome with regard to meeting the security and privacy requirements for the system. Implementation in this context refers to installing changed code in the operational system that may have an impact on security or privacy controls.",
          "Maintenance. Nonlocal maintenance | comparable security and sanitization. (a) Require that nonlocal maintenance and diagnostic services be performed from a system that implements a security capability comparable to the capability implemented on the system being serviced. \n(b) Remove the component to be serviced from the system prior to nonlocal maintenance or diagnostic services, sanitize the component (for organizational information), and after the service is performed, inspect and sanitize the component (for potentially malicious software) before reconnecting the component to the system. \n\nComparable security capability on systems, diagnostic tools, and equipment providing maintenance services implies that the implemented controls on those systems, tools, and equipment are at least as comprehensive as the controls on the system being serviced.",
          "Audit and accountability. Audit record review, analysis, and reporting | permitted actions. Specify the permitted actions for each [selection (one or more): system process; role; user] associated with the review, analysis, and reporting of audit record information. Organizations specify permitted actions for system processes, roles, and users associated with the review, analysis, and reporting of audit records through system account management activities. Specifying permitted actions on audit record information is a way to enforce the principle of least privilege. Permitted actions are enforced by the system and include read, write, execute, append, and delete.",
          "Maintenance. Maintenance tools | prevent unauthorized removal. Prevent the removal of maintenance equipment containing organizational information by: (a) verifying that there is no organizational information contained on the equipment; (b) sanitizing or destroying the equipment; (c) retaining the equipment within the facility; or (d) obtaining an exemption from [assignment: organization-defined personnel or roles] explicitly authorizing removal of the equipment from the facility. Organizational information includes all information owned by organizations and any information provided to organizations for which the organizations serve as information stewards.",
          "Security assessment and authorization. Penetration testing | independent penetration testing agent or team. Employ an independent penetration testing agent or team to perform penetration testing on the system or system components. Independent penetration testing agents or teams are individuals or groups who conduct impartial penetration testing of organizational systems. Impartiality implies that penetration testing agents or teams are free from perceived or actual conflicts of interest with respect to the development, operation, or management of the systems that are the targets of the penetration testing. CA-2 (1) provides additional information on independent assessments that can be applied to penetration testing.",
          "System and information integrity. Flaw remediation | time to remediate flaws and benchmarks for corrective actions. (a) Measure the time between flaw identification and flaw remediation. \n(b) Establish the following benchmarks for taking corrective actions: [assignment: organization-defined benchmarks]. \n\nOrganizations determine the average time it takes to correct system flaws after they have been identified. Subsequently, they establish organizational benchmarks (i.e., time frames) for taking corrective actions. Benchmarks can be determined based on the type of flaw or the severity of the potential vulnerability, especially if the flaw can be exploited.",
          "System and information integrity. Flaw remediation | automated flaw remediation status. Determine if system components have applicable security-relevant software and firmware updates installed using [assignment: organization-defined automated mechanisms]. [Assignment: Organization-defined frequency]. Automated mechanisms can track and determine the status of known flaws for system components.",
          "Contingency planning. Alternate processing site | separation from primary site. Identify an alternate processing site that is sufficiently separated from the primary processing site to reduce susceptibility to the same threats. Threats that affect alternate processing sites are defined in organizational assessments of risk and include natural disasters, structural failures, hostile attacks, and errors of omission or commission. Organizations determine what is considered a sufficient degree of separation between primary and alternate processing sites based on the types of threats that are of concern. For threats such as hostile attacks, the degree of separation between sites is less relevant.",
          "System and information integrity. System monitoring | system-generated alerts. Alert [assignment: organization-defined personnel or roles] when the following system-generated indications of compromise or potential compromise occur: [assignment: organization-defined compromise indicators]. Alerts may be generated from a variety of sources, including audit records or inputs from malicious code protection mechanisms, intrusion detection or prevention mechanisms, or boundary protection devices such as firewalls, gateways, and routers. Alerts can be automated and may be transmitted telephonically, by electronic mail messages, or by text messaging. Organizational personnel on the alert notification list can include system administrators, mission or business owners, system owners, information owners/stewards, senior agency information security officers, senior agency officials for privacy, system security officers, or privacy officers. In contrast to alerts generated by the system, alerts generated by organizations in SI-4 (12) focus on information sources external to the system, such as suspicious activity reports and reports on potential insider threats.",
          "Configuration management. System component inventory | updates during installation and removal. Update the inventory of system components as part of component installations, removals, and system updates. Organizations can improve the accuracy, completeness, and consistency of system component inventories if the inventories are updated as part of component installations or removals or during general system updates. If inventories are not updated at these key times, there is a greater likelihood that the information will not be appropriately captured and documented. System updates include hardware, software, and firmware components.",
          "Incident response. Incident handling | insider threats. Implement an incident handling capability for incidents involving insider threats. The explicit focus on handling incidents involving insider threats provides additional emphasis on this type of threat and the need for specific incident handling capabilities to provide appropriate and timely responses.",
          "System and communications protection. Security function isolation. Isolate security functions from non-security functions. Security functions are isolated from non-security functions by means of an isolation boundary implemented within a system via partitions and domains. The isolation boundary controls access to and protects the integrity of the hardware, software, and firmware that perform system security functions. Systems implement code separation in many ways, such as through the provision of security kernels via processor rings or processor modes. For non-kernel code, security function isolation is often achieved through file system protections that protect the code on disk and address space protections that protect executing code. Systems can restrict access to security functions using access control mechanisms and by implementing least privilege capabilities. While the ideal is for all code within the defined security function isolation boundary to only contain security-relevant code, it is sometimes necessary to include non-security functions as an exception. The isolation of security functions from non-security functions can be achieved by applying the systems security engineering design principles in SA-8, including SA-8 (1), SA-8 (3), SA-8 (4), SA-8 (10), SA-8 (12), SA-8 (13), SA-8 (14), and SA-8 (18).",
          "Maintenance. Maintenance tools | inspect media. Check media containing diagnostic and test programs for malicious code before the media is used in the system. If, upon inspection of media containing maintenance, diagnostic, and test programs, organizations determine that the media contains malicious code, the incident is handled consistent with organizational incident handling policies and procedures.",
          "Incident response. Incident response assistance. Provide an incident response support resource. This resource is integral to the organizational incident response capability and offers advice and assistance to users of the system for the handling and reporting of incidents. Incident response support resources provided by organizations include help desks, assistance groups, automated ticketing systems (to open and track incident response tickets), and access to forensics services or consumer redress services when required.",
          "Access control. Account management | disable accounts. Disable accounts within [assignment: organization-defined time period] when the accounts: (a) have expired; (b) are no longer associated with a user or individual; (c) are in violation of organizational policy; or (d) have been inactive for [assignment: organization-defined time period]. Disabling expired, inactive, or otherwise anomalous accounts supports the concepts of least privilege and least functionality, which reduce the attack surface of the system.",
          "Contingency planning. System backup | testing for reliability and integrity. Test backup information [assignment: organization-defined frequency] to verify media reliability and information integrity. Organizations need assurance that backup information can be reliably retrieved. Reliability pertains to the systems and system components where the backup information is stored, the operations used to retrieve the information, and the integrity of the information being retrieved. Independent and specialized tests can be used for each of the aspects of reliability. For example, decrypting and transporting (or transmitting) a random sample of backup files from the alternate storage or backup site and comparing the information to the same information at the primary processing site can provide such assurance.",
          "System and information integrity. Security and privacy function verification. a. Verify the correct operation of [assignment: organization-defined security and privacy functions]. \nb. Perform the verification of the functions specified in si-6a. [Selection (one or more): [assignment: organization-defined system transitional states]; upon command by a user with appropriate privilege; [assignment: organization-defined frequency]].\nc. Alert [assignment: organization-defined personnel or roles] to failed security and privacy verification tests.\nd. [Selection (one or more): Shut the system down; restart the system; [assignment: organization-defined alternative action(s)]] when anomalies are discovered.\n\nTransitional states for systems include system startup, restart, shutdown, and abort. System notifications include hardware indicator lights, electronic alerts to system administrators, and messages to local computer consoles.\n\nIn contrast to security function verification, privacy function verification ensures that privacy functions operate as expected and are approved by the senior agency official for privacy or that privacy attributes are applied or used as expected.",
          "Contingency planning. Alternate storage site | accessibility. Identify potential accessibility problems to the alternate storage site in the event of an area-wide disruption or disaster and outline explicit mitigation actions. Area-wide disruptions refer to those types of disruptions that are broad in geographic scope, with such determinations made by organizations based on organizational assessments of risk.\n\nExplicit mitigation actions include duplicating backup information at other alternate storage sites if access problems occur at originally designated alternate sites. Additionally, planning for physical access to retrieve backup information is necessary if electronic accessibility to the alternate site is disrupted.",
          "Physical and environmental protection. Emergency power | alternate power supply — minimal operational capability. Provide an alternate power supply for the system that is activated [selection: manually; automatically] and that can maintain minimally required operational capability in the event of an extended loss of the primary power source. Provision of an alternate power supply with minimal operating capability can be satisfied by accessing a secondary commercial power supply or other external power supply.",
          "System and information integrity. System monitoring | risk for individuals. Implement organization-defined additional monitoring of individuals who have been identified by organization-defined sources as posing an increased level of risk. Indications of increased risk from individuals can be obtained from different sources, including personnel records, intelligence agencies, law enforcement organizations, and other sources. The monitoring of individuals is coordinated with the management, legal, security, privacy, and human resource officials who conduct such monitoring. Monitoring is conducted in accordance with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines.",
          "Audit and accountability. Time stamps. a. Use internal system clocks to generate time stamps for audit records; and b. Record time stamps for audit records that meet [assignment: organization-defined granularity of time measurement] and that use Coordinated Universal Time, have a fixed local time offset from Coordinated Universal Time, or that include the local time offset as part of the time stamp. Time stamps generated by the system include date and time. Time is commonly expressed in Coordinated Universal Time (UTC), a modern continuation of Greenwich Mean Time (GMT), or local time with an offset from UTC. Granularity of time measurements refers to the degree of synchronization between system clocks and reference clocks (e.g., clocks synchronizing within hundreds of milliseconds or tens of milliseconds). Organizations may define different time granularities for different system components. Time service can be critical to other security capabilities such as access control and identification and authentication, depending on the nature of the mechanisms used to support those capabilities.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "0_and_the_of",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "0_and_the_of"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          -2.271932601928711,
          -2.7855117321014404,
          -0.719089925289154,
          -2.2356159687042236,
          -1.3013677597045898,
          0.17839699983596802,
          -2.3606510162353516,
          1.0653108358383179,
          -2.2803609371185303,
          -0.7395870089530945,
          -0.4290604889392853,
          -0.8976017832756042,
          0.07945086807012558,
          -1.2238093614578247,
          1.1099801063537598,
          -1.0174596309661865,
          -1.3570839166641235,
          -1.1599414348602295,
          -0.3195852041244507,
          -3.54657244682312,
          0.8131981492042542,
          -1.6958839893341064,
          -2.9429633617401123,
          -0.3563103973865509,
          -1.7279239892959595,
          -1.5887978076934814,
          -1.4274052381515503,
          -2.3010497093200684,
          -0.9739052653312683,
          1.0578078031539917,
          1.1793450117111206,
          -1.1051785945892334,
          -2.922636032104492,
          -3.609945774078369,
          -0.2013670802116394,
          -2.167480230331421,
          -1.093668818473816,
          -2.263970375061035,
          -0.6695482730865479,
          0.10212841629981995,
          -1.2577418088912964,
          -1.1044338941574097,
          -0.7906716465950012,
          -0.22332096099853516,
          -2.635080575942993,
          -1.8177635669708252,
          -1.0918240547180176,
          1.0960664749145508,
          -1.6388332843780518,
          -1.4937636852264404,
          -2.2890098094940186,
          -0.5793840885162354,
          0.008794546127319336,
          -0.3022278845310211,
          -2.7124977111816406,
          -0.5514569878578186,
          -2.273742437362671,
          -2.938957691192627,
          -1.737990379333496,
          -0.12235903739929199,
          -2.481602191925049,
          -2.206200122833252,
          -2.265371561050415,
          -1.3061730861663818,
          -1.2527308464050293,
          0.15699130296707153,
          -2.3958957195281982,
          -2.330764055252075,
          -2.969123601913452,
          -1.1882027387619019,
          -2.583069086074829,
          -1.7394633293151855,
          -1.3432239294052124,
          -1.2756880521774292,
          -2.850391387939453,
          -2.39113187789917,
          -1.4664214849472046,
          -2.140754222869873,
          -1.347406029701233,
          -0.14725340902805328,
          -2.841698408126831,
          -1.522128939628601,
          -1.8443933725357056,
          -2.474815607070923,
          -0.8558713793754578,
          -2.5859155654907227,
          1.1902573108673096,
          -1.0192903280258179,
          -1.0856279134750366,
          -1.8437962532043457,
          -2.1448938846588135,
          -3.573099136352539,
          -1.0272995233535767,
          -1.8526071310043335,
          -2.028879404067993,
          -0.4814758002758026,
          -0.8329797387123108,
          -2.4284236431121826,
          -1.386549949645996,
          -2.0858311653137207,
          -0.5149034261703491,
          -2.4461429119110107,
          1.5149383544921875,
          -0.2185274064540863,
          -0.2362157106399536,
          -1.6924965381622314,
          -0.5194318294525146,
          -2.416794776916504,
          -0.9879769086837769,
          -2.7281742095947266,
          -3.4850635528564453,
          -2.9760687351226807,
          -1.8995859622955322,
          -2.2819316387176514,
          -2.3630928993225098,
          0.060282666236162186,
          -2.2597274780273438,
          -1.8257859945297241,
          -3.0161945819854736,
          -1.988891363143921,
          -1.628426194190979,
          -0.3998229503631592,
          2.3510079383850098,
          -3.600250244140625,
          -1.7657791376113892,
          -0.7031559944152832,
          -2.007693290710449,
          -2.247288942337036,
          -2.1192493438720703,
          -3.440849542617798,
          -3.0228271484375,
          -1.8746401071548462,
          -0.8130908012390137,
          -2.3346621990203857,
          -1.9145225286483765,
          -2.094559669494629,
          -0.46951794624328613,
          -0.8892837166786194,
          -1.2886829376220703,
          -2.3875904083251953,
          -1.875172734260559,
          -2.0624759197235107,
          -2.7808523178100586,
          -0.8905208110809326,
          -0.9410085082054138,
          -2.2630691528320312,
          1.1094669103622437,
          0.15832766890525818,
          -0.4741027355194092,
          -1.5240598917007446,
          -2.3972203731536865,
          0.052986547350883484,
          -1.840683102607727,
          -2.198366165161133,
          -3.588679552078247,
          1.1594494581222534,
          -0.2984561026096344,
          -0.35382771492004395,
          -1.0070230960845947,
          -2.3594846725463867,
          -3.610565662384033,
          -1.3603358268737793,
          -0.9704303741455078,
          -2.845310926437378,
          -0.7756695747375488,
          -0.6018134355545044,
          -1.8443886041641235,
          -1.6303383111953735,
          1.0706387758255005,
          1.2119736671447754,
          -1.2427128553390503,
          -2.8571126461029053,
          1.0951626300811768,
          -2.4375417232513428,
          0.07225268334150314,
          3.1162269115448,
          -1.8421663045883179,
          -0.5398302674293518,
          -2.085101842880249,
          0.17837916314601898,
          -1.6233773231506348,
          -3.010594606399536,
          -0.8027305603027344,
          0.19745276868343353,
          1.0906106233596802,
          -1.0812578201293945,
          -1.3260520696640015,
          -1.7508307695388794,
          -1.5896598100662231,
          1.0448626279830933,
          -0.7102835178375244,
          -1.763631820678711,
          -2.4137752056121826,
          -0.8861173391342163,
          -1.702893853187561,
          -0.583696722984314,
          -1.9193308353424072,
          -0.9744215607643127,
          -1.0491589307785034,
          -0.1374027580022812,
          -1.6441327333450317,
          -1.0515750646591187,
          -1.9314519166946411,
          -1.1261526346206665,
          -0.3834700286388397,
          -2.3018877506256104,
          -1.6787608861923218,
          -3.522037982940674,
          -1.9600096940994263,
          1.2664704322814941,
          -1.8337489366531372,
          -0.41162121295928955,
          -2.164271593093872,
          -2.546241521835327,
          -0.4413425624370575,
          -1.9765002727508545,
          -1.104783535003662,
          -3.499765396118164,
          -1.542251706123352,
          -0.7843371033668518,
          -1.0641056299209595,
          -2.181356191635132,
          -1.8252657651901245,
          -2.638742446899414,
          -2.3287346363067627,
          -2.6370484828948975,
          -3.030992269515991,
          -1.63033127784729,
          1.1639748811721802,
          -1.3794209957122803,
          -3.5099430084228516,
          1.3704603910446167,
          -1.4594229459762573,
          -0.740753710269928,
          -2.836609125137329,
          -1.715256929397583,
          -1.4545425176620483,
          -2.560213088989258,
          0.30220651626586914,
          -1.1589069366455078,
          -0.8076473474502563,
          -2.3293018341064453,
          -2.3160431385040283,
          -1.6698964834213257,
          1.2094193696975708,
          1.1992249488830566,
          1.4030364751815796,
          -0.48142412304878235,
          -2.1123783588409424,
          -0.7488910555839539,
          -0.3914492726325989,
          -1.9131666421890259,
          -0.38018369674682617,
          -3.5021536350250244,
          -0.9989486336708069,
          -2.819622755050659,
          -2.246363401412964,
          -2.658731698989868,
          -1.6695244312286377,
          -1.3027911186218262,
          -2.792778491973877,
          -2.910081386566162,
          -0.7770023941993713,
          -0.7334684133529663,
          -1.4061537981033325,
          -3.309976577758789,
          -1.3686543703079224,
          -1.3369675874710083,
          -2.2515978813171387,
          -1.0486552715301514,
          -1.504037857055664,
          -2.126953601837158,
          -2.70737361907959,
          -1.341571569442749,
          -0.7854706645011902,
          -1.3679498434066772,
          -1.2169671058654785,
          -2.367690086364746,
          -1.3211175203323364,
          -2.145995616912842,
          -1.6082046031951904,
          -1.2006603479385376,
          -2.1577746868133545,
          -2.09670352935791,
          -1.7945574522018433,
          -3.4968271255493164,
          -0.35951757431030273,
          -1.373741865158081,
          -3.506988048553467,
          -2.4446141719818115,
          -2.165461778640747,
          -2.2040741443634033,
          -2.195984125137329,
          -0.7585139274597168,
          -1.9410310983657837,
          -0.8455287218093872,
          -1.4137561321258545
         ],
         "y": [
          1.7573065757751465,
          3.395369291305542,
          5.826212406158447,
          4.834601402282715,
          5.177561283111572,
          3.963557481765747,
          6.011507511138916,
          2.865997314453125,
          1.306093454360962,
          5.802010536193848,
          4.942838668823242,
          5.316796779632568,
          3.9329957962036133,
          2.7690768241882324,
          2.918530225753784,
          4.918370723724365,
          2.9311482906341553,
          3.9193482398986816,
          4.231173515319824,
          6.688095569610596,
          3.045382499694824,
          2.727863073348999,
          4.215526580810547,
          4.450530529022217,
          2.822157382965088,
          3.5670716762542725,
          2.524460792541504,
          1.2291237115859985,
          4.822396278381348,
          2.879568338394165,
          3.1747493743896484,
          5.5283708572387695,
          4.221685886383057,
          6.626074314117432,
          3.7394843101501465,
          1.8300774097442627,
          2.9760377407073975,
          1.3252432346343994,
          3.656912326812744,
          2.945981502532959,
          2.8889331817626953,
          4.605041980743408,
          4.788877487182617,
          4.357173442840576,
          6.004000186920166,
          3.905531883239746,
          5.660370826721191,
          2.806112289428711,
          4.770660877227783,
          4.507954120635986,
          5.994251251220703,
          4.478806495666504,
          3.8939433097839355,
          3.9402270317077637,
          3.4546680450439453,
          3.8856985569000244,
          1.1979659795761108,
          3.824069023132324,
          3.913034677505493,
          2.7483038902282715,
          5.945110321044922,
          1.9261614084243774,
          2.0519824028015137,
          3.874119997024536,
          3.768913984298706,
          3.2332217693328857,
          2.7923827171325684,
          4.7804341316223145,
          4.058088779449463,
          1.9194329977035522,
          5.763706207275391,
          3.1215221881866455,
          3.9571468830108643,
          1.7670085430145264,
          3.532475233078003,
          2.7649736404418945,
          4.06056547164917,
          6.134884357452393,
          5.542898178100586,
          2.758310317993164,
          3.3146698474884033,
          4.564440727233887,
          3.155463933944702,
          1.6952232122421265,
          4.873762130737305,
          4.42794942855835,
          3.0403592586517334,
          3.026458501815796,
          5.583730220794678,
          2.900367498397827,
          5.810203552246094,
          6.679327964782715,
          4.907132625579834,
          5.772935390472412,
          3.3898096084594727,
          5.324861526489258,
          5.016167640686035,
          2.7513158321380615,
          1.7101590633392334,
          6.135977268218994,
          4.330740451812744,
          1.3565261363983154,
          2.8486225605010986,
          4.342221736907959,
          3.996303081512451,
          3.1558258533477783,
          3.9183061122894287,
          1.4252837896347046,
          2.9272680282592773,
          3.465527057647705,
          6.734765529632568,
          4.120187282562256,
          4.0536417961120605,
          1.2338017225265503,
          1.164808988571167,
          4.114268779754639,
          6.000297546386719,
          5.782780647277832,
          4.129313945770264,
          2.975289821624756,
          3.650928497314453,
          4.011959552764893,
          -0.12632526457309723,
          6.676786422729492,
          2.873408555984497,
          5.77040958404541,
          6.180487155914307,
          1.451358675956726,
          6.140353679656982,
          6.565578937530518,
          3.887906551361084,
          2.9410293102264404,
          5.419464588165283,
          3.5063321590423584,
          2.224856376647949,
          5.543466567993164,
          3.132514238357544,
          3.764225721359253,
          1.770200490951538,
          2.747283697128296,
          4.013046741485596,
          6.078599452972412,
          3.3545632362365723,
          5.304439544677734,
          3.246022939682007,
          2.8249876499176025,
          3.1901607513427734,
          3.899052381515503,
          3.651217222213745,
          3.569031000137329,
          1.4218510389328003,
          3.7485997676849365,
          5.77213191986084,
          3.726891040802002,
          6.665934085845947,
          3.196586847305298,
          3.5501065254211426,
          3.5698232650756836,
          5.204776763916016,
          2.4223482608795166,
          6.6132612228393555,
          5.5545148849487305,
          3.4231555461883545,
          3.508756637573242,
          4.948042869567871,
          3.7358145713806152,
          4.072782516479492,
          4.319517135620117,
          3.2293541431427,
          3.135587453842163,
          4.2442779541015625,
          3.3273072242736816,
          3.120346784591675,
          5.9883575439453125,
          4.1552605628967285,
          -2.1858723163604736,
          4.064413547515869,
          4.076895236968994,
          1.100508689880371,
          3.898906707763672,
          3.042874574661255,
          3.781297445297241,
          5.3271484375,
          4.000084400177002,
          3.0198490619659424,
          4.685969352722168,
          3.3787503242492676,
          3.116708517074585,
          4.751460552215576,
          2.8586206436157227,
          5.7186126708984375,
          2.824700355529785,
          5.986702919006348,
          5.30951452255249,
          2.7264304161071777,
          5.379730224609375,
          2.648181676864624,
          2.8681697845458984,
          2.995596408843994,
          2.730485439300537,
          2.9288547039031982,
          4.8461809158325195,
          4.037502288818359,
          3.6868131160736084,
          3.602879047393799,
          1.2396695613861084,
          3.785982370376587,
          6.732194900512695,
          4.033865928649902,
          3.004164695739746,
          5.770781993865967,
          5.026960849761963,
          1.8374754190444946,
          6.165560722351074,
          3.8744659423828125,
          4.7612996101379395,
          5.489188194274902,
          6.727572441101074,
          3.355844497680664,
          5.79748010635376,
          2.974062204360962,
          5.857407569885254,
          5.88040018081665,
          3.0751171112060547,
          1.2441054582595825,
          5.628122806549072,
          4.135104656219482,
          3.9162721633911133,
          2.9846889972686768,
          3.3964345455169678,
          6.725444793701172,
          2.9749131202697754,
          2.851389169692993,
          3.8925793170928955,
          3.297891855239868,
          2.754642963409424,
          3.2873363494873047,
          3.471705913543701,
          3.687143564224243,
          2.8099122047424316,
          5.222000598907471,
          2.859602451324463,
          1.2740111351013184,
          4.073622226715088,
          3.1326496601104736,
          3.154804229736328,
          3.0057432651519775,
          3.8901920318603516,
          6.045679092407227,
          5.821426868438721,
          4.043166637420654,
          3.977538824081421,
          4.906665325164795,
          6.74242639541626,
          4.851032257080078,
          6.259645462036133,
          6.062710285186768,
          5.641300201416016,
          2.716677188873291,
          2.3310556411743164,
          3.343980312347412,
          3.830599308013916,
          5.811618804931641,
          5.770458698272705,
          3.2857866287231445,
          6.674201488494873,
          2.554262161254883,
          4.341062068939209,
          1.1685014963150024,
          2.99123477935791,
          4.729716777801514,
          3.7437827587127686,
          5.957344055175781,
          4.299874782562256,
          3.831003189086914,
          2.8967442512512207,
          3.8077304363250732,
          1.352284550666809,
          5.533994197845459,
          3.5450448989868164,
          3.7421586513519287,
          3.694056749343872,
          6.101955413818359,
          3.7815723419189453,
          2.8043503761291504,
          6.739117622375488,
          3.586122512817383,
          5.504587650299072,
          6.680724143981934,
          2.8400745391845703,
          5.873219966888428,
          3.6537156105041504,
          6.044844150543213,
          5.832260608673096,
          4.154693126678467,
          3.7645721435546875,
          3.963531970977783
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "Identity and access management (idm). Regular review of access rights. Basic criterion: Access rights of internal and external employees of the cloud service provider, as well as system components that play a role in automated authorization processes of the cloud service provider, are reviewed at least once a year to ensure that they still correspond to the actual area of use. The review is carried out by authorized persons from the cloud service provider’s organizational units, who can assess the appropriateness of the assigned access rights based on their knowledge of the task areas of the employees or system components. Identified deviations will be dealt with promptly, but no later than 7 days after their detection, by appropriate modification or withdrawal of the access rights.\n\nAdditional criterion: Privileged access rights are reviewed at least every six months.\n\nSupplementary information about the criterion: Complementary customer criterion notes on continuous auditing feasibility: Yes, the review audit cannot be recorded automatically. A registration of documents used for documentary purposes could take place (e.g., confirmation that the assignment of the access rights has been reviewed). A continuous audit could indicate when this review was last carried out. The cloud service provider must automate the review process (in particular, the confirmation that the review has been performed) so that the auditor can audit the steps to be performed in case deviations are detected.",
          "Portability and interoperability (pi). Documentation and safety of input and output interfaces. Basic criteria: The cloud service can be accessed by other cloud services or IT systems of cloud customers through documented inbound and outbound interfaces. Furthermore, the interfaces are clearly documented for subject matter experts on how they can be used to retrieve the data. Communication takes place through standardized communication protocols that ensure the confidentiality and integrity of the transmitted information, according to its protection requirements. Communication over untrusted networks is encrypted according to CRY-02. The type and scope of the documentation on the interfaces are geared to the needs of the cloud customers' subject matter experts to enable the use of these interfaces. The information is maintained in a way that is applicable for the cloud service's version intended for productive use. \n\nAdditional criteria: Supplementary information about the criterion complementary customer criterion. Cloud customers ensure, through suitable controls, that the provided interfaces (and their security) are adequate for their protection requirements, by means of appropriate checks before the start of use of the cloud service and each time the interfaces are changed. \n\nNotes on continuous auditing feasibility: Partially, the defined input and output interfaces of cloud services are rarely changed. Therefore, it is sufficient for the auditor to test these interfaces, the communication of potential changes, and the associated documentation as part of the recurring audit. In a continuous audit, however, the system status of the interfaces could be queried and evaluated continuously.",
          "Operations (ops). Managing vulnerabilities, malfunctions and errors – system hardening. Basic criterion: System components in the production environment used to provide the cloud service under the cloud service provider's responsibility are hardened according to generally accepted industry standards. The hardening requirements for each system component are documented. If non-modifiable (\"immutable\") images are used, compliance with the hardening specifications as defined in the hardening requirements is checked upon the creation of the images. Configuration and log files regarding the continuous availability of the images are retained.\n\nAdditional criterion: System components in the cloud service provider's area of responsibility are automatically monitored for compliance with hardening specifications. Deviations from the specifications are automatically reported to the appropriate departments of the cloud service provider for immediate assessment and action.\n\nSupplementary information about the criterion: System components in the sense of the basic criterion are objects required for the information security of the cloud service during the creation, processing, storage, transmission, deletion, or destruction of information in the cloud service provider's area of responsibility. For example, firewalls, load balancers, web servers, application servers, and database servers. These system components consist of hardware and software objects. This criterion is limited to software objects such as hypervisors, operating systems, databases, programming interfaces (APIs), images (e.g., for virtual machines and containers), and applications for logging and monitoring security events. The configuration and log files for non-modifiable images include, for example, the configuration of the images used with regard to implemented hardening specifications including version history, and logs for file integrity monitoring of images in productive use. Generally accepted industry standards include, for example, the security configuration benchmark of the \"Centre for Internet Security\" (CIS) or the corresponding modules in the BSI IT-Grundschutz-Kompendium. Compliance with hardening specifications can be monitored with, for example, file integrity monitoring.\n\nComplementary customer criterion: Cloud customers ensure through suitable controls that layers of the cloud service which are under their responsibility are hardened according to generally established and accepted industry standards. The hardening specifications applied are derived from a risk assessment of the planned usage of the cloud service.\n\nNotes on continuous auditing feasibility: Yes, the verification of compliance with the specifications for the hardening of system components can be automatically tested and subsequently documented (logs). The auditor can evaluate these logs automatically and continuously and thus carry out a continuous audit.",
          "Personnel (hr). Responsibilities in the event of termination or change of employment. Basic criterion: Internal and external employees have been informed about the responsibilities arising from employment terms and conditions relating to information security, which will remain in place when their employment is terminated or changed, and for how long. \n\nAdditional criterion: Supplementary information about the criterion: The cloud service provider ensures that the policies and instructions reflect applicable legal and regulatory requirements in accordance with SP-01. \n\nComplementary customer criterion: Notes on continuous auditing feasibility: Yes. As part of a comprehensive, system-based documentation of HR data, it is conceivable that the employee will receive confirmation that he or she has been informed about the required topics. This should be requested again at the end of the employment relationship. If such documentation was available in standardized and digital form, the auditor would be able to check each termination for this confirmation and identify any deviations. This makes continuous verification possible.",
          "Identity and access management (idm). Policy for user accounts and access rights. Basic criterion: A role and rights concept based on the business and security requirements of the cloud service provider, as well as a policy for managing user accounts and access rights for internal and external employees of the cloud service provider, and system components that have a role in automated authorization processes of the cloud service provider, are documented, communicated, and made available. According to SP-01, the following principles are applied: assignment of unique usernames; granting and modifying user accounts and access rights based on the \"least-privilege-principle\" and the \"need-to-know\" principle; segregation of duties between operational and monitoring functions (\"segregation of duties\"); segregation of duties between managing, approving, and assigning user accounts and access rights; approval by authorized individuals or systems for granting or modifying user accounts and access rights before accessing data of the cloud customer or system components used to provision the cloud service; regular review of assigned user accounts and access rights; blocking and removing access accounts in the event of inactivity; time-based or event-driven removal or adjustment of access rights in the event of changes to job responsibilities; two-factor or multi-factor authentication for users with privileged access; and requirements for the approval and documentation of the management of user accounts and access rights. \n\nAdditional criterion: Supplementary information about the criterion and system components in the sense of the basic criterion can be found in the definition in OPS-23. Automated authorization processes in the sense of this basic criterion concern procedures for automated software provisioning (continuous delivery), as well as for automated provisioning and deprovisioning of user accounts and access rights based on approved requests. \n\nComplementary customer criterion: Notes on continuous auditing feasibility: Partially, a policy can change ad-hoc. However, the continuous audit of policies is only partially feasible, as the only attributes that can be tested are the last change date and the status of review or approval, as far as this information is stored in a system. The content of a policy can hardly be tested automatically. The aspects mentioned in the policy can be converted into individual criteria and embedded in a continuous audit. Individual aspects of the policy which can be examined on an ongoing basis include: unique username; segregation of duties; rights profile management (approvals); authorized bodies or individuals; regular review; deactivation due to inactivity; and multi-factor authentication. \n\nApproval and documentation: Individual aspects of the policy which cannot be continuously examined in a practicable manner include: implementation of least-privilege/need-to-know principles; and withdrawal or adjustment of access rights as the task area changes.",
          "Security incident management (sim). Policy for security incident management. Basic Criterion: Policies and instructions with technical and organizational safeguards are documented, communicated, and provided in accordance with SP-01 to ensure a fast, effective, and proper response to all known security incidents. The cloud service provider defines guidelines for the classification, prioritization, and escalation of security incidents and creates interfaces to the incident management and business continuity management. In addition, the cloud service provider has set up a \"Computer Emergency Response Team\" (CERT), which contributes to the coordinated resolution of occurring security incidents. Customers affected by security incidents are informed in a timely and appropriate manner.\n\nAdditional Criterion: There are instructions on how to collect the data of a suspicious system conclusively in the event of a security incident. Additionally, there are analysis plans for typical security incidents and an evaluation methodology to ensure that the collected information does not lose its evidential value in any subsequent legal assessment.\n\nSupplementary Information about the Criterion: Complementary Customer Criterion: Cloud customers ensure, through suitable controls, that they receive notifications from the cloud service provider about security incidents that affect them and that these notifications are forwarded in a timely manner to the responsible departments for handling so that an appropriate response can be triggered.\n\nNotes on Continuous Auditing Feasibility: Partially, a continuous audit of the documented policies and instructions is not effective because they are not subject to high-frequency changes. Thus, the audit of the policies and instructions can be performed in the recurring audit. Similarly, setting up a CERT is not suitable for continuous auditing as it is an organizational body and does not require continuous monitoring. The timely communication of security incidents to affected customers can be covered by a continuous audit approach. In addition, the cloud service provider can document not only the security incidents by means of logs but also that they have been communicated to the customer via email, for example. The fact that there was communication to affected customers for every security incident can thus be evaluated automatically and continuously by the auditor. However, this procedure can be combined with the audit approach of further requirements of security incident management.",
          "Asset management (am). Commissioning of hardware. Basic criterion: The cloud service provider has an approval process for the use of hardware to be commissioned, which is used to provide the cloud service in the production environment, in which the risks arising from the commissioning are identified, analyzed and mitigated. Approval is granted after verification of the secure configuration of the mechanisms for error handling, logging, encryption, authentication, and authorization according to the intended use and based on the applicable policies. \n\nAdditional criterion: \n\nSupplementary information about the criterion: The basic criterion applies only to physical hardware objects, such as servers, storage systems, and network components. Virtual hardware and software objects are considered in the criteria areas (ops) and (dev). The approval process typically considers both the basic approval to use the hardware and the final approval of the configured assets. \n\nComplementary customer criterion: \n\nNotes on continuous auditing feasibility: \n\nYes, the approval of the commissioning of hardware by authorized personnel or system components must be digitally documented to allow continuous testing. A ticketing system, for example, is suitable for this purpose. Both the instance and the verification of the configuration must be stored in the respective ticket. This makes it possible for the auditor to check the tickets in an automated procedure. This requires an automated comparison of the authorized instance against a database containing all potential approvers. In addition, the verification of the configuration in the ticket must be audited automatically. The compliant use of the assets can then be ensured via an agent system which checks active assets. The status of this system can then be queried by the auditor for a continuous audit.",
          "Product safety and security (pss). Guidelines and recommendations for cloud customers. Basic criterion: The cloud service provider provides cloud customers with guidelines and recommendations for the secure use of the cloud service provided. The information contained therein is intended to assist the cloud customer in the secure configuration, installation, and use of the cloud service, to the extent applicable to the cloud service and the responsibility of the cloud user. The type and scope of the information provided will be based on the needs of subject matter experts of the cloud customers who set information security requirements, implement them, or verify the implementation (e.g. IT, compliance, internal audit). The information in the guidelines and recommendations for the secure use of the cloud service addresses the following aspects, where applicable to the cloud service: instructions for secure configuration; information sources on known vulnerabilities and update mechanisms; error handling and logging mechanisms; authentication mechanisms; roles and rights concept including combinations that result in an elevated risk; and services and functions for administration of the cloud service by privileged users. The information is maintained so that it is applicable to the cloud service provided in the version intended for productive use.\n\nAdditional criterion: Supplementary information about the criterion complementary customer criterion cloud customers ensure through suitable controls that the cloud service provider's information is used to derive policies, concepts, and measures for the secure configuration and use (according to their own risk assessment) of the cloud service. Compliance with these policies, concepts, and measures is checked. Changes to the information are promptly assessed for their impact on these documents, and any necessary changes are implemented.\n\nNotes on continuous auditing feasibility: Partially, the provision of information from the cloud service provider to cloud customers can only be audited continuously to a limited extent. For example, the cloud service provider can make the guidelines and recommendations available via its internal customer portal, which makes continuous audit only partially effective. Here, only an audit for completeness and the last modification date is conceivable, although a discussion of the content of the changes is not effective. For this, a semantic evaluation would be necessary.",
          "Media protection. Media sanitization. a. Sanitize [assignment: organization-defined system media] prior to disposal, release out of organizational control, or release for reuse using [assignment: organization-defined sanitization techniques and procedures]. b. Employ sanitization mechanisms with the strength and integrity commensurate with the security category or classification of the information. Media sanitization applies to all digital and non-digital system media subject to disposal or reuse, whether or not the media is considered removable. Examples include digital media in scanners, copiers, printers, notebook computers, workstations, network components, mobile devices, and non-digital media (e.g., paper and microfilm). The sanitization process removes information from system media such that the information cannot be retrieved or reconstructed. Sanitization techniques — including clearing, purging, cryptographic erase, de-identification of personally identifiable information, and destruction — prevent the disclosure of information to unauthorized individuals when such media is reused or released for disposal. Organizations determine the appropriate sanitization methods, recognizing that destruction is sometimes necessary when other methods cannot be applied to media requiring sanitization. Organizations use discretion on the employment of approved sanitization techniques and procedures for media that contains information deemed to be in the public domain or publicly releasable or information deemed to have no adverse impact on organizations or individuals if released for reuse or disposal. Sanitization of non-digital media includes destruction, removing a classified appendix from an otherwise unclassified document, or redacting selected sections or words from a document by obscuring the redacted sections or words in a manner equivalent in effectiveness to removing them from the document. NSA standards and policies control the sanitization process for media that contains classified information. NARA policies control the sanitization process for controlled unclassified information.",
          "Compliance (com). Internal audits of the information security management system. Basic criterion: Subject matter experts check the compliance of the Information Security Management System at regular intervals, at least annually, with the relevant and applicable legal, regulatory, self-imposed, or contractual requirements (cf. com-01) as well as compliance with the policies and instructions (cf. sp-01) within their scope of responsibility (cf. ois-01) through internal audits. Identified vulnerabilities and deviations are subject to risk assessment in accordance with the risk management procedure (cf. ois-06), and follow-up measures are defined and tracked (cf. ops-18). Additional criterion: Internal audits are supplemented by procedures to automatically monitor applicable requirements of policies and instructions with regard to the following aspects: configuration of system components to provide the cloud service within the cloud service provider's area of responsibility; performance and availability of these system components; response time to malfunctions and security incidents; recovery time (time to completion of error handling). Identified vulnerabilities and deviations are automatically reported to the appropriate cloud service provider's subject matter experts for immediate assessment and action. Cloud customers can view compliance with selected contractual requirements in real-time. Supplementary information about the criterion: Subject matter experts operate, e.g., in the cloud service provider's internal revision department or expert third parties commissioned by the cloud service provider, such as auditing companies, and may hold relevant certifications such as \"Certified Internal Auditor (CIA)\". With regard to ISMS compliance, see Section 9.2 of ISO/IEC 27001. Complementary customer criterion notes on continuous auditing feasibility: Yes, the regular performance of an internal audit of the ISMS can be set up as part of compliance monitoring. For this purpose, the results of the internal audit must be digitally documented, as well as the individual audit steps. A continuous audit of this internal audit is not effective but can only be considered after compliance monitoring has been set up. The continuous audit can then supply the date of the last audit as the output value.",
          "Asset management (am). Acceptable use and safe handling of assets policy. Basic criterion: Policies and instructions for acceptable use and safe handling of assets are documented, communicated, and provided in accordance with SP-01. They address the following aspects of the asset lifecycle as applicable to the asset:\n\n- Approval procedures for acquisition, commissioning, maintenance, decommissioning, and disposal by authorized personnel or system components\n- Inventory\n- Classification and labeling based on the need for protection of the information and measures\n- Measures for the level of protection identified\n- Secure configuration of mechanisms for error handling, logging, encryption, authentication, and authorization\n- Requirements for versions of software and images as well as application of patches\n- Handling of software for which support and security patches are not available anymore\n- Restriction of software installations or use of services\n- Protection against malware\n- Remote deactivation, deletion, or blocking\n- Physical delivery and transport\n- Dealing with incidents and vulnerabilities\n- Complete and irrevocable deletion of the data upon decommissioning\n\nAdditional criterion: Supplementary information about the criterion and complementary customer criterion notes on continuous auditing feasibility:\n\nPartially, a policy can change ad-hoc. However, the continuous audit of policies is only partially feasible as the only attributes that can be tested are the last change date and the status of review or approval, as far as this information is stored in a system. The content of a policy can hardly be tested automatically.",
          "Dealing with investigation requests from government agencies (inq). Legal assessment of investigative inquiries. Basic criterion: Investigation requests from government agencies are subjected to a legal assessment by subject matter experts of the cloud service provider. The assessment determines whether the government agency has an applicable and legally valid legal basis and what further steps need to be taken.\n\nAdditional criterion: Supplementary information about the criterion complementary customer criterion. Cloud customers ensure through suitable controls that the type and scope of government investigation requests and the associated disclosure of their own data has been dealt with in their own risk management and that the use of the cloud service only takes place when this risk has been deemed acceptable.\n\nNotes on continuous auditing feasibility: No. Although a continuous audit of the performance of the assessment and its documentation is conceivable, a continuous audit is not practical. Rather, the criterion aims at the qualification of the auditing personnel as well as the process behind it, which is both subject to manual audit.",
          "Procurement, development and modification of information systems (dev). Separation of environments. Basic criterion: Production environments are physically or logically separated from test or development environments to prevent unauthorized access to cloud customer data, the spread of malware, or changes to system components. Data contained in the production environments is not used in test or development environments to avoid compromising their confidentiality.\n\nAdditional criterion: Supplementary information about the criterion complementary customer criterion notes on continuous auditing feasibility: Yes, since fundamental changes in test or development environments that would affect the physical or logical separation are rarely made, a continuous audit is not practical. The respective environments must be tested initially and then audited again if changes are made.\n\n5.12 Control and monitoring of service providers and suppliers (SSO) objective: Ensure the protection of information that service providers or suppliers of the cloud service provider (subcontractors) can access and monitor the agreed services and security requirements.",
          "Portability and interoperability (pi). Contractual agreements for the provision of data. Basic Criterion: In contractual agreements, the following aspects are defined with regard to the termination of the contractual relationship, insofar as these are applicable to the cloud service: type, scope, and format of the data the cloud service provider provides to the cloud customer; definition of the timeframe within which the cloud service provider makes the data available to the cloud customer; definition of the point in time as of which the cloud service provider makes the data inaccessible to the cloud customer and deletes it; and the cloud customers’ responsibilities and obligations to cooperate for the provision of the data. The definitions are based on the needs of subject matter experts of potential customers who assess the suitability of the cloud service with regard to a dependency on the cloud service provider as well as legal and regulatory requirements.\n\nAdditional Criterion: The design of the aspects is based on legal and regulatory requirements in the environment of the cloud service provider. The cloud service provider identifies the requirements regularly, at least once a year, and checks them for actuality and adjusts the contractual agreements accordingly.\n\nSupplementary Information about the Criterion: The type and scope of the data and the responsibilities for its provision depend on the service model of the cloud service or the services and functions provided. In the case of IaaS and PaaS, the cloud customer is generally responsible for extracting and backing up the data that is stored in the cloud service before termination of the contractual relationship (cf. complementary requirement). The cloud service provider’s responsibility is typically limited to the provision of data for the configuration of the infrastructure or platform that the cloud customer has set up within its environment (e.g., configuration of networks, images of virtual machines and containers). With SaaS, the cloud customer typically relies on export functions provided by the cloud service provider. Data created by the cloud customer should be available in the same format as stored in the cloud service. Other data, including relevant log files and metadata, should be available in an applicable standard format, such as CSV, JSON, or XML.\n\nIn Germany, legal requirements for retention can be found, for example, in the German Tax Code (§ 147 AO) and the German Commercial Code (§ 257 HGB). These provide for a retention obligation of six or ten years.\n\nComplementary Customer Criterion: Cloud customers ensure through suitable controls that the data to which they are contractually entitled is requested from the cloud service provider at the end of the contract or accessed via defined interfaces (the type and scope of the data correspond to the contractual agreements that were concluded prior to the use of the cloud service) and that it is stored in accordance with the legal requirements applicable to this data.\n\nNotes on Continuous Auditing Feasibility: No, the cloud service provider should have a standardized template for its contracts. Hence, all contracts are structured according to the same pattern. This template is rarely changed. Therefore, a continuous audit is not practical. Therefore, it is sufficient to test the contracts and the associated template as part of the recurring audit.",
          "Identification and authentication. Authenticator management | password-based authentication. For password-based authentication: \n\n(a) Maintain a list of commonly-used, expected, or compromised passwords and update the list [assignment: organization-defined frequency] and when organizational passwords are suspected to have been compromised directly or indirectly. \n(b) Verify, when users create or update passwords, that the passwords are not found on the list of commonly-used, expected, or compromised passwords in ia-5 (1) (a). \n(c) Transmit passwords only over cryptographically-protected channels. \n(d) Store passwords using an approved salted key derivation function, preferably using a keyed hash. \n(e) Require immediate selection of a new password upon account recovery. \n(f) Allow user selection of long passwords and passphrases, including spaces and all printable characters. \n(g) Employ automated tools to assist the user in selecting strong password authenticators. \n(h) Enforce the following composition and complexity rules [assignment: organization-defined composition and complexity rules].\n\nPassword-based authentication applies to passwords regardless of whether they are used in single-factor or multi-factor authentication. Long passwords or passphrases are preferable over shorter passwords. Enforced composition rules provide marginal security benefits while decreasing usability. However, organizations may choose to establish certain rules for password generation (e.g., minimum character length for long passwords) under certain circumstances and can enforce this requirement in ia-5 (1) (h).\n\nAccount recovery can occur, for example, in situations when a password is forgotten. Cryptographically protected passwords include salted one-way cryptographic hashes of passwords. The list of commonly used, compromised, or expected passwords includes passwords obtained from previous breach corpuses, dictionary words, and repetitive or sequential characters. The list includes context-specific words, such as the name of the service, username, and derivatives thereof.",
          "Compliance (com). Information on information security performance and management assessment of the isms. Basic criterion: The top management of the cloud service provider is regularly informed about the information security performance within the scope of the ISMS in order to ensure its continued suitability, adequacy, and effectiveness. The information is included in the management review of the ISMS, which is performed at least once a year.\n\nAdditional criterion: Supplementary information about the criterion is that the top management is a natural person or group of people who make final decisions for the institution and are responsible for these. The aspects to be dealt with in the management review of the ISMS are listed in Section 9.3 of ISO/IEC 27001.\n\nComplementary customer criterion: Notes on continuous auditing feasibility - partially, the actual transmission of information to the cloud service provider's management can be logged and automated. However, the testing of the contents of the communication and the fact that these have also been included in the management assessment must still be carried out within the regular audit.\n\n5.16 Dealing with investigation requests from government agencies (INQ)\n\nObjective: Ensure appropriate handling of government investigation requests for legal review, information to cloud customers, and limitation of access to or disclosure of data.",
          "Cryptography and key management (cry). Encryption of sensitive data for storage. Basic criterion: The cloud service provider has established procedures and technical safeguards to encrypt cloud customers’ data during storage. The private keys used for encryption are known only to the cloud customer, in accordance with applicable legal and regulatory obligations and requirements. Exceptions follow a specified procedure. The procedures for the use of private keys, including any exceptions, must be contractually agreed with the cloud customer.\n\nAdditional criterion: The private keys used for encryption are known to the customer exclusively and without exception, in accordance with applicable legal and regulatory obligations and requirements.\n\nSupplementary information about the criterion: An exception to the requirement that keys are known only to the cloud customers may be the use of a master key by the cloud service provider. If the cloud service provider establishes a procedure to use a master key, the cloud service provider must perform sample-based checks regarding the suitability and effectiveness of the procedure, on a regular basis. This criterion does not apply to data that cannot be encrypted for the provision of the cloud service for functional reasons.\n\nComplementary customer criterion: Through suitable controls, cloud customers ensure that for parts of the cloud service under their responsibility (e.g., virtual machines within an IaaS solution), their data is encrypted during storage in accordance with the respective protection requirements.\n\nNotes on continuous auditing feasibility: Partially, the encryption of data of cloud customers is configured centrally; therefore, it is only suitable for continuous auditing to a limited extent. Exceptions to the encryption of data, according to a specified procedure, and the coordination of this with cloud customers should be documented and approved. This, too, is only suitable to a limited extent for continuous auditing, as these exceptions are decided on a case-by-case basis and do not occur at a high enough frequency. In a continuous audit, the system status can be queried to determine whether the encryption is active and whether the approved exceptions are being adhered to.",
          "Control and monitoring of service providers and suppliers (sso). Risk assessment of service providers and suppliers. Basic criterion: Service providers and suppliers of the cloud service provider undergo a risk assessment in accordance with the policies and instructions for the control and monitoring of third parties prior to contributing to the delivery of the cloud service. The adequacy of the risk assessment is reviewed regularly, at least annually, by qualified personnel of the cloud service provider during service usage. The risk assessment includes the identification, analysis, evaluation, handling, and documentation of risks with regard to the following aspects: protection needs regarding the confidentiality, integrity, availability, and authenticity of information processed, stored, or transmitted by the third party; impact of a protection breach on the provision of the cloud service; the cloud service provider's dependence on the service provider or supplier for the scope, complexity, and uniqueness of the service purchased, including the consideration of possible alternatives.\n\nAdditional criterion: Supplementary information about the criterion complementary customer criterion notes on continuous auditing feasibility: No continuous auditing of the risk assessment is not effective, as only its regular execution could be audited automatically, but not the content. In addition, the specified frequency of at least one year is covered by the recurring audit. Risk assessments are rarely carried out dynamically and therefore do not often change during the year.",
          "Personnel (hr). Security training and awareness programme. Basic criterion: The cloud service provider operates a target group-oriented security awareness and training program, which is completed by all internal and external employees of the cloud service provider on a regular basis. The program is regularly updated based on changes to policies and instructions and the current threat situation and includes the following aspects: handling system components used to provide the cloud service in the production environment in accordance with applicable policies and procedures; handling cloud customer data in accordance with applicable policies and instructions and applicable legal and regulatory requirements; information about the current threat situation; and correct behavior in the event of security incidents. \n\nAdditional criterion: The learning outcomes achieved through the awareness and training program are measured and evaluated in a target group-oriented manner. The measurements cover quantitative and qualitative aspects. The results are used to improve the awareness and training program. \n\nSupplementary information about the criterion: \n\nComplementary customer criterion: Notes on continuous auditing \n\nFeasibility: Yes, the concept behind the security awareness and training program does not require continuous assessment and is sufficiently covered by the recurring audit. However, the completion of the training can be traced via training portals. For a continuous audit that each employee has completed and, if necessary, repeated the relevant training courses for his role description, a clear system-based definition of the necessary training courses for each role description must be carried out at the cloud service provider. The expected dates which the respective training course is to be completed must also be recorded. The documentation that the training has been completed by the employee and, if necessary, successfully completed with an examination, should take place in the same portal. The auditor then has the option of examining the results of the training courses for employees of the cloud service provider for deviations by automatically and continuously comparing the expected training dates with the actual date on which the employees completed the training.",
          "Physical security (ps). Protection against interruptions caused by power failures and other such risks. Basic criterion: Measures to prevent the failure of the technical supply facilities required for the operation of system components with which information from cloud customers is processed are documented and set up in accordance with the security requirements of the cloud service provider (cf. PS-01 Security Concept). The following aspects should be considered:\n\n- Operational redundancy (n+1) in power and cooling supply.\n- Use of appropriately sized uninterruptible power supplies (UPS) and emergency power systems (NEA) designed to ensure that all data remains undamaged in the event of a power failure.\n- The functionality of UPS and NEA should be checked at least annually by suitable tests and exercises (cf. BCM-04 – Verification, Updating, and Testing of Business Continuity).\n- Maintenance (servicing, inspection, repair) of the utilities should be conducted in accordance with the manufacturer’s recommendations.\n- Protection of power supply and telecommunications lines against interruption, interference, damage, and eavesdropping.\n- The protection should be checked regularly, but at least every two years, as well as in the case of suspected manipulation by qualified personnel. The following aspects should be considered:\n  - Traces of violent attempts to open closed distributors.\n  - Up-to-dateness of the documentation in the distribution list.\n  - Conformity of the actual wiring and patching with the documentation.\n  - The short-circuits and earthing of unneeded cables are intact.\n  - Absence of impermissible installations and modifications.\n\nAdditional criterion: Uninterruptible power supplies (UPS) and emergency power supplies (NPS) should be designed to meet the availability requirements defined in the Service Level Agreement. The cooling supply should be designed in such a way that the permissible operating and environmental parameters are also ensured on at least five consecutive days with the highest outside temperatures measured to date within a radius of at least 50 km around the locations of the premises and buildings, with a safety margin of 3K (in relation to the outside temperature). The cloud service provider has previously determined the highest outdoor temperatures measured to date (cf. PS-01 Security Concept). The connection to the telecommunications network should have sufficient redundancy to ensure that the failure of a telecommunications network does not impair the security or performance of the cloud service provider.\n\nSupplementary information about the criterion: Measures to prevent the failure of the technical supply facilities include power supply, cooling, fire-fighting technology, telecommunications, security technology, etc. Cloud service providers can ensure that all data remains undamaged in the event of a power failure by shutting down servers following a defined procedure. Power supply and telecommunications lines can be protected against interruption, interference, damage, and eavesdropping by, for example, underground supply via different supply routes.\n\nComplementary customer criterion: Notes on continuous auditing feasibility: Partially, the physical security of premises, as well as failure precautions of the technical supply facilities, should be ensured on-site by an inspection of the data center. Therefore, a continuous examination is achievable only to a limited extent. If the built-in technology for failure prevention produces evaluable log data, this requirement can partly be audited continuously. However, this does not replace an inspection. Otherwise, a continuous inspection can be carried out at least partially by indicating the last inspection date.",
          "Physical security (ps). Redundancy model. Basic criterion: The cloud service is provided from two locations that are redundant to each other. The locations meet the security requirements of the cloud service provider (cf. ps-01 security concept) and are located in an adequate distance from each other to achieve operational redundancy. Operational redundancy is designed in a way that ensures the availability requirements specified in the service level agreement are met. The functionality of the redundancy is checked at least annually by suitable tests and exercises (cf. bcm-04 - verification, updating, and testing of business continuity). \n\nAdditional criterion: The cloud service is provided from more than two locations that provide redundancy to each other. The locations are sufficiently far apart to achieve georedundancy. If two locations fail at the same time, at least one third location is still available to prevent a total service failure. The georedundancy is designed in a way that ensures the availability requirements specified in the service level agreement are met. The functionality of the redundancy is checked at least annually by suitable tests and exercises (cf. bcm-04 - verification, updating, and testing of business continuity).\n\nSupplementary information about the criterion: Operational redundancy of the sites to each other, in the sense of the basic requirement, is given if based on the assessment of elementary risks at the site, corresponding distances of the premises and buildings to these risks are maintained. Very extensive events which, due to their extent, could affect several sites of the same redundancy group simultaneously or in a timely manner (e.g. floods, earthquakes) are not considered. A georedundancy of the sites to each other, in the sense of the optional, more far-reaching requirement, is given if a very extensive event at a site under no circumstances affects several sites of the same redundancy group simultaneously or promptly. The BSI publication \"Kriterien für die Standortwahl höchstverfügbarer und georedun-danter Rechenzentren\" provides assistance in this regard.\n\nThere are cloud providers who no longer address the issue of reliability of the cloud service on a physical level through redundancy from two independent locations but through resilience. The cloud service is provided simultaneously from more than two locations. The underlying distributed data center architecture ensures that the failure of a location or components of a location does not violate the defined availability criteria of the cloud service. Such an architecture can represent an alternative fulfillment (cf. chapter 3.4.7) of the criterion. The tests and exercises on functionality required in the criterion also apply analogously to resilient architectures.\n\nComplementary customer criterion: By means of suitable controls, cloud customers ensure that the existing redundancy model of the cloud provider and the evidence for the verification of the model comply with their own requirements for the availability and reliability of the cloud service.\n\nNotes on continuous auditing feasibility: Partially an annual audit of the effectiveness of the redundancy is only partially suitable for a continuous audit. A continuous audit could return the date of the last transaction to bring about redundancy. In addition, it would be possible to document every transaction that contributes to redundancy by means of logs and to evaluate these logs automatically and continuously. In addition, the status of the redundancy could be continuously queried.",
          "Compliance (com). Policy for planning and conducting audits. Basic criterion: Policies and instructions for planning and conducting audits are documented, communicated, and made available in accordance with SP-01. They address the following aspects: \n- Restriction to read-only access to system components in accordance with the agreed audit plan and as necessary to perform the activities. \n- Activities that may result in malfunctions to the cloud service or breaches of contractual requirements are performed during scheduled maintenance windows or outside peak periods. \n- Logging and monitoring of activities. \n\nAdditional criterion: The cloud service provider grants its cloud customers contractually guaranteed information and audit rights. \n\nSupplementary information about the criterion: \n- Complementary customer criterion - Cloud customers ensure through suitable controls that appropriate responses are made to malfunctions to the cloud service through such audits. \n- To the extent that contractually guaranteed information and audit rights exist, the cloud customers ensure through suitable controls that these rights are designed and executed in accordance with their own requirements. \n\nNotes on continuous auditing feasibility: \nPartially, a policy can change ad-hoc. However, the continuous audit of policies is only partially feasible as the only attributes that can be tested are the last change date and the status of review or approval, as far as this information is stored in a system. The content of a policy can hardly be tested automatically.",
          "Personnel (hr). Confidentiality agreements. Basic criterion: The non-disclosure or confidentiality agreements to be agreed with internal employees, external service providers, and suppliers of the cloud service provider are based on the requirements identified by the cloud service provider for the protection of confidential information and operational details. The agreements are to be accepted by external service providers and suppliers when the contract is agreed. The agreements must be accepted by internal employees of the cloud service provider before authorization to access data of cloud customers is granted. The requirements must be documented and reviewed at regular intervals (at least annually). If the review shows that the requirements need to be adapted, the non-disclosure or confidentiality agreements are updated. The cloud service provider must inform the internal employees, external service providers, and suppliers and obtain confirmation of the updated confidentiality or non-disclosure agreement.\n\nAdditional criterion: Supplementary information about the criterion in a confidentiality agreement. It should be described: which information must be kept confidential; the period for which this confidentiality agreement applies; what actions must be taken upon termination of this agreement, e.g. destruction or return of data medium; how the ownership of information is regulated; what rules apply to the use and disclosure of confidential information to other partners if necessary; and the consequences of a breach of the agreement. Confidentiality or non-disclosure agreements can be signed by means of an electronic signature, insofar as this is legally binding.\n\nComplementary customer criterion: Notes on continuous auditing feasibility: Yes, the signing of confidentiality agreements with internal employees, external service providers, and suppliers can be standardized and stored digitally. An automated continuous evaluation can then be carried out to check whether all parties have signed such a confidentiality agreement and whether the agreement is up-to-date.\n\n5.4 Asset Management (AM)\n\nObjective: Identify the organization's own assets and ensure an appropriate level of protection throughout their lifecycle.",
          "Operations (ops). Logging and monitoring – identification of events. Basic criterion: The logging data is automatically monitored for events that may violate the protection goals in accordance with the logging and monitoring requirements. This also includes the detection of relationships between events (event correlation). Identified events are automatically reported to the appropriate departments for prompt evaluation and action.\n\nAdditional criterion: Additional information about the criterion. Supplementary information about the criterion.\n\nComplementary customer criterion: Complementary notes on continuous auditing feasibility: Yes, the cloud service provider can automatically test the list of assets critical for monitoring and record this test in logs. The auditor can audit the log files for irregularities automatically and continuously.",
          "Cryptography and key management (cry). Secure key management. Basic criterion: Procedures and technical safeguards for secure key management in the area of responsibility of the cloud service provider include at least the following aspects: \n- Generation of keys for different cryptographic systems and applications \n- Issuing and obtaining public-key certificates \n- Provisioning and activation of the keys \n- Secure storage of keys (separation of key management system from application and middleware level), including description of how authorized users get access \n- Changing or updating cryptographic keys, including policies defining under which conditions and in which manner the changes and/or updates are to be realized \n- Handling of compromised keys \n- Withdrawal and deletion of keys \n- If pre-shared keys are used, the specific provisions relating to the safe use of this procedure are specified separately\n\nAdditional criterion: Supplementary information about the criterion\n  \nKeys should be withdrawn or deleted, e.g. in the event of compromise or employee changes. The cloud service provider protects the keys which are created and inserted into the cloud service by the cloud customers according to the same criteria as the keys created by the cloud service provider.\n\nComplementary customer criterion: Notes on continuous auditing feasibility\n  \nPartially for procedures and technical measures for key management to take into account the required aspects, these aspects must be implemented in the corresponding configuration. These configurations are rarely changed, and only these changes would have to be audited continuously. However, the system status could be reviewed and, in the event of irregularities, indicated and documented.\n\n5.9 Communication security (COS) \n\nObjective: Ensure the protection of information in networks and the corresponding information processing systems.",
          "Communication security (cos). Documentation of the network topology. Basic criterion: The documentation of the logical structure of the network used to provision or operate the cloud service is traceable and up-to-date. This is to avoid administrative errors during live operation and to ensure timely recovery in the event of malfunctions, in accordance with contractual obligations. The documentation should show how the subnets are allocated and how the network is zoned and segmented. Additionally, it should indicate the geographical locations where the cloud customers' data is stored.\n\nAdditional criterion: Supplementary information about the criterion zoning includes segmentation of the subnets with a firewall implemented at the network perimeters.\n\nComplementary customer criterion: Notes on continuous auditing feasibility: No, the documentation of the logical structure of the network is rarely changed and is stored centrally. Therefore, a continuous audit is not effective. However, a continuous audit could provide the date of the last change to the documentation.",
          "Communication security (cos). Security requirements for connections in the cloud service provider’s network. Basic criterion: Specific security requirements are designed, published, and provided for establishing connections within the cloud service provider's network. The security requirements define, for the cloud service provider's area of responsibility, in which cases the security zones are to be separated and in which cases cloud customers are to be logically or physically segregated. They also define which communication relationships and network and application protocols are permitted in each case. Additionally, the security requirements detail how the data traffic for administration and monitoring is segregated from each other on the network level, which internal, cross-location communication is permitted, and which cross-network communication is allowed.\n\nAdditional criterion: Management procedures (cf. OIS-06) and follow-up measures (cf. OPS-18) are defined and tracked. At specified intervals, the business justification for using all services, protocols, and ports is reviewed. \n\nSupplementary information: The review also includes the justifications for compensatory measures for the use of protocols that are considered insecure. Cross-location communication can be realized, for example, for individual regions or data centers via WAN, LAN, VPN, RAS.\n\nComplementary customer criterion: Additional criterion notes on continuous auditing feasibility: No. The required security requirements are centrally documented and rarely changed. Continuous auditing is not practical.",
          "Operations (ops). Logging and monitoring – accountability. Basic criterion: The log data generated allows for an unambiguous identification of user accesses at the tenant level to support (forensic) analysis in the event of a security incident. Interfaces are available to conduct forensic analyses and perform backups of infrastructure components and their network communication.\n\nAdditional criterion: Upon request of the cloud customer, the cloud service provider provides the logs relating to the cloud customer in an appropriate form and in a timely manner so that the cloud customer can investigate any incidents relating to them.\n\nSupplementary information about the criterion: Infrastructure components in the sense of this criterion are, for example, fabric controllers, network components, and virtualization servers.\n\nComplementary customer criterion: Cloud customers ensure through suitable controls that unique user IDs are assigned, which allow for a corresponding analysis in the event of a security incident.\n\nNotes on continuous auditing feasibility: No. For the generated logging data to allow unambiguous identification of user accesses at the tenant level, the creation of this data must be configured accordingly. This configuration does not have to be audited continuously but only if it is changed. The interfaces can also be audited initially and then tested again if changes are made.",
          "Cryptography and key management (cry). Policy for the use of encryption procedures and key management. Basic criterion: Policies and instructions with technical and organizational safeguards for encryption procedures and key management are documented, communicated, and provided according to SP-01. The following aspects are described:\n\n- Usage of strong encryption procedures and secure network protocols that correspond to the state-of-the-art.\n- Risk-based provisions for the use of encryption aligned with the information classification schemes (cf. AM-06). This includes considering the communication channel, type, strength, and quality of the encryption.\n- Requirements for secure generation, storage, archiving, retrieval, distribution, withdrawal, and deletion of encryption keys.\n- Consideration of relevant legal and regulatory obligations and requirements.\n\nAdditional criterion: \n\nSupplementary information about the criterion:\n\nThe state-of-the-art of strong encryption procedures and secure network protocols is specified in the following BSI technical guidelines valid at the given time:\n\n- BSI TR-02102-1: Cryptographic mechanisms - Recommendations and key lengths.\n- BSI TR-02102-2: Cryptographic mechanisms - Use of Transport Layer Security (TLS).\n- BSI TR-02102-3: Cryptographic mechanisms - Use of Internet Protocol Security (IPSec) and Internet Key Exchange (IKEv2).\n- BSI TR-02102-4: Cryptographic mechanisms - Use of Secure Shell (SSH).\n\nComplementary customer criterion:\n\nNotes on continuous auditing feasibility: Partially, a policy can change ad-hoc. However, the continuous audit of policies is only partially feasible as the only attributes that can be tested are the last change date and the status of review or approval, as far as this information is stored in a system. The content of a policy can hardly be tested automatically.",
          "Organisation of information security (ois). Information security management system (isms). Basic criterion: The cloud service provider operates an Information Security Management System (ISMS) in accordance with ISO/IEC 27001. The scope of the ISMS covers the cloud service provider's organizational units, locations, and procedures for providing the cloud service. The measures for setting up, implementing, maintaining, and continuously improving the ISMS are documented. The documentation includes: scope of the ISMS (Section 4.3 of ISO/IEC 27001), declaration of applicability (Section 6.1.3), and results of the last management review (Section 9.3).\n\nAdditional criterion: The Information Security Management System (ISMS) has a valid certification according to ISO/IEC 27001 or ISO 27001 based on IT-Grundschutz.\n\nSupplementary information about the criterion: The basic criterion can also be fulfilled without a valid certification of the ISMS according to ISO/IEC 27001 or ISO 27001 based on IT-Grundschutz if the submitted documentation meets the requirements of ISO/IEC 27001.\n\nComplementary customer criterion: Notes on continuous auditing feasibility: Partially, a continuous audit of the ISO 27001 certificate is partially feasible because the existence of a certificate can be continuously verified through the creation date of the certificate and passing an authenticity check. However, the certificate is usually issued for three years, and there will be no dynamic changes as a rule.",
          "Organisation of information security (ois). Risk management policy. Basic criteria: Policies and instructions for risk management procedures are documented, communicated, and provided in accordance with SP-01. The following aspects should be addressed:\n\n- Identification of risks associated with the loss of confidentiality, integrity, availability, and authenticity of information within the scope of the ISMS and assigning risk owners.\n- Analysis of the probability and impact of occurrence and determination of the level of risk.\n- Evaluation of the risk analysis based on defined criteria for risk acceptance and prioritization of handling.\n- Handling of risks through measures, including approval of authorization and acceptance of residual risks by risk owners.\n- Documentation of the activities implemented to enable consistent, valid, and comparable results.\n\nAdditional criterion: Supplementary information about the criterion is that the risk level can be determined by qualitative, semi-quantitative, and quantitative methods (cf. ISO 31010) based on the likelihood and impacts.\n\nComplementary customer criterion: Notes on continuous auditing feasibility: Partially, a policy can change ad-hoc. However, the continuous audit of policies is only partially feasible as the only attributes that can be tested are the last change date and the status of review or approval, as far as this information is stored in a system. The content of a policy can hardly be tested automatically.",
          "Physical security (ps). Physical site access control. Basic criterion: At access points to premises and buildings related to the cloud service provided, physical access controls are set up in accordance with the cloud service provider's security requirements (cf. PS-01 security concept) to prevent unauthorized access. Access controls are supported by an access control system. The requirements for the access control system are documented, communicated, and provided in a policy or concept in accordance with SP-01 and include the following aspects: \n\n- Specified procedure for the granting and revoking of access authorizations (cf. IDM-02) based on the principle of least authorization (\"least-privilege principle\") and as necessary for the performance of tasks (\"need-to-know principle\").\n- Automatic revocation of access authorizations if they have not been used for a period of 2 months.\n- Automatic withdrawal of access authorizations if they have not been used for a period of 6 months.\n- Two-factor authentication for access to areas hosting system components that process cloud customer information.\n- Visitors and external personnel are tracked individually by the access control during their work in the premises and buildings, identified as such (e.g., by visible wearing of a visitor pass), and supervised during their stay.\n- Existence and nature of access logging that enables the cloud service provider, in the sense of an effectiveness audit, to check whether only defined personnel have entered the premises and buildings related to the cloud service provided.\n\nAdditional criterion: Supplementary information about the criterion complementary customer criterion notes on continuous auditing:\n\nFeasibility: Yes. Access control via an access card system can be documented by the cloud service provider in the form of logs. These logs can be evaluated automatically. In addition, unauthorized access can also be traced through these logs. This can also be evaluated automatically. Therefore, a continuous audit is possible. Insofar as the withdrawal of access authorizations is standardized and documented in the same way, an automated evaluation is also possible here, and thus, a continuous audit can be carried out.",
          "Identity and access management (idm). Authentication mechanisms. Basic criterion: System components in the cloud service provider's area of responsibility that are used to provide the cloud service, authenticate users of the cloud service provider's internal and external employees, as well as system components that are involved in the cloud service provider's automated authorization processes. Access to the production environment requires two-factor or multi-factor authentication. Within the production environment, user authentication takes place through passwords, digitally signed certificates, or procedures that achieve at least an equivalent level of security. If digitally signed certificates are used, administration is carried out in accordance with the guideline for key management (cf. cry-01). The password requirements are derived from a risk assessment and documented, communicated, and provided in a password policy according to sp-01. Compliance with the requirements is enforced by the configuration of the system components, as far as technically possible. Additional criterion: Access to the non-production environment requires two-factor or multi-factor authentication. Within the non-production environment, users are authenticated using passwords, digitally signed certificates, or procedures that provide at least an equivalent level of security.\n\nSupplementary information about the criterion: Complementary customer criterion notes on continuous auditing feasibility: Yes, if the implementation is enforced by appropriate system configuration (automated control), the status of the configuration or its last change can be checked regularly.\n\n5.8 Cryptography and Key Management (CRY)\n\nObjective: Ensure appropriate and effective use of cryptography to protect the confidentiality, authenticity, or integrity of information.",
          "Communication security (cos). Technical safeguards. Basic criterion: Based on the results of a risk analysis carried out according to ISO-06, the cloud service provider has implemented technical safeguards that are suitable to promptly detect and respond to network-based attacks. These attacks are based on irregular incoming or outgoing traffic patterns and/or distributed denial of service (DDoS) attacks. The corresponding technical protection measures are documented, communicated, and provided in accordance with SP-01. \n\nAdditional criterion: Technical measures ensure that no unknown (physical or virtual) devices join the cloud service provider's (physical or virtual) network. This can be achieved through measures such as MACsec according to IEEE 802.1x:2010. \n\nSupplementary information about the criterion: Network-based attacks can include MAC spoofing and ARP poisoning attacks. \n\nComplementary customer criterion: Cloud customers are responsible for ensuring suitable controls for parts of the cloud service under their responsibility (e.g., virtual machines within an IaaS solution). They should detect and respond to network-based attacks based on anomalous inbound and outbound traffic patterns, such as MAC spoofing, ARP poisoning attacks, and DDoS attacks, in a timely manner. \n\nNotes on continuous auditing feasibility: The technical protective measures are suitable for continuous auditing, but they are rarely changed. However, the data fed into the overall SIEM system and the detection of correlating events are suitable for continuous auditing. This data can be evaluated automatically and continuously, as can the monitoring of correlating events.",
          "Control and monitoring of service providers and suppliers (sso). Policies and instructions for controlling and monitoring third parties. Basic criterion: Policies and instructions for controlling and monitoring third parties (e.g. service providers or suppliers) whose services contribute to the provision of the cloud service are documented, communicated, and provided in accordance with SP-01 with respect to the following aspects:\n\n- Requirements for the assessment of risks resulting from the procurement of third-party services\n- Requirements for the classification of third parties based on the risk assessment by the cloud service provider and the determination of whether the third party is a subcontractor (cf. supplementary information)\n- Information security requirements for the processing, storage, or transmission of information by third parties based on recognized industry standards\n- Information security awareness and training requirements for staff\n- Applicable legal and regulatory requirements\n- Requirements for dealing with vulnerabilities, security incidents, and malfunctions\n- Specifications for the contractual agreement of these requirements\n- Specifications for the monitoring of these requirements\n- Specifications for applying these requirements also to service providers used by the third parties, insofar as the services provided by these service providers also contribute to the provision of the cloud service.\n\nAdditional criterion: Subservice organizations of the cloud service provider are contractually obliged to provide regular reports by independent auditors on the suitability of the design and operating effectiveness of their service-related internal control system. The reports include the complementary subservice organizations that are required, together with the controls of the cloud service provider, to meet the applicable basic criteria of BSI C5 with reasonable assurance. In case no reports can be provided, the cloud service provider agrees to appropriate information and audit rights to assess the suitability and effectiveness of the service-related internal control system, including the complementary controls, by qualified personnel.\n\nSupplementary information about the criterion: Reports by independent auditors on the suitability of the design and operating effectiveness of their service-related internal control system are, for example, attestation reports in accordance with ISAE 3402, IDW PS 951, SOC 2, or BSI C5. Qualified personnel works, for example, in the cloud service provider's internal audit department or is commissioned by the cloud service provider in the form of expert third parties, such as audit firms, and may hold relevant certifications such as \"Certified Internal Auditor (CIA)\". The complementary controls at the subservice provider are necessary in order to, together with the controls of the cloud service provider, fulfill the applicable C5 criteria with reasonable assurance. Applicable legal and regulatory requirements may exist, for example, in the areas of data protection, intellectual property rights, or copyright. If legal or regulatory requirements provide for a regulation deviating from these criteria for the control of subcontractors, these regulations remain unaffected by the C5 criteria.\n\nComplementary customer criterion notes on continuous auditing feasibility: Partially regarding the availability of the documentation, a continuous audit is not practical since the associated processes and steps can be tested in a recurring audit. A continuous audit of whether changes have been made to the policies is possible, provided that these changes are documented by the cloud service provider and can be evaluated. However, an automated audit of the meaningfulness of the changes is difficult to implement. Regarding the proof that a communication/provision has taken place, a continuous audit is considered possible. For this, the cloud service provider would have to realize the notification based on a system (e.g. based on tickets or notes in the respective service provider contract).",
          "Identity and access management (idm). Access to cloud customer data. Basic criterion: The cloud customer is informed by the cloud service provider whenever internal or external employees of the cloud service provider read or write to the cloud customer’s data processed, stored, or transmitted in the cloud service or have accessed it without the prior consent of the cloud customer. The information is provided whenever data of the cloud customer is/was not encrypted, the encryption is/was disabled for access, or the contractual agreements do not explicitly exclude such information. The information contains the cause, time, duration, type, and scope of the access. The information is sufficiently detailed to enable subject matter experts of the cloud customer to assess the risks of the access. The information is provided in accordance with the contractual agreements or within 72 hours after the access.\n\nAdditional criterion: Access to the data processed, stored, or transmitted in the cloud service by internal or external employees of the cloud service provider requires the prior consent of an authorized department of the cloud customer, provided that the cloud customer's data is not encrypted, encryption is disabled for access, or contractual agreements do not explicitly exclude such consent. For the consent, the cloud customer's department is provided with meaningful information about the cause, time, duration, type, and scope of the access supporting assessing the risks associated with the access.\n\nSupplementary information about the criterion: Subject matter experts, in the sense of this basic criterion, are personnel from e.g. IT, compliance, or internal audit.\n\nComplementary customer criterion notes on continuous auditing feasibility: Yes, a continuous audit of the notifications carried out only appears practical if the accesses mentioned are also logged and classified automatically. The content of the notifications can only be audited if the content is specified by the cloud service provider according to a specific scheme. Then, a comparison and plausibility check can take place. A continuous audit would test all notifications after they have been received and thus check whether the process has been executed correctly in all cases.",
          "Business continuity management (bcm). Top management responsibility. Basic criterion: The top management (or a member of the top management) of the cloud service provider is named as the process owner of business continuity and emergency management. They are responsible for establishing the process within the company as well as ensuring compliance with the guidelines. They must ensure that sufficient resources are made available for an effective process. People in management and other relevant leadership positions demonstrate leadership and commitment to this issue by encouraging employees to actively contribute to the effectiveness of continuity and emergency management.\n\nAdditional criterion: Supplementary information about the criterion\n\nComplementary customer criterion: \n\nNotes on continuous auditing feasibility: No, the responsibilities for continuity and emergency management processes are initially named and rarely changed afterwards. Therefore, a continuous audit is not effective. However, a continuous audit can return the date of the last revision of the guidelines for continuity and emergency management.",
          "Product safety and security (pss). Roles and rights concept. Basic criterion: The cloud service provider provides cloud users with a roles and rights concept for managing access rights. It describes rights profiles for the functions provided by the cloud service. The rights profiles are suitable for enabling cloud users to manage access authorizations and permissions in accordance with the principle of least privilege and how it is necessary for the performance of tasks (\"need-to-know principle\") and to implement the principle of functional separation between operational and controlling functions (\"separation of duties\").\n\nAdditional criterion: Supplementary information about the criterion. In IaaS, a role and rights concept would describe, among other things, the rights profiles for the following functions of the cloud service: \n\n- Administration of the states of virtual machines (start, pause, stop) as well as for their migration or monitoring; \n- Management of available images that can be used to create virtual machines; \n- Management of virtual networks (e.g., configuration of virtual routers and switches). \n\nComplementary customer criterion: Cloud customers ensure through suitable controls that: \n\n- The granting of permissions to users in their area of responsibility is subject to authorization; \n- The appropriateness of the assigned authorizations is regularly reviewed and authorizations are adjusted or withdrawn in a timely manner in the event of necessary changes (e.g., employee resignation). \n\nNotes on continuous auditing feasibility: Partially, the existence of a roles and rights concept in the form of a configuration in the system can be monitored. However, it should be noted that, regarding the content of this concept, only deviations from target configurations can be checked. Whether these deviations are desired or not must still be recorded in a manual audit.",
          "Communication security (cos). Monitoring of connections in the cloud service provider’s network. Basic criterion: A distinction is made between trusted and untrusted networks. Based on a risk assessment, these are separated into different security zones for internal and external network areas (and DMZ, if applicable). Physical and virtualized network environments are designed and configured to restrict and monitor the established connection to trusted or untrusted networks according to the defined security requirements. The entirety of the conception and configuration undertaken to monitor the connections mentioned is assessed in a risk-oriented manner, at least annually, with regard to the resulting security requirements. Identified vulnerabilities and deviations are subject to risk assessment in accordance with the risk supplementary information about the criterion. The review of the security requirements depends on the measures implemented to design the networks. For example, monitoring and reviewing firewall rules or log files for abnormalities, as well as visual inspections of physical network components for changes.\n\nComplementary customer criterion: Cloud customers ensure through suitable controls that the virtual networks within the cloud service for which they are responsible are designed, configured, and documented in accordance with their network security requirements (e.g. logical segmentation of the cloud customer's organizational units).\n\nNotes on continuous auditing feasibility: Yes, if the business justification and the regular review of the monitoring concept are documented in a standardized way, these processes can be evaluated automatically. Thus, a continuous audit can be conducted. The separation of the networks is suitable for continuous auditing as well since the status of the separation can be continuously audited here.",
          "Operations (ops). Separation of datasets in the cloud infrastructure. Basic criterion: Cloud customer data stored and processed on shared virtual and physical resources is securely and strictly separated according to a documented approach based on OIS-07 risk analysis to ensure the confidentiality and integrity of this data. \n\nAdditional criterion: Resources in the storage network are segmented by secure zoning (LUN binding and LUN masking). Supplementary information about the criterion shared resources include memory, cores, and storage networks. \n\nTechnical segregation (separation) of the stored and processed data of cloud customers into shared resources can be achieved through firewalls, access lists, tagging, VLANs, virtualization, and measures in the storage network (e.g., LUN binding and LUN masking). \n\nWhere the adequacy and effectiveness of segregation cannot be assessed with reasonable assurance (e.g., due to complex implementation), evidence may also be provided through expert third-party review results (e.g., penetration tests to validate the concept). \n\nThe segregation of transmitted data is subject to control COS-06. \n\nComplementary customer criterion: Cloud customers ensure through suitable controls that the functions provided by the cloud service for segregating shared virtual and physical resources are used in such a way that risks related to segregation are adequately addressed according to the data's protection requirements. \n\nNotes on continuous auditing feasibility: Partially, the segregation according to a documented concept is implemented by means of a configuration that does not change with high frequency. A continuous audit of this configuration could check whether the configuration and thus the segregation of the data is implemented correctly. However, the effort for a continuous audit would be high, and the benefit limited due to the low change rate of the configuration. Thus, a continuous audit would only be of limited use here. If compliance with the measures taken is monitored, this criterion can be audited automatically. It would also be conceivable to continuously audit the actual data segregation. For this purpose, the cloud service provider would have to set up appropriate agents to monitor the data flow between the customer instances (or its absence) on a permanent and documented basis (logs). \n\n5.7 Identity and Access Management (IDM) \n\nObjective: Secure the authorization and authentication of users of the cloud service provider (typically privileged users) to prevent unauthorized access.",
          "Procurement, development and modification of information systems (dev). Approvals for provision in the production environment. Basic criterion: Authorized personnel or system components of the cloud service provider approve changes to the cloud service based on defined criteria (e.g. test results and required approvals) before these are made available to the cloud customers in the production environment. Cloud customers are involved in the release according to contractual requirements.\n\nAdditional criterion: Supplementary information about the criterion, the definitions for criterion dev-03 apply.\n\nComplementary customer criterion: Where changes are to be approved by the cloud customers in accordance with the contractual agreements before they are made available in the production environment, the cloud customers ensure through suitable controls that authorized and qualified personnel receive the information made available, assess the impact on the ISMS framework, and decide on the approval in accordance with the conditions specified by the cloud service provider.\n\nNotes on continuous auditing feasibility: Yes, verification that all tests have been completed, successfully, and approved by an authorized body can be automated by the cloud service provider and documented in logs. These logs can then be evaluated automatically and continuously by the auditor.",
          "Identity and access management (idm). Withdraw or adjust access rights as the task area changes. Basic criterion: Access rights are promptly revoked if the job responsibilities of the cloud service provider's internal or external staff or the tasks of system components involved in the cloud service provider's automated authorization processes change. Privileged access rights are adjusted or revoked within 48 hours after the change taking effect. All other access rights are adjusted or revoked within 14 days. After revocation, the procedure for granting user accounts and access rights (cf. idm-02) must be repeated. \n\nAdditional criterion: Supplementary information about the criterion changes in the task area of internal and external employees can be triggered by changes in the employment relationship (e.g., termination, transfer) or in contracts and agreements. For privileged access rights, the definition in idm-06 applies. \n\nComplementary customer criterion: \nNotes on continuous auditing feasibility: Yes, it is necessary to record the changes to the task area in terms of content together with the date of entry into force in order to compare these with the adjustments made to the access rights. A continuous audit seems possible but requires a great deal of effort to implement.",
          "Control and monitoring of service providers and suppliers (sso). Directory of service providers and suppliers. Basic criterion: The cloud service provider maintains a directory for controlling and monitoring the service providers and suppliers who contribute services to the delivery of the cloud service. The following information is maintained in the directory: company name, address, locations of data processing and storage, responsible contact person at the service provider/supplier, responsible contact person at the cloud service provider, description of the service, classification based on the risk assessment, beginning of service usage, and proof of compliance with contractually agreed requirements. The information in the list is checked at least annually for completeness, accuracy, and validity.\n\nAdditional criterion: Supplementary information about the criterion. It is not necessary to maintain a single central register in order to fulfill the basic criterion. \n\nComplementary customer criterion: Notes on continuous auditing feasibility. No ad-hoc completeness checks on the specified criteria can safely take place automatically, as can a comparison of changed data with relevant company databases. This can be set up by the cloud service provider. The auditor can then examine deviations as part of the recurring audit. However, due to the frequency and the completeness analysis, a continuous audit is not efficient due to the large effort required.",
          "Organisation of information security (ois). Interfaces and dependencies. Basic criterion: Interfaces and dependencies between cloud service delivery activities performed by the cloud service provider and activities performed by third parties are documented and communicated. This includes dealing with the following events: vulnerabilities, security incidents, and malfunctions. The type and scope of the documentation is geared towards the information requirements of the subject matter experts of the affected organizations in order to carry out the activities appropriately (e.g., definition of roles and responsibilities in guidelines, description of cooperation obligations in service descriptions and contracts). The communication of changes to the interfaces and dependencies takes place in a timely manner so that the affected organizations and third parties can react appropriately with organizational and technical measures before the changes take effect.\n\nAdditional criterion: Supplementary information about the criterion. The cloud service provider can define and document the interfaces and dependencies described in the basic criterion in guidelines and instructions. For example, cloud customers’ obligations to cooperate should be described in service descriptions and contracts. \n\nThird parties in the sense of this basic criterion are, e.g., cloud customers and sub-service providers.\n\nComplementary customer criterion: Cloud customers ensure through suitable controls that the guidelines and requirements for compliance with the contractual agreements with the cloud service provider (i.e., responsibilities, cooperation obligations, and interfaces for reporting security incidents) are adequately defined, documented, and set up.\n\nNotes on continuous auditing feasibility: No, an automated continuous audit for critical dependencies and interfaces is currently only possible at a high cost to the cloud service provider.",
          "Business continuity management (bcm). Verification, updating and testing of the business continuity. Basic criterion: The business impact analysis, business continuity plans, and contingency plans are reviewed, updated, and tested on a regular basis (at least annually) or after significant organizational or environmental changes. Tests involve affected customers (tenants) and relevant third parties. The tests are documented, and results are taken into account for future operational continuity measures.\n\nAdditional criterion: In addition to the tests, exercises are also carried out which, among other things, have resulted in scenarios from security incidents that have already occurred in the past.\n\nSupplementary information about the criterion: Tests are primarily conducted at the operational level and are aimed at operational target groups. Tests include, e.g.: test of technical precautionary measures; functional tests; and plan review. Exercises also take place on a tactical and strategic level. These include, e.g.: plan meeting; staff exercise; command post exercise; communication and alerting exercise; simulation of scenarios; and emergency or full exercise. After a completed exercise: review and possible adaptation of the existing alarm plan.\n\nRelevant third parties are, in particular, service providers and suppliers of the cloud service provider who contribute to the provision of the cloud service (cf. basic criteria sso-02 and sso-05).\n\nComplementary customer criterion: Cloud customers ensure through suitable controls that measures to prevent the impact of a cloud service or cloud service provider outage are regularly reviewed, updated, tested, and exercised. The cloud service provider is involved in the tests and exercises in accordance with the contractual agreements. Cloud customers ensure through suitable controls that the results of the cloud service provider's BCM tests and exercises are incorporated into their own BCM and that they are fully appreciated with regard to ensuring the customer's operational continuity. In tests and exercises that involve the customer and therefore require own measures on the customer side, cloud customers ensure that the appropriate measures for coping with the scenario are practiced and tested by means of suitable BCM controls.\n\nNotes on continuous auditing feasibility: Partially implementing the tests of the operational continuity plans in an annual cycle does not make the continuous audit of the entire criterion effective. The effort for both cloud service providers and auditors to automate and continuously test this process would be higher than the results. However, it is possible to continuously audit whether a test was carried out within the required time span. To do this, the cloud service provider must document, in a standardized manner, that and when a test was carried out.\n\n5.15 Compliance (COM)\n\nObjective: Avoid non-compliance with legal, regulatory, self-imposed, or contractual information security and compliance requirements.",
          "Procurement, development and modification of information systems (dev). Policies for the development/ procurement of information systems. Basic criterion: Policies and instructions with technical and organizational measures for the secure development of the cloud service are documented, communicated and provided in accordance with SP-01. The policies and instructions contain guidelines for the entire lifecycle of the cloud service and are based on recognized standards and methods with regard to the following aspects: security in software development (requirements, design, implementation, testing, and verification); security in software deployment (including continuous delivery); and security in operation (reaction to identified faults and vulnerabilities). \n\nAdditional criterion: In procurement, products are preferred which have been certified according to the \"Common Criteria for Information Technology Security Evaluation\" (short: Common Criteria - CC) according to evaluation assurance level EAL 4. If non-certified products are to be procured instead of available certified products, a risk assessment is carried out in accordance with OIS-07.\n\nSupplementary information about the criterion: The software provision can be carried out, for example, with continuous delivery methods. Accepted standards and methods are, for example: ISO/IEC 27034; and OWASP Secure Software Development Lifecycle (S-SDLC). \n\nComplementary customer criterion notes on continuous auditing feasibility: No. The contents of the policies and instructions for the proper development or procurement of information systems do not change at a high frequency. A continuous audit of this documentation is not practical. Therefore, the integration of these tests into the recurring audit is sufficient.",
          "Personnel (hr). Employment terms and conditions. Basic criterion: The cloud service provider's internal and external employees are required, by the employment terms and conditions, to comply with applicable policies and instructions relating to information security. The information security policy, and the policies and instructions based on it, must be acknowledged by the internal and external personnel in a documented form before access is granted to any cloud customer data or system components under the responsibility of the cloud service provider, used to provide the cloud service in the production environment.\n\nAdditional criterion: Supplementary information about the criterion. The cloud service provider ensures that the policies and instructions reflect applicable legal and regulatory requirements in accordance with SP-01.\n\nComplementary customer criterion: Notes on continuous auditing feasibility. Yes, due to the obligation of employees to comply with certain requirements, a continuous audit is not practical. Compliance with the requirements can be verified as part of a standard audit cycle. A continuous audit of the granting of access, only after acknowledgement of the instructions, is achievable as long as the cloud service provider designs the approval system to document the appropriate data (e.g., date of acknowledgement, which data the employee had access to and when). A clear definition and differentiation of customer data, as well as data in the productive environment, is essential. With the help of this data, the auditor can perform a comparison and detect deviations accordingly. The data could be monitored using an agent on a monitoring system.",
          "Operations (ops). Logging and monitoring – configuration. Basic criterion: Access to system components for logging and monitoring in the cloud service provider’s area of responsibility is restricted to authorized users. Changes to the configuration are made in accordance with the applicable policies (cf. dev-03). \n\nAdditional criterion: Access to system components for logging and monitoring in the cloud service provider’s area of responsibility requires two-factor authentication. \n\nSupplementary information about the criterion: \nComplementary customer criterion notes on continuous auditing feasibility: Yes, the continuous audit of this access restriction can be tested by log files of all changes to access rights for the system components for logging and monitoring. Changes can be automatically and continuously audited according to the person’s sense and need for access.",
          "Operations (ops). Logging and monitoring – storage of the logging data. Basic criterion: The cloud service provider retains the generated log data and keeps them in an appropriate, unchangeable, and aggregated form, regardless of the source of such data, so that a central, authorized evaluation of the data is possible. Log data is deleted if it is no longer required for the purpose for which they were collected. Between logging servers and the assets to be logged, authentication takes place to protect the integrity and authenticity of the information transmitted and stored. The transfer takes place using state-of-the-art encryption or a dedicated administration network (out-of-band management).\n\nAdditional criterion: The cloud service provider provides customer-specific logging (in terms of scope and duration of retention period) upon the request of the cloud customer. Depending on the protection requirements of the cloud service provider and the technical feasibility, a logical or physical separation of log and customer data is carried out.\n\nSupplementary information about the criterion:\nComplementary customer criterion\nNotes on continuous auditing feasibility: Yes, the storage of logging data at a central location can be documented by logs when the data is saved. The deletion of this data can also be automated and documented by logs. The auditor can then perform an automated and continuous evaluation of these logs.",
          "Identity and access management (idm). Granting and change of user accounts and access rights. Basic criterion: Specified procedures for granting and modifying user accounts and access rights for internal and external employees of the cloud service provider as well as for system components involved in automated authorization processes of the cloud service provider ensure compliance with the role and rights concept as well as the policy for managing user accounts and access rights.\n\nAdditional criterion: The cloud service provider offers cloud customers a self-service with which they can independently assign and change user accounts and access rights.\n\nSupplementary information about the criterion: Complementary customer criterion notes on continuous auditing feasibility: No. A continuous audit of procedures is strongly dependent on the underlying systematics and automation of the cloud service provider's procedures. This may vary in individual cases, but in general, a continuous audit does not appear to be effective.",
          "Cryptography and key management (cry). Encryption of data for transmission (transport encryption). Basic criterion: The cloud service provider has established procedures and technical measures for strong encryption and authentication for the transmission of data of cloud customers over public networks.\n\nAdditional criterion: The cloud service provider has established procedures and technical measures for strong encryption and authentication for the transmission of all data.\n\nSupplementary information about the criterion: When transmitting data with normal protection requirements within the cloud service provider's infrastructure, encryption is not mandatory, provided that the data is not transmitted via public networks. In this case, the non-public environment of the cloud service provider can generally be deemed trusted. The protocols TLS 1.2 and TLS 1.3 are currently regarded as strong, state-of-the-art transport encryptions, in each case in combination with perfect forward secrecy. The specific configuration should comply with the recommendations of the (current) version of the BSI Technical Guideline TR-02102-2 \"Cryptographic Procedures: Recommendations and Key Lengths - Part 2: Use of Transport Layer Security (TLS)\". Generally, the use of wildcard certificates is not considered a secure procedure.\n\nThe basic criterion for the transmission of cloud customers' data relates to, for example, the sending of electronic messages via public networks.\n\nComplementary customer criterion: Cloud customers ensure, through suitable controls for those parts of the cloud service under their responsibility, that their data is transmitted over encrypted connections in accordance with the respective protection requirements.\n\nNotes on continuous auditing feasibility: Partially, the procedures and technical measures for encrypting data during transmission are configured centrally. This configuration rarely changes. Therefore, a continuous audit would not be sensible, as only changes to this configuration would have to be checked. However, the system status can be audited continuously. This also applies to the additional criterion.",
          "Organisation of information security (ois). Application of the risk management policy. Basic criterion: The cloud service provider executes the process for handling risks as needed or at least once a year. The following aspects are taken into account when identifying risks, insofar as they are applicable to the cloud service provided and are within the area of responsibility of the cloud service provider: processing, storage, or transmission of data of cloud customers with different protection needs; occurrence of vulnerabilities and malfunctions in technical protective measures for separating shared resources; attacks via access points, including interfaces accessible from public networks; conflicting tasks and areas of responsibility that cannot be separated for organizational or technical reasons; and dependencies on subservice organizations. The analysis, evaluation, and treatment of risks, including the approval of actions and acceptance of residual risks, are reviewed for adequacy at least annually by the risk owners.\n\nAdditional criterion supplementary information about the criterion: This criterion applies only to risks that reside within the area of responsibility of the cloud service provider. Risks that arise for the cloud customer when using the cloud service are not covered by this criterion. When outsourcing activities for the provision of cloud services to subservice organizations, the responsibility for these risks remains with the cloud service provider. Requirements for measures to manage these risks can be found in the criteria area \"Control and monitoring of service providers and suppliers (SSO)\". Shared resources are e.g. networks, RAM, or storage.\n\nComplementary customer criterion notes on continuous auditing feasibility: Partially, the procedure for handling risks must be tested at least once a year and is therefore part of the standard audit cycle. However, the continuous audit of handling risk is only partially feasible as the only attributes that can be tested are the last review date and the status of review or approval, as far as this information is stored in a system. The content of the risks can hardly be tested automatically.\n\n5.2 Security policies and instructions (SP) objective: Provide policies and instructions regarding security requirements and to support business requirements.",
          "Operations (ops). Data backup and recovery – concept. Basic criterion: Policies and instructions for data backup and recovery are documented, communicated, and provided in accordance with SP-01. The following aspects need to be addressed:\n\n- The extent and frequency of data backups and the duration of data retention should align with contractual agreements with cloud customers and the cloud service provider's operational continuity requirements for Recovery Time Objective (RTO) and Recovery Point Objective (RPO).\n- Data should be backed up in an encrypted state-of-the-art form.\n- Access to backed-up data and execution of restores should be performed only by authorized persons.\n- Tests of recovery procedures (cf. OPS-08) should be conducted.\n\nAdditional criterion: Supplementary information about the criterion:\n\n- The data backup concept specifies the type of data backup to be carried out (e.g., type, manner, duration) and identifies any specific data that must be backed up in special cases (e.g., pure use of compute nodes without data storage).\n- Backup procedures should differentiate between backups and snapshots of virtual machines. Snapshots do not replace backups but can be included in the backup strategy to achieve Recovery Point Objectives (RPO) if they are stored outside the original data location.\n- The business requirements of the cloud service provider for the scope, frequency, and duration of data backup should be determined through a business impact analysis (cf. BCM-03) for development and operational processes of the cloud service.\n- If different data backup and recovery procedures exist for data under the responsibility of the cloud customer and the cloud service provider, both variants need to be included in a test according to this criteria catalogue.\n- For procedures to secure the data of the cloud service provider, only the adequacy and implementation of the controls need to be proven, but not their effectiveness.\n- For procedures to secure the data of cloud customers, proof of effectiveness must also be provided.\n\nComplementary customer criterion: Cloud customers need to ensure, through suitable controls, that the contractual agreements made with the cloud service provider regarding the scope, frequency, and duration of data retention meet their business requirements. The business requirements are assessed as part of the business impact analysis (cf. BCM-02).\n\nNotes on continuous auditing feasibility: Partially, a policy can change ad-hoc. However, continuous auditing of policies is only partially feasible as the only attributes that can be tested are the last change date and the status of review or approval, as far as this information is stored in a system. The content of a policy can hardly be tested automatically.",
          "Product safety and security (pss). Locations of data processing and storage. Basic criterion: The cloud customer is able to specify the locations (location/country) of the data processing and storage, including data backups, according to the contractually available options. This must be ensured by the cloud architecture.\n\nAdditional criterion: Supplementary information about the criterion. This criterion supplements the general condition BC-01. The cloud architecture must exist in such a way that it enables the technical design of the IT infrastructure to provide the cloud service in accordance with the data location specifications agreed with the customer.\n\nComplementary customer criterion: Cloud customers ensure, through suitable controls, that when selecting service providers and configuring the cloud service, they are informed about the available data processing and storage locations. If there is a choice between different locations, they select those that meet their own requirements. Depending on the use case and especially when using services of a cloud service provider based in another country, cloud customers take the laws applicable to them into account when making their selection (e.g., when processing personal data; compliance with legal retention obligations for business documents, etc.).\n\nNotes on continuous auditing feasibility: Yes, a continuous survey of the location of the data and the country from which the service is provided can be carried out automatically by the cloud service provider. This information can then be made available to the customer, for example, on their dashboard or on request.",
          "Physical security (ps). Protection from fire and smoke. Basic criterion: Premises and buildings related to the cloud service provided are protected from fire and smoke by structural, technical, and organizational measures that meet the security requirements of the cloud service provider (cf. PS-01 security concept). This includes the following aspects:\n\na) Structural measures: Establishment of fire sections with a fire resistance duration of at least 90 minutes for all structural parts.\n\nb) Technical measures: Early fire detection with automatic voltage release. The monitored areas are sufficiently fragmented to ensure that the prevention of the spread of incipient fires is proportionate to the maintenance of the availability of the cloud service provided. This includes an extinguishing system or oxygen reduction and a fire alarm system with reporting to the local fire department.\n\nc) Organizational measures: Regular fire protection inspections to check compliance with fire protection requirements and regular fire protection exercises.\n\nAdditional criterion: The environmental parameters are monitored. When the permitted control range is exceeded, alarm messages are generated and forwarded to the cloud service provider's subject matter experts.\n\nSupplementary information about the criterion: The monitoring of the environmental parameters is addressed in PS-01. When exceeding the allowed control range, alarm messages are generated and forwarded to the responsible cloud service provider. Structural parts include walls, ceilings, floors, doors, ventilation flaps, etc.\n\nComplementary customer criterion notes on continuous auditing feasibility: Yes, continuous testing is possible insofar as the built-in technology for testing the protective measures produces evaluable data, and these are stored in a standardized form. This would allow the security measures to be continuously evaluated by the auditor. If this technology is not fully available and an inspection of the data center is necessary, the possibility of continuous auditing is achievable only to a limited extent.",
          "Product safety and security (pss). Session management. Basic criterion: To protect confidentiality, availability, integrity, and authenticity during interactions with the cloud service, a suitable session management system is used that at least corresponds to the state-of-the-art and is protected against known attacks. Mechanisms are implemented that invalidate a session after it has been detected as inactive. The inactivity can be detected by time measurement. In this case, the time interval can be configured by the cloud service provider or – if technically possible – by the cloud customer.\n\nAdditional criterion: Supplementary information about the criterion of known attacks includes manipulation, forgery, session takeover, denial of service attacks, enveloping, replay, and null cipher attacks.\n\nComplementary customer criterion: Cloud customers can use appropriate controls to ensure that they are using the session management protection features of the cloud service in accordance with their own ISMS. They also set the time period after which a session becomes invalid according to their own ISMS specifications.\n\nNotes on continuous auditing feasibility: Partially, the use of session management is controlled by configurations. These configurations are changed or adapted at a low frequency, so continuous auditing is only partially effective. Nevertheless, monitoring the status of the underlying authentication system is conceivable, but only deviations from target configurations can be checked. Whether these deviations are normal must still be tested in a manual audit.",
          "Product safety and security (pss). Identification of vulnerabilities of the cloud service. Basic criterion: The cloud service provider applies appropriate measures to check the cloud service for vulnerabilities that might have been integrated into the cloud service during the software development process. The procedures for identifying such vulnerabilities are part of the software development process and, depending on a risk assessment, include the following activities: static application security testing; dynamic application security testing; code reviews by the cloud service provider’s subject matter experts; and obtaining information about confirmed vulnerabilities in software libraries provided by third parties and used in their own cloud service. The severity of identified vulnerabilities is assessed according to defined criteria, and measures are taken to immediately eliminate or mitigate them.\n\nAdditional criterion: The procedures for identifying such vulnerabilities also include annual code reviews or security penetration tests by qualified external third parties.\n\nSupplementary information about the criterion: Known vulnerabilities in externally related system components (e.g., operating systems) used for the development and provision of the cloud service but not going through the cloud service provider’s software development process are the subject of Criteria OPS-23 (Management of vulnerabilities, malfunctions, and errors – open vulnerability assessment).\n\nComplementary customer criterion: Notes on continuous auditing feasibility: Yes, the cloud service provider automatically checks its cloud services for vulnerabilities. This check is documented in a standardized digital form. By auditing this documentation, the auditor verifies whether the cloud service provider has performed a vulnerability scan. In addition, the severity of the identified vulnerabilities can be integrated into this continuous audit if the defined criteria and their application are standardized and machine-readable. The information on identified and/or repaired vulnerabilities can also be transferred directly to the affected customer, increasing transparency.",
          "Operations (ops). Data backup and recovery – monitoring. Basic criterion: The execution of data backups is monitored by technical and organizational measures. Malfunctions are investigated by qualified staff and rectified promptly to ensure compliance with contractual obligations to cloud customers or the cloud service provider's business requirements regarding the scope and frequency of data backup and the duration of storage.\n\nAdditional criterion: The relevant logs or summarized results are available to the cloud customer in a self-service portal for monitoring the data backup.\n\nSupplementary information about the criterion: If the data backup is not part of the contract concluded between the cloud service provider and the cloud customer, this criterion is not applicable. The cloud service provider must present this situation transparently in the system description.\n\nComplementary customer criterion: Cloud customers ensure, through suitable controls, that the backup of data within their area of responsibility is monitored by technical and organizational measures.\n\nNotes on continuous auditing feasibility: Yes, the execution of different data backups can be performed by continuously auditing the log files and the associated results of the data backup. Any errors in the data backup would be continuously detected and could be explained by appropriate measures and documentation in the audit.",
          "Procurement, development and modification of information systems (dev). Version control. Basic criterion: Version control procedures are set up to track dependencies of individual changes and to restore affected system components back to their previous state as a result of errors or identified vulnerabilities. \n\nAdditional criterion: Version control procedures provide appropriate safeguards to ensure that the integrity and availability of cloud customer data is not compromised when system components are restored back to their previous state. \n\nSupplementary information about the criterion: \n\nComplementary customer criterion notes on continuous auditing feasibility: Yes, the procedures for version control of the cloud service provider, and if necessary, resetting to previous states can be automated. This must be documented in logs. An automatic evaluation of these logs makes continuous auditing possible.",
          "Control and monitoring of service providers and suppliers (sso). Monitoring of compliance with requirements. Basic criterion: The cloud service provider monitors compliance with information security requirements and applicable legal and regulatory requirements in accordance with policies and instructions concerning controlling and monitoring of third parties. Monitoring includes a regular review of the following evidence to the extent that such evidence is to be provided by third parties in accordance with the contractual agreements: reports on the quality of the service provided; certificates of the management systems' compliance with international standards; independent third-party reports on the suitability and operating effectiveness of their service-related internal control systems; and records of the third parties on the handling of vulnerabilities, security incidents, and malfunctions. The frequency of the monitoring corresponds to the classification of the third party based on the risk assessment conducted by the cloud service provider (cf. SSO-02). The results of the monitoring are included in the review of the third party's risk assessment. Identified violations and deviations are subjected to analysis, evaluation, and treatment in accordance with the risk management procedure (cf. OIS-07). \n\nAdditional criterion: The procedures for monitoring compliance with the requirements are supplemented by automatic procedures relating to the following aspects: configuration of system components; performance and availability of system components; response time to malfunctions and security incidents; and recovery time (time until completion of error handling). Identified violations and discrepancies are automatically reported to the responsible personnel or system components of the cloud service provider for prompt assessment and action. \n\nSupplementary information about the criterion: Evidence for the review of the suitability and operating effectiveness of the service-related internal control system includes reports in accordance with ISAE 3402, IDW PS 951, SOC 2, or BSI C5. In the evidence provided by the third parties, the cloud service provider reviews, for example, the following aspects and, if necessary, incorporates the findings into the risk assessment in order to derive and initiate mitigating actions: the scope and the validity respectively the period covered by the evidence; for attestation reports: qualifications of the opinion, included deviations/other observations including management's response and corresponding controls to be implemented and executed by the cloud service provider; disclosed subcontractors incl. any changes among those (e.g. additional subcontractor); and stated security incidents. \n\nComplementary customer criterion: Cloud customers ensure through suitable controls that they stay informed about subservice organizations of their cloud service provider (e.g. on the basis of the information in the C5 attestation report) and decide on the basis of their need for protection of their data processed and stored in the cloud service whether further action should be taken to monitor and check these subservice organizations. \n\nNotes on continuous auditing feasibility: Partially, a continuous audit of some of the required evidence, such as the reviews conducted and their results, can be performed once the cloud service provider documents the associated steps using a tool. However, a review on content-level, such as reviewing the response to risk assessments and violations of service provider requirements, is difficult as it requires a semantic understanding. As a result, at least parts of the criterion are suitable for continuous audit.",
          "Identity and access management (idm). Confidentiality of authentication information. Basic criterion: The allocation of authentication information to access system components used to provide the cloud service to internal and external users of the cloud provider and system components that are involved in automated authorization processes of the cloud provider is done in an orderly manner that ensures the confidentiality of the information. If passwords are used as authentication information, their confidentiality is ensured by the following procedures, as far as technically possible: \n\n- Users can initially create the password themselves or must change an initial password when logging on to the system component for the first time. \n- An initial password loses its validity after a maximum of 14 days. \n- When creating passwords, compliance with the password specifications (cf. idm-09) is enforced as far as technically possible. \n- The user is informed about changing or resetting the password. \n- The server-side storage takes place using cryptographically strong hash functions. \n- Deviations are evaluated by means of a risk analysis and mitigating measures derived from this are implemented. \n\nAdditional criterion: \nThe users sign a declaration in which they assure that they treat personal (or shared) authentication information confidentially and keep it exclusively for themselves (within the members of the group). \n\nSupplementary information about the criterion: \nArgon2i, for example, is suitable for using a password hash function. Insofar as this is legally binding, declarations can be signed using an electronic signature. \n\nComplementary customer criterion: \nNotes on continuous auditing feasibility: Yes, if the implementation is enforced by appropriate system configuration (automated control), the status or the last change of the configuration can be checked regularly.",
          "Operations (ops). Managing vulnerabilities, malfunctions and errors – penetration tests. Basic criterion: The cloud service provider has penetration tests carried out by qualified internal personnel or external service providers at least once a year. The penetration tests are carried out according to a documented test methodology and include the system components relevant to the provision of the cloud service in the area of responsibility of the cloud service provider, which have been identified as such in a risk analysis. The cloud service provider assesses the severity of the findings made in penetration tests according to defined criteria. For findings with medium or high criticality regarding the confidentiality, integrity, or availability of the cloud service, actions must be taken within defined time windows for prompt remediation or mitigation.\n\nAdditional criterion: The tests are carried out every six months. They must always be performed by independent external auditors. Internal personnel for penetration tests may support the external service providers.\n\nSupplementary information about the criterion: Vulnerabilities should be classified according to damage potential, and a period of time should be specified for the required response. The following classification, according to the BSI publication \"Ein Praxis-Leitfaden für IS-Penetrationstests,\" can serve as an orientation: high: immediate reaction; medium: short-term response; low: medium-term response; and information: long-term response.\n\nComplementary customer criterion: Notes on continuous auditing feasibility: Partially, since penetration tests are carried out annually, a continuous audit is not practical since the effort required to automate the execution of the test is probably greater than the benefit.",
          "Product safety and security (pss). Authentication mechanisms. Basic criterion: The cloud service provider provides authentication mechanisms that can enforce strong authentication (e.g., two or more factors) for users, IT components, or applications within the cloud users' area of responsibility. These authentication mechanisms are set up at all access points that allow users, IT components, or applications to interact with the cloud service. For privileged users, IT components, or applications, these authentication mechanisms are enforced.\n\nAdditional criterion: The cloud service offers out-of-band authentication (OOB), in which the factors are transmitted via different channels (e.g., internet and mobile network).\n\nSupplementary information about the criterion: IT components, in the sense of this criterion, are independently usable objects with external interfaces that can be connected with other IT components. Access points, in the sense of this criterion, are those that can be accessed by users, IT components, or applications via networks (for users, for example, the login screen on the publicly accessible website of the cloud service provider). Multi-factor authentication can be performed with cryptographic certificates, smart cards, or tokens, for example.\n\nComplementary customer criterion: Cloud customers ensure, through suitable controls, that the authentication mechanisms offered by the cloud service are used in accordance with the customer's identity and authorization management requirements.\n\nNotes on continuous auditing feasibility: Partially, the implementation of authentication mechanisms for users takes place via configurations that are only adapted at a low frequency. Thus, continuous auditing is only partially effective here. Nevertheless, it is conceivable to monitor the status of the underlying authentication system, but only deviations from target configurations can be checked. Whether these deviations are desired or not must still be recorded in a manual audit.",
          "Operations (ops). Capacity management – planning. Basic criterion: The planning of capacities and resources (personnel and IT resources) follows an established procedure in order to avoid possible capacity bottlenecks. The procedures include forecasting future capacity requirements to identify usage trends and manage system overload. Cloud service providers take appropriate measures to ensure they continue to meet the requirements agreed with cloud customers for the provision of the cloud service in the event of capacity bottlenecks or outages, particularly those related to the dedicated use of system components, in accordance with the respective agreements.\n\nAdditional criterion: The forecasts are considered in accordance with the service level agreement for planning and preparing the provisioning.\n\nSupplementary information about the criterion: For economic reasons, cloud service providers typically strive for high utilization of IT resources (CPU, RAM, storage space, network). In multi-tenant environments, existing resources must still be shared between cloud users (clients) in a way that adheres to service level agreements. Proper planning and monitoring of IT resources are critical to the availability and competitiveness of the cloud service. If the procedures are not documented or are subject to a higher degree of confidentiality as a trade secret of the cloud service provider, the cloud service provider must be able to explain the procedures at least orally within the scope of this audit. Cloud customers must use appropriate controls to ensure that the capacity and resource requirements to be covered by the cloud service provider are planned and reflected in the SLA with the cloud service provider. The requirements can also be reviewed regularly through appropriate controls, and the SLA can be adjusted accordingly.\n\nComplementary customer criterion notes on continuous auditing feasibility: No. An audit of the planning of capacities and resources requires an assessment of the plausibility or meaningfulness of the content. At present, this can hardly be audited automatically and continuously.",
          "Business continuity management (bcm). Business impact analysis policies and instructions. Basic criteria: Policies and instructions to determine the impact of any malfunction to the cloud service or enterprise are documented, communicated, and made available in accordance with SP-01. The following aspects are considered as minimum: \n\n- Possible scenarios based on a risk analysis \n- Identification of critical products and services \n- Identify dependencies, including processes (including resources required), applications, business partners, and third parties \n- Capture threats to critical products and services \n- Identification of effects resulting from planned and unplanned malfunctions and changes over time \n- Determination of the maximum acceptable duration of malfunctions \n- Identification of restoration priorities \n- Determination of time targets for the resumption of critical products and services within the maximum acceptable time period (RTO) \n- Determination of time targets for the maximum reasonable period during which data can be lost and not recovered (RPO) \n- Estimation of the resources needed for resumption\n\nAdditional criteria: Supplementary information about the criterion scenarios to be considered according to the basic criteria are, for example, the loss of personnel, buildings, infrastructure, and service providers. \n\nComplementary customer criteria: Cloud customers ensure through suitable controls that the scenarios for a failure of the cloud service or the cloud service provider are sufficiently considered in the context of their business impact analysis.\n\nNotes on continuous auditing feasibility: Partially, a policy can change ad-hoc. However, the continuous audit of policies is only partially feasible as the only attributes that can be tested are the last change date and the status of review or approval, as far as this information is stored in a system. The content of a policy can hardly be tested automatically.",
          "Procurement, development and modification of information systems (dev). Risk assessment, categorisation and prioritisation of changes. Basic criterion: In accordance with the applicable policies (cf. dev-03), changes are subjected to a risk assessment with regard to potential effects on the system components concerned and are categorized and prioritized accordingly. Additional criterion: In accordance with the contractual agreements, meaningful information about the occasion, time, duration, type, and scope of the change is submitted to authorized bodies of the cloud customer so that they can carry out their own risk assessment before the change is made available in the production environment. Regardless of the contractual agreements, this is done for changes that have the highest risk category based on their risk assessment. Supplementary information about the criterion: Complementary customer criterion notes on continuous auditing feasibility: Yes, the evaluation of changes in releases can be standardized and automated by the cloud service provider. If this evaluation is carried out in standardized and digital form (tickets/logs), an automated evaluation can be carried out by the auditor.",
          "Operations (ops). Logging and monitoring – access, storage and deletion. Basic criterion: The requirements for the logging and monitoring of events and for the secure handling of metadata are implemented by technically supported procedures with regard to the following restrictions: access only for authorized users and systems; retention for the specified period; and deletion when further retention is no longer necessary for the purpose of collection.\n\nNotes on continuous auditing feasibility: No, a continuous check is only of limited use here, since the primary purpose of checking the handling of metadata is to check the guidelines and the associated configurations of the tools for securing, processing, and deleting metadata. In addition, the contractual basis for the use of metadata may also need to be considered. A continuous audit could include the configuration for deleting or anonymizing the metadata and automatically recording whether the configuration still exists and is implemented correctly. In this case, there would be a partial possibility for continuous auditing.",
          "Physical security (ps). Physical security and environmental control requirements. Basic criterion: Security requirements for premises and buildings related to the cloud service provided are based on the security objectives of the information security policy, identified protection requirements for the cloud service, and the assessment of risks to physical and environmental security. The security requirements are documented, communicated, and provided in a policy or concept according to SP-01. The security requirements for data centers are based on criteria that comply with established rules of technology. They are suitable for addressing the following risks in accordance with the applicable legal and contractual requirements: faults in planning, unauthorized access, insufficient surveillance, insufficient air conditioning, fire and smoke, water, power failure, and air ventilation and filtration. If the cloud service provider uses premises or buildings operated by third parties to provide the cloud service, the document describes which security requirements the cloud service provider places on these third parties. The appropriate and effective verification of implementation is carried out in accordance with the criteria for controlling and monitoring subcontractors (cf. SSO-01, SSO-02).\n\nAdditional criterion: The security requirements include time constraints for self-sufficient operation in the event of exceptional events (e.g., prolonged power outage, heat waves, low water in cold river water supply) and maximum tolerable utility downtime. The time limits for self-sufficient operation provide for at least 48 hours in the event of a failure of the external power supply. For self-sufficient operation during a heat period, the highest outside temperatures measured to date within a radius of at least 50 km around the locations of the premises and buildings have been determined with a safety margin of 3 K. The security requirements stipulate that the permissible operating and environmental parameters of the cooling supply must also be observed on at least five consecutive days with these outside temperatures, including the safety margin (cf. PS-06 Protection against Failure of the Supply Facilities). If water is taken from a river for air conditioning, it is determined at which water levels and water temperatures the air conditioning can be maintained for how long. The maximum tolerable downtimes of utility facilities are suitable for meeting the availability requirements contained in the service level agreement.\n\nSupplementary information about the criterion: Premises and buildings related to the cloud service provided include data centers and server rooms housing system components used to process cloud customer data and the technical utilities required to operate these system components (e.g., power supply, refrigeration, fire-fighting, telecommunications, security, etc.). Backup or redundancy computer centers. Premises and buildings operated by third parties are e.g., server housing, colocation, IaaS. Premises and buildings in which no data from cloud customers is processed or stored (e.g., offices of the cloud service provider, server rooms with system components for internal development and test systems) are not subject to this criteria area. The recognized rules of technology are defined in relevant standards, e.g., EN 50600 (Facilities and Infrastructures of Data Centers). Incorrect planning can endanger the operational safety and availability of the premises or buildings. This can result from an incorrect assessment of elementary hazards at the site (e.g., air traffic, earthquakes, floods, hazardous substances) as well as an incorrect conception of the bandwidth or energy supply. Time specifications for self-sustaining operation as well as maximum tolerable downtimes of utility facilities are typically collected during the business impact analysis (cf. BCM-02, BCM-03).\n\nComplementary customer criterion notes on continuous auditing feasibility: Partially, a policy can change ad-hoc. However, the continuous audit of policies is only partially feasible as the only attributes that can be tested are the last change date and the status of review or approval, as far as this information is stored in a system. The content of a policy can hardly be tested automatically.",
          "Procurement, development and modification of information systems (dev). Testing changes. Basic criterion: Changes to the cloud service are subject to appropriate testing during software development and deployment. The type and scope of the tests correspond to the risk assessment. The tests are carried out by appropriately qualified personnel of the cloud service provider or by automated test procedures that comply with the state-of-the-art. Cloud customers are involved in the tests in accordance with the contractual requirements. The severity of the errors and vulnerabilities identified in the tests, which are relevant for the deployment decision, is determined according to defined criteria and actions for timely remediation or mitigation are initiated. \n\nAdditional criterion: Supplementary information about the criterion. The errors and vulnerabilities identified in tests can be assessed, for example, according to the Common Vulnerability Scoring System (CVSS). \n\nComplementary customer criterion: Where changes are to be tested by the cloud customers in accordance with the contractual agreements prior to deployment in the production environment, the cloud customers ensure through suitable controls that the tests are performed appropriately to identify errors. In particular, this includes timely execution of the tests by qualified personnel in accordance with the conditions specified by the cloud service provider. \n\nNotes on continuous auditing feasibility: Yes, if the tests are carried out automatically, the execution and associated results can be documented in logs. These logs can then be read continuously by the auditor. Measures for the elimination of identified vulnerabilities can also be documented and carried out in a standardized manner, so that continuous auditing is possible.",
          "Operations (ops). Capacity management – monitoring. Basic criterion: Technical and organizational safeguards for the monitoring and provisioning and de-provisioning of cloud services are defined. Thus, the cloud service provider ensures that resources are provided and/or services are rendered according to the contractual agreements and that compliance with the service level agreements is ensured. \n\nAdditional criterion: To monitor capacity and availability, the relevant information is available to the cloud customer in a self-service portal. \n\nSupplementary information about the criterion: Technical and organizational measures typically include the use of monitoring tools with an alarm function when defined threshold values are exceeded, a process for correlating events and an interface to incident management, continuous monitoring of the systems by qualified personnel, and redundancies in the IT systems. \n\nComplementary customer criterion: Cloud customers ensure through suitable controls that the contractual agreements made with the cloud service provider for the provision of resources or services can be monitored. In case of deviations, appropriate controls ensure that the cloud service provider is informed so that the cloud service provider can take appropriate action. \n\nNotes on continuous auditing feasibility: Yes, the part of resource monitoring can be continuously audited by checking capacity forecasts and monitoring the resource management tool. Furthermore, the logs of provisioning and de-provisioning and their impact on resource management can be continuously audited by the changes in resource management.",
          "Compliance (com). Identification of applicable legal, regulatory, self-imposed or contractual requirements. Basic criterion: The legal, regulatory, self-imposed, and contractual requirements relevant to the information security of the cloud service, as well as the cloud service provider's procedures for complying with these requirements, are explicitly defined and documented.\n\nAdditional criterion: Supplementary information about the criterion. The cloud service provider's documentation may refer to the following requirements, among others: requirements for the protection of personal data (e.g., EU General Data Protection Regulation); compliance requirements based on contractual obligations with cloud customers (e.g., ISO/IEC 27001, SOC 2, PCI-DSS); generally accepted accounting principles (e.g., in accordance with HGB or IFRS); requirements regarding access to data and auditability of digital documents (e.g., according to GDPDU); and other laws (e.g., according to BSIG or AktG).\n\nComplementary customer criterion: Notes on continuous auditing feasibility. No, a continuous audit of contract specifications, regulations, and their documentation does not seem to be effective. In this case, the test within the recurring audit is sufficient. A continuous audit could assist in giving the date of the last audit of the criteria.",
          "Security incident management (sim). Documentation and reporting of security incidents. Basic criterion: After a security incident has been processed, the solution is documented in accordance with the contractual agreements, and the report is sent to the affected customers for final acknowledgement or, if applicable, as confirmation. \n\nAdditional criterion: The customer can either actively approve solutions, or the solution is automatically approved after a certain period. Information on security incidents or confirmed security breaches is made available to all affected customers. The contract between the cloud service provider and the cloud customer regulates which data is made available to the cloud customer for their own analysis in the event of security incidents. \n\nSupplementary information about the criterion: Complementary customer criterion. Cloud customers ensure through suitable controls that they receive notifications from the cloud service provider about security incidents that affect them and their resolution, and that these notifications are forwarded promptly to the entity responsible for handling them so that an appropriate response can be made. \n\nNotes on continuous auditing feasibility: Yes. In the logs or tickets that document the security incidents (cf. sim-03), the cloud service provider also describes the solution pursued to eliminate the incident. Additionally, the cloud service provider also documents the confirmation to the customer. The auditor can then automatically and continuously read out whether the documented security incidents have been resolved and whether a solution has been documented. The same applies to the communication of the resolution of the incidents to affected customers. If this is not the case, the unresolved security incident can be documented as the output value of the continuous audit.",
          "Personnel (hr). Disciplinary measures. Basic criterion: In the event of violations of policies and instructions or applicable legal and regulatory requirements, actions are taken in accordance with a defined policy that includes the following aspects: verifying whether a violation has occurred; and consideration of the nature and severity of the violation and its impact. The internal and external employees of the cloud service provider are informed about possible disciplinary measures. The use of disciplinary measures is appropriately documented.\n\nAdditional criterion: Supplementary information about the criterion. The cloud service provider ensures that the policies and instructions reflect applicable legal and regulatory requirements in accordance with SP-01.\n\nComplementary customer criterion: Notes on continuous auditing feasibility: No continuous audit is not practical, as the associated processes and steps can be tested once within a recurring audit. A system-based definition of the violations as well as the corresponding regulations does not appear practical, since in this context individual case decisions are often necessary which cannot be covered by predefined algorithms.",
          "Business continuity management (bcm). Planning business continuity. Basic criterion: Based on the business impact analysis, a single framework for operational continuity and business plan planning will be implemented, documented, and enforced to ensure that all plans are consistent. Planning is based on established standards, which are documented in a \"Statement of Applicability\". Business continuity plans and contingency plans take the following aspects into account: \n\n- Defined purpose and scope with consideration of the relevant dependencies.\n- Accessibility and comprehensibility of the plans for persons who are to act accordingly.\n- Ownership by at least one designated person responsible for review, updating, and approval.\n- Defined communication channels, roles, and responsibilities, including notification of the customer.\n- Recovery procedures, manual interim solutions, and reference information (taking into account prioritization in the recovery of cloud infrastructure components and services and alignment with customers).\n- Methods for putting the plans into effect.\n- Continuous process improvement.\n- Interfaces to security incident management. \n\nAdditional criterion: \n\nSupplementary information about the criterion: The consistency of plans, according to the basic criterion, must also be maintained when different locations are used.\n\nComplementary customer criterion: \n\nCloud customers ensure through suitable controls that the results of the business impact analysis are sufficiently considered when planning the operational continuity and the business plan in order to provide for the effects of a failure of the cloud service or cloud service provider. \n\nCloud customers ensure through suitable controls that the availability of the cloud service, its recovery time according to the BCM plan, and the data loss of the cloud service are consistent with their own availability requirements and tolerable data loss. \n\nNotes on continuous auditing feasibility: \n\nNo, the introduction of the framework and the business plan based on a business impact analysis is a manual process of the cloud service provider. A continuous audit is not practical. The plans can be tested as part of the recurring audit.",
          "Product safety and security (pss). Online register of known vulnerabilities. Basic criteria: The cloud service provider operates or refers to a daily updated online register of known vulnerabilities that affect the cloud service provider and assets provided by the cloud service provider that the cloud customers have to install, provide, or operate themselves under the customers' responsibility. The presentation of the vulnerabilities follows the common vulnerability scoring system (CVSS). The online register is easily accessible to any cloud customer. The information contained therein forms a suitable basis for risk assessment and possible follow-up measures on the part of cloud users. For each vulnerability, it is indicated whether software updates (e.g., patch, update) are available, when they will be rolled out, and whether they will be deployed by the cloud service provider, the cloud customer, or both of them together. \n\nAdditional criteria: Assets provided by the cloud service provider, which must be installed, provided, or operated by cloud users within their area of responsibility, are equipped with automatic update mechanisms. After approval by the respective cloud user, software updates can be rolled out in such a way that they can be distributed to all affected users without human interaction. Supplementary information about the criteria assets provided by the cloud service provider that cloud customers have to install, deploy, or operate themselves in their area of responsibility are, for example, local software clients and apps as well as tools for integrating the cloud service. If the cloud service relies on other cloud services, this registry has to incorporate or refer to the vulnerabilities of those other cloud services in order for this criterion to be met. \n\nComplementary customer criteria: Cloud customers ensure through suitable controls that the information in this register is incorporated sufficiently quickly into their own risk management, evaluated, and if necessary, taken into account in their own area of responsibility. \n\nNotes on continuous auditing feasibility: Yes, a continuous audit includes, above all, whether the information is updated daily. The distribution of software updates must be documented by the cloud service provider (logs). This documentation can then be automatically and continuously evaluated by the auditor to ensure that the software used on assets in the cloud users’ area of responsibility is up-to-date.",
          "Control and monitoring of service providers and suppliers (sso). Exit strategy for the receipt of benefits. Basic criterion: The cloud service provider has defined and documented exit strategies for the purchase of services where the risk assessment of the service providers and suppliers regarding the scope, complexity, and uniqueness of the purchased service resulted in a very high dependency (cf. supplementary information). Exit strategies are aligned with operational continuity plans and include the following aspects: analysis of the potential costs, impacts, resources, and timing of the transition of a purchased service to an alternative service provider or supplier; definition and allocation of roles, responsibilities, and sufficient resources to perform the activities for a transition; definition of success criteria for the transition; and definition of indicators for monitoring the performance of services, which should initiate the withdrawal from the service if the results are unacceptable. \n\nAdditional criterion: Supplementary information about the criterion - a very high dependency can be assumed in the following situations, in particular: the purchased service is absolutely required for the provision of the cloud service. This situation is given when the cloud service provider provides the cloud service from data centers operated by third parties and provides a SaaS service and uses the IaaS or PaaS of another cloud service provider. The service cannot be obtained within one month from an alternative service provider or supplier, as: it is unique on the market and no other supplier can deliver it; it is strongly individualized by the service provider or supplier and/or the cloud service provider; it cannot be supplied by any other provider in the required quality of service; and it requires specific knowledge that is only/mainly available to the current service provider or supplier and not to the cloud service provider. \n\nComplementary customer criterion: Notes on continuous auditing feasibility - No, the existence of individual exit strategies is not a practical test item for continuous audit. \n\n5.13 Security Incident Management (SIM) \n\nObjective: Ensure a consistent and comprehensive approach to the capture, assessment, communication, and escalation of security incidents.",
          "Product safety and security (pss). Images for virtual machines and containers. Basic criterion: If cloud customers operate virtual machines or containers with the cloud service, the cloud service provider must ensure the following aspects: The cloud customer can restrict the selection of images of virtual machines or containers according to their specifications so that users of this cloud customer can only launch the images or containers released according to these restrictions. If the cloud service provider provides images of virtual machines or containers to the cloud customer, the cloud service provider must appropriately inform the cloud customer of the changes made to the previous version. In addition, these images provided by the cloud service provider must be hardened according to generally accepted industry standards. \n\nAdditional criterion: At startup and runtime of virtual machine or container images, an integrity check must be performed that detects image manipulations and reports them to the cloud customer. \n\nSupplementary information about the criterion: This criterion is typically not applicable to the SaaS service model. Generally accepted industry standards are, for example, the Security Configuration Benchmark of the Centre for Internet Security (CIS) or the corresponding modules in the BSI IT-Grundschutz-Kompendium. \n\nComplementary customer criterion: Cloud customers must use appropriate controls to ensure that the images of virtual machines or containers they operate with the cloud service comply with their information security management requirements and that the results of the integrity checks at startup and at runtime are processed according to these requirements. \n\nNotes on continuous auditing feasibility: Partially, these functions must be centrally audited at regular intervals but not continuously. Therefore, it is sufficient to integrate this into the recurring audit. With an agent system, it would be possible to continuously query the configurations of the individual virtual machines and thus compare them with the target image. This could also be set up on demand and thus become part of the control that takes over the integrity check.",
          "Procurement, development and modification of information systems (dev). Logging of changes. Basic criterion: System components and tools for source code management and software deployment that are used to make changes to system components of the cloud service in the production environment are subject to a role and rights concept, according to IDM-01, and authorization mechanisms. They must be configured in such a way that all changes are logged and can, therefore, be traced back to the individuals or system components executing them.\n\nAdditional criterion: Supplementary information about the criterion complementary customer criterion notes on continuous auditing feasibility: Yes, the changes to the role and rights concept according to IDM-01 are documented in logs by the cloud service provider. Thus, an automatic and continuous evaluation of these logs can be carried out. Irregularities are detected and logged. The auditor can perform a continuous audit by automatically evaluating the logs and logged irregularities.",
          "Communication security (cos). Policies for data transmission. Basic criterion: Policies and instructions with technical and organizational safeguards are documented, communicated, and provided to protect the transmission of data against unauthorized interception, manipulation, copying, modification, redirection, or destruction. These policies and instructions should reference the classification of information (cf. am-06). \nAdditional criterion: A safeguard against unauthorized interception, manipulation, copying, modification, redirection, or destruction of data during transmission is the use of transport encryption according to cry-02. \nComplementary customer criterion: Cloud customers should ensure, through suitable controls, that the transmitted data to the cloud service is protected against tampering, copying, modifying, redirecting, or deleting based on their protection needs. \nNotes on continuous auditing feasibility: It is not feasible to continuously audit policies as they can change ad-hoc. However, the last change date and status of review or approval can be tested if this information is stored in a system. The content of a policy is difficult to test automatically. \n5.10 Portability and Interoperability (PI) \nObjective: Enable the ability to access the cloud service through other cloud services or IT systems of the cloud customers, retrieve the stored data at the end of the contractual relationship, and securely delete it from the cloud service provider.",
          "Operations (ops). Capacity management – controlling of resources. Basic criterion: Depending on the capabilities of the respective service model, the cloud customer can control and monitor the allocation of the system resources assigned to the customer for administration/use in order to avoid overcrowding of resources and to achieve sufficient performance.\n\nAdditional criterion: Supplementary information about the criterion resources, according to the possibilities of the service model, are, for example, computing capacity; storage capacity; configuration of network properties; application programming interfaces (APIs); and databases.\n\nComplementary customer criterion: Cloud customers ensure through suitable controls that they manage and monitor the system resources in their area of responsibility.\n\nNotes on continuous auditing feasibility: Partially, the existence of tools for controlling resources by the cloud customers themselves is, in itself, a continuous process, which can be continuously checked provided that the cloud service provider can prove the functionality of these tools by means of logs. However, continuously checking this only generates limited value. The functionality of the provided tools can be continuously audited if they are documented and can be evaluated by the cloud service provider.",
          "Asset management (am). Decommissioning of hardware. Basic criterion: The decommissioning of hardware used to operate system components supporting the cloud service production environment, under the responsibility of the cloud service provider, requires approval based on the applicable policies. The decommissioning includes the complete and permanent deletion of the data or proper destruction of the media.\n\nAdditional criterion: Supplementary information about the criterion: The deletion of data or physical destruction of data mediums can take place, for example, according to DIN 66399 or BSI IT-Grundschutz Module Con.6.\n\nComplementary customer criterion: \n\nNotes on continuous auditing feasibility: Yes, the approval of the decommissioning of hardware by authorized personnel or system components must be digitally documented to allow continuous testing. A ticketing system, for example, is suitable for this purpose. Both the instance and the verification of the complete deletion of the data must be stored in the respective ticket. This enables the auditor to check the tickets in an automated procedure. This requires an automated comparison of the authorized instance against a database containing all potential approvers. In addition, the deletion of the data documented in the ticket must be audited automatically. The compliant use of the assets can be ensured via an agent system which checks active assets. The status of this system can then be queried by the auditor for a continuous audit.",
          "Dealing with investigation requests from government agencies (inq). Limiting access to or disclosure of data in investigation requests. Basic criterion: The cloud service provider's procedures establish access to or disclose data of cloud customers in the context of investigation requests from governmental agencies. These procedures ensure that the agencies only gain access to or insight into the data that is the subject of the investigation request. If clear limitation of the data is not possible, the cloud service provider anonymizes or pseudonymizes the data. This ensures that government agencies can only assign it to those cloud customers who are the subject of the investigation request. \n\nAdditional criterion: Supplementary information about the criterion complementary customer criterion notes on continuous auditing feasibility. Partially, a separate role for the investigator is to be provided (cf. also inq-03). It is conceivable that certain data types for this role may not be visible, pseudonymized or anonymized. Additionally, data of customers that are not part of the investigation may be excluded. However, this requires manual effort in the configuration and assignment of the investigator role. Under these conditions, however, a continuous audit of whether and to what extent the investigator had access to data is conceivable. \n\n5.17 Product Safety and Security (PSS): Objective: Provides up-to-date information on the secure configuration and known vulnerabilities of the cloud service for cloud customers. It also provides appropriate mechanisms for troubleshooting and logging, as well as authentication and authorization of users of cloud customers.",
          "Product safety and security (pss). Software defined networking. Basic criterion: If the cloud service offers functions for software-defined networking (SDN), the confidentiality of the data of the cloud user is ensured by suitable SDN procedures. The cloud service provider validates the functionality of the SDN functions before providing new SDN features to cloud users or modifying existing SDN features. Identified defects are assessed and corrected in a risk-oriented manner.\n\nAdditional criterion: Supplementary information about the criterion: This criterion is typically not applicable to the SaaS service model. Suitable SDN methods for increasing confidentiality are, for example, L2 overlay networking (tagging) or tunneling/encapsulation.\n\nComplementary customer criterion: Notes on continuous auditing feasibility: Yes. Validation during provision and modification of SDN functions and identification of defects can be documented in a standardized manner by the cloud service provider. This documentation can be audited continuously and automatically by the auditor. The \"marking\" of the data is carried out by a configuration that has to be tested centrally. A continuous audit of all transmitted data packets would not be effective here. The status of the configuration can be continuously audited against a target value, and a content evaluation must be carried out manually.",
          "Operations (ops). Logging and monitoring – concept. Basic criterion: The cloud service provider has established policies and instructions that govern the logging and monitoring of events on system components within its area of responsibility. These policies and instructions are documented, communicated, and provided according to SP-01 with respect to the following aspects: \n- Definition of events that could lead to a violation of the protection goals \n- Specifications for activating, stopping, and pausing the various logs \n- Information regarding the purpose and retention period of the logs \n- Define roles and responsibilities for setting up and monitoring logging \n- Time synchronization of system components \n- Compliance with legal and regulatory frameworks \n\nAdditional criterion: Supplementary information about the criterion legal and regulatory frameworks can define, for example, legal requirements for retention and deletion of data. \n\nComplementary Customer Criterion: Cloud customers ensure, through suitable controls, that appropriate logging and monitoring of events that may affect the security and availability of the cloud service (e.g., administrator activities, system failures, authentication checks, data deletions, etc.) takes place for those layers of the cloud service under their responsibility. \n\nNotes on Continuous Auditing Feasibility: Partially, a policy can change ad-hoc. However, the continuous audit of policies is only partially feasible as the only attributes that can be tested are the last change date and the status of review or approval, as far as this information is stored in a system. The content of a policy can hardly be tested automatically.",
          "Security incident management (sim). Processing of security incidents. Basic criterion: Subject matter experts of the cloud service provider, together with external security providers where appropriate, classify, prioritize, and perform root-cause analyses for events that could constitute a security incident.\n\nAdditional criterion: The cloud service provider simulates the identification, analysis, and defense of security incidents and attacks at least once a year through appropriate tests and exercises (e.g. red team training).\n\nSupplementary information about the criterion: Complementary customer criterion notes on continuous auditing feasibility: Yes, the cloud service provider documents all security incidents in digital form, which contains information about the classification, prioritization, and root cause analysis of the incidents. The root cause analysis should be standardized to facilitate continuous auditing. An automatic and continuous evaluation of these security incidents can then be carried out by the auditor by excluding the logs or tickets produced and testing whether the security incident has been classified and prioritized and whether these steps have been carried out based on a standardized root cause analysis. The continuous audit thus provides a constant statement as to whether security incidents have been correctly recorded, classified, and subjected to a root cause analysis.",
          "Product safety and security (pss). Error handling and logging mechanisms. Basic criterion: The cloud service provided is equipped with error handling and logging mechanisms. These enable cloud users to obtain security-related information about the security status of the cloud service as well as the data, services, or functions it provides. The information is detailed enough to allow cloud users to check the following aspects, insofar as they are applicable to the cloud service: which data, services, or functions available to the cloud user within the cloud service have been accessed by whom and when (audit logs); malfunctions during the processing of automatic or manual actions; and changes to security-relevant configuration parameters, error handling and logging mechanisms, user authentication, action authorization, cryptography, and communication security. The logged information is protected from unauthorized access and modification and can be deleted by the cloud customer. If the cloud customer is responsible for the activation or type and scope of logging, the cloud service provider must provide appropriate logging capabilities. \n\nAdditional criterion: Cloud users can retrieve security-related information via documented interfaces which are suitable for further processing this information as part of their security information and event management (SIEM). \n\nSupplementary information about the criterion: In the case of a SaaS service for secure data exchange, the terms data, services, or functions would mean, for example, the logging of all read or write accesses to the stored files and their metadata. \n\nComplementary customer criterion: If the cloud service is equipped with error handling and logging mechanisms, cloud customers must activate these and configure them according to defined requirements. The cloud customer must incorporate their own information security management for this purpose. \n\nNotes on continuous auditing feasibility: Yes, the information about the security status of cloud services and further data provided can be read automatically and continuously, as these must be made available to cloud users in digital form. This enables continuous auditing.",
          "Operations (ops). Protection against malware – implementation. Basic criterion: System components under the cloud service provider's responsibility that are used to deploy the cloud service in the production environment are configured with malware protection according to the policies and instructions. If protection programs are set up with signature and behavior-based malware detection and removal, these protection programs are updated at least daily.\n\nAdditional criterion: The configuration of the protection mechanisms is monitored automatically. Deviations from the specifications are automatically reported to the subject matter experts so that the deviations are immediately assessed and the necessary measures taken.\n\nSupplementary information about the criterion: Protection against malicious programs can be implemented by operating system-specific protection mechanisms or explicit protection programs (e.g., for signature- and behavior-based detection and removal of malicious programs).\n\nComplementary customer criterion: Cloud customers ensure, through suitable controls, that the layers of the cloud service for which they are responsible have security products in place to detect and remove malware.\n\nNotes on continuous auditing feasibility: Yes, the first step should be to check whether all systems are covered. This should be monitored by continuously checking a tool, including the additions and deletions of entries. In the second step, the log files for the updates of the individual servers and the regular scans should be audited continuously. Identified malware or irregularities should be marked and tracked as part of the continuous scan.",
          "Physical security (ps). Perimeter protection. Basic criterion: The structural shell of premises and buildings related to the cloud service provided are physically solid and protected by adequate security measures that meet the security requirements of the cloud service provider (cf. PS-01 Security Concept). The security measures are designed to detect and prevent unauthorized access so that the information security of the cloud service is not compromised. The outer doors, windows, and other construction elements exhibit an appropriate security level and withstand a burglary attempt for at least 10 minutes. The surrounding wall constructions as well as the locking mechanisms meet the associated requirements.\n\nAdditional criterion: The security measures installed at the site include permanently present security personnel (at least 2 individuals), video surveillance, and anti-burglary systems. Supplementary information about the criterion security measures for detecting unauthorized access can be security personnel, video surveillance, or burglar alarm systems. \n\nThe resistance class RC4 according to DIN EN 1627 stipulates that doors, windows, and other components must withstand a break-in attempt for at least 10 minutes. The US standard SD-STD-01.01 Rev.G. is an international equivalent to this standard.\n\nComplementary customer criterion notes on continuous auditing feasibility: \n\nPartially, a continuous inspection of the structural shell of buildings is only partially feasible. Only the protection against unauthorized access can provide evaluable data in the form of access logs that are stored.",
          "Communication security (cos). Networks for administration. Basic criterion: There are separate networks for the administrative management of the infrastructure and for the operation of management consoles. These networks are logically or physically separated from the cloud customer's network and protected from unauthorized access by multi-factor authentication (cf. idm-09). Networks used by the cloud service provider to migrate or create virtual machines are also physically or logically separated from other networks.\n\nAdditional criterion: Supplementary information about the criterion complementary customer criterion notes on continuous auditing feasibility: No, a continuous audit is not practical since infrastructure components and the logical and physical separation of the networks are implemented initially. A continuous audit of these components may require a system status, but it is difficult to test all aspects continuously.",
          "Operations (ops). Logging and monitoring – metadata management concept. Basic criterion: Policies and instructions for the secure handling of metadata (usage data) are documented, communicated, and provided according to SP-01 with regard to the following aspects: \n\n- Metadata is collected and used solely for billing, incident management, and security incident management purposes. \n\n- Exclusively anonymous metadata is used to deploy and enhance the cloud service, ensuring that no conclusions can be drawn about the cloud customer or user. \n\n- No commercial use of metadata is allowed. \n\n- Storage of metadata is for a fixed period reasonably related to the purposes of the collection. \n\n- Immediate deletion of metadata is required if the purposes of the collection are fulfilled and further storage is no longer necessary. \n\n- Provision of metadata to cloud customers is done according to contractual agreements. \n\nAdditional criterion: Personal data is automatically removed from the log data before the cloud service provider processes it, to the extent that it is technically possible. The removal should be performed in a way that allows the cloud service provider to continue using the log data for the purpose for which it was collected. \n\nSupplementary information about the criterion: Metadata refers to all data generated by the cloud service provider through the use of its service by the cloud customer, excluding content-related data. This includes login/logout times, IP addresses, customers' GPS location, resources used (network, storage, computer), accessed data, data sharing, and communication details. This data is used for billing purposes, (security) incident management, and can also be utilized for analyzing customer behavior and making decision-making and work processes visible to the cloud service provider, depending on the specific cloud service. The criteria aim to provide a transparent and clear definition of the collection and use of metadata. \n\nIn addition, metadata also refers to data generated when the cloud service provider accesses customer data (e.g., for indexing). \n\nComplementary customer criterion notes on continuous auditing feasibility: Partially, policy changes can occur ad-hoc. However, continuous auditing of policies is only partially feasible, as the only attributes that can be tested are the last change date and the status of review or approval, to the extent that this information is stored in a system. The content of a policy can hardly be tested automatically.",
          "Product safety and security (pss). Confidentiality of authentication information. Basic criterion: If passwords are used as authentication information for the cloud service, their confidentiality is ensured by the following procedures: \n- Users can initially create the password themselves or must change an initial password when logging into the cloud service for the first time.\n- An initial password loses its validity after a maximum of 14 days.\n- When creating passwords, compliance with the length and complexity requirements of the cloud service provider (cf. idm-09) or the cloud customer is technically enforced.\n- The user is informed about changing or resetting the password.\n- The server-side storage takes place using state-of-the-art cryptographically strong hash functions in combination with at least 32-bit long salt values.\n\nAdditional criterion: Supplementary information about the criterion: \n- The state-of-the-art regarding cryptographically strong hash functions is described in the current version of the BSI Technical Guideline TR-02102-1 \"Cryptographic Mechanisms: Recommendations and Key Lengths\".\n- In version 2019-01 of this guideline, these were: SHA-256, SHA-512/256, SHA-384, SHA-512; and SHA3-256, SHA3-384, SHA3-512.\n\nComplementary customer criterion: \n- Cloud customers ensure through suitable controls that they use sufficiently secure passwords (cf. idm-09) according to their own assessment and that the risks of unauthorized access associated with their own choice are borne.\n\nNotes on continuous auditing feasibility: \n- No compliance with security policies for password assignment is configured centrally and adjusted at a low frequency.\n- A continuous audit is therefore only of limited use.",
          "Communication security (cos). Segregation of data traffic in jointly used network environments. Basic criterion: Data traffic of cloud customers in jointly used network environments is segregated on network level according to a documented concept to ensure the confidentiality and integrity of the data transmitted. \nAdditional criterion: In the case of IaaS/PaaS, secure segregation is ensured by physically separated networks or by means of strongly encrypted VLANs. For the definition of strong encryption, the BSI technical guideline TR-02102 must be considered. \nSupplementary information about the criterion: If the suitability and effectiveness of the logical segmentation cannot be assessed with sufficient certainty (e.g. due to a complex implementation), evidence can also be provided based on audit results of expert third parties (e.g. security audits to validate the concept). The segregation of stored and processed data is subject to the criterion OPS-24. After successful authentication via an insecure communication channel (HTTP), a secure communication channel (HTTPS) is to be used. \nWith IaaS/PaaS, secure segregation is ensured by physically separated networks or strong encryption of the networks. For the definition of strong encryption, the BSI technical guideline TR-02102 must be considered (cf. CRY-01). \nIf the cloud service provider does not use shared network environments for cloud customers and instead uses a physical segregation, the basic criterion is not applicable. \nComplementary customer criterion: Through suitable controls, cloud customers ensure that, for parts of the cloud service under their responsibility, virtual networks are designed, configured, and documented in accordance with their network security requirements (e.g. logical segmentation of organizational units). \nNotes on continuous auditing feasibility: No. The logical segregation of cloud customer network traffic at the network level is centrally configured and rarely changed. Thus, a continuous audit is not beneficial since no highly frequented automated query can be performed to support the continuous audit.",
          "Asset management (am). Asset inventory. Basic criterion: The cloud service provider has established procedures for inventorying assets. The inventory is performed automatically and/or by the people or teams responsible for the assets to ensure a complete, accurate, valid, and consistent inventory throughout the asset lifecycle. Assets are recorded with the information needed to apply the risk management procedure (cf. OIS-07), including the measures taken to manage these risks throughout the asset lifecycle. Changes to this information are logged.\n\nAdditional criterion: Logging and monitoring applications take into account the information collected on the assets to identify the impact on cloud services and functions in case of events that could lead to a breach of protection objectives. It also supports information provided to affected cloud customers in accordance with contractual agreements.\n\nSupplementary information about the criterion: Assets within the meaning of this criteria area are the objects required for the information security of the cloud service. This includes the creation, processing, storage, transmission, deletion, or destruction of information in the cloud service provider's area of responsibility. Examples of these objects are firewalls, load balancers, web servers, application servers, and database servers. \n\nThese objects consist of hardware and software objects. Hardware objects are physical and virtual infrastructure resources (e.g., servers, storage systems, network components) as well as end devices if the cloud service provider has determined in a risk assessment that they could endanger the information security of the cloud service in the event of loss or unauthorized access (e.g., mobile devices used as security tokens for authentication). Software objects include hypervisors, containers, operating systems, databases, microservices, and programming interfaces (APIs).\n\nThe lifecycle of an asset includes: acquisition, commissioning, maintenance, decommissioning, and disposal.\n\nComplementary customer criterion notes on continuous auditing feasibility: Yes, the cloud service provider must ensure that assets are automatically captured in a database. Automatic capture of physical assets must also be ensured. However, it would be conceivable to automatically capture these assets when logging onto a network for the first time. The creation of virtual assets can be directly linked to the entry into the database. If all assets are recorded automatically, changes to the database can be documented (logs), and these logs can then be continuously evaluated.\n\nIt is important to ensure that the information contained in the inventory and logs is complete. If automated processes are available, the auditor can create an evaluation of the changes in the inventory based on the logs. To check the completeness, the first step would be to query all current assets at the cloud service provider. This asset list could then be compared with the entries in the asset management database.",
          "Identity and access management (idm). Privileged access rights. Basic criterion: Privileged access rights for internal and external employees, as well as technical users of the cloud service provider, are assigned and changed in accordance with the policy for managing user accounts and access rights (cf. idm-01) or a separate specific policy. Privileged access rights are personalized, limited in time according to a risk assessment, and assigned as necessary for the execution of tasks (\"need-to-know principle\"). Technical users are assigned to internal or external employees of the cloud service provider. Activities of users with privileged access rights are logged in order to detect any misuse of privileged access in suspicious cases. The logged information is automatically monitored for defined events that may indicate misuse. When such an event is identified, the responsible personnel are automatically informed so that they can promptly assess whether misuse has occurred and take corresponding action. In the event of proven misuse of privileged access rights, disciplinary measures are taken in accordance with hr-04.\n\nAdditional criterion: Supplementary information about the criterion \"privileged access rights\" in the sense of the basic criterion: are those that enable employees of the cloud service provider to perform any of the following activities: read or write access to the cloud customers' data processed, stored, or transmitted in the cloud service, unless such data is encrypted or the encryption can be deactivated for access by the cloud service provider; and changes to the operational and/or security configuration of the system components in the production environment, in particular the starting, stopping, deleting, or deactivating of system components, if this can affect the confidentiality, integrity, or availability of the data of the cloud customers (also indirectly, e.g. by deactivating the logging and monitoring of security-relevant events). Misused privileged access rights can be treated e.g. as a security incident, cf. sim-01.\n\nComplementary customer criterion: Notes on continuous auditing feasibility: partially, the assignment of audit authorizations must be audited manually. This includes the classification as privileged, personalization, and evaluation of the need-to-know principle. The time limit could be read, but the implementation effort would be very high. A continuous audit does not appear to be sensible here. Only the system status could be audited continuously. The automatic triggering of a notification in suspicious cases could be compared with documented measures to handle these cases. However, this entire process must be digitized for this purpose, and the effort involved currently appears to be very high. However, a continuous audit could show the time of the last manual audit.",
          "Access control. Unsuccessful logon attempts. a. Enforce a limit of [assignment: organization-defined number] consecutive invalid logon attempts by a user during a [assignment: organization-defined time period]. \nb. Automatically [selection (one or more): lock the account or node for an [assignment: organization-defined time period]; lock the account or node until released by an administrator; delay next logon prompt per [assignment: organization-defined delay algorithm]; notify system administrator; take other [assignment: organization-defined action]] when the maximum number of unsuccessful attempts is exceeded. The need to limit unsuccessful logon attempts and take subsequent action when the maximum number of attempts is exceeded applies regardless of whether the logon occurs via a local or network connection. Due to the potential for denial of service, automatic lockouts initiated by systems are usually temporary and automatically release after a predetermined, organization-defined time period. If a delay algorithm is selected, organizations may employ different algorithms for different components of the system based on the capabilities of those components. Responses to unsuccessful logon attempts may be implemented at the operating system and the application levels. Organization-defined actions that may be taken when the number of allowed consecutive invalid logon attempts is exceeded include prompting the user to answer a secret question in addition to the username and password, invoking a lockdown mode with limited user capabilities (instead of full lockout), allowing users to only logon from specified internet protocol (IP) addresses, requiring a captcha to prevent automated attacks, or applying user profiles such as location, time of day, IP address, device, or media access control (MAC) address. If automatic system lockout or execution of a delay algorithm is not implemented in support of the availability objective, organizations consider a combination of other actions to help prevent brute force attacks. In addition to the above, organizations can prompt users to respond to a secret question before the number of allowed unsuccessful logon attempts is exceeded. Automatically unlocking an account after a specified period of time is generally not permitted. However, exceptions may be required based on operational mission or need.",
          "Organisation of information security (ois). Segregation of duties. Basic criterion: Conflicting tasks and responsibilities are separated based on an OIS-06 risk assessment to reduce the risk of unauthorized or unintended changes or misuse of cloud customer data processed, stored, or transmitted in the cloud service. The risk assessment covers the following areas, insofar as these are applicable to the provision of the cloud service and are in the area of responsibility of the cloud service provider: \n\nAdministration of rights profiles, approval and assignment of access and access authorizations (cf. IDM-01)\nDevelopment, testing, and release of changes (cf. DEV-01)\nOperation of the system components. \n\nIf separation cannot be established for organizational or technical reasons, measures are in place to monitor the activities in order to detect unauthorized or unintended changes as well as misuse and to take appropriate actions. \n\nAdditional criterion: \n\nSupplementary information about the criterion identified events that may constitute unauthorized or unintentional changes to or misuse of cloud customer data may, for example, be treated as a security incident (cf. SIM-01). \n\nComplementary customer criterion: \n\nNotes on continuous auditing feasibility: \n\nYes, continuous audit is possible, especially in the case of changes to role profiles and responsibilities. This would require an initial check of the defined roles and responsibilities by the cloud service provider. The roles that are added or changed on a monthly basis could then be automated and continuously checked.",
          "Operations (ops). Logging and monitoring – availability of the monitoring software. Basic criterion: The cloud service provider monitors the system components for logging and monitoring in its area of responsibility. Failures are automatically and promptly reported to the cloud service provider's responsible departments so that they can assess the failures and take the required action.\n\nAdditional criterion: The system components for logging and monitoring are designed in such a way that the overall functionality is not restricted if individual components fail.\n\nSupplementary information about the criterion:\n\nComplementary customer criterion notes on continuous auditing feasibility: Yes, automatically communicated failures can be tracked in logs. A continuous and automated audit of these failures can be carried out by evaluating these logs.",
          "Operations (ops). Data backup and recovery – storage. Basic criterion: The cloud service provider transfers data to be backed up to a remote location or transports it on backup media to a remote location. If the data backup is transmitted to the remote location via a network, the data backup or the transmission of the data takes place in an encrypted form that corresponds to the state-of-the-art. The distance to the main site is chosen after sufficient consideration of the factors recovery times and impact of disasters on both sites. The physical and environmental security measures at the remote site are at the same level as at the main site.\n\nAdditional criterion:\nSupplementary information about the criterion: If the data backup is not part of the contract concluded between the cloud service provider and the cloud customer, this criterion is not applicable. The cloud service provider must present this situation transparently in the system description.\n\nA remote location can be, for example, another data center of the cloud service provider.\n\nComplementary customer criterion:\nNotes on continuous auditing feasibility: Yes. If the data is transported physically, a continuous audit of this criterion means that the successful storage has been confirmed. In the case of electronic transmission, the log files of the transmission can be continuously evaluated, and the result of this audit can be transmitted.",
          "Risk assessment. Vulnerability monitoring and scanning. a. Monitor and scan for vulnerabilities in the system and hosted applications. [Assignment: Organization-defined frequency and/or randomly in accordance with organization-defined process]. When new vulnerabilities potentially affecting the system are identified and reported.\nb. Employ vulnerability monitoring tools and techniques that facilitate interoperability among tools and automate parts of the vulnerability management process. Use standards for: \n1. Enumerating platforms, software flaws, and improper configurations.\n2. Formatting checklists and test procedures.\n3. Measuring vulnerability impact.\nc. Analyze vulnerability scan reports and results from vulnerability monitoring.\nd. Remediate legitimate vulnerabilities. [Assignment: Organization-defined response times]. In accordance with an organizational assessment of risk.\ne. Share information obtained from the vulnerability monitoring process and control assessments with [Assignment: Organization-defined personnel or roles] to help eliminate similar vulnerabilities in other systems.\nf. Employ vulnerability monitoring tools that include the capability to readily update the vulnerabilities to be scanned. \n\nThe security categorization of information and systems guides the frequency and comprehensiveness of vulnerability monitoring (including scans). Organizations determine the required vulnerability monitoring for system components, ensuring that the potential sources of vulnerabilities such as infrastructure components (e.g., switches, routers, guards, sensors), networked printers, scanners, and copiers are not overlooked. The capability to readily update vulnerability monitoring tools as new vulnerabilities are discovered and announced and as new scanning methods are developed helps to ensure that new vulnerabilities are not missed by employed vulnerability monitoring tools. The vulnerability monitoring tool update process helps to ensure that potential vulnerabilities in the system are identified and addressed as quickly as possible. Vulnerability monitoring and analyses for custom software may require additional approaches such as static analysis, dynamic analysis, binary analysis, or a hybrid of the three approaches. Organizations can use these analysis approaches in source code reviews and in a variety of tools including web-based application scanners, static analysis tools, and binary analyzers. Vulnerability monitoring includes scanning for patch levels, scanning for functions, ports, protocols, and services that should not be accessible to users or devices, and scanning for flow control mechanisms that are improperly configured or operating incorrectly. Vulnerability monitoring may also include continuous vulnerability monitoring tools that use instrumentation to continuously analyze components. Instrumentation-based tools may improve accuracy and may be run throughout an organization without scanning. Vulnerability monitoring tools that facilitate interoperability include tools that are Security Content Automated Protocol (SCAP)-validated. Thus, organizations consider using scanning tools that express vulnerabilities in the Common Vulnerabilities and Exposures (CVE) naming convention and that employ the Open Vulnerability Assessment Language (OVAL) to determine the presence of vulnerabilities. Sources for vulnerability information include the Common Weakness Enumeration (CWE) listing and the National Vulnerability Database (NVD). Control assessments such as red team exercises provide additional sources of potential vulnerabilities for which to scan. Organizations also consider using scanning tools that express vulnerability impact by the Common Vulnerability Scoring System (CVSS). Vulnerability monitoring includes a channel and process for receiving reports of security vulnerabilities from the public at-large. Vulnerability disclosure programs can be as simple as publishing a monitored email address or web form that can receive reports, including notification authorizing good-faith research and disclosure of security vulnerabilities. Organizations generally expect that such research is happening with or without their authorization and can use public vulnerability disclosure channels to increase the likelihood that discovered vulnerabilities are reported directly to the organization for remediation. Organizations may also employ the use of financial incentives (also known as bug bounties) to further encourage external security researchers to report discovered vulnerabilities. Bug bounty programs can be tailored to the organization’s needs. Bounties can be operated indefinitely or over a defined period of time and can be offered to the general public or to a curated group. Organizations may run public and private bounties simultaneously and could choose to offer partially credentialed access to certain participants in order to evaluate security vulnerabilities from privileged vantage points.",
          "Security incident management (sim). Duty of the users to report security incidents to a central body. Basic criterion: The cloud service provider informs employees and external business partners of their obligations. If necessary, they agree to, or are contractually obliged to, report all security events that become known to them and are directly related to the cloud service provided by the cloud service provider to a previously designated central office of the cloud service provider promptly. In addition, the cloud service provider communicates that \"false reports\" of events that do not subsequently turn out to be incidents do not have any negative consequences.\n\nAdditional criterion: Supplementary information about the criterion complementary customer criterion cloud customers ensure, through suitable controls, that identified security events which the cloud service provider is required to process are communicated promptly to previously designated responsible personnel. The identification of such security events is supported by suitable controls (cf. complementary criterion for ops-10).\n\nNotes on continuous auditing feasibility: Partially, the cloud service provider should inform its employees and external business partners about their obligations in a standardized and digital format. This obligation usually occurs when the employee joins the company or the business relationship. This enables the auditor to automatically and continuously audit whether all employees and external business partners are notified of their obligations by automatically testing whether the clause, if any, is included in the contract when the contract is signed.",
          "Procurement, development and modification of information systems (dev). Policies for changes to information systems. Basic criterion: Policies and instructions with technical and organizational safeguards for change management of system components of the cloud service within the scope of software deployment are documented, communicated, and provided according to SP-01. The following aspects should be considered:\n\n1. Criteria for risk assessment, categorization, and prioritization of changes.\n2. Related requirements for the type and scope of testing to be performed and necessary approvals for the development/implementation of the change.\n3. Approvals for releases of changes in the production environment by authorized personnel or system components.\n4. Requirements for the performance and documentation of tests.\n5. Requirements for segregation of duties during development, testing, and release of changes.\n6. Requirements for informing cloud customers about the type and scope of changes and their obligations to cooperate based on contractual agreements.\n7. Requirements for documenting changes in system, operational, and user documentation.\n8. Requirements for the implementation and documentation of emergency changes, maintaining the same level of security as normal changes.\n\nAdditional criterion: Supplementary information about changes in the sense of the basic criterion refers to those that can lead to changes in the configuration, functionality, or security of system components of the cloud service in the production environment. This includes changes to the infrastructure and source code. If individual changes are combined in a new release, update, patch, or comparable software object for software provisioning, this software object is considered a change within the meaning of the basic criterion, but not the individual changes contained therein. Changes to the existing network configuration must also undergo a specified procedure as they are necessary for the effective segregation of cloud customers. Personnel and system components authorized to approve changes must adhere to the requirements for access and access authorizations (cf. IDM-01), following a specified procedure (cf. IDM-02). Relevant information includes descriptions of new functions. The cloud customer's obligations to cooperate may include carrying out certain tests.\n\nComplementary customer criterion: Notes on continuous auditing feasibility: No, the contents of the policies and instructions for managing and modifying system components are not changed at a high frequency. A continuous audit of this documentation is therefore not effective. It is sufficient to integrate these tests into the recurring audit.",
          "Dealing with investigation requests from government agencies (inq). Conditions for access to or disclosure of data in investigation requests. Basic criterion: Access to or disclosure of cloud customer data in connection with government investigation requests is subject to the proviso that the cloud service provider's legal assessment has shown that an applicable and valid legal basis exists and that the investigation request must be granted on that basis.\n\nAdditional criterion:\n\n- Supplementary information about the criterion\n- Complementary customer criterion\n- Notes on continuous auditing feasibility: Yes, to the extent that a separate role is assigned to the investigator in order to gain access to the data. The prerequisites specified in the request can be entered and checked by the system and linked to the assignment of the investigator role. A continuous query can then be made to ensure that the role was only granted if the prerequisites defined by the system were fulfilled. Deviations can be audited manually.",
          "Security policies and instructions (sp). Review and approval of policies and instructions. Basic criterion: Information security policies and instructions are reviewed at least annually for adequacy by the cloud service provider's subject matter experts. The review shall consider at least the following aspects: organizational and technical changes in the procedures for providing the cloud service and legal and regulatory changes in the cloud service provider's environment. Revised policies and instructions are approved before they become effective.\n\nAdditional Criterion:\nSupplementary information about the criterion:\nComplementary customer criterion notes on continuous auditing feasibility:\nPartially, a continuous automated audit of the content changes to policies and instructions is only partially practicable at the current state-of-the-art. A continuous audit of the reviewers' authorization and expertise does not appear to be effective either, as this cannot be linked to specified parameters of an automated evaluation. A continuous examination of this criterion could therefore only consist of returning the date of the last examination.",
          "Security incident management (sim). Evaluation and learning process. Basic criterion: Mechanisms are in place to measure and monitor the type and scope of security incidents and to report them to support agencies. The information obtained from the evaluation is used to identify recurrent or significant incidents and to identify the need for further protection.\n\nAdditional criterion: Supplementary information about the criterion supporting bodies may be external service providers or government agencies such as the BSI.\n\nComplementary customer criterion: Cloud customers ensure, through suitable controls, that they include into their ISMS the findings and measures related to previous security incidents reported by the cloud service provider. The cloud customers evaluate whether and which supporting measures they might take on their side.\n\nNotes on continuous auditing feasibility: No, the existing mechanisms for measuring the type and scope of security incidents are rarely changed. As a result, continuous auditing is not effective. In addition, in some cases, it can be a manual task carried out by employees to identify recurring incidents or incidents with significant consequences and to develop associated protective measures.\n\n5.14 Business Continuity Management (BCM) Objective: Plan, implement, maintain, and test procedures and measures for business continuity and emergency management.",
          "Operations (ops). Involvement of cloud customers in the event of incidents. Basic criterion: The cloud service provider periodically informs the cloud customer on the status of incidents affecting the cloud customer, or, where appropriate and necessary, involves the customer in the resolution, in a manner consistent with the contractual agreements. As soon as an incident has been resolved from the cloud service provider’s perspective, the cloud customer is informed according to the contractual agreements about the actions taken.\n\nAdditional criterion: Supplementary information about the criterion complementary customer criterion. Cloud customers ensure through suitable controls that they receive notifications from the cloud service provider regarding incidents that affect them, and that these notifications are forwarded in a timely manner to the department responsible for processing them so that appropriate action can be taken.\n\nNotes on continuous auditing feasibility: Yes, a continuous audit is possible if customers are informed about incidents via a standardized communication channel and this is documented (e-mails, logs). The auditor can then evaluate the compiled documentation automatically and continuously. However, it seems more effective to combine the evaluation of the communication of incidents to cloud customers with the evaluation of the elimination of the incidents. As soon as the incidents have been resolved automatically, in the best case, an automatic message is generated and sent to the cloud customer. This message is to be documented. This makes it possible for the auditor to evaluate whether the cloud customer has been properly informed on a regular basis about all incidents affecting them but not beyond.",
          "Operations (ops). Data backup and recovery – regular testing. Basic criterion: Restore procedures are tested regularly, at least annually. The tests allow an assessment to be made as to whether the contractual agreements as well as the specifications for the maximum tolerable downtime (Recovery Time Objective, RTO) and the maximum permissible data loss (Recovery Point Objective, RPO) are adhered to (cf. BCM-02). Deviations from the specifications are reported to the responsible personnel or system components so that these can promptly assess the deviations and initiate the necessary actions. \n\nAdditional criterion: At the customer's request, the cloud service provider informs the cloud customer of the results of the recovery tests. Recovery tests are embedded in the cloud service provider's emergency management. \n\nSupplementary information about the criterion: If the data backup is not part of the contract concluded between the cloud service provider and the cloud customer, this criterion is not applicable. The cloud service provider must present this situation transparently in the system description. \n\nComplementary customer criterion notes on continuous auditing feasibility: Partially, if the tests on the restoration procedures are performed at regular intervals, the time of execution and results can be audited automatically. However, the effort of a continuous audit of this criterion is high and the added value limited if the tests are carried out in an annual cycle.",
          "Procurement, development and modification of information systems (dev). Outsourcing of the development. Basic criterion: In the case of outsourced development of the cloud service (or individual system components), specifications regarding the following aspects are contractually agreed between the cloud service provider and the outsourced development contractor: security in software development (requirements, design, implementation, tests and verifications) in accordance with recognized standards and methods; acceptance testing of the quality of the services provided in accordance with the agreed functional and non-functional requirements; and providing evidence that sufficient verifications have been carried out to rule out the existence of known vulnerabilities.\n\nAdditional criterion: Supplementary information about the criterion outsourced development in the sense of the basic criterion: refers to the development of system components used specifically for the cloud service by a contractor of the cloud service provider. The development takes place according to the processes of the contractor. The purchase of software available on the market as well as the integration of external employees into the processes of the cloud service provider do not constitute outsourcing in the sense of this basic criterion.\n\nComplementary customer criterion: Notes on continuous auditing feasibility: No. An outsourced development of a cloud service provider’s cloud services and the associated contract creation and signing will not be performed with high frequency. Changes in contract structures are also rare. Therefore, a continuous audit in these cases is not effective.",
          "Operations (ops). Testing and documentation of known vulnerabilities. Basic criterion: System components in the area of responsibility of the cloud service provider for the provision of the cloud service are automatically checked for known vulnerabilities at least once a month in accordance with the policies for handling vulnerabilities (cf. ops-18). The severity is assessed in accordance with defined criteria, and measures for timely remediation or mitigation are initiated within defined time windows. \n\nAdditional criterion: Available security patches are applied depending on the severity of the vulnerabilities, as determined based on the latest version of the Common Vulnerability Scoring System (CVSS): \n- Critical (CVSS = 9.0 – 10.0): 3 hours.\n- High (CVSS = 7.0 – 8.9): 3 days.\n- Average (CVSS = 4.0 – 6.9): 1 month.\n- Low (CVSS = 0.1 – 3.9): 3 months. \n\nSupplementary information about the criterion: \nIn contrast to penetration tests (cf. ops-20), which are carried out manually and according to an individual scheme, the check for open vulnerabilities is performed automatically, using so-called vulnerability scanners. \n\nComplementary customer criterion: \nCloud customers ensure through suitable controls that system components under their responsibility are regularly checked for vulnerabilities and mitigated by appropriate measures. \n\nNotes on continuous auditing feasibility: \nYes, the periodic check for vulnerabilities and the corresponding results, as well as the analysis and remediation of identified vulnerabilities, are documented by the cloud service provider. An automated and continuous audit of this procedure can be implemented by the auditor by automatically evaluating the documented results.",
          "Asset management (am). Asset classification and labelling. Basic criterion: Assets are classified and, if possible, labeled. The classification and labeling of an asset reflect the protection needs of the information it processes, stores, or transmits. The need for protection is determined by the individuals or groups responsible for the assets of the cloud service provider, according to a uniform schema. The schema provides levels of protection for the confidentiality, integrity, availability, and authenticity protection objectives. \n\nAdditional criterion: Logging and monitoring applications take the asset protection needs into account in order to inform the responsible stakeholder of events that could lead to a violation of the protection goals, so that the necessary measures are taken with an appropriate priority. Actions for events on assets with a higher level of protection take precedence over events on assets with a lower need for protection. \n\nSupplementary information about the criterion: If the cloud service provider does not make a differentiated classification of the assets, all assets are to be assigned to the highest defined protection requirement. \n\nComplementary customer criterion: Cloud customers can use appropriate controls to ensure that the need for protection of the information that can be processed or stored with the cloud service is adequately determined. Cloud customers can also use appropriate controls to ensure that the information processed or stored with the cloud service is protected against tampering, copying, modifying, redirecting, or deleting in accordance with its protection needs. \n\nNotes on continuous auditing feasibility: Yes, the classification of the assets and the determination of the need for protection should take place during the initial acquisition of the assets. Thus, the classification should also be documented in an asset management tool. The determination of the protection requirement can also be carried out in a standardized form and stored digitally. If there are changes in the classification, these should also be recorded in logs. The auditor can then automatically test whether all assets on the platform are classified and whether the classification was determined using a standardized format. For changes in the classification, it can be automatically reconstructed whether these were also carried out based on the uniform schema. For this purpose, the logs produced can be evaluated as part of a continuous audit. \n\n5.5 Physical Security (PS) \n\nObjective: Prevent unauthorized physical access and protect against theft, damage, loss, and outage of operations.",
          "Identity and access management (idm). Locking and withdrawal of user accounts in the event of inactivity or multiple failed logins. Basic criterion: User accounts of internal and external employees of the cloud service provider, as well as for system components involved in automated authorization processes of the cloud service provider, are automatically locked if they have not been used for a period of two months. Approval from authorized personnel or system components is required to unlock these accounts. Locked user accounts are automatically revoked after six months. After revocation, the procedure for granting user accounts and access rights (cf. idm-02) must be repeated. \n\nAdditional criterion: Supplementary information about the criterion locking can result from a longer absence of the employee, for example, due to illness, parental leave, or sabbatical. \n\nComplementary customer criterion: Notes on continuous auditing feasibility: Yes, automated processes can easily be included in the continuous audit. Appropriate evaluation and reporting mechanisms must be used by the cloud service provider. The auditor must use data analyses to detect deviations.",
          "Physical security (ps). Surveillance of operational and environmental parameters. Basic criterion: The operating parameters of the technical utilities (cf. PS-06) and the environmental parameters of the premises and buildings related to the cloud service provided are monitored and controlled in accordance with the security requirements of the cloud service provider (cf. PS-01 security concept). When the permitted control range is exceeded, the responsible departments of the cloud provider are automatically informed in order to promptly initiate the necessary measures for return to the control range.\n\nAdditional criterion; supplementary information about the criterion: Operating parameters and environmental parameters of the premises and buildings include, for example, air temperature and humidity, leakage.\n\nComplementary customer criterion: Notes on continuous auditing feasibility: Yes, the monitoring and control of the operating parameters of the technical supply facilities is carried out automatically and documented in a standardized manner, for example, in logs. These logs are then automated by the inspector and can be continuously evaluated.\n\n5.6 Operations (OPS)\n\nObjective: Ensure proper and regular operation, including appropriate measures for planning and monitoring capacity, protection against malware, logging and monitoring events, and dealing with vulnerabilities, malfunctions, and failures.",
          "Personnel (hr). Verification of qualification and trustworthiness. Basic criterion: The competency and integrity of all internal and external employees of the cloud service provider with access to cloud customer data or system components under the cloud service provider's responsibility, who are responsible for providing the cloud service in the production environment, shall be verified prior to commencement of employment in accordance with local legislation and regulations by the cloud service provider. To the extent permitted by law, the review will cover the following areas: \n\n- Verification of the person through an identity card. \n- Verification of the CV. \n- Verification of academic titles and degrees. \n- Request for a police clearance certificate for applicants. \n- Certificate of good conduct or national equivalent. \n- Evaluation of the risk of potential blackmail. \n\nAdditional criterion: \nSupplementary information about the criterion: External employees, in the sense of the criteria, are those who perform activities in accordance with the processes and procedures of the cloud service provider. Employees of sub-service providers who perform activities according to their own processes and procedures are not covered by this criterion. The verification of qualification and trustworthiness can be supported by a specialized service provider. Depending on national legislation, national equivalents of the German certificate of good conduct may also be permitted. The assessment of the extent to which a potential employee can be blackmailed can be carried out, for example, by checking their creditworthiness. \n\nComplementary customer criterion notes on continuous auditing feasibility: Partially, continuous auditing is only partially achievable due to complications arising from local deviations in laws and regulations. It would be conceivable to continuously query the process steps stored in the system for each new hire in relation to the specified areas, based on a list of employees maintained in the HR system where new hires are registered. To do this, the cloud service provider would have to go through and document these steps, applying a system-based approach. The auditor could then use an agent or a connected monitoring system to detect any deviations from the standard process.",
          "Organisation of information security (ois). Information security policy. Basic criterion: The top management of the cloud service provider has adopted an information security policy and communicated it to internal and external employees, as well as cloud customers. The policy describes the following:\n\n- The importance of information security, based on the requirements of cloud customers in relation to information security.\n- The security objectives and desired security level, based on the business goals and tasks of the cloud service provider.\n- The most important aspects of the security strategy to achieve the set security objectives.\n- The organizational structure for information security in the ISMS application area.\n\nAdditional criterion:\n\nSupplementary information about the criterion: The top management refers to a natural person or group of persons who make the final decisions for the institution and are responsible for those decisions.\n\nComplementary customer criterion:\n\nNotes on continuous auditing feasibility: \nPartially, a policy can change ad-hoc. However, the continuous audit of policies is only partially feasible as the only attributes that can be tested are the last change date and the status of review or approval, as far as this information is stored in a system. The content of a policy can hardly be tested automatically.",
          "Operations (ops). Managing vulnerabilities, malfunctions and errors – measurements, analyses and assessments of procedures. Basic criterion: The cloud service provider regularly measures, analyzes, and assesses the procedures with which vulnerabilities and incidents are handled to verify their continued suitability, appropriateness, and effectiveness. Results are evaluated at least quarterly by accountable departments at the cloud service provider to initiate continuous improvement actions and to verify their effectiveness. \n\nAdditional criterion: Supplementary information about the criterion includes common vulnerabilities and exposures (CVE) or similar methods that are suitable for documenting vulnerabilities and incidents. \n\nComplementary customer criterion: Notes on continuous auditing feasibility - Yes, the measurements, analyses, and evaluations are based on data that could be continuously queried in order to verify the plausibility of the results derived from them. The initiation and review of measures for continuous improvement require a manual audit.",
          "Asset management (am). Commitment to permissible use, safe handling and return of assets. Basic criterion: The cloud service provider's internal and external employees are provably committed to the policies and instructions for acceptable use and safe handling of assets before they can be used. If the cloud service provider has determined in a risk assessment that loss or unauthorized access could compromise the information security of the cloud service, any assets handed over are provably returned upon termination of employment.\n\nAdditional criterion: Physical assets of internal and external employees are managed centrally. Central management enables software, data, and policy distribution, as well as remote deactivation, deletion, or locking.\n\nSupplementary information about the criterion:\nThe basic criterion essentially concerns mobile devices (e.g., notebooks, tablets, smartphones, etc.) where confidential information is stored. Unauthorized access to these devices can be used to obtain privileged access to the cloud service (e.g., if these are used as security tokens for authentication).\n\nComplementary customer criterion notes on continuous auditing feasibility: Yes, the obligation of the employees to follow the policies and instructions can be made in digital form. This can be used to create a monitoring system that documents the non-obligation to employee guidelines in the form of logs. In this case, the auditor can check the exceptions in the form of logs and request evidence of what additional steps the cloud service provider has taken in these cases to minimize the risk. The compliant use of the assets can then be ensured via an agent system that checks active assets. The status of this system can then be queried by the auditor for a continuous audit.",
          "Procurement, development and modification of information systems (dev). Safety training and awareness programme regarding continuous software delivery and associated systems, components or tools.. Basic criterion: The cloud service provider provides a training program for regular, target group-oriented security training and awareness for internal and external employees on standards and methods of secure software development and provision, as well as on how to use the tools used for this purpose. The program is regularly reviewed and updated with regard to the applicable policies and instructions, the assigned roles and responsibilities, and the tools used.\n\nAdditional criterion: Supplementary information about the criterion.\n\nComplementary customer criterion: Notes on continuous auditing feasibility.\n\nFeasibility: Yes, the cloud service provider can automatically check the valid policies and instructions, the assigned roles and responsibilities, and the tools used and document the results in logs. These logs can be automatically evaluated by the auditor, and thus, a continuous audit can be carried out.",
          "System and information integrity. Flaw remediation. a. Identify, report, and correct system flaws.\nb. Test software and firmware updates related to flaw remediation for effectiveness and potential side effects before installation.\nc. Install security-relevant software and firmware updates within [assignment: organization-defined time period] of the release of the updates.\nd. Incorporate flaw remediation into the organizational configuration management process.\n\nThe need to remediate system flaws applies to all types of software and firmware. Organizations identify systems affected by software flaws, including potential vulnerabilities resulting from those flaws, and report this information to designated organizational personnel with information security and privacy responsibilities.\n\nSecurity-relevant updates include patches, service packs, and malicious code signatures. Organizations also address flaws discovered during assessments, continuous monitoring, incident response activities, and system error handling.\n\nBy incorporating flaw remediation into configuration management processes, required remediation actions can be tracked and verified. Organization-defined time periods for updating security-relevant software and firmware may vary based on a variety of risk factors, including the security category of the system, the criticality of the update (i.e., severity of the vulnerability related to the discovered flaw), the organizational risk tolerance, the mission supported by the system, or the threat environment.\n\nSome types of flaw remediation may require more testing than other types. Organizations determine the type of testing needed for the specific type of flaw remediation activity under consideration and the types of changes that are to be configuration-managed. \n\nIn some situations, organizations may determine that the testing of software or firmware updates is not necessary or practical, such as when implementing simple malicious code signature updates. In testing decisions, organizations consider whether security-relevant software or firmware updates are obtained from authorized sources with appropriate digital signatures.",
          "Communication security (cos). Cross-network access. Basic criterion: Each network perimeter is controlled by security gateways. The system access authorization for cross-network access is based on a security assessment, considering the requirements of the cloud customers.\n\nAdditional criterion: Each network perimeter is controlled by redundant and highly-available security gateways.\n\nSupplementary information about the criterion: Cross-network access refers to access from one network to another network through a defined network perimeter.\n\nComplementary customer criterion: Cloud customers ensure, through suitable controls, that access to their virtual networks within the cloud service is controlled according to their protection needs. This is achieved by using security gateways on the perimeters of the virtual networks for which they are responsible.\n\nNotes on continuous auditing feasibility: Yes, if the control of the network perimeters is documented (e.g., by logs), these logs can be automatically evaluated. This provides the possibility of a continuous audit for this part of the criterion. If the security evaluation for access authorizations is conducted in a standardized form by the cloud service provider, it can also be automatically evaluated. In such a case, a continuous audit for the second part of the criterion would also be possible.",
          "Security policies and instructions (sp). Exceptions from existing policies and instructions. Basic Criterion: Exceptions to the policies and instructions for information security, as well as respective controls, go through the OIS-06 risk management process. This includes the approval of these exceptions and the acceptance of the associated risks by the risk owners. The approvals of exceptions are documented, limited in time, and reviewed for appropriateness at least annually by the risk owners.\n\nAdditional Criterion: Supplementary information about the criterion exceptions, in the sense of the basic criterion, can have organizational or technical causes. For example, an organizational unit may need to deviate from the intended processes and procedures to meet the requirements of a cloud customer. Additionally, a system component may lack technical properties to configure it according to the applicable requirements. Cloud customers can use appropriate controls to ensure that they obtain information from the cloud service provider about deviations from information security policies and instructions. This allows them to assess and appropriately manage the associated risks to their own information security.\n\nComplementary Customer Criterion: Notes on continuous auditing feasibility: Partially, exceptions to policies and instructions are to be reviewed annually. However, the continuous audit of these exceptions is only partially feasible, as the only attributes that can be tested are the last change date and the status or review or approval, as far as this information is stored in a system. The content of an exception can hardly be tested automatically.\n\n5.3 Personnel (HR) Objective: Ensure that employees understand their responsibilities, are aware of their responsibilities with regard to information security, and that the organization's assets are protected in the event of changes in responsibilities or termination.",
          "Dealing with investigation requests from government agencies (inq). Informing cloud customers about investigation requests. Basic criterion: The cloud service provider informs the affected cloud customer(s) without undue delay, unless the applicable legal basis on which the government agency is based prohibits this or there are clear indications of illegal actions in connection with the use of the cloud service. \nAdditional criterion: Supplementary information about the criterion. This does not affect other legal or regulatory requirements that require earlier information for cloud customers. \nComplementary customer criterion: Cloud customers ensure through suitable controls that such notifications are received and legally checked according to their own specifications and possibilities. \nNotes on continuous auditing feasibility: Partially for internal process monitoring at the cloud service provider and facilitation of the audit, a continuous audit of the period between receipt of the request and information of the customers is conceivable. However, as this depends on local legal basis, the effort to establish this in the respective regions will be quite high. If a transaction processing system is implemented at the cloud service provider, at least the process in this system can be continuously audited.",
          "Portability and interoperability (pi). Secure deletion of data. Basic criterion: The cloud service provider's procedures for deleting the cloud customers' data upon termination of the contractual relationship ensure compliance with the contractual agreements (cf. pi-02). The deletion includes data in the cloud customer's environment, metadata, and data stored in the data backups. The deletion procedures prevent recovery by forensic means.\n\nAdditional criterion supplementary information about the criterion suitable methods for data deletion are, e.g., multiple overwriting or deletion of the encryption key.\n\nComplementary customer criterion: Cloud customers ensure through suitable controls that the legal and regulatory framework (e.g., legal requirements for storage and deletion) is identified and that the deletion of their data is initiated accordingly.\n\nNotes on continuous auditing feasibility: Yes, the complete deletion of the data is documented by the cloud service provider using logs. The logs should include which data has been deleted so that it can be tracked whether data has been deleted in the cloud customer's environment, metadata, and data in the backup. The auditor can then perform an automated evaluation of these logs. The auditor can also check the system status of the procedure for deleting the data. The fact that the deletion procedures prevent recovery by forensic means does not have to be audited continuously. The deletion procedures used can be tested as part of the recurring audit.\n\n5.11 Procurement, development, and modification of information systems (dev) objective: Ensure information security in the development cycle of information systems.",
          "Product safety and security (pss). Authorisation mechanisms. Basic criterion: Access to the functions provided by the cloud service is restricted by access controls (authorization mechanisms) that verify whether users, IT components, or applications are authorized to perform certain actions. The cloud service provider validates the functionality of the authorization mechanisms before new functions are made available to cloud users and in the event of changes to the authorization mechanisms of existing functions (cf. dev-06). The severity of identified vulnerabilities is assessed according to defined criteria based on industry-standard metrics (e.g., Common Vulnerability Scoring System), and measures for timely resolution or mitigation are initiated. Vulnerabilities that have not been fixed are listed in the online register of known vulnerabilities (cf. pss-02).\n\nAdditional criterion: Access controls are attribute-based to enable granular and contextual checks against multiple attributes of a user, IT component, or application (e.g., role, location, authentication method).\n\nSupplementary information about the criterion: Complementary customer criterion notes on continuous auditing feasibility: Yes, the changes to authorization mechanisms and the identification of vulnerabilities are documented in a standardized manner by the cloud service provider. This documentation can be automated and continuously audited. If the elimination of the vulnerabilities and their prioritization also takes place in a standardized form (according to standardized criteria), these points can be integrated into the continuous audit.",
          "Organisation of information security (ois). Contact with relevant government agencies and interest groups. Basic criterion: The cloud service provider leverages relevant authorities and interest groups in order to stay informed about current threats and vulnerabilities. The information flows into the procedures for handling risks (cf. OIS-06) and vulnerabilities (cf. OPS-19). \n\nAdditional criterion: If the cloud service is used by public sector organizations in Germany, the cloud service provider leverages contacts with the National IT Situation Centre and the CERT Association of the BSI. \n\nSupplementary information about the criterion: Relevant contacts are, for example, the Federal Office for Information Security (BSI), OWASP Foundation, and CERT networks such as DFN-CERT and TF-CSIRT. \n\nPublic sector organizations in Germany are, for example, authorities and ministries. \n\nComplementary customer criterion notes on continuous auditing feasibility: Yes, a continuous audit of the cloud service provider's contacts with relevant authorities and stakeholders can be achieved by continuously storing relevant information on a monthly basis, such as a list of contacted entities and evidence of receipt of a response. \n\nA continuous flow of information demonstrates a constant connection to relevant authorities and interest groups. Furthermore, the distribution of the information and, if necessary, the documentation of the handling of identified risks and vulnerabilities could be continuously audited for the coverage of this criterion.",
          "Security assessment and authorization. Penetration testing. Conduct penetration testing [assignment: organization-defined frequency] on [assignment: organization-defined systems or system components]. Penetration testing is a specialized type of assessment conducted on systems or individual system components to identify vulnerabilities that could be exploited by adversaries. Penetration testing goes beyond automated vulnerability scanning and is conducted by agents and teams with demonstrable skills and experience that include technical expertise in network, operating system, and/or application-level security. Penetration testing can be used to validate vulnerabilities or determine the degree of penetration resistance of systems to adversaries within specified constraints. Such constraints include time, resources, and skills. Penetration testing attempts to duplicate the actions of adversaries and provides a more in-depth analysis of security- and privacy-related weaknesses or deficiencies. Penetration testing is especially important when organizations are transitioning from older technologies to newer technologies (e.g., transitioning from IPv4 to IPv6 network protocols). Organizations can use the results of vulnerability analyses to support penetration testing activities. Penetration testing can be conducted internally or externally on the hardware, software, or firmware components of a system and can exercise both physical and technical controls. A standard method for penetration testing includes a pretest analysis based on full knowledge of the system, pretest identification of potential vulnerabilities based on the pretest analysis, and testing designed to determine the exploitability of vulnerabilities. All parties agree to the rules of engagement before commencing penetration testing scenarios. Organizations correlate the rules of engagement for the penetration tests with the tools, techniques, and procedures that are anticipated to be employed by adversaries. Penetration testing may result in the exposure of information that is protected by laws or regulations to individuals conducting the testing. Rules of engagement, contracts, or other appropriate mechanisms can be used to communicate expectations for how to protect this information. Risk assessments guide the decisions on the level of independence required for the personnel conducting penetration testing.",
          "Operations (ops). Protection against malware – concept. Basic criterion: Policies and instructions with specifications for protection against malware are documented, communicated, and provided in accordance with SP-01. The following aspects should be considered:\n\n- Use of system-specific protection mechanisms\n- Operating protection programs on system components under the responsibility of the cloud service provider that are used to provide the cloud service in the production environment\n- Operation of protection programs for employees’ terminal equipment \n\nAdditional criterion: The cloud service provider creates regular reports on the checks performed, which are reviewed and analyzed by authorized bodies or committees. \n\nPolicies and instructions should describe the technical measures taken to securely configure and monitor the management console (both the customer’s self-service and the service provider’s cloud administration) to protect it from malware. Updates should be applied at the highest frequency that the vendor(s) contractually offer(s). \n\nSupplementary information about the criterion \"protection programs for employee devices\" can be, for example, server-based protection programs that scan files in attachments on the server or filter network traffic.\n\nComplementary customer criterion notes on continuous auditing feasibility: Partially, a policy can change ad-hoc. However, the continuous audit of policies is only partially feasible, as the only attributes that can be tested are the last change date and the status of review or approval, as far as this information is stored in a system. The content of a policy can hardly be tested automatically.",
          "Operations (ops). Managing vulnerabilities, malfunctions and errors – concept. Basic criterion: Guidelines and instructions with technical and organizational measures are documented, communicated, and provided in accordance with SP-01 to ensure the timely identification and addressing of vulnerabilities in the system components used to provide the cloud service. These guidelines and instructions contain specifications regarding the following aspects: regular identification of vulnerabilities; assessment of the severity of identified vulnerabilities; prioritization and implementation of actions to promptly remediate or mitigate identified vulnerabilities based on severity and according to defined timelines; and handling of system components for which no measures are initiated for the timely remediation or mitigation of vulnerabilities. \n\nAdditional criterion: Supplementary information about the criterion identified vulnerabilities can be classified according to established metrics such as CVSS or OWASP. The decision not to remediate or mitigate identified vulnerabilities must be made by the cloud service provider based on a risk assessment. If necessary, risk-compensating measures must be taken. \n\nComplementary customer criterion: Cloud customers ensure, through suitable controls, that they check system components in their area of responsibility for vulnerabilities on a regular basis and mitigate these with appropriate measures. \n\nNotes on continuous auditing feasibility: No, a policy can change ad-hoc. However, the continuous audit of policies is only partially feasible as the only attributes that can be tested are the last change date and the status of review or approval, as far as this information is stored in a system. The content of a policy can hardly be tested automatically.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "1_the_of_cloud",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "1_the_of_cloud"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          11.034689903259277,
          11.592191696166992,
          9.867354393005371,
          13.580899238586426,
          10.0836820602417,
          10.311873435974121,
          11.283651351928711,
          10.41928482055664,
          5.530409812927246,
          9.76175308227539,
          11.993131637573242,
          13.543214797973633,
          13.607000350952148,
          10.482749938964844,
          5.869117259979248,
          12.608031272888184,
          10.123072624206543,
          12.008831977844238,
          10.719918251037598,
          9.907731056213379,
          9.875102996826172,
          12.077410697937012,
          10.47694206237793,
          13.622520446777344,
          11.396845817565918,
          13.404668807983398,
          11.742706298828125,
          11.912759780883789,
          11.329606056213379,
          12.146543502807617,
          12.15123176574707,
          10.145034790039062,
          11.375656127929688,
          11.439276695251465,
          10.693979263305664,
          9.981925010681152,
          13.576520919799805,
          10.058908462524414,
          11.62369441986084,
          10.372360229492188,
          12.533831596374512,
          12.840688705444336,
          12.203226089477539,
          10.216231346130371,
          10.772663116455078,
          10.656657218933105,
          11.24436092376709,
          13.600937843322754,
          11.867695808410645,
          13.294370651245117,
          10.103687286376953,
          10.663484573364258,
          10.0189790725708,
          11.67409610748291,
          11.754366874694824,
          12.183704376220703,
          6.31616735458374,
          12.108087539672852,
          13.473346710205078,
          9.867408752441406,
          11.355109214782715,
          10.656716346740723,
          10.121933937072754,
          10.698538780212402,
          11.463394165039062,
          12.621343612670898,
          13.04720401763916,
          10.787464141845703,
          6.34480619430542,
          11.749751091003418,
          10.837767601013184,
          10.915188789367676,
          13.600407600402832,
          10.709693908691406,
          6.326799392700195,
          10.043238639831543,
          10.112359046936035,
          13.604839324951172,
          11.740654945373535,
          12.609691619873047,
          11.546281814575195,
          12.115039825439453,
          12.36322021484375,
          12.388663291931152,
          11.066173553466797,
          10.182252883911133,
          11.660005569458008,
          10.210310935974121,
          13.5779447555542,
          10.180008888244629,
          6.108174800872803,
          9.955267906188965,
          10.890193939208984,
          10.946441650390625,
          5.674807548522949,
          11.739583015441895,
          13.615976333618164,
          11.791595458984375,
          6.249672889709473,
          11.976991653442383,
          10.060789108276367,
          13.647201538085938,
          13.50595474243164,
          13.473133087158203,
          10.753469467163086,
          11.79529857635498,
          10.580095291137695,
          6.318324089050293,
          10.838703155517578,
          12.794715881347656,
          13.49260139465332,
          10.694937705993652,
          13.340373039245605,
          13.664514541625977,
          11.001354217529297,
          13.558587074279785,
          5.677329063415527,
          11.94169807434082,
          11.053377151489258,
          12.500340461730957,
          9.930158615112305,
          6.306135654449463,
          6.329123497009277,
          5.702394485473633,
          11.958967208862305,
          6.3217058181762695,
          10.967881202697754
         ],
         "y": [
          -0.43389755487442017,
          -0.09161581844091415,
          -1.16989266872406,
          0.791741132736206,
          -1.198550820350647,
          -0.901557445526123,
          -0.24970757961273193,
          -0.9280382990837097,
          -1.1078243255615234,
          -1.098043441772461,
          0.12298445403575897,
          0.7249840497970581,
          0.8047835826873779,
          -0.9884263873100281,
          -1.0170165300369263,
          0.5939505100250244,
          -0.8987946510314941,
          0.28981831669807434,
          -0.9888293743133545,
          -1.3591481447219849,
          -1.176257610321045,
          0.271790087223053,
          -0.885047972202301,
          0.8069135546684265,
          -0.34066659212112427,
          0.6822443604469299,
          0.060515183955430984,
          0.48320454359054565,
          -0.4131377339363098,
          0.33039432764053345,
          0.2602190375328064,
          -1.2504878044128418,
          -0.3886486291885376,
          -0.25813326239585876,
          -0.9845300912857056,
          -0.8675011396408081,
          0.6954676508903503,
          -0.9393793940544128,
          -0.04477495700120926,
          -0.944722592830658,
          0.5888135433197021,
          0.671758234500885,
          0.44136732816696167,
          -0.8573627471923828,
          -0.8827407360076904,
          -0.7934313416481018,
          -0.30083853006362915,
          0.7738490104675293,
          0.4008343517780304,
          0.7788481712341309,
          -0.8747244477272034,
          -0.8274086713790894,
          -1.2482266426086426,
          -0.023740552365779877,
          0.17325171828269958,
          0.46618640422821045,
          -0.7944191694259644,
          0.5268056392669678,
          0.8264495730400085,
          -1.203312635421753,
          -0.39269790053367615,
          -0.9172155857086182,
          -0.8456310629844666,
          -0.6222361326217651,
          -0.24345830082893372,
          0.6147280335426331,
          0.8297758102416992,
          -0.9282485246658325,
          -0.7643647193908691,
          0.18035082519054413,
          -0.8844266533851624,
          -0.535567581653595,
          0.767475962638855,
          -0.8722307682037354,
          -0.8114792704582214,
          -1.2072782516479492,
          -0.8490804433822632,
          0.8455243706703186,
          0.06174228712916374,
          0.6061485409736633,
          0.018196552991867065,
          0.20651894807815552,
          0.5207370519638062,
          0.5092089176177979,
          -0.4451957643032074,
          -0.8530324101448059,
          -0.004107239656150341,
          -1.167095422744751,
          0.677761971950531,
          -1.051401138305664,
          -0.9590877890586853,
          -0.9975045919418335,
          -0.8204576373100281,
          -0.8434519171714783,
          -1.0750863552093506,
          0.15215837955474854,
          0.7929583787918091,
          0.3150465488433838,
          -0.8386707305908203,
          0.2453261762857437,
          -1.3091849088668823,
          0.8282523155212402,
          0.778008222579956,
          0.7249905467033386,
          -0.6335877180099487,
          0.2678091526031494,
          -0.6612173914909363,
          -0.7945929169654846,
          -0.8254574537277222,
          0.6592856049537659,
          0.7013807892799377,
          -0.9804849028587341,
          0.7242304682731628,
          0.8694663643836975,
          -0.6767533421516418,
          0.8427673578262329,
          -1.0693364143371582,
          0.2519323527812958,
          -0.7647937536239624,
          0.5698737502098083,
          -0.9932832717895508,
          -0.7975719571113586,
          -0.7929380536079407,
          -1.0508900880813599,
          0.1271856129169464,
          -0.7819435000419617,
          -0.2582211196422577
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "System and communications protection. Transmission confidentiality and integrity. Protect the confidentiality and integrity of transmitted information. Protecting the confidentiality and integrity of transmitted information applies to internal and external networks as well as any system components that can transmit information, including servers, notebook computers, desktop computers, mobile devices, printers, copiers, scanners, facsimile machines, and radios. Unprotected communication paths are exposed to the possibility of interception and modification. Protecting the confidentiality and integrity of information can be accomplished by physical or logical means. Physical protection can be achieved by using protected distribution systems. A protected distribution system is a wireline or fiber-optics telecommunications system that includes terminals and adequate electromagnetic, acoustical, electrical, and physical controls to permit its use for the unencrypted transmission of classified information. Logical protection can be achieved by employing encryption techniques. Organizations that rely on commercial providers who offer transmission services as commodity services rather than as fully dedicated services may find it difficult to obtain the necessary assurances regarding the implementation of needed controls for transmission confidentiality and integrity. In such situations, organizations determine what types of confidentiality or integrity services are available in standard, commercial telecommunications service packages. If it is not feasible to obtain the necessary controls and assurances of control effectiveness through appropriate contracting vehicles, organizations can implement appropriate compensating controls.",
          "Awareness and training. Role-based training. a. Provide role-based security and privacy training to personnel with the following roles and responsibilities: [assignment: organization-defined roles and responsibilities]. 1. Before authorizing access to the system, information, or performing assigned duties, and [assignment: organization-defined frequency] thereafter. 2. When required by system changes.\nb. Update role-based training content [assignment: organization-defined frequency] and following [assignment: organization-defined events].\nc. Incorporate lessons learned from internal or external security incidents or breaches into role-based training. \nOrganizations determine the content of training based on the assigned roles and responsibilities of individuals as well as the security and privacy requirements of organizations and the systems to which personnel have authorized access, including technical training specifically tailored for assigned duties. Roles that may require role-based training include senior leaders or management officials (e.g., head of agency/chief executive officer, chief information officer, senior accountable official for risk management, senior agency information security officer, senior agency official for privacy), system owners, authorizing officials, system security officers, privacy officers, acquisition and procurement officials, enterprise architects, systems engineers, software developers, systems security engineers, privacy engineers, system, network, and database administrators, auditors, personnel conducting configuration management activities, personnel performing verification and validation activities, personnel with access to system-level software, control assessors, personnel with contingency planning and incident response duties, personnel with privacy management responsibilities, and personnel with access to personally identifiable information. \nComprehensive role-based training addresses management, operational, and technical roles and responsibilities covering physical, personnel, and technical controls. Role-based training also includes policies, procedures, tools, methods, and artifacts for the security and privacy roles defined. Organizations provide the training necessary for individuals to fulfill their responsibilities related to operations and supply chain risk management within the context of organizational security and privacy programs. Role-based training also applies to contractors who provide services to federal agencies. Types of training include web-based and computer-based training, classroom-style training, and hands-on training (including micro-training). Updating role-based training on a regular basis helps to ensure that the content remains relevant and effective. Events that may precipitate an update to role-based training content include, but are not limited to, assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines.",
          "Access control. Access control for mobile devices. A. Establish configuration requirements, connection requirements, and implementation guidance for organization-controlled mobile devices, to include when such devices are outside of controlled areas. \nB. Authorize the connection of mobile devices to organizational systems.\n\nA mobile device is a computing device that has a small form factor such that it can easily be carried by a single individual. It is designed to operate without a physical connection, possesses local, non-removable or removable data storage, and includes a self-contained power source. Mobile device functionality may also include voice communication capabilities, on-board sensors that allow the device to capture information, and/or built-in features for synchronizing local data with remote locations. Examples include smartphones and tablets. Mobile devices are typically associated with a single individual. The processing, storage, and transmission capability of the mobile device may be comparable to or merely a subset of notebook/desktop systems, depending on the nature and intended purpose of the device.\n\nProtection and control of mobile devices are behavior or policy-based and require users to take physical action to protect and control such devices when outside of controlled areas. Controlled areas are spaces for which organizations provide physical or procedural controls to meet the requirements established for protecting information and systems. Due to the large variety of mobile devices with different characteristics and capabilities, organizational restrictions may vary for the different classes or types of such devices.\n\nUsage restrictions and specific implementation guidance for mobile devices include:\n- Configuration management\n- Device identification and authentication\n- Implementation of mandatory protective software\n- Scanning devices for malicious code\n- Updating virus protection software\n- Scanning for critical software updates and patches\n- Conducting primary operating system (and possibly other resident software) integrity checks\n- Disabling unnecessary hardware\n\nUsage restrictions and authorization to connect may vary among organizational systems. For example, the organization may authorize the connection of mobile devices to its network and impose a set of usage restrictions, while a system owner may withhold authorization for mobile device connection to specific applications or impose additional usage restrictions before allowing mobile device connections to a system.\n\nAdequate security for mobile devices goes beyond the requirements specified in AC-19. Many safeguards for mobile devices are reflected in other controls. AC-20 addresses mobile devices that are not organization-controlled.",
          "System and communications protection. Policy and procedures. A. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]: 1. [Selection (one or more): organization level; mission/business process-level; system-level] system and communications protection policy that: (a) addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance; and (b) is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines; and 2. Procedures to facilitate the implementation of the system and communications protection policy and the associated system and communications protection controls.\n\nB. Designate an [assignment: organization-defined official] to manage the development, documentation, and dissemination of the system and communications protection policy and procedures.\n\nC. Review and update the current system and communications protection: 1. Policy [assignment: organization-defined frequency] and following [assignment: organization-defined events]; and 2. Procedures [assignment: organization-defined frequency] and following [assignment: organization-defined events].\n\nSystem and communications protection policy and procedures address the controls in the SC family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of system and communications protection policy and procedures. Security and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations. Procedures can be established for security and privacy programs, for mission or business processes, and for systems, if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents. Events that may precipitate an update to system and communications protection policy and procedures include assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Maintenance. Controlled maintenance. a. Schedule, document, and review records of maintenance, repair, and replacement on system components in accordance with manufacturer or vendor specifications and/or organizational requirements.\nb. Approve and monitor all maintenance activities, whether performed on-site or remotely, and whether the system or system components are serviced on-site or removed to another location.\nc. Require that [assignment: organization-defined personnel or roles] explicitly approve the removal of the system or system components from organizational facilities for off-site maintenance, repair, or replacement.\nd. Sanitize equipment to remove the following information from associated media prior to removal from organizational facilities for off-site maintenance, repair, or replacement: [assignment: organization-defined information].\ne. Check all potentially impacted controls to verify that the controls are still functioning properly following maintenance, repair, or replacement actions.\nf. Include the following information in organizational maintenance records: [assignment: organization-defined information].\n\nControlling system maintenance addresses the information security aspects of the system maintenance program and applies to all types of maintenance to system components conducted by local or non-local entities. Maintenance includes peripherals such as scanners, copiers, and printers. Information necessary for creating effective maintenance records includes the date and time of maintenance, a description of the maintenance performed, names of the individuals or group performing the maintenance, the name of the escort, and system components or equipment that is removed or replaced. Organizations consider supply chain-related risks associated with replacement components for systems.",
          "Access control. Policy and procedures. A. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]: 1. [Selection (one or more): organization-level; mission/business process-level; system-level] access control policy that:\n(a) Addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance.\n(b) Is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines.\n2. Procedures to facilitate the implementation of the access control policy and the associated access controls.\n\nB. Designate an [assignment: organization-defined official] to manage the development, documentation, and dissemination of the access control policy and procedures.\n\nC. Review and update the current access control:\n1. Policy [assignment: organization-defined frequency] and following [assignment: organization-defined events].\n2. Procedures [assignment: organization-defined frequency] and following [assignment: organization-defined events].\n\nAccess control policy and procedures address the controls in the AC family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of access control policy and procedures. Security and privacy program policies and procedures at the organization level are preferable in general and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies reflecting the complex nature of organizations. Procedures can be established for security and privacy programs, for mission or business processes, and for systems if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents. Events that may precipitate an update to access control policy and procedures include assessment or audit findings, security incidents or breaches, or changes in laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "System and services acquisition. Acquisition process | design and implementation information for controls. Require the developer of the system, system component, or system service to provide design and implementation information for the controls that includes: [selection (one or more): security-relevant external system interfaces; high-level design; low-level design; source code or hardware schematics; [assignment: organization-defined design and implementation information]] at [assignment: organization-defined level of detail]. Organizations may require different levels of detail in the documentation for the design and implementation of controls in organizational systems, system components, or system services based on mission and business requirements, requirements for resiliency and trustworthiness, and requirements for analysis and testing. Systems can be partitioned into multiple subsystems. Each subsystem within the system can contain one or more modules. The high-level design for the system is expressed in terms of subsystems and the interfaces between subsystems providing security-relevant functionality. The low-level design for the system is expressed in terms of modules and the interfaces between modules providing security-relevant functionality. Design and implementation documentation can include manufacturer, version, serial number, verification hash signature, software libraries used, date of purchase or download, and the vendor or download source. Source code and hardware schematics are referred to as the implementation representation of the system.",
          "Identification and authentication. Identification and authentication (organizational users) | multi-factor authentication to privileged accounts. Implement multi-factor authentication for access to privileged accounts. Multi-factor authentication requires the use of two or more different factors to achieve authentication. The authentication factors are defined as follows: something you know (e.g., a personal identification number [PIN]), something you have (e.g., a physical authenticator such as a cryptographic private key), or something you are (e.g., a biometric). \n\nMulti-factor authentication solutions that feature physical authenticators include hardware authenticators that provide time-based or challenge-response outputs and smart cards such as the U.S. government Personal Identity Verification (PIV) card or the Department of Defense (DoD) Common Access Card (CAC). In addition to authenticating users at the system level (i.e., at logon), organizations may employ authentication mechanisms at the application level, at their discretion, to provide increased security.\n\nRegardless of the type of access (i.e., local, network, remote), privileged accounts are authenticated using multi-factor options appropriate for the level of risk. Organizations can add additional security measures, such as additional or more rigorous authentication mechanisms, for specific types of access.",
          "Access control. Information sharing. a. Enable authorized users to determine whether access authorizations assigned to a sharing partner match the information's access and use restrictions for [assignment: organization-defined information sharing circumstances where user discretion is required]. \nB. Employ [assignment: organization-defined automated mechanisms or manual processes] to assist users in making information sharing and collaboration decisions. Information sharing applies to information that may be restricted in some manner based on some formal or administrative determination. Examples of such information include contract-sensitive information, classified information related to special access programs or compartments, privileged information, proprietary information, and personally identifiable information. Security and privacy risk assessments, as well as applicable laws, regulations, and policies, can provide useful inputs to these determinations. Depending on the circumstances, sharing partners may be defined at the individual, group, or organizational level. Information may be defined by content, type, security category, or special access program or compartment. Access restrictions may include non-disclosure agreements (NDA). Information flow techniques and security attributes may be used to provide automated assistance to users making sharing and collaboration decisions.",
          "Incident response. Incident response plan. A. Develop an incident response plan that:\n\n1. Provides the organization with a roadmap for implementing its incident response capability.\n2. Describes the structure and organization of the incident response capability.\n3. Provides a high-level approach for how the incident response capability fits into the overall organization.\n4. Meets the unique requirements of the organization, which relate to mission, size, structure, and functions.\n5. Defines reportable incidents.\n6. Provides metrics for measuring the incident response capability within the organization.\n7. Defines the resources and management support needed to effectively maintain and mature an incident response capability.\n8. Addresses the sharing of incident information.\n9. Is reviewed and approved by [assignment: organization-defined personnel or roles] [assignment: organization-defined frequency].\n10. Explicitly designates responsibility for incident response to [assignment: organization-defined entities, personnel, or roles].\n\nB. Distribute copies of the incident response plan to [assignment: organization-defined incident response personnel (identified by name and/or role) and organizational elements].\n\nC. Update the incident response plan to address system and organizational changes or problems encountered during plan implementation, execution, or testing.\n\nD. Communicate incident response plan changes to [assignment: organization-defined incident response personnel (identified by name and/or role) and organizational elements].\n\nE. Protect the incident response plan from unauthorized disclosure and modification.\n\nIt is important that organizations develop and implement a coordinated approach to incident response. Organizational mission and business functions determine the structure of incident response capabilities. As part of the incident response capabilities, organizations consider the coordination and sharing of information with external organizations, including external service providers and other organizations involved in the supply chain. For incidents involving personally identifiable information (i.e., breaches), include a process to determine whether notice to oversight organizations or affected individuals is appropriate and provide that notice accordingly.",
          "System and services acquisition. Developer screening. Require that the developer of [assignment: organization-defined system, system component, or system service] has appropriate access authorizations as determined by assigned [assignment: organization-defined official government duties]. The developer should also satisfy the following additional personnel screening criteria: [assignment: organization-defined additional personnel screening criteria]. Developer screening is directed at external developers. Internal developer screening is addressed by PS-3. Because the system, system component, or system service may be used in critical activities essential to the national or economic security interests of the United States, organizations have a strong interest in ensuring that developers are trustworthy. The degree of trust required of developers may need to be consistent with that of the individuals who access the systems, system components, or system services once deployed. Authorization and personnel screening criteria include clearances, background checks, citizenship, and nationality. Developer trustworthiness may also include a review and analysis of company ownership and relationships that the company has with entities that may potentially affect the quality and reliability of the systems, components, or services being developed. Satisfying the required access authorizations and personnel screening criteria includes providing a list of all individuals who are authorized to perform development activities on the selected system, system component, or system service so that organizations can validate that the developer has satisfied the authorization and screening requirements.",
          "System and services acquisition. Developer testing and evaluation. Require the developer of the system, system component, or system service, at all post-design stages of the system development life cycle, to: a. develop and implement a plan for ongoing security and privacy control assessments; b. perform [selection (one or more): unit; integration; system; regression] testing/evaluation [assignment: organization-defined frequency] at [assignment: organization-defined depth and coverage]; c. produce evidence of the execution of the assessment plan and the results of the testing and evaluation; d. implement a verifiable flaw remediation process; and e. correct flaws identified during testing and evaluation. Developmental testing and evaluation confirms that the required controls are implemented correctly, operating as intended, enforcing the desired security and privacy policies, and meeting established security and privacy requirements. Security properties of systems and the privacy of individuals may be affected by the interconnection of system components or changes to those components. The interconnections or changes—including upgrading or replacing applications, operating systems, and firmware—may adversely affect previously implemented controls. Ongoing assessment during development allows for additional types of testing and evaluation that developers can conduct to reduce or eliminate potential flaws. Testing custom software applications may require approaches such as manual code review, security architecture review, and penetration testing, as well as static analysis, dynamic analysis, binary analysis, or a hybrid of the three analysis approaches. Developers can use the analysis approaches, along with security instrumentation and fuzzing, in a variety of tools and in source code reviews. The security and privacy assessment plans include the specific activities that developers plan to carry out, including the types of analyses, testing, evaluation, and reviews of software and firmware components; the degree of rigor to be applied; the frequency of the ongoing testing and evaluation; and the types of artifacts produced during those processes. The depth of testing and evaluation refers to the rigor and level of detail associated with the assessment process. The coverage of testing and evaluation refers to the scope (i.e., number and type) of the artifacts included in the assessment process. Contracts specify the acceptance criteria for security and privacy assessment plans, flaw remediation processes, and the evidence that the plans and processes have been diligently applied. Methods for reviewing and protecting assessment plans, evidence, and documentation are commensurate with the security category or classification level of the system. Contracts may specify protection requirements for documentation.",
          "Maintenance. Maintenance tools. a. Approve, control, and monitor the use of system maintenance tools; and b. Review previously approved system maintenance tools [assignment: organization-defined frequency]. Approving, controlling, monitoring, and reviewing maintenance tools address security-related issues associated with maintenance tools that are not within system authorization boundaries and are used specifically for diagnostic and repair actions on organizational systems. Organizations have flexibility in determining roles for the approval of maintenance tools and how that approval is documented. A periodic review of maintenance tools facilitates the withdrawal of approval for outdated, unsupported, irrelevant, or no-longer-used tools. Maintenance tools can include hardware, software, and firmware items and may be pre-installed, brought in with maintenance personnel on media, cloud-based or downloaded from a website. Such tools can be vehicles for transporting malicious code, either intentionally or unintentionally, into a facility and subsequently into systems. Maintenance tools can include hardware and software diagnostic test equipment and packet sniffers. The hardware and software components that support maintenance and are part of the system (including the software implementing utilities such as ping, ls, ipconfig, or the hardware and software implementing the monitoring port of an Ethernet switch) are not addressed by maintenance tools.",
          "System and communications protection. Architecture and provisioning for name/address resolution service. Ensure the systems that collectively provide name/address resolution service for an organization are fault-tolerant and implement internal and external role separation. Systems that provide name and address resolution services include Domain Name System (DNS) servers. To eliminate single points of failure in systems and enhance redundancy, organizations employ at least two authoritative Domain Name System servers—one configured as the primary server and the other configured as the secondary server. Additionally, organizations typically deploy the servers in two geographically separated network subnetworks (i.e., not located in the same physical facility). \n\nFor role separation, DNS servers with internal roles only process name and address resolution requests from within organizations (i.e., from internal clients). DNS servers with external roles only process name and address resolution information requests from clients external to organizations (i.e., on external networks, including the internet). Organizations specify clients that can access authoritative DNS servers in certain roles (e.g., by address ranges and explicit lists).",
          "Awareness and training. Literacy training and awareness. a. Provide security and privacy literacy training to system users (including managers, senior executives, and contractors): 1. As part of initial training for new users and [assignment: organization-defined frequency] thereafter; and 2. When required by system changes or following [assignment: organization-defined events]. \nb. Employ the following techniques to increase the security and privacy awareness of system users [assignment: organization-defined awareness techniques]. \nc. Update literacy training and awareness content [assignment: organization-defined frequency] and following [assignment: organization-defined events]. \nd. Incorporate lessons learned from internal or external security incidents or breaches into literacy training and awareness techniques. \n\nOrganizations provide basic and advanced levels of literacy training to system users, including measures to test the knowledge level of users. Organizations determine the content of literacy training and awareness based on specific organizational requirements, the systems to which personnel have authorized access, and work environments (e.g., telework). The content includes an understanding of the need for security and privacy as well as actions by users to maintain security and personal privacy and to respond to suspected incidents. The content addresses the need for operations security and the handling of personally identifiable information. Awareness techniques include displaying posters, offering supplies inscribed with security and privacy reminders, displaying logon screen messages, generating email advisories or notices from organizational officials, and conducting awareness events. \n\nLiteracy training after the initial training described in at-2a.1 is conducted at a minimum frequency consistent with applicable laws, directives, regulations, and policies. Subsequent literacy training may be satisfied by one or more short ad hoc sessions and include topical information on recent attack schemes, changes to organizational security and privacy policies, revised security and privacy expectations, or a subset of topics from the initial training. Updating literacy training and awareness content on a regular basis helps to ensure that the content remains relevant. Events that may precipitate an update to literacy training and awareness content include, but are not limited to, assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines.",
          "Configuration management. Configuration change control. A. Determine and document the types of changes to the system that are configuration-controlled.\nB. Review proposed configuration-controlled changes to the system and approve or disapprove such changes with explicit consideration for security and privacy impact analyses.\nC. Document configuration change decisions associated with the system.\nD. Implement approved configuration-controlled changes to the system.\nE. Retain records of configuration-controlled changes to the system for [assignment: organization-defined time period].\nF. Monitor and review activities associated with configuration-controlled changes to the system.\nG. Coordinate and provide oversight for configuration change control activities through [assignment: organization-defined configuration change control element] that convenes [selection (one or more): [assignment: organization-defined frequency]; when [assignment: organization-defined configuration change conditions]].\n\nConfiguration change control for organizational systems involves the systematic proposal, justification, implementation, testing, review, and disposition of system changes, including system upgrades and modifications. Configuration change control includes changes to baseline configurations, configuration items of systems, operational procedures, configuration settings for system components, remediate vulnerabilities, and unscheduled or unauthorized changes. Processes for managing configuration changes to systems include configuration control boards or change advisory boards that review and approve proposed changes. For changes that impact privacy risk, the senior agency official for privacy updates privacy impact assessments and system of records notices. For new systems or major upgrades, organizations consider including representatives from the development organizations on the configuration control boards or change advisory boards. Auditing of changes includes activities before and after changes are made to systems and the auditing activities required to implement such changes. See also SA-10.",
          "Identification and authentication. Identifier management. Manage system identifiers by: a. receiving authorization from [assignment: organization-defined personnel or roles] to assign an individual, group, role, service, or device identifier; b. selecting an identifier that identifies an individual, group, role, service, or device; c. assigning the identifier to the intended individual, group, role, service, or device; and d. preventing reuse of identifiers for [assignment: organization-defined time period]. Common device identifiers include Media Access Control (MAC) addresses, Internet Protocol (IP) addresses, or device-unique token identifiers. The management of individual identifiers is not applicable to shared system accounts. Typically, individual identifiers are the usernames of the system accounts assigned to those individuals. In such instances, the account management activities of AC-2 use account names provided by IA-4. Identifier management also addresses individual identifiers not necessarily associated with system accounts. Preventing the reuse of identifiers implies preventing the assignment of previously used individual, group, role, service, or device identifiers to different individuals, groups, roles, services, or devices.",
          "System and services acquisition. Security and privacy engineering principles. Apply the following systems security and privacy engineering principles in the specification, design, development, implementation, and modification of the system and system components: [Assignment: organization-defined systems security and privacy engineering principles]. Systems security and privacy engineering principles are closely related to and implemented throughout the system development life cycle (see SA-3). Organizations can apply systems security and privacy engineering principles to new systems under development or to systems undergoing upgrades. For existing systems, organizations apply systems security and privacy engineering principles to system upgrades and modifications to the extent feasible, given the current state of hardware, software, and firmware components within those systems.\n\nThe application of systems security and privacy engineering principles helps organizations develop trustworthy, secure, and resilient systems and reduces the susceptibility to disruptions, hazards, threats, and the creation of privacy problems for individuals. Examples of system security engineering principles include: developing layered protections; establishing security and privacy policies, architecture, and controls as the foundation for design and development; incorporating security and privacy requirements into the system development life cycle; delineating physical and logical security boundaries; ensuring that developers are trained on how to build secure software; tailoring controls to meet organizational needs; and performing threat modeling to identify use cases, threat agents, attack vectors, and patterns, design patterns, and compensating controls needed to mitigate risk.\n\nOrganizations that apply systems security and privacy engineering concepts and principles can facilitate the development of trustworthy, secure systems, system components, and system services; reduce risk to acceptable levels; and make informed risk management decisions. System security engineering principles can also be used to protect against certain supply chain risks, including incorporating tamper-resistant hardware into a design.",
          "Risk assessment. Policy and procedures. A. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]: 1. [Selection (one or more): organization level; mission/business process-level; system-level] risk assessment policy that: (a) addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance; and (b) is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines; and 2. procedures to facilitate the implementation of the risk assessment policy and the associated risk assessment controls; \n\nB. Designate an [assignment: organization-defined official] to manage the development, documentation, and dissemination of the risk assessment policy and procedures; and \n\nC. Review and update the current risk assessment: 1. policy [assignment: organization-defined frequency] and following [assignment: organization-defined events]; and 2. procedures [assignment: organization-defined frequency] and following [assignment: organization-defined events].\n\nRisk assessment policy and procedures address the controls in the RA family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of risk assessment policy and procedures. Security and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies reflecting the complex nature of organizations. Procedures can be established for security and privacy programs, for mission or business processes, and for systems, if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents. Events that may precipitate an update to risk assessment policy and procedures include assessment or audit findings, security incidents or breaches, or changes in laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Configuration management. Least functionality. a. Configure the system to provide only [assignment: organization-defined mission essential capabilities]. \nb. Prohibit or restrict the use of the following functions, ports, protocols, software, and/or services: [assignment: organization-defined prohibited or restricted functions, system ports, protocols, software, and/or services].\n\nSystems provide a wide variety of functions and services. Some of the functions and services routinely provided by default may not be necessary to support essential organizational missions, functions, or operations. Additionally, it is sometimes convenient to provide multiple services from a single system component, but doing so increases risk over limiting the services provided by that single component.\n\nWhere feasible, organizations limit component functionality to a single function per component. Organizations consider removing unused or unnecessary software and disabling unused or unnecessary physical and logical ports and protocols to prevent unauthorized connection of components, transfer of information, and tunneling. Organizations employ network scanning tools, intrusion detection and prevention systems, and end-point protection technologies, such as firewalls and host-based intrusion detection systems, to identify and prevent the use of prohibited functions, protocols, ports, and services.\n\nLeast functionality can also be achieved as part of the fundamental design and development of the system (see SA-8, SC-2, and SC-3).",
          "Access control. Publicly accessible content. A. Designate individuals authorized to make information publicly accessible.\nB. Train authorized individuals to ensure that publicly accessible information does not contain nonpublic information.\nC. Review the proposed content of information prior to posting onto the publicly accessible system to ensure that nonpublic information is not included.\nD. Review the content on the publicly accessible system for nonpublic information [assignment: organization-defined frequency] and remove such information, if discovered.\n\nIn accordance with applicable laws, executive orders, directives, policies, regulations, standards, and guidelines, the public is not authorized to have access to nonpublic information, including information protected under the privacy and proprietary information. \n\nPublicly accessible content addresses systems that are controlled by the organization and accessible to the public, typically without identification or authentication. Posting information on non-organizational systems (e.g., non-organizational public websites, forums, and social media) is covered by organizational policy. \n\nWhile organizations may have individuals who are responsible for developing and implementing policies about the information that can be made publicly accessible, publicly accessible content addresses the management of the individuals who make such information publicly accessible.",
          "Maintenance. Maintenance personnel | individuals without appropriate access. (a) Implement procedures for the use of maintenance personnel that lack appropriate security clearances or are not U.S. citizens, that include the following requirements: \n\n(1) Maintenance personnel who do not have needed access authorizations, clearances, or formal access approvals are escorted and supervised during the performance of maintenance and diagnostic activities on the system by approved organizational personnel who are fully cleared, have appropriate access authorizations, and are technically qualified.\n\n(2) Prior to initiating maintenance or diagnostic activities by personnel who do not have needed access authorizations, clearances, or formal access approvals, all volatile information storage components within the system are sanitized and all nonvolatile storage media are removed or physically disconnected from the system and secured.\n\n(b) Develop and implement [assignment: organization-defined alternate controls] in the event a system component cannot be sanitized, removed, or disconnected from the system. \n\nProcedures for individuals who lack appropriate security clearances or who are not U.S. citizens are intended to deny visual and electronic access to classified or controlled unclassified information contained on organizational systems. \n\nProcedures for the use of maintenance personnel can be documented in security plans for the systems.",
          "Security assessment and authorization. Control assessments | independent assessors. Employ independent assessors or assessment teams to conduct control assessments. Independent assessors or assessment teams are individuals or groups who conduct impartial assessments of systems. Impartiality means that assessors are free from any perceived or actual conflicts of interest regarding the development, operation, sustainment, or management of the systems under assessment or the determination of control effectiveness. To achieve impartiality, assessors do not create a mutual or conflicting interest with the organizations where the assessments are being conducted, assess their own work, act as management or employees of the organizations they are serving, or place themselves in positions of advocacy for the organizations acquiring their services.\n\nIndependent assessments can be obtained from elements within organizations or be contracted to public or private sector entities outside of organizations. Authorizing officials determine the required level of independence based on the security categories of systems and/or the risk to organizational operations, organizational assets, or individuals. Authorizing officials also determine if the level of assessor independence provides sufficient assurance that the results are sound and can be used to make credible, risk-based decisions. Assessor independence determination includes whether contracted assessment services have sufficient independence, such as when system owners are not directly involved in contracting processes or cannot influence the impartiality of the assessors conducting the assessments.\n\nDuring the system design and development phase, having independent assessors is analogous to having independent SMEs involved in design reviews. When organizations that own the systems are small or the structures of the organizations require that assessments be conducted by individuals that are in the developmental, operational, or management chain of the system owners, independence in assessment processes can be achieved by ensuring that assessment results are carefully reviewed and analyzed by independent teams of experts to validate the completeness, accuracy, integrity, and reliability of the results. Assessments performed for purposes other than to support authorization decisions are more likely to be usable for such decisions when performed by assessors with sufficient independence, thereby reducing the need to repeat assessments.",
          "Access control. Permitted actions without identification or authentication. a. Identify [assignment: organization-defined user actions] that can be performed on the system without identification or authentication consistent with organizational mission and business functions. \nB. Document and provide supporting rationale in the security plan for the system, user actions not requiring identification or authentication. \nSpecific user actions may be permitted without identification or authentication if organizations determine that identification and authentication are not required for the specified user actions. \nOrganizations may allow a limited number of user actions without identification or authentication, including when individuals access public websites or other publicly accessible federal systems, when individuals use mobile phones to receive calls, or when facsimiles are received. \nOrganizations identify actions that normally require identification or authentication but may, under certain circumstances, allow identification or authentication mechanisms to be bypassed. \nSuch bypasses may occur, for example, via a software-readable physical switch that commands bypass of the login functionality and is protected from accidental or unmonitored use. \nPermitting actions without identification or authentication does not apply to situations where identification and authentication have already occurred and are not repeated, but rather to situations where identification and authentication have not yet occurred. \nOrganizations may decide that there are no user actions that can be performed on organizational systems without identification and authentication, and therefore, the value for the assignment operation can be none.",
          "Incident response. Incident response training. a. Provide incident response training to system users consistent with assigned roles and responsibilities:\n\n1. Within [assignment: organization-defined time period] of assuming an incident response role or responsibility or acquiring system access.\n2. When required by system changes.\n3. [Assignment: organization-defined frequency] thereafter.\n\nb. Review and update incident response training content [assignment: organization-defined frequency] and following [assignment: organization-defined events].\n\nIncident response training is associated with the assigned roles and responsibilities of organizational personnel to ensure that the appropriate content and level of detail are included in such training. For example, users may only need to know who to call or how to recognize an incident; system administrators may require additional training on how to handle incidents; and incident responders may receive more specific training on forensics, data collection techniques, reporting, system recovery, and system restoration. Incident response training includes user training in identifying and reporting suspicious activities from external and internal sources. Incident response training for users may be provided as part of AT-2 or AT-3.\n\nEvents that may precipitate an update to incident response training content include, but are not limited to, incident response plan testing or response to an actual incident (lessons learned), assessment or audit findings, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines.",
          "Identification and authentication. Authenticator management | public key-based authentication. (a) For public key-based authentication: (1) Enforce authorized access to the corresponding private key. (2) Map the authenticated identity to the account of the individual or group. (b) When Public Key Infrastructure (PKI) is used: (1) Validate certificates by constructing and verifying a certification path to an accepted trust anchor, including checking certificate status information. (2) Implement a local cache of revocation data to support path discovery and validation. Public key cryptography is a valid authentication mechanism for individuals, machines, and devices. For PKI solutions, status information for certification paths includes certificate revocation lists or certificate status protocol responses. For PIV cards, certificate validation involves the construction and verification of a certification path to the Common Policy root trust anchor, which includes certificate policy processing. Implementing a local cache of revocation data to support path discovery and validation also supports system availability in situations where organizations are unable to access revocation information via the network.",
          "Audit and accountability. Response to audit logging process failures. a. Alert (assignment: organization-defined personnel or roles) within (assignment: organization-defined time period) in the event of an audit logging process failure. B. Take the following additional actions: (assignment: organization-defined additional actions). Audit logging process failures include software and hardware errors, failures in audit log capturing mechanisms, and reaching or exceeding audit log storage capacity. Organization-defined actions include overwriting the oldest audit records, shutting down the system, and stopping the generation of audit records. Organizations may choose to define additional actions for audit logging process failures based on the type of failure, the location of the failure, the severity of the failure, or a combination of such factors. When the audit logging process failure is related to storage, the response is carried out for the audit log storage repository (i.e., the distinct system component where the audit logs are stored), the system on which the audit logs reside, the total audit log storage capacity of the organization (i.e., all audit log storage repositories combined), or all three. Organizations may decide to take no additional actions after alerting designated roles or personnel.",
          "System and communications protection. Denial-of-service protection. a. [Selection: Protect against; Limit] the effects of the following types of denial-of-service events: [Assignment: Organization-defined types of denial-of-service events]. \nb. Employ the following controls to achieve the denial-of-service objective: [Assignment: Organization-defined controls by type of denial-of-service event]. \n\nDenial-of-service events may occur due to a variety of internal and external causes, such as an attack by an adversary or a lack of planning to support organizational needs with respect to capacity and bandwidth. Such attacks can occur across a wide range of network protocols (e.g., IPv4, IPv6). \n\nA variety of technologies are available to limit or eliminate the origination and effects of denial-of-service events. For example, boundary protection devices can filter certain types of packets to protect system components on internal networks from being directly affected by or the source of denial-of-service attacks. Employing increased network capacity and bandwidth, combined with service redundancy, also reduces the susceptibility to denial-of-service events.",
          "System and communications protection. Protection of information at rest. Protect the confidentiality and integrity of the following information at rest: Organization-defined information at rest. Information at rest refers to the state of information when it is not in process or in transit and is located on system components. Such components include internal or external hard disk drives, storage area network devices, or databases. However, the focus of protecting information at rest is not on the type of storage device or frequency of access but rather on the state of the information. Information at rest addresses the confidentiality and integrity of information and covers user information and system information.\n\nSystem-related information that requires protection includes configurations or rule sets for firewalls, intrusion detection and prevention systems, filtering routers, and authentication information. Organizations may employ different mechanisms to achieve confidentiality and integrity protections, including the use of cryptographic mechanisms and file share scanning. Integrity protection can be achieved, for example, by implementing write-once-read-many (WORM) technologies. When adequate protection of information at rest cannot otherwise be achieved, organizations may employ other controls, including frequent scanning to identify malicious code at rest and secure offline storage in lieu of online storage.",
          "Planning. Policy and procedures. A. Develop, document, and disseminate to organization-defined personnel or roles: 1. Organization level planning policy that addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance. The policy should be consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. 2. Procedures to facilitate the implementation of the planning policy and the associated planning controls. \n\nB. Designate an organization-defined official to manage the development, documentation, and dissemination of the planning policy and procedures. \n\nC. Review and update the current planning: 1. Policy organization-defined frequency and following organization-defined events. 2. Procedures organization-defined frequency and following organization-defined events. \n\nPlanning policy and procedures are essential for the controls in the PL family implemented within systems and organizations. The risk management strategy plays a crucial role in establishing such policies and procedures. Security and privacy programs should collaborate on their development as they contribute to security and privacy assurance. Preferably, security and privacy program policies and procedures should be established at the organization level, which may eliminate the need for mission level or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or represented by multiple policies that reflect the complex nature of organizations. Procedures can be established for security and privacy programs, mission/business processes, and systems, if necessary. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents. Events that may require an update to planning policy and procedures include, but are not limited to, assessment or audit findings, security incidents or breaches, or changes in laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "System and communications protection. Boundary protection | split tunneling for remote devices. Prevent split tunneling for remote devices connecting to organizational systems, unless the split tunnel is securely provisioned using [assignment: organization-defined safeguards.]. Split tunneling is the process of allowing a remote user or device to establish a non-remote connection with a system and simultaneously communicate via some other connection to a resource in an external network. This method of network access enables a user to access remote devices and simultaneously access uncontrolled networks. Split tunneling might be desirable for remote users to communicate with local system resources, such as printers or file servers. However, split tunneling can facilitate unauthorized external connections, making the system vulnerable to attack and the exfiltration of organizational information. Split tunneling can be prevented by disabling configuration settings that allow such capability in remote devices and by preventing those configuration settings from being configurable by users. Prevention can also be achieved by detecting split tunneling (or configuration settings that allow split tunneling) in the remote device and prohibiting the connection if the remote device is using split tunneling. A Virtual Private Network (VPN) can be used to securely provision a split tunnel. A securely provisioned VPN includes locking connectivity to exclusive, managed, and named environments or to a specific set of pre-approved addresses without user control.",
          "System and services acquisition. External system services. a. Require that providers of external system services comply with organizational security and privacy requirements and employ the following controls: [assignment: organization-defined controls]. \nb. Define and document organizational oversight and user roles and responsibilities with regard to external system services. \nc. Employ the following processes, methods, and techniques to monitor control compliance by external service providers on an ongoing basis: [assignment: organization-defined processes, methods, and techniques]. \n\nExternal system services are provided by an external provider, and the organization has no direct control over the implementation of the required controls or the assessment of control effectiveness. Organizations establish relationships with external service providers in a variety of ways, including through business partnerships, contracts, interagency agreements, lines of business arrangements, licensing agreements, joint ventures, and supply chain exchanges. \n\nThe responsibility for managing risks from the use of external system services remains with authorizing officials. For services external to organizations, a chain of trust requires that organizations establish and retain a certain level of confidence that each provider in the consumer-provider relationship provides adequate protection for the services rendered. The extent and nature of this chain of trust vary based on relationships between organizations and the external providers. Organizations document the basis for the trust relationships so that the relationships can be monitored. \n\nExternal system services documentation includes government, service providers, end user security roles and responsibilities, and service-level agreements. Service-level agreements define the expectations of performance for implemented controls, describe measurable outcomes, and identify remedies and response requirements for identified instances of noncompliance.",
          "Identification and authentication. Authenticator management. Manage system authenticators by:\n\na. Verifying, as part of the initial authenticator distribution, the identity of the individual, group, role, service, or device receiving the authenticator.\n\nb. Establishing initial authenticator content for any authenticators issued by the organization.\n\nc. Ensuring that authenticators have sufficient strength of mechanism for their intended use.\n\nd. Establishing and implementing administrative procedures for initial authenticator distribution, for lost or compromised or damaged authenticators, and for revoking authenticators.\n\ne. Changing default authenticators prior to first use.\n\nf. Changing or refreshing authenticators [assignment: organization-defined time period by authenticator type] or when [assignment: organization-defined events] occur.\n\ng. Protecting authenticator content from unauthorized disclosure and modification.\n\nh. Requiring individuals to take, and having devices implement, specific controls to protect authenticators.\n\ni. Changing authenticators for group or role accounts when membership to those accounts changes.\n\nAuthenticators include passwords, cryptographic devices, biometrics, certificates, one-time password devices, and ID badges. Device authenticators include certificates and passwords.\n\nInitial authenticator content is the actual content of the authenticator (e.g., the initial password). In contrast, the requirements for authenticator content contain specific criteria or characteristics (e.g., minimum password length).\n\nDevelopers may deliver system components with factory default authentication credentials (i.e., passwords) to allow for initial installation and configuration. Default authentication credentials are often well-known, easily discoverable, and present a significant risk.\n\nThe requirement to protect individual authenticators may be implemented via control PL-4 or PS-6 for authenticators in the possession of individuals and by controls AC-3, AC-6, and SC-28 for authenticators stored in organizational systems, including passwords stored in hashed or encrypted formats or files containing encrypted or hashed passwords accessible with administrator privileges.\n\nSystems support authenticator management by organization-defined settings and restrictions for various authenticator characteristics (e.g., minimum password length, validation time window for time synchronous one-time tokens, and number of allowed rejections during the verification stage of biometric authentication).\n\nActions can be taken to safeguard individual authenticators, including maintaining possession of authenticators, not sharing authenticators with others, and immediately reporting lost, stolen, or compromised authenticators.\n\nAuthenticator management includes issuing and revoking authenticators for temporary access when no longer needed.",
          "Access control. Account management. a. Define and document the types of accounts allowed and specifically prohibited for use within the system. \nb. Assign account managers. \nc. Require [assignment: organization-defined prerequisites and criteria] for group and role membership. \nd. Specify: 1. Authorized users of the system. 2. Group and role membership. 3. Access authorizations (i.e., privileges) and [assignment: organization-defined attributes (as required)] for each account. \ne. Require approvals by [assignment: organization-defined personnel or roles] for requests to create accounts. \nf. Create, enable, modify, disable, and remove accounts in accordance with [assignment: organization-defined policy, procedures, prerequisites, and criteria]. \ng. Monitor the use of accounts. \nh. Notify account managers and [assignment: organization-defined personnel or roles] within: 1. [assignment: organization-defined time period] when accounts are no longer required. 2. [assignment: organization-defined time period] when users are terminated or transferred. 3. [assignment: organization-defined time period] when system usage or need-to-know changes for an individual. \ni. Authorize access to the system based on: 1. A valid access authorization. 2. Intended system usage. 3. [assignment: organization-defined attributes (as required)]. \nj. Review accounts for compliance with account management requirements [assignment: organization-defined frequency]. \nk. Establish and implement a process for changing shared or group account authenticators (if deployed) when individuals are removed from the group. \nl. Align account management processes with personnel termination and transfer processes. \n\nExamples of system account types include individual, shared, group, system, guest, anonymous, emergency, developer, temporary, and service. Identification of authorized system users and the specification of access privileges reflect the requirements in other controls in the security plan. Users requiring administrative privileges on system accounts receive additional scrutiny by organizational personnel responsible for approving such accounts and privileged access, including system owner, mission or business owner, senior agency information security officer, or senior agency official for privacy. \n\nTypes of accounts that organizations may wish to prohibit due to increased risk include shared, group, emergency, anonymous, temporary, and guest accounts. Where access involves personally identifiable information, security programs collaborate with the senior agency official for privacy to establish the specific conditions for group and role membership, specify authorized users, group and role membership, and access authorizations for each account, and create, adjust, or remove system accounts in accordance with organizational policies. Policies can include such information as account expiration dates or other factors that trigger the disabling of accounts. Organizations may choose to define access privileges or other attributes by account, type of account, or a combination of the two. Examples of other attributes required for authorizing access include restrictions on time of day, day of week, and point of origin. In defining other system account attributes, organizations consider system-related requirements and mission/business requirements. Failure to consider these factors could affect system availability. \n\nTemporary and emergency accounts are intended for short-term use. Organizations establish temporary accounts as part of normal account activation procedures when there is a need for short-term accounts without the demand for immediacy in account activation. Organizations establish emergency accounts in response to crisis situations and with the need for rapid account activation. Therefore, emergency account activation may bypass normal account authorization processes. Emergency and temporary accounts are not to be confused with infrequently used accounts, including local logon accounts used for special tasks or when network resources are unavailable (may also be known as accounts of last resort). Such accounts remain available and are not subject to automatic disabling or removal dates. Conditions for disabling or deactivating accounts include when shared/group, emergency, or temporary accounts are no longer required and when individuals are transferred or terminated. Changing shared/group authenticators when members leave the group is intended to ensure that former group members do not retain access to the shared or group account. Some types of system accounts may require specialized training.",
          "Media protection. Media storage. A. Physically control and securely store [assignment: organization-defined types of digital and/or non-digital media] within [assignment: organization-defined controlled areas]. \nB. Protect system media types defined in MP-4A until the media are destroyed or sanitized using approved equipment, techniques, and procedures. System media includes digital and non-digital media. Digital media includes flash drives, diskettes, magnetic tapes, external or removable hard disk drives (e.g., solid state, magnetic), compact discs, and digital versatile discs. Non-digital media includes paper and microfilm. \nPhysically controlling stored media includes conducting inventories, ensuring procedures are in place to allow individuals to check out and return media to the library, and maintaining accountability for stored media. \nSecure storage includes a locked drawer, desk, or cabinet or a controlled media library. The type of media storage is commensurate with the security category or classification of the information on the media. \nControlled areas are spaces that provide physical and procedural controls to meet the requirements established for protecting information and systems. Fewer controls may be needed for media that contains information determined to be in the public domain, publicly releasable, or have limited adverse impacts on organizations, operations, or individuals if accessed by other than authorized personnel. In these situations, physical access controls provide adequate protection.",
          "Configuration management. Least functionality | authorized software — allow-by-exception. (a) Identify [assignment: organization-defined software programs authorized to execute on the system]. \n(b) Employ a deny-all, permit-by-exception policy to allow the execution of authorized software programs on the system. \n(c) Review and update the list of authorized software programs [assignment: organization-defined frequency]. Authorized software programs can be limited to specific versions or from a specific source. \nTo facilitate a comprehensive authorized software process and increase the strength of protection for attacks that bypass application-level authorized software, software programs may be decomposed into and monitored at different levels of detail. These levels include applications, application programming interfaces, application modules, scripts, system processes, system services, kernel functions, registries, drivers, and dynamic link libraries. \nThe concept of permitting the execution of authorized software may also be applied to user actions, system ports and protocols, IP addresses/ranges, websites, and MAC addresses. Organizations consider verifying the integrity of authorized software programs using digital signatures, cryptographic checksums, or hash functions. Verification of authorized software can occur either prior to execution or at system startup. The identification of authorized URLs for websites is addressed in CA-3 (5) and SC-7.",
          "Incident response. Incident handling | integrated incident response team. Establish and maintain an integrated incident response team that can be deployed to any location identified by the organization in [assignment: organization-defined time period]. An integrated incident response team is a team of experts that assesses, documents, and responds to incidents so that organizational systems and networks can recover quickly and implement the necessary controls to avoid future incidents. Incident response team personnel include forensic and malicious code analysts, tool developers, systems security and privacy engineers, and real-time operations personnel. The incident handling capability includes performing rapid forensic preservation of evidence and analysis of and response to intrusions. For some organizations, the incident response team can be a cross-organizational entity. \n\nAn integrated incident response team facilitates information sharing and allows organizational personnel (e.g., developers, implementers, and operators) to leverage team knowledge of the threat and implement defensive measures that enable organizations to deter intrusions more effectively. Moreover, integrated teams promote the rapid detection of intrusions, the development of appropriate mitigations, and the deployment of effective defensive measures. \n\nFor example, when an intrusion is detected, the integrated team can rapidly develop an appropriate response for operators to implement, correlate the new incident with information on past intrusions, and augment ongoing cyber intelligence development. Integrated incident response teams are better able to identify adversary tactics, techniques, and procedures that are linked to the operations tempo or specific mission and business functions and to define responsive actions in a way that does not disrupt those mission and business functions. Incident response teams can be distributed within organizations to make the capability resilient.",
          "Supply chain risk management family. Supply chain risk management plan. A. Develop a plan for managing supply chain risks associated with the research and development, design, manufacturing, acquisition, delivery, integration, operations and maintenance, and disposal of the following systems, system components, or system services: [assignment: organization-defined systems, system components, or system services]. \nB. Review and update the supply chain risk management plan [assignment: organization-defined frequency] or as required, to address threat, organizational, or environmental changes. \nC. Protect the supply chain risk management plan from unauthorized disclosure and modification. \n\nThe dependence on products, systems, and services from external providers, as well as the nature of the relationships with those providers, present an increasing level of risk to an organization. Threat actions that may increase security or privacy risks include unauthorized production, the insertion or use of counterfeits, tampering, theft, insertion of malicious software and hardware, and poor manufacturing and development practices in the supply chain. Supply chain risks can be endemic or systemic within a system element or component, a system, an organization, a sector, or the nation. \n\nManaging supply chain risk is a complex, multifaceted undertaking that requires a coordinated effort across an organization to build trust relationships and communicate with internal and external stakeholders. Supply chain risk management (SCRM) activities include identifying and assessing risks, determining appropriate risk response actions, developing SCRM plans to document response actions, and monitoring performance against plans. \n\nThe SCRM plan (at the system-level) is implementation-specific, providing policy implementation, requirements, constraints, and implications. It can either be stand-alone or incorporated into system security and privacy plans. The SCRM plan addresses managing, implementation, and monitoring of SCRM controls and the development/sustainment of systems across the SDLC to support mission and business functions. \n\nBecause supply chains can differ significantly across and within organizations, SCRM plans are tailored to the individual program, organizational, and operational contexts. Tailored SCRM plans provide the basis for determining whether a technology, service, system component, or system is fit for purpose, and as such, the controls need to be tailored accordingly. Tailored SCRM plans help organizations focus their resources on the most critical mission and business functions based on mission and business requirements and their risk environment. \n\nSupply chain risk management plans include an expression of the supply chain risk tolerance for the organization, acceptable supply chain risk mitigation strategies or controls, a process for consistently evaluating and monitoring supply chain risk, approaches for implementing and communicating the plan, a description of and justification for supply chain risk mitigation measures taken, and associated roles and responsibilities. Finally, supply chain risk management plans address requirements for developing trustworthy, secure, privacy-protective, and resilient system components and systems, including the application of the security design principles implemented as part of life cycle-based systems security engineering processes (see SA-8).",
          "Maintenance. Policy and procedures. A. Develop, document, and disseminate to organization-defined personnel or roles:\n\n1. Organization-level maintenance policy that addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance. The policy should be consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines.\n\n2. Procedures to facilitate the implementation of the maintenance policy and the associated maintenance controls.\n\nB. Designate an organization-defined official to manage the development, documentation, and dissemination of the maintenance policy and procedures.\n\nC. Review and update the current maintenance:\n\n1. Policy organization-defined frequency and following organization-defined events.\n\n2. Procedures organization-defined frequency and following organization-defined events.\n\nMaintenance policy and procedures address the controls in the MA family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of maintenance policy and procedures.\n\nSecurity and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations. Procedures can be established for security and privacy programs, for mission or business processes, and for systems if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents.\n\nEvents that may precipitate an update to maintenance policy and procedures include assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Planning. Baseline selection. Select a control baseline for the system. Control baselines are predefined sets of controls specifically assembled to address the protection needs of a group, organization, or community of interest. Controls are chosen for baselines to either satisfy mandates imposed by laws, executive orders, directives, regulations, policies, standards, and guidelines or address threats common to all users of the baseline under the assumptions specific to the baseline. Baselines represent a starting point for the protection of individuals' privacy, information, and information systems with subsequent tailoring actions to manage risk in accordance with mission, business, or other constraints (see PL-11). Federal control baselines are provided in SP 800-53b. The selection of a control baseline is determined by the needs of stakeholders. Stakeholder needs consider mission and business requirements as well as mandates imposed by applicable laws, executive orders, directives, policies, regulations, standards, and guidelines. For example, the control baselines in SP 800-53b are based on the requirements from FISMA and privacy. The requirements, along with the NIST standards and guidelines implementing the legislation, direct organizations to select one of the control baselines after reviewing the information types and the information that is processed, stored, and transmitted on the system; analyzing the potential adverse impact of the loss or compromise of the information or system on the organization's operations and assets, individuals, other organizations, or the nation; and considering the results from system and organizational risk assessments. CNSSI 1253 provides guidance on control baselines for national security systems.",
          "System and communications protection. Boundary protection. a. Monitor and control communications at the external managed interfaces to the system and at key internal managed interfaces within the system. \nb. Implement subnetworks for publicly accessible system components that are physically or logically separated from internal organizational networks. \nc. Connect to external networks or systems only through managed interfaces consisting of boundary protection devices arranged in accordance with an organizational security and privacy architecture. Managed interfaces include gateways, routers, firewalls, guards, network-based malicious code analysis, virtualization systems, or encrypted tunnels implemented within a security architecture. \nSubnetworks that are physically or logically separated from internal networks are referred to as demilitarized zones or DMZs. \nRestricting or prohibiting interfaces within organizational systems includes restricting external web traffic to designated web servers within managed interfaces, prohibiting external traffic that appears to be spoofing internal addresses, and prohibiting internal traffic that appears to be spoofing external addresses. \nSP 800-189 provides additional information on source address validation techniques to prevent ingress and egress of traffic with spoofed addresses. \nCommercial telecommunications services are provided by network components and consolidated management systems shared by customers. These services may also include third party-provided access lines and other service elements. \nSuch services may represent sources of increased risk despite contract security provisions. \nBoundary protection may be implemented as a common control for all or part of an organizational network, such that the boundary to be protected is greater than a system-specific boundary (i.e., an authorization boundary).",
          "Planning. System security and privacy plans. a. Develop security and privacy plans for the system that: \n1. Are consistent with the organization's enterprise architecture.\n2. Explicitly define the constituent system components.\n3. Describe the operational context of the system in terms of mission and business processes.\n4. Identify the individuals that fulfill system roles and responsibilities.\n5. Identify the information types processed, stored, and transmitted by the system.\n6. Provide the security categorization of the system, including supporting rationale.\n7. Describe any specific threats to the system that are of concern to the organization.\n8. Provide the results of a privacy risk assessment for systems processing personally identifiable information.\n9. Describe the operational environment for the system and any dependencies on or connections to other systems or system components.\n10. Provide an overview of the security and privacy requirements for the system.\n11. Identify any relevant control baselines or overlays, if applicable.\n12. Describe the controls in place or planned for meeting the security and privacy requirements, including a rationale for any tailoring decisions.\n13. Include risk determinations for security and privacy architecture and design decisions.\n14. Include security- and privacy-related activities affecting the system that require planning and coordination with [assignment: organization-defined individuals or groups].\n15. Are reviewed and approved by the authorizing official or designated representative prior to plan implementation.\n\nb. Distribute copies of the plans and communicate subsequent changes to the plans to [assignment: organization-defined personnel or roles].\nc. Review the plans [assignment: organization-defined frequency].\nd. Update the plans to address changes to the system and environment of operation or problems identified during plan implementation or control assessments.\ne. Protect the plans from unauthorized disclosure and modification.\n\nSystem security and privacy plans are scoped to the system and system components within the defined authorization boundary and contain an overview of the security and privacy requirements for the system and the controls selected to satisfy the requirements. The plans describe the intended application of each selected control in the context of the system with a sufficient level of detail to correctly implement the control and to subsequently assess the effectiveness of the control. The control documentation describes how system-specific and hybrid controls are implemented and the plans and expectations regarding the functionality of the system. System security and privacy plans can also be used in the design and development of systems in support of life cycle-based security and privacy engineering processes. System security and privacy plans are living documents that are updated and adapted throughout the system development life cycle (e.g., during capability determination, analysis of alternatives, requests for proposal, and design reviews). \n\nSection 2.1 describes the different types of requirements that are relevant to organizations during the system development life cycle and the relationship between requirements and controls. Organizations may develop a single, integrated security and privacy plan or maintain separate plans. Security and privacy plans relate security and privacy requirements to a set of controls and control enhancements. The plans describe how the controls and control enhancements meet the security and privacy requirements but do not provide detailed, technical descriptions of the design or implementation of the controls and control enhancements. Security and privacy plans contain sufficient information (including specifications of control parameter values for selection and assignment operations explicitly or by reference) to enable a design and implementation that is unambiguously compliant with the intent of the plans and subsequent determinations of risk to organizational operations and assets, individuals, other organizations, and the nation if the plan is implemented. Security and privacy plans need not be single documents. The plans can be a collection of various documents, including documents that already exist. Effective security and privacy plans make extensive use of references to policies, procedures, and additional documents, including design and implementation specifications where more detailed information can be obtained. The use of references helps reduce the documentation associated with security and privacy programs and maintains the security- and privacy-related information in other established management and operational areas, including enterprise architecture, system development life cycle, systems engineering, and acquisition. Security and privacy plans need not contain detailed contingency plan or incident response plan information but can instead provide—explicitly or by reference—sufficient information to define what needs to be accomplished by those plans. Security- and privacy-related activities that may require coordination and planning with other individuals or groups within the organization include assessments, audits, inspections, hardware and software maintenance, acquisition and supply chain risk management, patch management, and contingency plan testing. Planning and coordination include emergency and nonemergency (i.e., planned or non-urgent unplanned) situations. The process defined by organizations to plan and coordinate security- and privacy-related activities can also be included in other documents, as appropriate.",
          "Contingency planning. Alternate processing site. a. Establish an alternate processing site, including necessary agreements to permit the transfer and resumption of [assignment: organization-defined system operations] for essential mission and business functions within [assignment: organization-defined time period consistent with recovery time and recovery point objectives], when the primary processing capabilities are unavailable. \nb. Make available at the alternate processing site, the equipment and supplies required to transfer and resume operations or put contracts in place to support delivery to the site within the organization-defined time period for transfer and resumption. \nc. Provide controls at the alternate processing site that are equivalent to those at the primary site. \n\nAlternate processing sites are geographically distinct from primary processing sites and provide processing capability if the primary processing site is not available. The alternate processing capability may be addressed using a physical processing site or other alternatives, such as failover to a cloud-based service provider or other internally or externally provided processing service. Geographically distributed architectures that support contingency requirements may also be considered alternate processing sites. \n\nControls that are covered by alternate processing site agreements include the environmental conditions at alternate sites, access rules, physical and environmental protection requirements, and the coordination for the transfer and assignment of personnel. Requirements are allocated to alternate processing sites that reflect the requirements in contingency plans to maintain essential mission and business functions despite disruption, compromise, or failure in organizational systems.",
          "Security assessment and authorization. Information exchange. a. Approve and manage the exchange of information between the system and other systems using [selection (one or more): interconnection security agreements; information exchange security agreements; memoranda of understanding or agreement; service level agreements; user agreements; nondisclosure agreements; [assignment: organization-defined type of agreement]].\n\nb. Document, as part of each exchange agreement, the interface characteristics, security and privacy requirements, controls, and responsibilities for each system, and the impact level of the information communicated.\n\nc. Review and update the agreements [assignment: organization-defined frequency].\n\nSystem information exchange requirements apply to information exchanges between two or more systems. System information exchanges include connections via leased lines or virtual private networks, connections to internet service providers, database sharing or exchanges of database transaction information, connections and exchanges with cloud services, exchanges via web-based services, or exchanges of files via file transfer protocols, network protocols (e.g., IPv4, IPv6), email, or other organization-to-organization communications.\n\nOrganizations consider the risk related to new or increased threats that may be introduced when systems exchange information with other systems that may have different security and privacy requirements and controls. This includes systems within the same organization and systems that are external to the organization.\n\nA joint authorization of the systems exchanging information, as described in CA-6 (1) or CA-6 (2), may help to communicate and reduce risk. Authorizing officials determine the risk associated with system information exchange and the controls needed for appropriate risk mitigation.\n\nThe types of agreements selected are based on factors such as the impact level of the information being exchanged, the relationship between the organizations exchanging information (e.g., government to government, government to business, business to business, government or business to service provider, government or business to individual), or the level of access to the organizational system by users of the other system.\n\nIf systems that exchange information have the same authorizing official, organizations need not develop agreements. Instead, the interface characteristics between the systems (e.g., how the information is being exchanged, how the information is protected) are described in the respective security and privacy plans.\n\nIf the systems that exchange information have different authorizing officials within the same organization, the organizations can develop agreements or provide the same information that would be provided in the appropriate agreement type from CA-3a in the respective security and privacy plans for the systems.\n\nOrganizations may incorporate agreement information into formal contracts, especially for information exchanges established between federal agencies and nonfederal organizations (including service providers, contractors, system developers, and system integrators). Risk considerations include systems that share the same networks.",
          "Configuration management. System component inventory. a. Develop and document an inventory of system components that: 1. accurately reflects the system; 2. includes all components within the system; 3. does not include duplicate accounting of components or components assigned to any other system; 4. is at the level of granularity deemed necessary for tracking and reporting; and 5. includes the following information to achieve system component accountability: [Assignment: organization-defined information deemed necessary to achieve effective system component accountability]. And b. Review and update the system component inventory [Assignment: organization-defined frequency]. \n\nSystem components are discrete, identifiable information technology assets that include hardware, software, and firmware. Organizations may choose to implement centralized system component inventories that include components from all organizational systems. In such situations, organizations ensure that the inventories include system-specific information required for component accountability. The information necessary for effective accountability of system components includes the system name, software owners, software version numbers, hardware inventory specifications, software license information, and for networked components, the machine names and network addresses across all implemented protocols (e.g., IPv4, IPv6). \n\nInventory specifications include date of receipt, cost, model, serial number, manufacturer, supplier information, component type, and physical location. Preventing duplicate accounting of system components addresses the lack of accountability that occurs when component ownership and system association is not known, especially in large or complex connected systems. Effective prevention of duplicate accounting of system components necessitates use of a unique identifier for each component. \n\nFor software inventory, centrally managed software that is accessed via other systems is addressed as a component of the system on which it is installed and managed. Software installed on multiple organizational systems and managed at the system level is addressed for each individual system and may appear more than once in a centralized component inventory, necessitating a system association for each software instance in the centralized inventory to avoid duplicate accounting of components. \n\nScanning systems implementing multiple network protocols (e.g., IPv4 and IPv6) can result in duplicate components being identified in different address spaces. The implementation of CM-8 (7) can help to eliminate duplicate accounting of components.",
          "Identification and authentication. Identification and authentication (organizational users) | multi-factor authentication to non-privileged accounts. Implement multi-factor authentication for access to non-privileged accounts. Multi-factor authentication requires the use of two or more different factors to achieve authentication. The authentication factors are defined as follows: something you know (e.g., a personal identification number [PIN]), something you have (e.g., a physical authenticator such as a cryptographic private key), or something you are (e.g., a biometric). \n\nMulti-factor authentication solutions that feature physical authenticators include hardware authenticators that provide time-based or challenge-response outputs and smart cards such as the U.S. government personal identity verification card or the DoD common access card. \n\nIn addition to authenticating users at the system level, organizations may also employ authentication mechanisms at the application level, at their discretion, to provide increased information security. Regardless of the type of access (i.e., local, network, remote), non-privileged accounts are authenticated using multi-factor options appropriate for the level of risk. \n\nOrganizations can provide additional security measures, such as additional or more rigorous authentication mechanisms, for specific types of access.",
          "Planning. Baseline tailoring. Tailor the selected control baseline by applying specified tailoring actions. The concept of tailoring allows organizations to specialize or customize a set of baseline controls by applying a defined set of tailoring actions. Tailoring actions facilitate such specialization and customization by allowing organizations to develop security and privacy plans that reflect their specific mission and business functions, the environments where their systems operate, the threats and vulnerabilities that can affect their systems, and any other conditions or situations that can impact their mission or business success. Tailoring guidance is provided in SP 800-53b. Tailoring a control baseline is accomplished by identifying and designating common controls, applying scoping considerations, selecting compensating controls, assigning values to control parameters, supplementing the control baseline with additional controls as needed, and providing information for control implementation. The general tailoring actions in SP 800-53b can be supplemented with additional actions based on the needs of organizations. Tailoring actions can be applied to the baselines in SP 800-53b in accordance with the security and privacy requirements from FISMA, privacy, and OMB A-130. Alternatively, other communities of interest adopting different control baselines can apply the tailoring actions in SP 800-53b to specialize or customize the controls that represent the specific needs and concerns of those entities.",
          "Awareness and training. Policy and procedures. a. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]: 1. [Selection (one or more): organization level; mission/business process-level; system-level] awareness and training policy that: (a) addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance; and (b) is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines; and 2. Procedures to facilitate the implementation of the awareness and training policy and the associated awareness and training controls. \nb. Designate an [assignment: organization-defined official] to manage the development, documentation, and dissemination of the awareness and training policy and procedures. \nc. Review and update the current awareness and training: 1. Policy [assignment: organization-defined frequency] and following [assignment: organization-defined events]; and 2. Procedures [assignment: organization-defined frequency] and following [assignment: organization-defined events].\nAwareness and training policy and procedures address the controls in the AT family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of awareness and training policy and procedures. Security and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations. Procedures can be established for security and privacy programs, for mission or business processes, and for systems, if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents. Events that may precipitate an update to awareness and training policy and procedures include assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Contingency planning. Contingency plan. A. Develop a contingency plan for the system that:\n1. Identifies essential mission and business functions and associated contingency requirements.\n2. Provides recovery objectives, restoration priorities, and metrics.\n3. Addresses contingency roles, responsibilities, assigned individuals with contact information.\n4. Addresses maintaining essential mission and business functions despite a system disruption, compromise, or failure.\n5. Addresses eventual, full system restoration without deterioration of the controls originally planned and implemented.\n6. Addresses the sharing of contingency information.\n7. Is reviewed and approved by [Assignment: organization-defined personnel or roles].\n\nB. Distribute copies of the contingency plan to [Assignment: organization-defined key contingency personnel (identified by name and/or by role) and organizational elements].\n\nC. Coordinate contingency planning activities with incident handling activities.\n\nD. Review the contingency plan for the system [Assignment: organization-defined frequency].\n\nE. Update the contingency plan to address changes to the organization, system, or environment of operation and problems encountered during contingency plan implementation, execution, or testing.\n\nF. Communicate contingency plan changes to [Assignment: organization-defined key contingency personnel (identified by name and/or by role) and organizational elements].\n\nG. Incorporate lessons learned from contingency plan testing, training, or actual contingency activities into contingency testing and training.\n\nH. Protect the contingency plan from unauthorized disclosure and modification.\n\nContingency planning for systems is part of an overall program for achieving continuity of operations for organizational mission and business functions. Contingency planning addresses system restoration and implementation of alternative mission or business processes when systems are compromised or breached. Contingency planning is considered throughout the system development life cycle and is a fundamental part of the system design. Systems can be designed for redundancy, to provide backup capabilities, and for resilience. \n\nContingency plans reflect the degree of restoration required for organizational systems since not all systems need to fully recover to achieve the level of continuity of operations desired. System recovery objectives reflect applicable laws, executive orders, directives, regulations, policies, standards, guidelines, organizational risk tolerance, and system impact level. Actions addressed in contingency plans include orderly system degradation, system shutdown, fallback to a manual mode, alternate information flows, and operating in modes reserved for when systems are under attack. \n\nBy coordinating contingency planning with incident handling activities, organizations ensure that the necessary planning activities are in place and activated in the event of an incident. Organizations consider whether continuity of operations during an incident conflicts with the capability to automatically disable the system, as specified in IR-4 (5). Incident response planning is part of contingency planning for organizations and is addressed in the IR (incident response) family.",
          "Supply chain risk management family. Supply chain controls and processes. a. Establish a process or processes to identify and address weaknesses or deficiencies in the supply chain elements and processes of [assignment: organization-defined system or system component] in coordination with [assignment: organization-defined supply chain personnel]. \nB. Employ the following controls to protect against supply chain risks to the system, system component, or system service and to limit the harm or consequences from supply chain-related events: [assignment: organization-defined supply chain controls]. \nC. Document the selected and implemented supply chain processes and controls in [Selection: security and privacy plans; supply chain risk management plan; [assignment: organization-defined document]]. \n\nSupply chain elements include organizations, entities, or tools employed for the research and development, design, manufacturing, acquisition, delivery, integration, operations and maintenance, and disposal of systems and system components. \nSupply chain processes include hardware, software, and firmware development processes; shipping and handling procedures; personnel security and physical security programs; configuration management tools, techniques, and measures to maintain provenance; or other programs, processes, or procedures associated with the development, acquisition, maintenance, and disposal of systems and system components. \nSupply chain elements and processes may be provided by organizations, system integrators, or external providers. \nWeaknesses or deficiencies in supply chain elements or processes represent potential vulnerabilities that can be exploited by adversaries to cause harm to the organization and affect its ability to carry out its core missions or business functions. \nSupply chain personnel are individuals with roles and responsibilities in the supply chain.",
          "Incident response. Information spillage response. Respond to information spills by:\n\na. Assigning [assignment: organization-defined personnel or roles] with responsibility for responding to information spills.\nb. Identifying the specific information involved in the system contamination.\nc. Alerting [assignment: organization-defined personnel or roles] of the information spill using a method of communication not associated with the spill.\nd. Isolating the contaminated system or system component.\ne. Eradicating the information from the contaminated system or component.\nf. Identifying other systems or system components that may have been subsequently contaminated.\ng. Performing the following additional actions: [assignment: organization-defined actions].\n\nInformation spillage refers to instances where information is placed on systems that are not authorized to process such information. Information spills occur when information that is thought to be of a certain classification or impact level is transmitted to a system and subsequently determined to be of a higher classification or impact level. At that point, corrective action is required. \n\nThe nature of the response is based on the classification or impact level of the spilled information, the security capabilities of the system, the specific nature of the contaminated storage media, and the access authorizations of individuals with authorized access to the contaminated system. \n\nThe methods used to communicate information about the spill after the fact do not involve methods directly associated with the actual spill to minimize the risk of further spreading the contamination before such contamination is isolated and eradicated.",
          "System and information integrity. Security alerts, advisories, and directives. a. Receive system security alerts, advisories, and directives from [assignment: organization-defined external organizations] on an ongoing basis. \nb. Generate internal security alerts, advisories, and directives as deemed necessary. \nc. Disseminate security alerts, advisories, and directives to: [selection (one or more): [assignment: organization-defined personnel or roles]; [assignment: organization-defined elements within the organization]; [assignment: organization-defined external organizations]]. \nd. Implement security directives in accordance with established time frames, or notify the issuing organization of the degree of noncompliance. \n\nThe Cybersecurity and Infrastructure Security Agency (CISA) generates security alerts and advisories to maintain situational awareness throughout the federal government. Security directives are issued by OMB or other designated organizations with the responsibility and authority to issue such directives. Compliance with security directives is essential due to the critical nature of many of these directives and the potential (immediate) adverse effects on organizational operations and assets, individuals, other organizations, and the nation should the directives not be implemented in a timely manner. \n\nExternal organizations include supply chain partners, external mission or business partners, external service providers, and other peer or supporting organizations.",
          "System and communications protection. Secure name/address resolution service (authoritative source). A. Provide additional data origin authentication and integrity verification artifacts along with the authoritative name resolution data the system returns in response to external name/address resolution queries. \nB. Provide the means to indicate the security status of child zones and, if the child supports secure resolution services, enable verification of a chain of trust among parent and child domains when operating as part of a distributed, hierarchical namespace. Providing authoritative source information enables external clients, including remote internet clients, to obtain origin authentication and integrity verification assurances for the host/service name to network address resolution information obtained through the service. Systems that provide name and address resolution services include Domain Name System (DNS) servers. Additional artifacts include DNS Security Extensions (DNSSEC) digital signatures and cryptographic keys. Authoritative data includes DNS resource records. The means for indicating the security status of child zones include the use of delegation signer resource records in the DNS. Systems that use technologies other than the DNS to map between host and service names and network addresses provide other means to assure the authenticity and integrity of response data.",
          "System and services acquisition. Unsupported system components. a. Replace system components when support for the components is no longer available from the developer, vendor, or manufacturer; or b. Provide the following options for alternative sources for continued support for unsupported components [selection (one or more): in-house support; [assignment: organization-defined support from external providers]]. Support for system components includes software patches, firmware updates, replacement parts, and maintenance contracts. An example of unsupported components includes when vendors no longer provide critical software patches or product updates, which can result in an opportunity for adversaries to exploit weaknesses in the installed components. Exceptions to replacing unsupported system components include systems that provide critical mission or business capabilities where newer technologies are not available or where the systems are so isolated that installing replacement components is not an option. Alternative sources for support address the need to provide continued support for system components that are no longer supported by the original manufacturers, developers, or vendors when such components remain essential to organizational mission and business functions. If necessary, organizations can establish in-house support by developing customized patches for critical software components or, alternatively, obtain the services of external providers who provide ongoing support for the designated unsupported components through contractual relationships. Such contractual relationships can include open-source software value-added vendors. The increased risk of using unsupported system components can be mitigated, for example, by prohibiting the connection of such components to public or uncontrolled networks, or implementing other forms of isolation.",
          "Identification and authentication. Policy and procedures. A. Develop, document, and disseminate to organization-defined personnel or roles: \n\n1. Organization level identification and authentication policy that addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance. The policy should be consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines.\n\n2. Procedures to facilitate the implementation of the identification and authentication policy and the associated identification and authentication controls.\n\nB. Designate an organization-defined official to manage the development, documentation, and dissemination of the identification and authentication policy and procedures.\n\nC. Review and update the current identification and authentication:\n\n1. Policy organization-defined frequency and following organization-defined events.\n\n2. Procedures organization-defined frequency and following organization-defined events.\n\nThe identification and authentication policy and procedures address the controls in the IA family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of identification and authentication policy and procedures. \n\nSecurity and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations. Procedures can be established for security and privacy programs, for mission or business processes, and for systems, if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents.\n\nEvents that may precipitate an update to identification and authentication policy and procedures include assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Physical and environmental protection. Policy and procedures. A. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]:\n\n1. [Selection (one or more): organization level; mission/business process-level; system-level] physical and environmental protection policy that:\n(a) Addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance; and\n(b) Is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines; and\n\n2. Procedures to facilitate the implementation of the physical and environmental protection policy and the associated physical and environmental protection controls;\n\nB. Designate an [assignment: organization-defined official] to manage the development, documentation, and dissemination of the physical and environmental protection policy and procedures; and\n\nC. Review and update the current physical and environmental protection:\n\n1. Policy [assignment: organization-defined frequency] and following [assignment: organization-defined events]; and\n\n2. Procedures [assignment: organization-defined frequency] and following [assignment: organization-defined events].\n\nPhysical and environmental protection policy and procedures address the controls in the PE family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of physical and environmental protection policy and procedures. Security and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations. Procedures can be established for security and privacy programs, for mission or business processes, and for systems if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents. Events that may precipitate an update to physical and environmental protection policy and procedures include assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Risk assessment. Security categorization. a. Categorize the system and information it processes, stores, and transmits.\nb. Document the security categorization results, including supporting rationale, in the security plan for the system.\nc. Verify that the authorizing official or the authorizing official designated representative reviews and approves the security categorization decision.\nSecurity categories describe the potential adverse impacts or negative consequences to organizational operations, organizational assets, and individuals if organizational information and systems are compromised through a loss of confidentiality, integrity, or availability. Security categorization is also a type of asset loss characterization in systems security engineering processes that is carried out throughout the system development life cycle. Organizations can use privacy risk assessments or privacy impact assessments to better understand the potential adverse effects on individuals. CNSSI 1253 provides additional guidance on categorization for national security systems.\nOrganizations conduct the security categorization process as an organization-wide activity with the direct involvement of Chief Information Officers, Senior Agency Information Security Officers, Senior Agency Officials for Privacy, system owners, mission and business owners, and information owners or stewards. Organizations consider the potential adverse impacts to other organizations and, in accordance with USA PATRIOT and Homeland Security Presidential Directives, potential national-level adverse impacts.\nSecurity categorization processes facilitate the development of inventories of information assets and, along with CM-8, mappings to specific system components where information is processed, stored, or transmitted. The security categorization process is revisited throughout the system development life cycle to ensure that the security categories remain accurate and relevant.",
          "Personnel security. External personnel security. a. Establish personnel security requirements, including security roles and responsibilities for external providers.\nb. Require external providers to comply with personnel security policies and procedures established by the organization.\nc. Document personnel security requirements.\nd. Require external providers to notify [assignment: organization-defined personnel or roles] of any personnel transfers or terminations of external personnel who possess organizational credentials and/or badges, or who have system privileges within [assignment: organization-defined time period].\ne. Monitor provider compliance with personnel security requirements.\n\nExternal provider refers to organizations other than the organization operating or acquiring the system. External providers include service bureaus, contractors, and other organizations that provide system development, information technology services, testing or assessment services, outsourced applications, and network/security management. Organizations explicitly include personnel security requirements in acquisition-related documents.\n\nExternal providers may have personnel working at organizational facilities with credentials, badges, or system privileges issued by organizations. Notifications of external personnel changes ensure the appropriate termination of privileges and credentials. Organizations define the transfers and terminations deemed reportable by security-related characteristics that include functions, roles, and the nature of credentials or privileges associated with transferred or terminated individuals.",
          "Security assessment and authorization. Continuous monitoring. Develop a system-level continuous monitoring strategy and implement continuous monitoring in accordance with the organization-level continuous monitoring strategy. This includes:\n\na. Establishing the following system-level metrics to be monitored: [assignment: organization-defined system-level metrics].\n\nb. Establishing [assignment: organization-defined frequencies] for monitoring and [assignment: organization-defined frequencies] for assessment of control effectiveness.\n\nc. Conducting ongoing control assessments in accordance with the continuous monitoring strategy.\n\nd. Performing ongoing monitoring of system and organization-defined metrics based on the continuous monitoring strategy.\n\ne. Correlating and analyzing information generated by control assessments and monitoring.\n\nf. Taking response actions to address results of the analysis of control assessment and monitoring information.\n\ng. Reporting the security and privacy status of the system to [assignment: organization-defined personnel or roles] [assignment: organization-defined frequency].\n\nContinuous monitoring at the system level enables ongoing awareness of the system's security and privacy posture, supporting organizational risk management decisions. The terms \"continuous\" and \"ongoing\" imply that organizations assess and monitor their controls and risks at a frequency sufficient to support risk-based decisions. Different types of controls may require different monitoring frequencies.\n\nThe results of continuous monitoring generate risk response actions by organizations. When monitoring the effectiveness of multiple controls grouped into capabilities, a root-cause analysis may be necessary to determine the specific control that has failed. Continuous monitoring programs enable organizations to maintain authorizations of systems and common controls in highly dynamic operational environments with changing mission and business needs, threats, vulnerabilities, and technologies.\n\nHaving access to security and privacy information on a continuous basis through reports and dashboards provides organizational officials with the ability to make effective and timely risk management decisions, including ongoing authorization decisions. Automation supports more frequent updates to hardware, software, and firmware inventories, authorization packages, and other system information.\n\nEffectiveness is further enhanced when continuous monitoring outputs are formatted to provide specific, measurable, actionable, relevant, and timely information.\n\nContinuous monitoring activities are scaled based on the security categories of systems. Monitoring requirements, including the need for specific monitoring, may be referenced in other controls and control enhancements, such as AC-2g, AC-2 (7), AC-2 (12) (a), AC-2 (7) (b), AC-2 (7) (c), AC-17 (1), AT-4a, AU-13, AU-13 (1), AU-13 (2), CM-3f, CM-6d, CM-11c, IR-5, MA-2b, MA-3a, MA-4a, PE-3d, PE-6, PE-14b, PE-16, PE-20, PM-6, PM-23, PM-31, PS-7e, SA-9c, SR-4, SC-5 (3) (b), SC-7a, SC-7 (24) (b), SC-18b, SC-43b, and SI-4.",
          "System and services acquisition. System development life cycle. A. Acquire, develop, and manage the system using [assignment: organization-defined system development life cycle] that incorporates information security and privacy considerations. \nB. Define and document information security and privacy roles and responsibilities throughout the system development life cycle. \nC. Identify individuals having information security and privacy roles and responsibilities. \nD. Integrate the organizational information security and privacy risk management process into system development life cycle activities. \n\nA system development life cycle process provides the foundation for the successful development, implementation, and operation of organizational systems. The integration of security and privacy considerations early in the system development life cycle is a foundational principle of systems security engineering and privacy engineering. To apply the required controls within the system development life cycle requires a basic understanding of information security and privacy, threats, vulnerabilities, adverse impacts, and risk to critical mission and business functions. The security engineering principles in SA-8 help individuals properly design, code, and test systems and system components. \n\nOrganizations include qualified personnel (e.g., senior agency information security officers, senior agency officials for privacy, security and privacy architects, and security and privacy engineers) in system development life cycle processes to ensure that established security and privacy requirements are incorporated into organizational systems. Role-based security and privacy training programs can ensure that individuals with key security and privacy roles and responsibilities have the experience, skills, and expertise to conduct assigned system development life cycle activities. The effective integration of security and privacy requirements into enterprise architecture also helps to ensure that important security and privacy considerations are addressed throughout the system life cycle and that those considerations are directly related to organizational mission and business processes. This process also facilitates the integration of the information security and privacy architectures into the enterprise architecture, consistent with the risk management strategy of the organization. \n\nBecause the system development life cycle involves multiple organizations (e.g., external suppliers, developers, integrators, service providers), acquisition and supply chain risk management functions and controls play significant roles in the effective management of the system during the life cycle.",
          "System and services acquisition. System documentation. a. Obtain or develop administrator documentation for the system, system component, or system service that describes:\n1. Secure configuration, installation, and operation of the system, component, or service.\n2. Effective use and maintenance of security and privacy functions and mechanisms.\n3. Known vulnerabilities regarding configuration and use of administrative or privileged functions.\n\nb. Obtain or develop user documentation for the system, system component, or system service that describes:\n1. User-accessible security and privacy functions and mechanisms and how to effectively use those functions and mechanisms.\n2. Methods for user interaction, which enable individuals to use the system, component, or service in a more secure manner and protect individual privacy.\n3. User responsibilities in maintaining the security of the system, component, or service and privacy of individuals.\n\nc. Document attempts to obtain system, system component, or system service documentation when such documentation is either unavailable or nonexistent and take [assignment: organization-defined actions] in response.\n\nd. Distribute documentation to [assignment: organization-defined personnel or roles]. System documentation helps personnel understand the implementation and operation of controls. Organizations consider establishing specific measures to determine the quality and completeness of the content provided. System documentation may be used to support the management of supply chain risk, incident response, and other functions.\n\nPersonnel or roles that require documentation include system owners, system security officers, and system administrators. Attempts to obtain documentation include contacting manufacturers or suppliers and conducting web-based searches. The inability to obtain documentation may occur due to the age of the system or component or the lack of support from developers and contractors. When documentation cannot be obtained, organizations may need to recreate the documentation if it is essential to the implementation or operation of the controls.\n\nThe protection provided for the documentation is commensurate with the security category or classification of the system. Documentation that addresses system vulnerabilities may require an increased level of protection. Secure operation of the system includes initially starting the system and resuming secure system operation after a lapse in system operation.",
          "Audit and accountability. Policy and procedures. A. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]:\n1. [Selection (one or more): organization level; mission/business process-level; system-level] audit and accountability policy that:\n(a) Addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance; and\n(b) Is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines; and\n2. Procedures to facilitate the implementation of the audit and accountability policy and the associated audit and accountability controls.\n\nB. Designate an [assignment: organization-defined official] to manage the development, documentation, and dissemination of the audit and accountability policy and procedures.\n\nC. Review and update the current audit and accountability:\n1. Policy [assignment: organization-defined frequency] and following [assignment: organization-defined events]; and\n2. Procedures [assignment: organization-defined frequency] and following [assignment: organization-defined events].\n\nAudit and accountability policy and procedures address the controls in the AU family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of audit and accountability policy and procedures.\n\nSecurity and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations.\n\nProcedures can be established for security and privacy programs, for mission or business processes, and for systems if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents.\n\nEvents that may precipitate an update to audit and accountability policy and procedures include assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Planning. Rules of behavior. a. Establish and provide to individuals requiring access to the system, the rules that describe their responsibilities and expected behavior for information and system usage, security, and privacy.\nb. Receive a documented acknowledgment from such individuals, indicating that they have read, understand, and agree to abide by the rules of behavior, before authorizing access to information and the system.\nc. Review and update the rules of behavior [assignment: organization-defined frequency].\nd. Require individuals who have acknowledged a previous version of the rules of behavior to read and re-acknowledge [selection (one or more): [assignment: organization-defined frequency]; when the rules are revised or updated].\n\nRules of behavior represent a type of access agreement for organizational users. Other types of access agreements include nondisclosure agreements, conflict-of-interest agreements, and acceptable use agreements (see ps-6). Organizations consider rules of behavior based on individual user roles and responsibilities and differentiate between rules that apply to privileged users and rules that apply to general users. Establishing rules of behavior for some types of non-organizational users, including individuals who receive information from federal systems, is often not feasible given the large number of such users and the limited nature of their interactions with the systems. Rules of behavior for organizational and non-organizational users can also be established in ac-8.\n\nThe related Controls section provides a list of controls that are relevant to organizational rules of behavior. PL-4b, the documented acknowledgment portion of the control, may be satisfied by the literacy training and awareness and role-based training programs conducted by organizations if such training includes rules of behavior. Documented acknowledgments for rules of behavior include electronic or physical signatures and electronic agreement check boxes or radio buttons.",
          "Access control. Information flow enforcement. Enforce approved authorizations for controlling the flow of information within the system and between connected systems based on [assignment: organization-defined information flow control policies]. Information flow control regulates where information can travel within a system and between systems (in contrast to who is allowed to access the information) and without regard to subsequent accesses to that information. Flow control restrictions include blocking external traffic that claims to be from within the organization, keeping export-controlled information from being transmitted in the clear to the internet, restricting web requests that are not from the internal web proxy server, and limiting information transfers between organizations based on data structures and content. \n\nTransferring information between organizations may require an agreement specifying how the information flow is enforced (see ca-3). Transferring information between systems in different security or privacy domains with different security or privacy policies introduces the risk that such transfers violate one or more domain security or privacy policies. In such situations, information owners/stewards provide guidance at designated policy enforcement points between connected systems. Organizations consider mandating specific architectural solutions to enforce specific security and privacy policies. Enforcement includes prohibiting information transfers between connected systems (i.e., allowing access only), verifying write permissions before accepting information from another security or privacy domain or connected system, employing hardware mechanisms to enforce one-way information flows, and implementing trustworthy regrading mechanisms to reassess security or privacy attributes and labels. Organizations commonly employ information flow control policies and enforcement mechanisms to control the flow of information between designated sources and destinations within systems and between connected systems. Flow control is based on the characteristics of the information and/or the information path. Enforcement occurs, for example, in boundary protection devices that employ rule sets or establish configuration settings that restrict system services, provide a packet-filtering capability based on header information, or provide a message-filtering capability based on message content. \n\nOrganizations also consider the trustworthiness of filtering and/or inspection mechanisms (i.e., hardware, firmware, and software components) that are critical to information flow enforcement. Control enhancements 3 through 32 primarily address cross-domain solution needs that focus on more advanced filtering techniques, in-depth analysis, and stronger flow enforcement mechanisms implemented in cross-domain products, such as high-assurance guards. Such capabilities are generally not available in commercial off-the-shelf products. Information flow enforcement also applies to control plane traffic (e.g., routing and DNS).",
          "Risk assessment. Criticality analysis. Identify critical system components and functions by performing a criticality analysis for organization-defined systems, system components, or system services at organization-defined decision points in the system development life cycle. Not all system components, functions, or services necessarily require significant protections. For example, criticality analysis is a key tenet of supply chain risk management and informs the prioritization of protection activities.\n\nThe identification of critical system components and functions considers applicable laws, executive orders, regulations, directives, policies, standards, system functionality requirements, system and component interfaces, and system and component dependencies. Systems engineers conduct a functional decomposition of a system to identify mission-critical functions and components.\n\nThe functional decomposition includes the identification of organizational missions supported by the system, decomposition into the specific functions to perform those missions, and traceability to the hardware, software, and firmware components that implement those functions, including when the functions are shared by many components within and external to the system.\n\nThe operational environment of a system or a system component may impact the criticality, including the connections to and dependencies on cyber-physical systems, devices, system-of-systems, and outsourced IT services. System components that allow unmediated access to critical system components or functions are considered critical due to the inherent vulnerabilities that such components create.\n\nComponent and function criticality are assessed in terms of the impact of a component or function failure on the organizational missions that are supported by the system that contains the components and functions. Criticality analysis is performed when an architecture or design is being developed, modified, or upgraded. If such analysis is performed early in the system development life cycle, organizations may be able to modify the system design to reduce the critical nature of these components and functions, such as by adding redundancy or alternate paths into the system design.\n\nCriticality analysis can also influence the protection measures required by development contractors. In addition to criticality analysis for systems, system components, and system services, criticality analysis of information is an important consideration. Such analysis is conducted as part of security categorization in RA-2.",
          "Configuration management. System component inventory | automated unauthorized component detection. (A) Detect the presence of unauthorized hardware, software, and firmware components within the system using [assignment: organization-defined automated mechanisms]. [Assignment: Organization-defined frequency].\n\n(B) Take the following actions when unauthorized components are detected: [Selection (one or more): disable network access by such components; isolate the components; notify [assignment: organization-defined personnel or roles]].\n\nAutomated unauthorized component detection is applied in addition to monitoring for unauthorized remote connections and mobile devices. Monitoring for unauthorized system components may be accomplished on an ongoing basis or by periodic scanning of systems for that purpose. Automated mechanisms may also be used to prevent the connection of unauthorized components (see CM-7 (9)). Automated mechanisms can be implemented in systems or in separate system components.\n\nWhen acquiring and implementing automated mechanisms, organizations consider whether such mechanisms depend on the ability of the system component to support an agent or supplicant in order to be detected since some types of components do not have or cannot support agents (e.g., IoT devices, sensors).\n\nIsolation can be achieved, for example, by placing unauthorized system components in separate domains or subnets or quarantining such components. This type of component isolation is commonly referred to as sandboxing.",
          "System and communications protection. Mobile code. a. Define acceptable and unacceptable mobile code and mobile code technologies; and b. Authorize, monitor, and control the use of mobile code within the system. Mobile code includes any program, application, or content that can be transmitted across a network (e.g., embedded in an email, document, or website) and executed on a remote system. Decisions regarding the use of mobile code within organizational systems are based on the potential for the code to cause damage to the systems if used maliciously. Mobile code technologies include Java applets, JavaScript, HTML5, WebGL, and VBScript. Usage restrictions and implementation guidelines apply to both the selection and use of mobile code installed on servers and mobile code downloaded and executed on individual workstations and devices, including notebook computers and smartphones. Mobile code policy and procedures address specific actions taken to prevent the development, acquisition, and introduction of unacceptable mobile code within organizational systems, including requiring mobile code to be digitally signed by a trusted source.",
          "Incident response. Policy and procedures. A. Develop, document, and disseminate to organization-defined personnel or roles:\n1. Organization level incident response policy that addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance. The policy should be consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines.\n2. Procedures to facilitate the implementation of the incident response policy and the associated incident response controls.\n\nB. Designate an organization-defined official to manage the development, documentation, and dissemination of the incident response policy and procedures.\n\nC. Review and update the current incident response:\n1. Policy organization-defined frequency and following organization-defined events.\n2. Procedures organization-defined frequency and following organization-defined events.\n\nThe incident response policy and procedures address the controls in the IR family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures.\n\nPolicies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of incident response policy and procedures. Security and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures.\n\nThe policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations. Procedures can be established for security and privacy programs, mission or business processes, and systems if needed.\n\nProcedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents.\n\nEvents that may precipitate an update to incident response policy and procedures include assessment or audit findings, security incidents or breaches, or changes in laws, executive orders, directives, regulations, policies, standards, and guidelines.\n\nSimply restating controls does not constitute an organizational policy or procedure.",
          "Access control. System use notification. a. Display [assignment: organization-defined system use notification message or banner] to users before granting access to the system that provides privacy and security notices consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines, and state that users are accessing a U.S. government system. System usage may be monitored, recorded, and subject to audit. Unauthorized use of the system is prohibited and subject to criminal and civil penalties. Use of the system indicates consent to monitoring and recording.\n\nb. Retain the notification message or banner on the screen until users acknowledge the usage conditions and take explicit actions to log on to or further access the system.\n\nc. For publicly accessible systems:\n\n1. Display system use information [assignment: organization-defined conditions] before granting further access to the publicly accessible system.\n\n2. Display references, if any, to monitoring, recording, or auditing that are consistent with privacy accommodations for such systems that generally prohibit those activities.\n\n3. Include a description of the authorized uses of the system.\n\nSystem use notifications can be implemented using messages or warning banners displayed before individuals log in to systems. System use notifications are used only for access via logon interfaces with human users. Notifications are not required when human interfaces do not exist.\n\nBased on an assessment of risk, organizations consider whether or not a secondary system use notification is needed to access applications or other system resources after the initial network logon.\n\nOrganizations consider system use notification messages or banners displayed in multiple languages based on organizational needs and the demographics of system users. Organizations consult with the privacy office for input regarding privacy messaging and the Office of the General Counsel or organizational equivalent for legal review and approval of warning banner content.",
          "Audit and accountability. Audit record review, analysis, and reporting. a. Review and analyze system audit records [assignment: organization-defined frequency] for indications of [assignment: organization-defined inappropriate or unusual activity] and the potential impact of the inappropriate or unusual activity. \nb. Report findings to [assignment: organization-defined personnel or roles]. \nc. Adjust the level of audit record review, analysis, and reporting within the system when there is a change in risk based on law enforcement information, intelligence information, or other credible sources of information.\n\nAudit record review, analysis, and reporting covers information security- and privacy-related logging performed by organizations, including logging that results from the monitoring of account usage, remote access, wireless connectivity, mobile device connection, configuration settings, system component inventory, use of maintenance tools and non-local maintenance, physical access, temperature and humidity, equipment delivery and removal, communications at system interfaces, and use of mobile code or voice over internet protocol (VoIP). Findings can be reported to organizational entities that include the incident response team, help desk, and security or privacy offices. If organizations are prohibited from reviewing and analyzing audit records or unable to conduct such activities, the review or analysis may be carried out by other organizations granted such authority. The frequency, scope, and/or depth of the audit record review, analysis, and reporting may be adjusted to meet organizational needs based on new information received.",
          "System and communications protection. Boundary protection | external telecommunications services. (a) Implement a managed interface for each external telecommunication service. \n(b) Establish a traffic flow policy for each managed interface. \n(c) Protect the confidentiality and integrity of the information being transmitted across each interface. \n(d) Document each exception to the traffic flow policy with a supporting mission or business need and duration of that need. \n(e) Review exceptions to the traffic flow policy [assignment: organization-defined frequency] and remove exceptions that are no longer supported by an explicit mission or business need. \n(f) Prevent unauthorized exchange of control plane traffic with external networks. \n(g) Publish information to enable remote networks to detect unauthorized control plane traffic from internal networks. \n(h) Filter unauthorized control plane traffic from external networks. External telecommunication services can provide data and/or voice communications services. Examples of control plane traffic include Border Gateway Protocol (BGP) routing, Domain Name System (DNS), and management protocols. See SP 800-189 for additional information on the use of the Resource Public Key Infrastructure (RPKI) to protect BGP routes and detect unauthorized BGP announcements.",
          "Supply chain risk management family. Supply chain risk management plan | establish scrm team. Establish a Supply Chain Risk Management team consisting of [assignment: organization-defined personnel, roles, and responsibilities] to lead and support the following SCRM activities: [assignment: organization-defined supply chain risk management activities]. To implement Supply Chain Risk Management plans, organizations establish a coordinated, team-based approach to identify and assess supply chain risks and manage these risks by using programmatic and technical mitigation techniques. The team approach enables organizations to conduct an analysis of their supply chain, communicate with internal and external partners or stakeholders, and gain broad consensus regarding the appropriate resources for SCRM. The SCRM team consists of organizational personnel with diverse roles and responsibilities for leading and supporting SCRM activities, including Risk Executive, Information Technology, Contracting, Information Security, Privacy, Mission or Business, Legal, Supply Chain and Logistics, Acquisition, Business Continuity, and other relevant functions. Members of the SCRM team are involved in various aspects of the SDLC and, collectively, have an awareness of and provide expertise in acquisition processes, legal practices, vulnerabilities, threats, and attack vectors, as well as an understanding of the technical aspects and dependencies of systems. The SCRM team can be an extension of the Security and Privacy Risk Management processes or be included as part of an organizational risk management team.",
          "Identification and authentication. Identification and authentication (organizational users). Uniquely identify and authenticate organizational users and associate that unique identification with processes acting on behalf of those users. Organizations can satisfy the identification and authentication requirements by complying with the requirements in HSPD 12. Organizational users include employees or individuals who organizations consider to have an equivalent status to employees (e.g., contractors and guest researchers). \n\nUnique identification and authentication of users applies to all accesses other than those that are explicitly identified in AC-14 and that occur through the authorized use of group authenticators without individual authentication. Since processes execute on behalf of groups and roles, organizations may require unique identification of individuals in group accounts or for detailed accountability of individual activity. \n\nOrganizations employ passwords, physical authenticators, or biometrics to authenticate user identities or, in the case of multi-factor authentication, some combination thereof. Access to organizational systems is defined as either local access or network access. Local access is any access to organizational systems by users or processes acting on behalf of users, where access is obtained through direct connections without the use of networks. \n\nNetwork access is access to organizational systems by users (or processes acting on behalf of users) where access is obtained through network connections (i.e., nonlocal accesses). Remote access is a type of network access that involves communication through external networks. Internal networks include local area networks and wide area networks. \n\nThe use of encrypted virtual private networks for network connections between organization-controlled endpoints and non-organization-controlled endpoints may be treated as internal networks with respect to protecting the confidentiality and integrity of information traversing the network. Identification and authentication requirements for non-organizational users are described in IA-8.",
          "Security policies and instructions (sp). Documentation, communication and provision of policies and instructions. Basic criterion: Policies and instructions (including concepts and guidelines) are derived from the information security policy and are documented according to a uniform structure. They are communicated and made available to all internal and external employees of the cloud service provider in an appropriate manner. The policies and instructions are version controlled and approved by the top management of the cloud service provider or an authorized body. The policies and instructions describe at least the following aspects: objectives; scope; roles and responsibilities, including staff qualification requirements and the establishment of substitution rules; roles and dependencies on other organizations (especially cloud customers and sub-service organizations); steps for the execution of the security strategy; and applicable legal and regulatory requirements.\n\nAdditional criterion: Supplementary information about the criterion. The appropriateness of the demand-oriented communication and provision must be assessed against the size and complexity of the cloud service provider's organization and the type of cloud service offered. Possible criteria are: integration of guidelines and instructions in the onboarding of new employees; training and information campaigns when adopting new or revising existing policies and instructions; form of provision.\n\nPolicies and instructions are required for the following basic criteria in which the content is specified in more detail: risk management policy (OIS-06); acceptable use and handling of assets policy (AM-02); security requirements for premises and buildings (PS-01); physical site access control (PS-04); concept for protection against malware (OPS-04); concept for data protection and recovery (OPS-06); concept for logging and monitoring (OPS-10); concept for metadata handling (OPS-11); concept for handling of vulnerabilities, malfunctions, and errors (OPS-18); policy for system and data access authorizations (IDM-01); policy for the use of encryption procedures and key management (CRY-01); policies for data transmission (COS-08); policies for the development/procurement of information systems (DEV-01); policies for changes to information systems (DEV-03); policies and instructions for controlling and monitoring third parties (SSO-01); policy for security incident management (SIM-01); business impact analysis policies and procedures (BCM-02); policy for planning and conducting audits (COM-02).\n\nComplementary customer criterion: Notes on continuous auditing feasibility: partially regarding the uniformity and content of the policies and instructions, there is a need for manual testing, so continuous testing cannot be fully achieved. The communication/provision of policies and instructions can be queried via various registers. Registries for all approved policies and instructions can serve as a basis for reviewing the policies/instructions provided in the usual channels and may be combined with a conditional access check. These requirements must first be met by the cloud service provider. Versioning after approval by authorized personnel can be automatically audited and is therefore suitable for continuous audit.",
          "Security assessment and authorization. Internal system connections. a. Authorize internal connections of [assignment: organization-defined system components or classes of components] to the system.\nb. Document, for each internal connection, the interface characteristics, security and privacy requirements, and the nature of the information communicated.\nc. Terminate internal system connections after [assignment: organization-defined conditions].\nd. Review [assignment: organization-defined frequency] the continued need for each internal connection.\n\nInternal system connections are connections between organizational systems and separate constituent system components. These include connections between components that are part of the same system, as well as components used for system development. Intra-system connections encompass connections with mobile devices, notebook and desktop computers, tablets, printers, copiers, facsimile machines, scanners, sensors, and servers.\n\nInstead of authorizing each internal system connection individually, organizations have the option to authorize internal connections for a class of system components with common characteristics and/or configurations. For example, printers, scanners, and copiers with a specified processing, transmission, and storage capability, or smart phones and tablets with a specific baseline configuration.\n\nThe continued need for an internal system connection should be reviewed from the perspective of whether it provides support for organizational missions or business functions.",
          "System and services acquisition. Acquisition process. Include the following requirements, descriptions, and criteria, explicitly or by reference, using standardized contract language in the acquisition contract for the system, system component, or system service:\n\na. Security and privacy functional requirements.\nb. Strength of mechanism requirements.\nc. Security and privacy assurance requirements.\nd. Controls needed to satisfy the security and privacy requirements.\ne. Security and privacy documentation requirements.\nf. Requirements for protecting security and privacy documentation.\ng. Description of the system development environment and environment in which the system is intended to operate.\nh. Allocation of responsibility or identification of parties responsible for information security, privacy, and supply chain risk management.\ni. Acceptance criteria.\n\nSecurity and privacy functional requirements are typically derived from the high-level security and privacy requirements described in SA-2. The derived requirements include security and privacy capabilities, functions, and mechanisms. Strength requirements associated with such capabilities, functions, and mechanisms include the degree of correctness, completeness, resistance to tampering or bypass, and resistance to direct attack. Assurance requirements include development processes, procedures, and methodologies, as well as the evidence from development and assessment activities that provide grounds for confidence that the required functionality is implemented and possesses the required strength of the mechanism. SP 800-160-1 describes the process of requirements engineering as part of the system development life cycle.\n\nControls can be viewed as descriptions of the safeguards and protection capabilities appropriate for achieving the particular security and privacy objectives of the organization and for reflecting the security and privacy requirements of stakeholders. Controls are selected and implemented to satisfy system requirements and include developer and organizational responsibilities. Controls can include technical, administrative, and physical aspects. In some cases, the selection and implementation of a control may necessitate additional specification by the organization in the form of derived requirements or instantiated control parameter values. The derived requirements and control parameter values may be necessary to provide the appropriate level of implementation detail for controls within the system development life cycle.\n\nSecurity and privacy documentation requirements address all stages of the system development life cycle. Documentation provides user and administrator guidance for the implementation and operation of controls. The level of detail required in such documentation is based on the security categorization or classification level of the system and the degree to which organizations depend on the capabilities, functions, or mechanisms to meet risk response expectations. Requirements can include mandated configuration settings that specify allowed functions, ports, protocols, and services. Acceptance criteria for systems, system components, and system services are defined in the same manner as the criteria for any organizational acquisition or procurement.",
          "Contingency planning. Policy and procedures. A. Develop, document, and disseminate to organization-defined personnel or roles: \n\n1. Organization level contingency planning policy that addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance. The policy should be consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. \n\n2. Procedures to facilitate the implementation of the contingency planning policy and the associated contingency planning controls. \n\nB. Designate an organization-defined official to manage the development, documentation, and dissemination of the contingency planning policy and procedures. \n\nC. Review and update the current contingency planning: \n\n1. Policy organization-defined frequency and following organization-defined events. \n\n2. Procedures organization-defined frequency and following organization-defined events. \n\nContingency planning policy and procedures address the controls in the CP family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of contingency planning policy and procedures. \n\nSecurity and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations. \n\nProcedures can be established for security and privacy programs, for mission or business processes, and for systems, if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents. \n\nEvents that may precipitate an update to contingency planning policy and procedures include assessment or audit findings, security incidents or breaches, or changes in laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Security assessment and authorization. Policy and procedures. A. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]: 1. [Selection (one or more): organization-level; mission/business process-level; system-level] assessment, authorization, and monitoring policy that: (a) addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance; and (b) is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines; and 2. Procedures to facilitate the implementation of the assessment, authorization, and monitoring policy and the associated assessment, authorization, and monitoring controls. \n\nB. Designate an [assignment: organization-defined official] to manage the development, documentation, and dissemination of the assessment, authorization, and monitoring policy and procedures. \n\nC. Review and update the current assessment, authorization, and monitoring: 1. Policy [assignment: organization-defined frequency] and following [assignment: organization-defined events]; and 2. Procedures [assignment: organization-defined frequency] and following [assignment: organization-defined events]. \n\nAssessment, authorization, and monitoring policy and procedures address the controls in the CA family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of assessment, authorization, and monitoring policy and procedures. Security and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. \n\nThe policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations. Procedures can be established for security and privacy programs, for mission or business processes, and for systems, if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents. \n\nEvents that may precipitate an update to assessment, authorization, and monitoring policy and procedures include assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Planning. Security and privacy architectures. a. Develop security and privacy architectures for the system that: \n1. Describe the requirements and approach to be taken for protecting the confidentiality, integrity, and availability of organizational information. \n2. Describe the requirements and approach to be taken for processing personally identifiable information to minimize privacy risk to individuals. \n3. Describe how the architectures are integrated into and support the enterprise architecture. \n4. Describe any assumptions about, and dependencies on, external systems and services. \n\nb. Review and update the architectures [assignment: organization-defined frequency] to reflect changes in the enterprise architecture. \n\nc. Reflect planned architecture changes in security and privacy plans, concept of operations (conops), criticality analysis, organizational procedures, and procurements and acquisitions. \n\nThe security and privacy architectures at the system level are consistent with the organization-wide security and privacy architectures described in PM-7, which are integral to and developed as part of the enterprise architecture. The architectures include an architectural description, the allocation of security and privacy functionality (including controls), security- and privacy-related information for external interfaces, information being exchanged across the interfaces, and the protection mechanisms associated with each interface. The architectures can also include other information, such as user roles and the access privileges assigned to each role, security and privacy requirements, types of information processed, stored, and transmitted by the system, supply chain risk management requirements, restoration priorities of information and system services, and other protection needs. \n\nSP 800-160-1 provides guidance on the use of security architectures as part of the system development life cycle process. \nOMB M-19-03 requires the use of the systems security engineering concepts described in SP 800-160-1 for high-value assets. \n\nSecurity and privacy architectures are reviewed and updated throughout the system development life cycle, from analysis of alternatives through review of the proposed architecture in the RFP responses to the design reviews before and during implementation (e.g., during preliminary design reviews and critical design reviews). \n\nIn today’s modern computing architectures, it is becoming less common for organizations to control all information resources. There may be key dependencies on external information services and service providers. Describing such dependencies in the security and privacy architectures is necessary for developing a comprehensive mission and business protection strategy. \n\nEstablishing, developing, documenting, and maintaining under configuration control a baseline configuration for organizational systems is critical to implementing and maintaining effective architectures. \n\nThe development of the architectures is coordinated with the Senior Agency Information Security Officer and the Senior Agency Official for Privacy to ensure that the controls needed to support security and privacy requirements are identified and effectively implemented. \n\nIn many circumstances, there may be no distinction between the security and privacy architecture for a system. In other circumstances, security objectives may be adequately satisfied, but privacy objectives may only be partially satisfied by the security requirements. In these cases, consideration of the privacy requirements needed to achieve satisfaction will result in a distinct privacy architecture. The documentation, however, may simply reflect the combined architectures. \n\nPL-8 is primarily directed at organizations to ensure that architectures are developed for the system and, moreover, that the architectures are integrated with or tightly coupled to the enterprise architecture. In contrast, SA-17 is primarily directed at the external information technology product and system developers and integrators. SA-17, which is complementary to PL-8, is selected when organizations outsource the development of systems or components to external entities and when there is a need to demonstrate consistency with the organization’s enterprise architecture and security and privacy architectures.",
          "Personnel security. Policy and procedures. A. Develop, document, and disseminate to organization-defined personnel or roles:\n1. Organization level personnel security policy that addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance. The policy should be consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines.\n2. Procedures to facilitate the implementation of the personnel security policy and the associated personnel security controls.\n\nB. Designate an organization-defined official to manage the development, documentation, and dissemination of the personnel security policy and procedures.\n\nC. Review and update the current personnel security:\n1. Policy, organization-defined frequency, and following organization-defined events.\n2. Procedures, organization-defined frequency, and following organization-defined events.\n\nPersonnel security policy and procedures for the controls in the PS family are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on their development.\n\nSecurity and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission level or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies reflecting the complex nature of organizations.\n\nProcedures can be established for security and privacy programs, for mission/business processes, and for systems, if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents.\n\nEvents that may precipitate an update to personnel security policy and procedures include, but are not limited to, assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "System and services acquisition. Policy and procedures. a. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]: \n1. [Selection (one or more): organization-level; mission/business process-level; system-level] system and services acquisition policy that: \n(a) Addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance.\n(b) Is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. \n2. Procedures to facilitate the implementation of the system and services acquisition policy and the associated system and services acquisition controls. \n\nb. Designate an [assignment: organization-defined official] to manage the development, documentation, and dissemination of the system and services acquisition policy and procedures. \n\nc. Review and update the current system and services acquisition: \n1. Policy [assignment: organization-defined frequency] and following [assignment: organization-defined events]. \n2. Procedures [assignment: organization-defined frequency] and following [assignment: organization-defined events]. \n\nSystem and services acquisition policy and procedures address the controls in the SA family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of system and services acquisition policy and procedures. \n\nSecurity and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations. Procedures can be established for security and privacy programs, for mission or business processes, and for systems if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents. \n\nEvents that may precipitate an update to system and services acquisition policy and procedures include assessment or audit findings, security incidents or breaches, or changes in laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Media protection. Policy and procedures. A. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]: 1. [Selection (one or more): organization level; mission/business process-level; system-level] media protection policy that: (a) addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance; and (b) is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines; and 2. procedures to facilitate the implementation of the media protection policy and the associated media protection controls. \n\nB. Designate an [assignment: organization-defined official] to manage the development, documentation, and dissemination of the media protection policy and procedures.\n\nC. Review and update the current media protection: 1. policy [assignment: organization-defined frequency] and following [assignment: organization-defined events]; and 2. procedures [assignment: organization-defined frequency] and following [assignment: organization-defined events]. \n\nMedia protection policy and procedures address the controls in the MP family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of media protection policy and procedures. Security and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations. Procedures can be established for security and privacy programs, for mission or business processes, and for systems, if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents. Events that may precipitate an update to media protection policy and procedures include assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "System and services acquisition. Developer configuration management. Require the developer of the system, system component, or system service to: \na. Perform configuration management during system, component, or service [selection (one or more): design; development; implementation; operation; disposal]. \nb. Document, manage, and control the integrity of changes to [assignment: organization-defined configuration items under configuration management]. \nc. Implement only organization-approved changes to the system, component, or service. \nd. Document approved changes to the system, component, or service and the potential security and privacy impacts of such changes. \ne. Track security flaws and flaw resolution with the system, component, or service and report findings to [assignment: organization-defined personnel]. \n\nOrganizations consider the quality and completeness of configuration management activities conducted by developers as direct evidence of applying effective security controls. \n\nControls include protecting the master copies of material used to generate security-relevant portions of the system hardware, software, and firmware from unauthorized modification or destruction. \n\nMaintaining the integrity of changes to the system, system component, or system service requires strict configuration control throughout the system development life cycle to track authorized changes and prevent unauthorized changes. \n\nThe configuration items that are placed under configuration management include the formal model, the functional, high-level, and low-level design specifications, other design data, implementation documentation, source code and hardware schematics, the current running version of the object code, tools for comparing new versions of security-relevant hardware descriptions and source code with previous versions, and test fixtures and documentation. \n\nDepending on the mission and business needs of organizations and the nature of the contractual relationships in place, developers may provide configuration management support during the operations and maintenance stage of the system development life cycle.",
          "System and services acquisition. Developer security and privacy architecture and design. Require the developer of the system, system component, or system service to produce a design specification and security and privacy architecture that: a. is consistent with the organization's security and privacy architecture that is an integral part of the organization's enterprise architecture; b. accurately and completely describes the required security and privacy functionality and the allocation of controls among physical and logical components; and c. expresses how individual security and privacy functions, mechanisms, and services work together to provide required security and privacy capabilities and a unified approach to protection. Developer security and privacy architecture and design are directed at external developers, although they could also be applied to internal (in-house) development. In contrast, PL-8 is directed at internal developers to ensure that organizations develop a security and privacy architecture that is integrated with the enterprise architecture. The distinction between SA-17 and PL-8 is especially important when organizations outsource the development of systems, system components, or system services and when there is a requirement to demonstrate consistency with the enterprise architecture and security and privacy architecture of the organization. ISO 15408-2, ISO 15408-3, and SP 800-160-1 provide information on security architecture and design, including formal policy models, security-relevant components, formal and informal correspondence, conceptually simple design, and structuring for least privilege and testing.",
          "Supply chain risk management family. Acquisition strategies, tools, and methods. Employ the following acquisition strategies, contract tools, and procurement methods to protect against, identify, and mitigate supply chain risks: [assignment: organization-defined acquisition strategies, contract tools, and procurement methods]. The use of the acquisition process provides an important vehicle to protect the supply chain. There are many useful tools and techniques available, including obscuring the end use of a system or system component, using blind or filtered buys, requiring tamper-evident packaging, or using trusted or controlled distribution. The results from a supply chain risk assessment can guide and inform the strategies, tools, and methods that are most applicable to the situation. Tools and techniques may provide protections against unauthorized production, theft, tampering, insertion of counterfeits, insertion of malicious software or backdoors, and poor development practices throughout the system development life cycle.\n\nOrganizations also consider providing incentives for suppliers who implement controls, promote transparency into their processes and security and privacy practices, provide contract language that addresses the prohibition of tainted or counterfeit components, and restrict purchases from untrustworthy suppliers. Organizations consider providing training, education, and awareness programs for personnel regarding supply chain risk, available mitigation strategies, and when the programs should be employed. Methods for reviewing and protecting development plans, documentation, and evidence are commensurate with the security and privacy requirements of the organization. Contracts may specify documentation protection requirements.",
          "Risk assessment. Risk assessment. A. Conduct a risk assessment, including: 1. identifying threats to and vulnerabilities in the system; 2. determining the likelihood and magnitude of harm from unauthorized access, use, disclosure, disruption, modification, or destruction of the system, the information it processes, stores, or transmits, and any related information; and 3. determining the likelihood and impact of adverse effects on individuals arising from the processing of personally identifiable information. B. Integrate risk assessment results and risk management decisions from the organization and mission or business process perspectives with system-level risk assessments. C. Document risk assessment results in [selection: security and privacy plans; risk assessment report; [assignment: organization-defined document]]. D. Review risk assessment results [assignment: organization-defined frequency]. E. Disseminate risk assessment results to [assignment: organization-defined personnel or roles]. F. Update the risk assessment [assignment: organization-defined frequency] or when there are significant changes to the system, its environment of operation, or other conditions that may impact the security or privacy state of the system. Risk assessments consider threats, vulnerabilities, likelihood, and impact to organizational operations and assets, individuals, other organizations, and the nation. Risk assessments also consider risk from external parties, including contractors who operate systems on behalf of the organization, individuals who access organizational systems, service providers, and outsourcing entities. Organizations can conduct risk assessments at all three levels in the risk management hierarchy (i.e., organization level, mission/business process level, or information system level) and at any stage in the system development life cycle. Risk assessments can also be conducted at various steps in the risk management framework, including preparation, categorization, control selection, control implementation, control assessment, authorization, and control monitoring. Risk assessment is an ongoing activity carried out throughout the system development life cycle. Risk assessments can also address information related to the system, including system design, the intended use of the system, testing results, and supply chain-related information or artifacts. Risk assessments can play an important role in control selection processes, particularly during the application of tailoring guidance and in the earliest phases of capability determination.",
          "System and information integrity. System monitoring. A. Monitor the system to detect:\n1. Attacks and indicators of potential attacks in accordance with the following monitoring objectives: [Assignment: organization-defined monitoring objectives].\n2. Unauthorized local, network, and remote connections.\n\nB. Identify unauthorized use of the system through the following techniques and methods: [Assignment: organization-defined techniques and methods].\n\nC. Invoke internal monitoring capabilities or deploy monitoring devices:\n1. Strategically within the system to collect organization-determined essential information.\n2. At ad hoc locations within the system to track specific types of transactions of interest to the organization.\n\nD. Analyze detected events and anomalies.\n\nE. Adjust the level of system monitoring activity when there is a change in risk to organizational operations and assets, individuals, other organizations, or the nation.\n\nF. Obtain a legal opinion regarding system monitoring activities.\n\nG. Provide [Assignment: organization-defined system monitoring information] to [Assignment: organization-defined personnel or roles] [Selection (one or more): as needed; [Assignment: organization-defined frequency]].\n\nSystem monitoring includes external and internal monitoring. External monitoring includes the observation of events occurring at external interfaces to the system. Internal monitoring includes the observation of events occurring within the system. Organizations monitor systems by observing audit activities in real-time or by observing other system aspects such as access patterns, characteristics of access, and other actions. The monitoring objectives guide and inform the determination of the events.\n\nSystem monitoring capabilities are achieved through a variety of tools and techniques, including intrusion detection and prevention systems, malicious code protection software, scanning tools, audit record monitoring software, and network monitoring software. Depending on the security architecture, the distribution and configuration of monitoring devices may impact throughput at key internal and external boundaries as well as at other locations across a network due to the introduction of network throughput latency. If throughput management is needed, such devices are strategically located and deployed as part of an established organization-wide security architecture. Strategic locations for monitoring devices include selected perimeter locations and near key servers and server farms that support critical applications. Monitoring devices are typically employed at the managed interfaces associated with controls SC-7 and AC-17.\n\nThe information collected is a function of the organizational monitoring objectives and the capability of systems to support such objectives. Specific types of transactions of interest include Hypertext Transfer Protocol (HTTP) traffic that bypasses HTTP proxies. System monitoring is an integral part of organizational continuous monitoring and incident response programs, and output from system monitoring serves as input to those programs.\n\nSystem monitoring requirements, including the need for specific types of system monitoring, may be referenced in other controls (e.g., AC-2g, AC-2 (7), AC-2 (12) (a), AC-17 (1), AU-13, AU-13 (1), AU-13 (2), CM-3f, CM-6d, MA-3a, MA-4a, SC-5 (3) (b), SC-7a, SC-7 (24) (b), SC-18b, SC-43b). Adjustments to levels of system monitoring are based on law enforcement information, intelligence information, or other sources of information.\n\nThe legality of system monitoring activities is based on applicable laws, executive orders, directives, regulations, policies, standards, and guidelines.",
          "Configuration management. Policy and procedures. a. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]: 1. [Selection (one or more): organization level; mission/business process-level; system-level] configuration management policy that: (a) addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance; and (b) is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines; and 2. Procedures to facilitate the implementation of the configuration management policy and the associated configuration management controls. \n\nb. Designate an [assignment: organization-defined official] to manage the development, documentation, and dissemination of the configuration management policy and procedures.\n\nc. Review and update the current configuration management: \n1. Policy [assignment: organization-defined frequency] and following [assignment: organization-defined events].\n2. Procedures [assignment: organization-defined frequency] and following [assignment: organization-defined events].\n\nConfiguration management policy and procedures address the controls in the CM family that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of configuration management policy and procedures.\n\nSecurity and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations. Procedures can be established for security and privacy programs, for mission/business processes, and for systems, if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents. \n\nEvents that may precipitate an update to configuration management policy and procedures include, but are not limited to, assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "System and information integrity. Malicious code protection. A. Implement [selection (one or more): signature-based; non-signature-based] malicious code protection mechanisms at system entry and exit points to detect and eradicate malicious code. \nB. Automatically update malicious code protection mechanisms as new releases are available in accordance with organizational configuration management policy and procedures. \nC. Configure malicious code protection mechanisms to: \n1. Perform periodic scans of the system [assignment: organization-defined frequency] and real-time scans of files from external sources at [selection (one or more): endpoint; network entry and exit points] as the files are downloaded, opened, or executed in accordance with organizational policy. \n2. [selection (one or more): block malicious code; quarantine malicious code; take [assignment: organization-defined action]]; and send an alert to [assignment: organization-defined personnel or roles] in response to malicious code detection. \nD. Address the receipt of false positives during malicious code detection and eradication and the resulting potential impact on the availability of the system. \n\nSystem entry and exit points include firewalls, remote access servers, workstations, electronic mail servers, web servers, proxy servers, notebook computers, and mobile devices. \n\nMalicious code includes viruses, worms, trojan horses, and spyware. Malicious code can also be encoded in various formats contained within compressed or hidden files or hidden in files using techniques such as steganography. Malicious code can be inserted into systems in a variety of ways, including by electronic mail, the world-wide web, and portable storage devices. Malicious code insertions occur through the exploitation of system vulnerabilities. \n\nA variety of technologies and methods exist to limit or eliminate the effects of malicious code. Malicious code protection mechanisms include both signature- and non-signature-based technologies. Non-signature-based detection mechanisms include artificial intelligence techniques that use heuristics to detect, analyze, and describe the characteristics or behavior of malicious code and to provide controls against such code for which signatures do not yet exist or for which existing signatures may not be effective. Malicious code for which active signatures do not yet exist or may be ineffective includes polymorphic malicious code (i.e., code that changes signatures when it replicates). Non-signature-based mechanisms also include reputation-based technologies. \n\nIn addition to the above technologies, pervasive configuration management, comprehensive software integrity controls, and anti-exploitation software may be effective in preventing the execution of unauthorized code. Malicious code may be present in commercial off-the-shelf software as well as custom-built software and could include logic bombs, backdoors, and other types of attacks that could affect organizational mission and business functions. \n\nIn situations where malicious code cannot be detected by detection methods or technologies, organizations rely on other types of controls, including secure coding practices, configuration management and control, trusted procurement processes, and monitoring practices to ensure that software does not perform functions other than the functions intended. \n\nOrganizations may determine that, in response to the detection of malicious code, different actions may be warranted. For example, organizations can define actions in response to malicious code detection during periodic scans, the detection of malicious downloads, or the detection of maliciousness when attempting to open or execute files.",
          "System and communications protection. Boundary protection | prevent exfiltration. (a) Prevent the exfiltration of information; and (b) conduct exfiltration tests [assignment: organization-defined frequency]. Prevention of exfiltration applies to both intentional and unintentional exfiltration of information. Techniques used to prevent the exfiltration of information from systems may be implemented at internal endpoints, external boundaries, and across managed interfaces. These techniques include adherence to protocol formats, monitoring for beaconing activity from systems, disconnecting external network interfaces except when explicitly needed, employing traffic profile analysis to detect deviations from the volume and types of traffic expected, call backs to command and control centers, conducting penetration testing, monitoring for steganography, disassembling and reassembling packet headers, and using data loss and data leakage prevention tools. Devices that enforce strict adherence to protocol formats include deep packet inspection firewalls and extensible markup language (XML) gateways. These devices verify adherence to protocol formats and specifications at the application layer and identify vulnerabilities that cannot be detected by devices that operate at the network or transport layers. The prevention of exfiltration is similar to data loss prevention or data leakage prevention and is closely associated with cross-domain solutions and system guards that enforce information flow requirements.",
          "Access control. Remote access. a. Establish and document usage restrictions, configuration/connection requirements, and implementation guidance for each type of remote access allowed; and b. Authorize each type of remote access to the system prior to allowing such connections. Remote access is access to organizational systems (or processes acting on behalf of users) that communicate through external networks such as the internet. Types of remote access include dial-up, broadband, and wireless. Organizations use encrypted Virtual Private Networks (VPNs) to enhance confidentiality and integrity for remote connections. The use of encrypted VPNs provides sufficient assurance to the organization that it can effectively treat such connections as internal networks if the cryptographic mechanisms used are implemented in accordance with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Still, VPN connections traverse external networks, and the encrypted VPN does not enhance the availability of remote connections. VPNs with encrypted tunnels can also affect the ability to adequately monitor network communications traffic for malicious code. Remote access controls apply to systems other than public web servers or systems designed for public access. Authorization of each remote access type addresses authorization prior to allowing remote access without specifying the specific formats for such authorization. While organizations may use information exchange and system connection security agreements to manage remote access connections to other systems, such agreements are addressed as part of CA-3. Enforcing access restrictions for remote access is addressed via AC-3.",
          "System and information integrity. Information input validation. Check the validity of the following information inputs: [assignment: organization-defined information inputs to the system]. Checking the valid syntax and semantics of system inputs - including character set, length, numerical range, and acceptable values - verifies that inputs match specified definitions for format and content. For example, if the organization specifies that numerical values between 1-100 are the only acceptable inputs for a field in a given application, inputs of 387, abc, or %k% are invalid inputs and are not accepted as input to the system. Valid inputs are likely to vary from field to field within a software application. Applications typically follow well-defined protocols that use structured messages (i.e., commands or queries) to communicate between software modules or system components. Structured messages can contain raw or unstructured data interspersed with metadata or control information. If software applications use attacker-supplied inputs to construct structured messages without properly encoding such messages, then the attacker could insert malicious commands or special characters that can cause the data to be interpreted as control information or metadata. Consequently, the module or component that receives the corrupted output will perform the wrong operations or otherwise interpret the data incorrectly. Prescreening inputs prior to passing them to interpreters prevents the content from being unintentionally interpreted as commands. Input validation ensures accurate and correct inputs and prevents attacks such as cross-site scripting and a variety of injection attacks.",
          "System and information integrity. Policy and procedures. a. Develop, document, and disseminate to organization-defined personnel or roles: \n1. Organization-level, system-level, and mission/business process-level system and information integrity policies that:\n(a) Address purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance.\n(b) Are consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines.\n2. Procedures to facilitate the implementation of the system and information integrity policy and associated controls.\n\nb. Designate an organization-defined official to manage the development, documentation, and dissemination of the system and information integrity policy and procedures.\n\nc. Review and update the current system and information integrity policies and procedures:\n1. Policy - organization-defined frequency and following organization-defined events.\n2. Procedures - organization-defined frequency and following organization-defined events.\n\nSystem and information integrity policies and procedures should address the controls in the SI family that are implemented within systems and organizations. The risk management strategy plays a crucial role in establishing these policies and procedures. Collaborative efforts between the security and privacy programs are essential in developing the system and information integrity policies and procedures. Organization-level security and privacy program policies and procedures are generally preferred, as they may eliminate the need for mission- or system-specific policies and procedures. The policy can be incorporated into the general security and privacy policy or represented by multiple policies that reflect the complexity of organizations. Procedures can be established for security and privacy programs, mission or business processes, and systems, if necessary. Procedures outline the implementation of policies or controls and can be directed at individuals or roles. They can be documented within system security and privacy plans or as separate documents. Updates to the system and information integrity policy and procedures may arise from assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Merely restating controls does not constitute an organizational policy or procedure.",
          "Media protection. Media marking. a. Mark system media indicating the distribution limitations, handling caveats, and applicable security markings (if any) of the information; and b. Exempt [assignment: organization-defined types of system media] from marking if the media remain within [assignment: organization-defined controlled areas]. Security marking refers to the application or use of human-readable security attributes. Digital media includes diskettes, magnetic tapes, external or removable hard disk drives (e.g., solid state, magnetic), flash drives, compact discs, and digital versatile discs. Non-digital media includes paper and microfilm. Controlled Unclassified Information (CUI) is defined by the National Archives and Records Administration along with the appropriate safeguarding and dissemination requirements for such information and is codified in 32 CFR 2002. Security markings are generally not required for media that contains information determined by organizations to be in the public domain or to be publicly releasable. Some organizations may require markings for public information indicating that the information is publicly releasable. System media marking reflects applicable laws, executive orders, directives, policies, regulations, standards, and guidelines.",
          "Media protection. Media use. a. [selection: Restrict; Prohibit] the use of [assignment: organization-defined types of system media] on [assignment: organization-defined systems or system components] using [assignment: organization-defined controls]; and b. Prohibit the use of portable storage devices in organizational systems when such devices have no identifiable owner. System media includes both digital and non-digital media. Digital media includes diskettes, magnetic tapes, flash drives, compact discs, digital versatile discs, and removable hard disk drives. Non-digital media includes paper and microfilm. Media use protections also apply to mobile devices with information storage capabilities. In contrast to MP-2, which restricts user access to media, MP-7 restricts the use of certain types of media on systems. For example, restricting or prohibiting the use of flash drives or external hard disk drives. Organizations use technical and non-technical controls to restrict the use of system media. Organizations may restrict the use of portable storage devices, for example, by using physical cages on workstations to prohibit access to certain external ports or disabling or removing the ability to insert, read, or write to such devices. Organizations may also limit the use of portable storage devices to only approved devices, including devices provided by the organization, devices provided by other approved organizations, and devices that are not personally owned. Finally, organizations may restrict the use of portable storage devices based on the type of device. For example, by prohibiting the use of writable, portable storage devices and implementing this restriction by disabling or removing the capability to write to such devices. Requiring identifiable owners for storage devices reduces the risk of using such devices by allowing organizations to assign responsibility for addressing known vulnerabilities in the devices.",
          "Risk assessment. Risk assessment | supply chain risk assessment. (a) Assess supply chain risks associated with [assignment: organization-defined systems, system components, and system services]; and (b) update the supply chain risk assessment [assignment: organization-defined frequency], when there are significant changes to the relevant supply chain or when changes to the system, environments of operation, or other conditions may necessitate a change in the supply chain. Supply chain-related events include disruption, use of defective components, insertion of counterfeits, theft, malicious development practices, improper delivery practices, and insertion of malicious code. These events can have a significant impact on the confidentiality, integrity, or availability of a system and its information and therefore can also adversely impact organizational operations (including mission, functions, image, or reputation), organizational assets, individuals, other organizations, and the nation. The supply chain-related events may be unintentional or malicious and can occur at any point during the system life cycle. An analysis of supply chain risk can help an organization identify systems or components for which additional supply chain risk mitigations are required.",
          "Identification and authentication. Device identification and authentication. Uniquely identify and authenticate [assignment: organization-defined devices and/or types of devices] before establishing a [selection (one or more): local; remote; network] connection. Devices that require unique device-to-device identification and authentication are defined by type, device, or a combination of type and device. Organization-defined device types include devices that are not owned by the organization. Systems use shared known information (e.g., media access control [MAC], Transmission Control Protocol/Internet Protocol [TCP/IP] addresses) for device identification or organizational authentication solutions (e.g., Institute of Electrical and Electronics Engineers (IEEE) 802.1X and Extensible Authentication Protocol [EAP], RADIUS server with EAP-Transport Layer Security [TLS] authentication, Kerberos) to identify and authenticate devices on local and wide area networks. Organizations determine the required strength of authentication mechanisms based on the security categories of systems and mission or business requirements. Because of the challenges of implementing device authentication on a large scale, organizations can restrict the application of the control to a limited number/type of devices based on mission or business needs.",
          "Personnel security. Position risk designation. a. Assign a risk designation to all organizational positions. \nb. Establish screening criteria for individuals filling those positions. \nc. Review and update position risk designations [assignment: organization-defined frequency]. \n\nPosition risk designations reflect Office of Personnel Management (OPM) policy and guidance. Proper position designation is the foundation of an effective and consistent suitability and personnel security program. The Position Designation System (PDS) assesses the duties and responsibilities of a position to determine the degree of potential damage to the efficiency or integrity of the service due to misconduct of an incumbent of a position and establishes the risk level of that position. \n\nThe PDS assessment also determines if the duties and responsibilities of the position present the potential for position incumbents to bring about a material adverse effect on national security and the degree of that potential effect, which establishes the sensitivity level of a position. The results of the assessment determine what level of investigation is conducted for a position. \n\nRisk designations can guide and inform the types of authorizations that individuals receive when accessing organizational information and information systems. Position screening criteria include explicit information security role appointment requirements. \n\nParts 1400 and 731 of Title 5, Code of Federal Regulations, establish the requirements for organizations to evaluate relevant covered positions for a position sensitivity and position risk designation commensurate with the duties and responsibilities of those positions.",
          "Access control. Use of external systems. a. [Selection (one or more): Establish [assignment: organization-defined terms and conditions]; Identify [assignment: organization-defined controls asserted to be implemented on external systems]], consistent with the trust relationships established with other organizations owning, operating, and/or maintaining external systems, allowing authorized individuals to: 1. access the system from external systems; and 2. process, store, or transmit organization-controlled information using external systems; or b. Prohibit the use of [assignment: organizationally-defined types of external systems]. External systems are systems that are used by but not part of organizational systems, and for which the organization has no direct control over the implementation of required controls or the assessment of control effectiveness. External systems include personally owned systems, components, or devices; privately-owned computing and communications devices in commercial or public facilities; systems owned or controlled by nonfederal organizations; systems managed by contractors; and federal information systems that are not owned by, operated by, or under the direct supervision or authority of the organization. External systems also include systems owned or operated by other components within the same organization and systems within the organization with different authorization boundaries. Organizations have the option to prohibit the use of any type of external system or prohibit the use of specified types of external systems (e.g., prohibit the use of any external system that is not organizationally owned or prohibit the use of personally-owned systems). For some external systems (i.e., systems operated by other organizations), the trust relationships that have been established between those organizations and the originating organization may be such that no explicit terms and conditions are required. Systems within these organizations may not be considered external. These situations occur when, for example, there are pre-existing information exchange agreements (either implicit or explicit) established between organizations or components or when such agreements are specified by applicable laws, executive orders, directives, regulations, policies, or standards. Authorized individuals include organizational personnel, contractors, or other individuals with authorized access to organizational systems and over which organizations have the authority to impose specific rules of behavior regarding system access. Restrictions that organizations impose on authorized individuals need not be uniform, as the restrictions may vary depending on trust relationships between organizations. Therefore, organizations may choose to impose different security restrictions on contractors than on state, local, or tribal governments. External systems used to access public interfaces to organizational systems are outside the scope of AC-20. Organizations establish specific terms and conditions for the use of external systems in accordance with organizational security policies and procedures. At a minimum, terms and conditions address the specific types of applications that can be accessed on organizational systems from external systems and the highest security category of information that can be processed, stored, or transmitted on external systems. If the terms and conditions with the owners of the external systems cannot be established, organizations may impose restrictions on organizational personnel using those external systems.",
          "Access control. Device lock. a. Prevent further access to the system by [selection (one or more): initiating a device lock after [assignment: organization-defined time period] of inactivity; requiring the user to initiate a device lock before leaving the system unattended]. \nb. Retain the device lock until the user reestablishes access using established identification and authentication procedures. Device locks are temporary actions taken to prevent logical access to organizational systems when users stop work and move away from the immediate vicinity of those systems but do not want to log out because of the temporary nature of their absences. Device locks can be implemented at the operating system level or at the application level. A proximity lock may be used to initiate the device lock (e.g., via a Bluetooth-enabled device or dongle). User-initiated device locking is behavior or policy-based and, as such, requires users to take physical action to initiate the device lock. Device locks are not an acceptable substitute for logging out of systems, such as when organizations require users to log out at the end of workdays.",
          "Supply chain risk management family. Policy and procedures. A. Develop, document, and disseminate to [assignment: organization-defined personnel or roles]: 1. [Selection (one or more): organization level; mission/business process-level; system-level] supply chain risk management policy that: (a) addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance; and (b) is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines; and 2. Procedures to facilitate the implementation of the supply chain risk management policy and the associated supply chain risk management controls. \n\nB. Designate an [assignment: organization-defined official] to manage the development, documentation, and dissemination of the supply chain risk management policy and procedures. \n\nC. Review and update the current supply chain risk management: 1. Policy [assignment: organization-defined frequency] and following [assignment: organization-defined events]; and 2. Procedures [assignment: organization-defined frequency] and following [assignment: organization-defined events]. \n\nSupply chain risk management policy and procedures address the controls in the SR family as well as supply chain-related controls in other families that are implemented within systems and organizations. The risk management strategy is an important factor in establishing such policies and procedures. Policies and procedures contribute to security and privacy assurance. Therefore, it is important that security and privacy programs collaborate on the development of supply chain risk management policy and procedures. Security and privacy program policies and procedures at the organization level are preferable, in general, and may obviate the need for mission- or system-specific policies and procedures. The policy can be included as part of the general security and privacy policy or be represented by multiple policies that reflect the complex nature of organizations. Procedures can be established for security and privacy programs, for mission or business processes, and for systems, if needed. Procedures describe how the policies or controls are implemented and can be directed at the individual or role that is the object of the procedure. Procedures can be documented in system security and privacy plans or in one or more separate documents. Events that may precipitate an update to supply chain risk management policy and procedures include assessment or audit findings, security incidents or breaches, or changes in applicable laws, executive orders, directives, regulations, policies, standards, and guidelines. Simply restating controls does not constitute an organizational policy or procedure.",
          "Security assessment and authorization. Authorization. a. Assign a senior official as the authorizing official for the system. \nb. Assign a senior official as the authorizing official for common controls available for inheritance by organizational systems. \nc. Ensure that the authorizing official for the system, before commencing operations: \n   1. Accepts the use of common controls inherited by the system. \n   2. Authorizes the system to operate. \nd. Ensure that the authorizing official for common controls authorizes the use of those controls for inheritance by organizational systems. \ne. Update the authorizations [assignment: organization-defined frequency]. Authorizations are official management decisions by senior officials to authorize the operation of systems, authorize the use of common controls for inheritance by organizational systems, and explicitly accept the risk to organizational operations and assets, individuals, other organizations, and the nation based on the implementation of agreed-upon controls. \nAuthorizing officials provide budgetary oversight for organizational systems and common controls or assume responsibility for the mission and business functions supported by those systems or common controls. The authorization process is a federal responsibility, and therefore, authorizing officials must be federal employees. \nAuthorizing officials are both responsible and accountable for security and privacy risks associated with the operation and use of organizational systems. Nonfederal organizations may have similar processes to authorize systems and senior officials that assume the authorization role and associated responsibilities. \nAuthorizing officials issue ongoing authorizations of systems based on evidence produced from implemented continuous monitoring programs. Robust continuous monitoring programs reduce the need for separate reauthorization processes. Through the employment of comprehensive continuous monitoring processes, the information contained in authorization packages (i.e., security and privacy plans, assessment reports, and plans of action and milestones) is updated on an ongoing basis. This provides authorizing officials, common control providers, and system owners with an up-to-date status of the security and privacy posture of their systems, controls, and operating environments. To reduce the cost of reauthorization, authorizing officials can leverage the results of continuous monitoring processes to the maximum extent possible as the basis for rendering reauthorization decisions.",
          "Security assessment and authorization. Control assessments. a. Select the appropriate assessor or assessment team for the type of assessment to be conducted. \nb. Develop a control assessment plan that describes the scope of the assessment, including: \n1. Controls and control enhancements under assessment. \n2. Assessment procedures to be used to determine control effectiveness. \n3. Assessment environment, assessment team, and assessment roles and responsibilities. \nc. Ensure the control assessment plan is reviewed and approved by the authorizing official or designated representative prior to conducting the assessment. \nd. Assess the controls in the system and its environment of operation [assignment: organization-defined frequency] to determine the extent to which the controls are implemented correctly, operating as intended, and producing the desired outcome with respect to meeting established security and privacy requirements. \ne. Produce a control assessment report that documents the results of the assessment. \nf. Provide the results of the control assessment to [assignment: organization-defined individuals or roles]. \nOrganizations ensure that control assessors possess the required skills and technical expertise to develop effective assessment plans and to conduct assessments of system-specific, hybrid, common, and program management controls, as appropriate. The required skills include general knowledge of risk management concepts and approaches as well as comprehensive knowledge of and experience with the hardware, software, and firmware system components implemented. Organizations assess controls in systems and the environments in which those systems operate as part of initial and ongoing authorizations, continuous monitoring, FISMA annual assessments, system design and development, systems security engineering, privacy engineering, and the system development life cycle. Assessments help to ensure that organizations meet information security and privacy requirements, identify weaknesses and deficiencies in the system design and development process, provide essential information needed to make risk-based decisions as part of authorization processes, and comply with vulnerability mitigation procedures. Organizations conduct assessments on the implemented controls as documented in security and privacy plans. Assessments can also be conducted throughout the system development life cycle as part of systems engineering and systems security engineering processes. The design for controls can be assessed as RFPs are developed, responses assessed, and design reviews conducted. If a design to implement controls and subsequent implementation in accordance with the design are assessed during development, the final control testing can be a simple confirmation utilizing previously completed control assessment and aggregating the outcomes. Organizations may develop a single, consolidated security and privacy assessment plan for the system or maintain separate plans. A consolidated assessment plan clearly delineates the roles and responsibilities for control assessment. If multiple organizations participate in assessing a system, a coordinated approach can reduce redundancies and associated costs. Organizations can use other types of assessment activities, such as vulnerability scanning and system monitoring, to maintain the security and privacy posture of systems during the system life cycle. Assessment reports document assessment results in sufficient detail, as deemed necessary by organizations, to determine the accuracy and completeness of the reports and whether the controls are implemented correctly, operating as intended, and producing the desired outcome with respect to meeting requirements. Assessment results are provided to the individuals or roles appropriate for the types of assessments being conducted. For example, assessments conducted in support of authorization decisions are provided to authorizing officials, senior agency officials for privacy, senior agency information security officers, and authorizing official designated representatives. To satisfy annual assessment requirements, organizations can use assessment results from the following sources: initial or ongoing system authorizations, continuous monitoring, systems engineering processes, or system development life cycle activities. Organizations ensure that assessment results are current, relevant to the determination of control effectiveness, and obtained with the appropriate level of assessor independence. Existing control assessment results can be reused to the extent that the results are still valid and can also be supplemented with additional assessments as needed. After the initial authorizations, organizations assess controls during continuous monitoring. Organizations also establish the frequency for ongoing assessments in accordance with organizational continuous monitoring strategies. External audits, including audits by external entities such as regulatory agencies, are outside the scope of CA-2.",
          "Configuration management. Configuration management plan. Develop, document, and implement a configuration management plan for the system that:\n\na. Addresses roles, responsibilities, and configuration management processes and procedures.\nb. Establishes a process for identifying configuration items throughout the system development life cycle and for managing the configuration of the configuration items.\nc. Defines the configuration items for the system and places the configuration items under configuration management.\nd. Is reviewed and approved by [assignment: organization-defined personnel or roles].\ne. Protects the configuration management plan from unauthorized disclosure and modification.\n\nConfiguration management activities occur throughout the system development life cycle. As such, there are developmental configuration management activities (e.g., the control of code and software libraries) and operational configuration management activities (e.g., control of installed components and how the components are configured). Configuration management plans satisfy the requirements in configuration management policies while being tailored to individual systems.\n\nConfiguration management plans define processes and procedures for how configuration management is used to support system development life cycle activities. Configuration management plans are generated during the development and acquisition stage of the system development life cycle. The plans describe how to advance changes through change management processes, update configuration settings and baselines, maintain component inventories, control development, test, and operational environments, and develop, release, and update key documents.\n\nOrganizations can employ templates to help ensure the consistent and timely development and implementation of configuration management plans. Templates can represent a configuration management plan for the organization with subsets of the plan implemented on a system by system basis.\n\nConfiguration management approval processes include the designation of key stakeholders responsible for reviewing and approving proposed changes to systems and personnel who conduct security and privacy impact analyses prior to the implementation of changes to the systems.\n\nConfiguration items are the system components, such as the hardware, software, firmware, and documentation to be configuration-managed. As systems continue through the system development life cycle, new configuration items may be identified, and some existing configuration items may no longer need to be under configuration control.",
          "Physical and environmental protection. Physical access control. A. Enforce physical access authorizations at [assignment: organization-defined entry and exit points to the facility where the system resides] by:\n\n1. Verifying individual access authorizations before granting access to the facility.\n2. Controlling ingress and egress to the facility using [selection (one or more): [assignment: organization-defined physical access control systems or devices] or guards].\n\nB. Maintain physical access audit logs for [assignment: organization-defined entry or exit points].\n\nC. Control access to areas within the facility designated as publicly accessible by implementing the following controls: [assignment: organization-defined physical access controls].\n\nD. Escort visitors and control visitor activity [assignment: organization-defined circumstances requiring visitor escorts and control of visitor activity].\n\nE. Secure keys, combinations, and other physical access devices.\n\nF. Inventory [assignment: organization-defined physical access devices] every [assignment: organization-defined frequency].\n\nG. Change combinations and keys [assignment: organization-defined frequency] and/or when keys are lost, combinations are compromised, or when individuals possessing the keys or combinations are transferred or terminated.\n\nPhysical access control applies to employees and visitors. Individuals with permanent physical access authorizations are not considered visitors.\n\nPhysical access controls for publicly accessible areas may include physical access control logs/records, guards, or physical access devices and barriers to prevent movement from publicly accessible areas to non-public areas.\n\nOrganizations determine the types of guards needed, including professional security staff, system users, or administrative staff. Physical access devices include keys, locks, combinations, biometric readers, and card readers.\n\nPhysical access control systems comply with applicable laws, executive orders, directives, policies, regulations, standards, and guidelines. Organizations have flexibility in the types of audit logs employed. Audit logs can be procedural, automated, or some combination thereof.\n\nPhysical access points can include facility access points, interior access points to systems that require supplemental access controls, or both. Components of systems may be in areas designated as publicly accessible with organizations controlling access to the components.",
          "Contingency planning. Contingency training. A. Provide contingency training to system users consistent with assigned roles and responsibilities. \n\n1. Within the organization-defined time period of assuming a contingency role or responsibility. \n2. When required by system changes. \n3. Organization-defined frequency thereafter. \n\nB. Review and update contingency training content. \nOrganization-defined frequency and following organization-defined events. \n\nContingency training provided by organizations is linked to the assigned roles and responsibilities of organizational personnel to ensure the appropriate content and level of detail is included. For example, some individuals may only need to know when and where to report for duty during contingency operations and if normal duties are affected. System administrators may require additional training on how to establish systems at alternate processing and storage sites. Organizational officials may receive more specific training on how to conduct mission-essential functions in designated off-site locations and how to establish communications with other governmental entities for purposes of coordination on contingency-related activities. \n\nTraining for contingency roles or responsibilities reflects the specific continuity requirements in the contingency plan. Events that may precipitate an update to contingency training content include, but are not limited to, contingency plan testing or an actual contingency (lessons learned), assessment or audit findings, security incidents or breaches, or changes in laws, executive orders, directives, regulations, policies, standards, and guidelines. \n\nAt the discretion of the organization, participation in a contingency plan test or exercise, including lessons learned sessions subsequent to the test or exercise, may satisfy contingency plan training requirements.",
          "Configuration management. Configuration settings. A. Establish and document configuration settings for components employed within the system that reflect the most restrictive mode consistent with operational requirements using [assignment: organization-defined common secure configurations].\nB. Implement the configuration settings.\nC. Identify, document, and approve any deviations from established configuration settings for [assignment: organization-defined system components] based on [assignment: organization-defined operational requirements].\nD. Monitor and control changes to the configuration settings in accordance with organizational policies and procedures.\n\nConfiguration settings are the parameters that can be changed in the hardware, software, or firmware components of the system that affect the security and privacy posture or functionality of the system. Information technology products for which configuration settings can be defined include mainframe computers, servers, workstations, operating systems, mobile devices, input/output devices, protocols, and applications. Parameters that impact the security posture of systems include registry settings; account, file, or directory permission settings; and settings for functions, protocols, ports, services, and remote connections. Privacy parameters are parameters impacting the privacy posture of systems, including the parameters required to satisfy other privacy controls. Privacy parameters include settings for access controls, data processing preferences, and processing and retention permissions.\n\nOrganizations establish organization-wide configuration settings and subsequently derive specific configuration settings for systems. The established settings become part of the configuration baseline for the system. Common secure configurations (also known as security configuration checklists, lockdown and hardening guides, and security reference guides) provide recognized, standardized, and established benchmarks that stipulate secure configuration settings for information technology products and platforms as well as instructions for configuring those products or platforms to meet operational requirements. Common secure configurations can be developed by a variety of organizations, including information technology product developers, manufacturers, vendors, federal agencies, consortia, academia, industry, and other organizations in the public and private sectors.\n\nImplementation of a common secure configuration may be mandated at the organization level, mission and business process level, system level, or at a higher level, including by a regulatory agency. Common secure configurations include the United States Government Configuration Baseline (USGCB) and Security Technical Implementation Guides (STIGs), which affect the implementation of CM-6 and other controls such as AC-19 and CM-7. The Security Content Automation Protocol (SCAP) and the defined standards within the protocol provide an effective method to uniquely identify, track, and control configuration settings.",
          "Audit and accountability. Event logging. a. Identify the types of events that the system is capable of logging in support of the audit function: [Assignment: organization-defined event types that the system is capable of logging]. \nb. Coordinate the event logging function with other organizational entities requiring audit-related information to guide and inform the selection criteria for events to be logged. \nc. Specify the following event types for logging within the system: [Assignment: organization-defined event types (subset of the event types defined in AU-2a.) along with the frequency of (or situation requiring) logging for each identified event type]. \nd. Provide a rationale for why the event types selected for logging are deemed to be adequate to support after-the-fact investigations of incidents. \ne. Review and update the event types selected for logging [Assignment: organization-defined frequency].\n\nAn event is an observable occurrence in a system. The types of events that require logging are those events that are significant and relevant to the security of systems and the privacy of individuals. Event logging also supports specific monitoring and auditing needs. Event types include password changes, failed logons or failed accesses related to systems, security or privacy attribute changes, administrative privilege usage, PIV credential usage, data action changes, query parameters, or external credential usage. \n\nIn determining the set of event types that require logging, organizations consider the monitoring and auditing appropriate for each of the controls to be implemented. For completeness, event logging includes all protocols that are operational and supported by the system. To balance monitoring and auditing requirements with other system needs, event logging requires identifying the subset of event types that are logged at a given point in time. \n\nFor example, organizations may determine that systems need the capability to log every file access successful and unsuccessful, but not activate that capability except for specific circumstances due to the potential burden on system performance. The types of events that organizations desire to be logged may change. Reviewing and updating the set of logged events is necessary to help ensure that the events remain relevant and continue to support the needs of the organization. \n\nOrganizations consider how the types of logging events can reveal information about individuals that may give rise to privacy risk and how best to mitigate such risks. For example, there is the potential to reveal personally identifiable information in the audit trail, especially if the logging event is based on patterns or time of usage. Event logging requirements, including the need to log specific event types, may be referenced in other controls and control enhancements. These include AC-2(4), AC-3(10), AC-6(9), AC-17(1), CM-3f, CM-5(1), IA-3(3)(b), MA-4(1), MP-4(2), PE-3, PM-21, PT-7, RA-8, SC-7(9), SC-7(15), SI-3(8), SI-4(22), SI-7(8), and SI-10(1). \n\nOrganizations include event types that are required by applicable laws, executive orders, directives, policies, regulations, standards, and guidelines. Audit records can be generated at various levels, including at the packet level as information traverses the network. Selecting the appropriate level of event logging is an important part of a monitoring and auditing capability and can identify the root causes of problems. When defining event types, organizations consider the logging necessary to cover related event types, such as the steps in distributed, transaction-based processes, and the actions that occur in service-oriented architectures.",
          "Media protection. Media transport. a. Protect and control [assignment: organization-defined types of system media] during transport outside of controlled areas using [assignment: organization-defined controls]. b. Maintain accountability for system media during transport outside of controlled areas. c. Document activities associated with the transport of system media. d. Restrict the activities associated with the transport of system media to authorized personnel.\n\nSystem media includes digital and non-digital media. Digital media includes flash drives, diskettes, magnetic tapes, external or removable hard disk drives (e.g., solid state and magnetic), compact discs, and digital versatile discs. Non-digital media includes microfilm and paper.\n\nControlled areas are spaces for which organizations provide physical or procedural controls to meet requirements established for protecting information and systems. Controls to protect media during transport include cryptography and locked containers. Cryptographic mechanisms can provide confidentiality and integrity protections depending on the mechanisms implemented.\n\nActivities associated with media transport include releasing media for transport, ensuring that media enters the appropriate transport processes, and the actual transport. Authorized transport and courier personnel may include individuals external to the organization.\n\nMaintaining accountability of media during transport includes restricting transport activities to authorized personnel and tracking and/or obtaining records of transport activities as the media moves through the transportation system to prevent and detect loss, destruction, or tampering.\n\nOrganizations establish documentation requirements for activities associated with the transport of system media in accordance with organizational assessments of risk. Organizations maintain the flexibility to define record-keeping methods for the different types of media transport as part of a system of transport-related records.",
          null
         ],
         "marker": {
          "opacity": 0.5,
          "size": 5
         },
         "mode": "markers+text",
         "name": "2_and_the_or",
         "text": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "2_and_the_or"
         ],
         "textfont": {
          "size": 12
         },
         "type": "scattergl",
         "x": [
          2.8560056686401367,
          4.222026348114014,
          3.1519923210144043,
          3.402888298034668,
          3.37674880027771,
          3.448335886001587,
          3.363102674484253,
          3.4087822437286377,
          2.684760093688965,
          4.530116081237793,
          3.898359775543213,
          3.638746738433838,
          3.418184757232666,
          2.765678882598877,
          4.412297248840332,
          3.2633564472198486,
          4.157210826873779,
          4.8063507080078125,
          3.4591190814971924,
          3.045978307723999,
          2.470386505126953,
          3.3910233974456787,
          4.352839469909668,
          3.880861282348633,
          3.8481898307800293,
          3.1630449295043945,
          3.950021743774414,
          2.975062370300293,
          2.8905398845672607,
          4.365279197692871,
          3.011531114578247,
          3.2290852069854736,
          3.440096616744995,
          3.8778624534606934,
          2.5951271057128906,
          3.119220495223999,
          4.512389183044434,
          3.022451162338257,
          4.344272136688232,
          4.608955383300781,
          3.179363965988159,
          3.347419261932373,
          4.267749786376953,
          4.068497180938721,
          4.1050567626953125,
          3.293935537338257,
          4.572999477386475,
          3.5248634815216064,
          4.466452598571777,
          4.557386875152588,
          5.007942199707031,
          3.789548635482788,
          3.045701742172241,
          5.060023307800293,
          4.347223281860352,
          3.55226469039917,
          4.596632957458496,
          3.673508644104004,
          4.141941070556641,
          4.289268970489502,
          3.3879435062408447,
          3.4147586822509766,
          4.685823917388916,
          4.039169788360596,
          3.919567108154297,
          4.659019947052002,
          2.7279744148254395,
          4.363094806671143,
          4.821366786956787,
          4.2423882484436035,
          3.0036208629608154,
          3.02150297164917,
          3.411550283432007,
          3.240753173828125,
          3.821498155593872,
          3.240875244140625,
          4.347489833831787,
          3.388244152069092,
          3.2463529109954834,
          4.331313610076904,
          3.538330554962158,
          3.5129926204681396,
          3.647831439971924,
          3.1298611164093018,
          3.001800537109375,
          3.594465494155884,
          3.548098087310791,
          3.4252471923828125,
          3.174487829208374,
          3.070338249206543,
          3.048945665359497,
          3.1904795169830322,
          4.325555324554443,
          2.4758658409118652,
          4.932031631469727,
          2.9589385986328125,
          3.2780492305755615,
          3.87524151802063,
          4.774768829345703,
          3.022449016571045,
          3.2812485694885254,
          3.8512279987335205,
          3.3519740104675293,
          3.332146406173706,
          4.842337608337402,
          4.141049385070801,
          3.4946582317352295,
          4.198677062988281,
          4.918118476867676,
          3.701812982559204
         ],
         "y": [
          -0.3664076030254364,
          -1.7100434303283691,
          -0.8347870111465454,
          -1.9987338781356812,
          -1.2103426456451416,
          -2.01887845993042,
          -1.4439383745193481,
          0.043082352727651596,
          -0.30811411142349243,
          -1.5330657958984375,
          -1.363092064857483,
          -1.4172662496566772,
          -1.2054283618927002,
          0.12419748306274414,
          -1.612414836883545,
          -2.116279125213623,
          -0.8827857375144958,
          -1.4212981462478638,
          -2.133535861968994,
          -0.17212289571762085,
          -0.17396633327007294,
          -1.0087761878967285,
          -1.2535595893859863,
          -1.0102163553237915,
          -0.9279821515083313,
          0.10651201754808426,
          -0.842820942401886,
          -0.24251696467399597,
          -0.3009662926197052,
          -1.9373531341552734,
          -0.38647696375846863,
          -1.7754648923873901,
          0.026817118749022484,
          -1.6491057872772217,
          -0.27121177315711975,
          -0.1407018005847931,
          -1.4905983209609985,
          -1.9536371231079102,
          -1.99004328250885,
          -1.2772860527038574,
          -0.7031552195549011,
          -1.6657757759094238,
          -1.60244619846344,
          -1.4595434665679932,
          -1.2774274349212646,
          0.049614064395427704,
          -1.1805123090744019,
          -2.093153238296509,
          -1.5633819103240967,
          -1.4212394952774048,
          -1.2621287107467651,
          -1.102551817893982,
          -0.02859243005514145,
          -1.1881523132324219,
          -2.0215916633605957,
          -2.0203824043273926,
          -1.3208624124526978,
          -1.0201715230941772,
          -1.5045098066329956,
          -1.4971452951431274,
          -1.3389220237731934,
          -2.095914602279663,
          -1.4356354475021362,
          -1.3358535766601562,
          -1.4631115198135376,
          -1.1761326789855957,
          0.1506408154964447,
          -1.979392647743225,
          -1.1700226068496704,
          -1.151410698890686,
          -0.397884726524353,
          -1.9528074264526367,
          -0.6664084792137146,
          -1.654050350189209,
          -1.1282069683074951,
          -1.6869235038757324,
          -1.9886534214019775,
          -2.1085052490234375,
          -1.6260933876037598,
          -1.972511649131775,
          -2.093141555786133,
          -1.9871621131896973,
          -1.447832703590393,
          -1.6460603475570679,
          -1.957970142364502,
          -1.858017921447754,
          -1.359387755393982,
          -1.925484538078308,
          -0.58873051404953,
          -0.369812548160553,
          -0.5152189135551453,
          -0.16521060466766357,
          -1.9859424829483032,
          -0.1624409258365631,
          -1.3016700744628906,
          -1.9721672534942627,
          0.02518395334482193,
          -1.8981237411499023,
          -1.418622374534607,
          -0.003816819516941905,
          -2.0161726474761963,
          -1.9266513586044312,
          -2.1089296340942383,
          -1.5658272504806519,
          -1.3752732276916504,
          -1.875742793083191,
          -1.5511130094528198,
          -1.2525166273117065,
          -1.3251380920410156,
          -1.2456012964248657
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "text": "D1",
          "x": -4.152150511741638,
          "y": 2.620018595457077,
          "yshift": 10
         },
         {
          "showarrow": false,
          "text": "D2",
          "x": 5.781020605564118,
          "xshift": 10,
          "y": 7.753790354728698
         }
        ],
        "height": 750,
        "legend": {
         "bordercolor": "Black",
         "borderwidth": 1
        },
        "shapes": [
         {
          "line": {
           "color": "#CFD8DC",
           "width": 2
          },
          "type": "line",
          "x0": 5.781020605564118,
          "x1": 5.781020605564118,
          "y0": -2.5137531638145445,
          "y1": 7.753790354728698
         },
         {
          "line": {
           "color": "#9E9E9E",
           "width": 2
          },
          "type": "line",
          "x0": -4.152150511741638,
          "x1": 15.714191722869874,
          "y0": 2.620018595457077,
          "y1": 2.620018595457077
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.6
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(237,237,237)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(217,217,217)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 1,
            "tickcolor": "rgb(36,36,36)",
            "ticks": "outside"
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "rgb(103,0,31)"
            ],
            [
             0.1,
             "rgb(178,24,43)"
            ],
            [
             0.2,
             "rgb(214,96,77)"
            ],
            [
             0.3,
             "rgb(244,165,130)"
            ],
            [
             0.4,
             "rgb(253,219,199)"
            ],
            [
             0.5,
             "rgb(247,247,247)"
            ],
            [
             0.6,
             "rgb(209,229,240)"
            ],
            [
             0.7,
             "rgb(146,197,222)"
            ],
            [
             0.8,
             "rgb(67,147,195)"
            ],
            [
             0.9,
             "rgb(33,102,172)"
            ],
            [
             1,
             "rgb(5,48,97)"
            ]
           ],
           "sequential": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ]
          },
          "colorway": [
           "#1F77B4",
           "#FF7F0E",
           "#2CA02C",
           "#D62728",
           "#9467BD",
           "#8C564B",
           "#E377C2",
           "#7F7F7F",
           "#BCBD22",
           "#17BECF"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           }
          },
          "shapedefaults": {
           "fillcolor": "black",
           "line": {
            "width": 0
           },
           "opacity": 0.3
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "baxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          }
         }
        },
        "title": {
         "text": "Topic clusters (BERT finetuned)"
        },
        "width": 1200,
        "xaxis": {
         "visible": false
        },
        "yaxis": {
         "visible": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize Topics\n",
    "fig = topic_model.visualize_documents(docs, embeddings=embeddings)\n",
    "fig.update_layout(\n",
    "    title=\"Topic clusters (BERT finetuned)\",\n",
    "    legend=dict(bordercolor=\"Black\", borderwidth=1),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preferred topic modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do most of the rest of the BERTopic algorithm in one function\n",
    "<!-- - Dimensionality reduction\n",
    "- Clustering\n",
    "- Tokenizer\n",
    "- Weighting Scheme -->\n",
    "\n",
    "\n",
    "- Step 1 - Extract embeddings (though we pre-calculated ours)\n",
    "\n",
    "` embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")`\n",
    "\n",
    "- Step 2 - Reduce dimensionality\n",
    "\n",
    "`umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine')`\n",
    "\n",
    "- Step 3 - Cluster reduced embeddings\n",
    "\n",
    "`hdbscan_model = HDBSCAN(min_cluster_size=15, metric='euclidean', cluster_selection_method='eom', prediction_data=True)`\n",
    "\n",
    "- Step 4 - Tokenize topics\n",
    "\n",
    "`vectorizer_model = CountVectorizer(stop_words=\"english\")`\n",
    "\n",
    "- Step 5 - Create topic representation\n",
    "\n",
    "`ctfidf_model = ClassTfidfTransformer()`\n",
    "\n",
    "- Step 6 - (Optional but strongly recommended) Fine-tune topic representations \n",
    "\n",
    "`representation_model=representation_model` \n",
    "\n",
    "See [documentation](https://maartengr.github.io/BERTopic/getting_started/parameter%20tuning/parametertuning.html#min_topic_size \"More info on minimum topic size and other parameters\") for more on min_topic_size and other parameter choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, models\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name ../outputs/fine_tuned_model. Creating a new one with mean pooling.\n",
      "2024-08-29 15:02:45,837 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-08-29 15:02:46,942 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-08-29 15:02:46,945 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-08-29 15:02:47,012 - BERTopic - Cluster - Completed ✓\n",
      "2024-08-29 15:02:47,013 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-08-29 15:02:58,442 - BERTopic - Representation - Completed ✓\n",
      "2024-08-29 15:02:58,568 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-08-29 15:02:59,608 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-08-29 15:02:59,608 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-08-29 15:02:59,733 - BERTopic - Cluster - Completed ✓\n",
      "2024-08-29 15:02:59,734 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-08-29 15:03:07,767 - BERTopic - Representation - Completed ✓\n"
     ]
    }
   ],
   "source": [
    "# Load fine-tuned sentence-transformers model\n",
    "# model_path = \"outputs/sentence_transformers_compatible_model\"\n",
    "model_path = \"../outputs/fine_tuned_model\"\n",
    "finetuned_model = SentenceTransformer(model_path)\n",
    "\n",
    "# Load pre-generated embeddings\n",
    "pre_generated_embeddings = list(df['finetuned_embeddings'].values)\n",
    "pre_generated_embeddings = np.array(pre_generated_embeddings)\n",
    "\n",
    "# specifying dimensionality reduction\n",
    "umap_model = UMAP(n_neighbors=15, n_components=5, metric='cosine', low_memory=False, random_state=42)  # may need to tweak\n",
    "\n",
    "# specifying cluster model\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=2, metric='euclidean', prediction_data=True)  # To Do: check with new min cluster size\n",
    "\n",
    "# better stop words handling\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\", min_df=2, ngram_range=(1, 3))\n",
    "\n",
    "# Create a representation model, 3 parts\n",
    "keybert_model = KeyBERTInspired(random_state=42)\n",
    "mmr_model = MaximalMarginalRelevance(diversity=0.3)\n",
    "representation_model = {\n",
    "    \"KeyBERT\": keybert_model,\n",
    "    # \"OpenAI\": openai_model,  # Uncomment if you will use OpenAI\n",
    "    \"MMR\": mmr_model\n",
    "}\n",
    "\n",
    "# Instantiate BERTopic with fine-tuned model's embeddings and the representation model\n",
    "topic_model = BERTopic(embedding_model=finetuned_model,\n",
    "                       umap_model=umap_model,\n",
    "                       hdbscan_model=hdbscan_model,\n",
    "                       vectorizer_model=vectorizer_model,\n",
    "                       verbose=True,\n",
    "                       n_gram_range=(1, 3),\n",
    "                       min_topic_size=5,\n",
    "                       calculate_probabilities=True,\n",
    "                       representation_model=representation_model).fit(docs, embeddings)\n",
    "\n",
    "topics, probs = topic_model.fit_transform(docs, embeddings)\n",
    "\n",
    "# note that embedding_model=finetuned_model doesn't remake embeddings. see https://github.com/MaartenGr/BERTopic/issues/1601                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>KeyBERT</th>\n",
       "      <th>MMR</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1_information_time_organization_organization defined</td>\n",
       "      <td>[information, time, organization, organization defined, defined, training, communications, integrity, assignment organization, assignment organization defined]</td>\n",
       "      <td>[information integrity monitoring, unauthorized, software firmware information, software firmware, firmware information, organizational systems, communications traffic, criticality analysis, inbou...</td>\n",
       "      <td>[information, time, organization, organization defined, defined, training, communications, integrity, assignment organization, assignment organization defined]</td>\n",
       "      <td>[System and information integrity. Software, firmware, and information integrity. a. Employ integrity verification tools to detect unauthorized changes to the following software, firmware, and inf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>0_cloud_criterion_cloud service_service</td>\n",
       "      <td>[cloud, criterion, cloud service, service, service provider, provider, cloud service provider, continuous, customer, data]</td>\n",
       "      <td>[continuous auditing feasibility, auditing feasibility, auditing feasibility partially, cloud service provider, notes continuous auditing, supplementary information criterion, continuous auditing,...</td>\n",
       "      <td>[cloud, criterion, cloud service, service, service provider, provider, cloud service provider, continuous, customer, data]</td>\n",
       "      <td>[Dealing with investigation requests from government agencies (inq). Informing cloud customers about investigation requests. Basic criterion: The cloud service provider informs the affected cloud ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>1_privacy_organization_procedures_security privacy</td>\n",
       "      <td>[privacy, organization, procedures, security privacy, security, policy, systems, organization defined, defined, organizations]</td>\n",
       "      <td>[executive orders directives, policies standards guidelines, orders directives regulations, directives regulations policies, orders directives, directives regulations, risk management, organizatio...</td>\n",
       "      <td>[privacy, organization, procedures, security privacy, security, policy, systems, organization defined, defined, organizations]</td>\n",
       "      <td>[Maintenance. Policy and procedures. A. Develop, document, and disseminate to organization-defined personnel or roles:\\n\\n1. Organization-level maintenance policy that addresses purpose, scope, ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>2_audit_audit records_records_audit record</td>\n",
       "      <td>[audit, audit records, records, audit record, record, audit accountability, event, accountability, audit information, audit accountability audit]</td>\n",
       "      <td>[audit accountability audit, accountability audit, audit accountability, accountability audit record, repositories, audit log storage, audit record review, accountability, correlate, review analys...</td>\n",
       "      <td>[audit, audit records, records, audit record, record, audit accountability, event, accountability, audit information, audit accountability audit]</td>\n",
       "      <td>[Audit and accountability. Content of audit records | additional audit information. Generate audit records containing the following additional information: [assignment: organization-defined additi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>3_authentication_identity_authenticators_identification authentication</td>\n",
       "      <td>[authentication, identity, authenticators, identification authentication, identification, credentials, organizational users, non, users, piv]</td>\n",
       "      <td>[identification authentication authenticator, authentication authenticator management, authentication identification authentication, personal identity verification, authentication authenticator, a...</td>\n",
       "      <td>[authentication, identity, authenticators, identification authentication, identification, credentials, organizational users, non, users, piv]</td>\n",
       "      <td>[Identification and authentication. Identification and authentication (non-organizational users) | acceptance of external authenticators. (a) Accept only external authenticators that are NIST-comp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  ...                                                                                                                                                                                      Representative_Docs\n",
       "0     -1  ...  [System and information integrity. Software, firmware, and information integrity. a. Employ integrity verification tools to detect unauthorized changes to the following software, firmware, and inf...\n",
       "1      0  ...  [Dealing with investigation requests from government agencies (inq). Informing cloud customers about investigation requests. Basic criterion: The cloud service provider informs the affected cloud ...\n",
       "2      1  ...  [Maintenance. Policy and procedures. A. Develop, document, and disseminate to organization-defined personnel or roles:\\n\\n1. Organization-level maintenance policy that addresses purpose, scope, ro...\n",
       "3      2  ...  [Audit and accountability. Content of audit records | additional audit information. Generate audit records containing the following additional information: [assignment: organization-defined additi...\n",
       "4      3  ...  [Identification and authentication. Identification and authentication (non-organizational users) | acceptance of external authenticators. (a) Accept only external authenticators that are NIST-comp...\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check results\n",
    "topic_model.get_topic_info().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.678373292383996,
          0.678373292383996,
          0
         ],
         "xaxis": "x",
         "y": [
          -15,
          -15,
          -25,
          -25
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.678373292383996,
          0.7350907177771527,
          0.7350907177771527,
          0
         ],
         "xaxis": "x",
         "y": [
          -20,
          -20,
          -35,
          -35
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.8250872173967346,
          0.8250872173967346,
          0.7350907177771527
         ],
         "xaxis": "x",
         "y": [
          -5,
          -5,
          -27.5,
          -27.5
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(255,65,54)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.7406858630259534,
          0.7406858630259534,
          0
         ],
         "xaxis": "x",
         "y": [
          -45,
          -45,
          -55,
          -55
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(35,205,205)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.42590322315753626,
          0.42590322315753626,
          0
         ],
         "xaxis": "x",
         "y": [
          -65,
          -65,
          -75,
          -75
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.7406858630259534,
          1.0614088745543024,
          1.0614088745543024,
          0.42590322315753626
         ],
         "xaxis": "x",
         "y": [
          -50,
          -50,
          -70,
          -70
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(133,20,75)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.7474718705108474,
          0.7474718705108474,
          0
         ],
         "xaxis": "x",
         "y": [
          -85,
          -85,
          -95,
          -95
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(255,220,0)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.7511759833580698,
          0.7511759833580698,
          0
         ],
         "xaxis": "x",
         "y": [
          -115,
          -115,
          -125,
          -125
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(255,220,0)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.7784952426229951,
          0.7784952426229951,
          0.7511759833580698
         ],
         "xaxis": "x",
         "y": [
          -105,
          -105,
          -120,
          -120
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.7474718705108474,
          1.0857470750071614,
          1.0857470750071614,
          0.7784952426229951
         ],
         "xaxis": "x",
         "y": [
          -90,
          -90,
          -112.5,
          -112.5
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(40,35,35)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.7937071309839826,
          0.7937071309839826,
          0
         ],
         "xaxis": "x",
         "y": [
          -135,
          -135,
          -145,
          -145
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(40,35,35)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.7592242617182938,
          0.7592242617182938,
          0
         ],
         "xaxis": "x",
         "y": [
          -165,
          -165,
          -175,
          -175
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(40,35,35)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.848727806750946,
          0.848727806750946,
          0.7592242617182938
         ],
         "xaxis": "x",
         "y": [
          -155,
          -155,
          -170,
          -170
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(40,35,35)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.7937071309839826,
          0.9252853477398404,
          0.9252853477398404,
          0.848727806750946
         ],
         "xaxis": "x",
         "y": [
          -140,
          -140,
          -162.5,
          -162.5
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.8653175229493681,
          0.8653175229493681,
          0
         ],
         "xaxis": "x",
         "y": [
          -185,
          -185,
          -195,
          -195
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.9252853477398404,
          1.0056960024770563,
          1.0056960024770563,
          0.8653175229493681
         ],
         "xaxis": "x",
         "y": [
          -151.25,
          -151.25,
          -190,
          -190
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          1.0857470750071614,
          1.1203108027118833,
          1.1203108027118833,
          1.0056960024770563
         ],
         "xaxis": "x",
         "y": [
          -101.25,
          -101.25,
          -170.625,
          -170.625
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(255,65,54)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.7003425484006081,
          0.7003425484006081,
          0
         ],
         "xaxis": "x",
         "y": [
          -215,
          -215,
          -225,
          -225
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(255,65,54)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.8869300196248829,
          0.8869300196248829,
          0.7003425484006081
         ],
         "xaxis": "x",
         "y": [
          -205,
          -205,
          -220,
          -220
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          1.1203108027118833,
          1.2052580606759997,
          1.2052580606759997,
          0.8869300196248829
         ],
         "xaxis": "x",
         "y": [
          -135.9375,
          -135.9375,
          -212.5,
          -212.5
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          1.0614088745543024,
          1.2579083677018348,
          1.2579083677018348,
          1.2052580606759997
         ],
         "xaxis": "x",
         "y": [
          -60,
          -60,
          -174.21875,
          -174.21875
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(35,205,205)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.8230393712746744,
          0.8230393712746744,
          0
         ],
         "xaxis": "x",
         "y": [
          -235,
          -235,
          -245,
          -245
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.7702168106852181,
          0.7702168106852181,
          0
         ],
         "xaxis": "x",
         "y": [
          -265,
          -265,
          -275,
          -275
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.8679439779917446,
          0.8679439779917446,
          0.7702168106852181
         ],
         "xaxis": "x",
         "y": [
          -255,
          -255,
          -270,
          -270
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.8679439779917446,
          0.9096853060310948,
          0.9096853060310948,
          0
         ],
         "xaxis": "x",
         "y": [
          -262.5,
          -262.5,
          -285,
          -285
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.6472701610473284,
          0.6472701610473284,
          0
         ],
         "xaxis": "x",
         "y": [
          -305,
          -305,
          -315,
          -315
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.6472701610473284,
          0.7411935253024722,
          0.7411935253024722,
          0
         ],
         "xaxis": "x",
         "y": [
          -310,
          -310,
          -325,
          -325
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.8327765903914003,
          0.8327765903914003,
          0.7411935253024722
         ],
         "xaxis": "x",
         "y": [
          -295,
          -295,
          -317.5,
          -317.5
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.8327765903914003,
          0.9085702604471104,
          0.9085702604471104,
          0
         ],
         "xaxis": "x",
         "y": [
          -306.25,
          -306.25,
          -335,
          -335
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.9096853060310948,
          0.9729750242661918,
          0.9729750242661918,
          0.9085702604471104
         ],
         "xaxis": "x",
         "y": [
          -273.75,
          -273.75,
          -320.625,
          -320.625
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.8230393712746744,
          1.067987458882716,
          1.067987458882716,
          0.9729750242661918
         ],
         "xaxis": "x",
         "y": [
          -240,
          -240,
          -297.1875,
          -297.1875
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(255,65,54)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.680463194178179,
          0.680463194178179,
          0
         ],
         "xaxis": "x",
         "y": [
          -345,
          -345,
          -355,
          -355
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(255,65,54)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.680463194178179,
          0.8019123508007217,
          0.8019123508007217,
          0
         ],
         "xaxis": "x",
         "y": [
          -350,
          -350,
          -365,
          -365
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          1.067987458882716,
          1.139438637585983,
          1.139438637585983,
          0.8019123508007217
         ],
         "xaxis": "x",
         "y": [
          -268.59375,
          -268.59375,
          -357.5,
          -357.5
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(35,205,205)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.7568662420534117,
          0.7568662420534117,
          0
         ],
         "xaxis": "x",
         "y": [
          -385,
          -385,
          -395,
          -395
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(35,205,205)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.851928808029965,
          0.851928808029965,
          0.7568662420534117
         ],
         "xaxis": "x",
         "y": [
          -375,
          -375,
          -390,
          -390
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(133,20,75)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.676852259052571,
          0.676852259052571,
          0
         ],
         "xaxis": "x",
         "y": [
          -405,
          -405,
          -415,
          -415
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(255,220,0)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.8519478553193212,
          0.8519478553193212,
          0
         ],
         "xaxis": "x",
         "y": [
          -425,
          -425,
          -435,
          -435
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.676852259052571,
          1.028391345194479,
          1.028391345194479,
          0.8519478553193212
         ],
         "xaxis": "x",
         "y": [
          -410,
          -410,
          -430,
          -430
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.851928808029965,
          1.0881106908723805,
          1.0881106908723805,
          1.028391345194479
         ],
         "xaxis": "x",
         "y": [
          -382.5,
          -382.5,
          -420,
          -420
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          1.139438637585983,
          1.2903296650127354,
          1.2903296650127354,
          1.0881106908723805
         ],
         "xaxis": "x",
         "y": [
          -313.046875,
          -313.046875,
          -401.25,
          -401.25
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          1.2579083677018348,
          1.3560375913962954,
          1.3560375913962954,
          1.2903296650127354
         ],
         "xaxis": "x",
         "y": [
          -117.109375,
          -117.109375,
          -357.1484375,
          -357.1484375
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.8250872173967346,
          1.4127051309018603,
          1.4127051309018603,
          1.3560375913962954
         ],
         "xaxis": "x",
         "y": [
          -16.25,
          -16.25,
          -237.12890625,
          -237.12890625
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "autosize": false,
        "height": 860,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "hovermode": "closest",
        "plot_bgcolor": "#ECEFF1",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Hierarchical Clustering</b>",
         "x": 0.5,
         "xanchor": "center",
         "yanchor": "top"
        },
        "width": 1000,
        "xaxis": {
         "mirror": "allticks",
         "rangemode": "tozero",
         "showgrid": false,
         "showline": true,
         "showticklabels": true,
         "ticks": "outside",
         "type": "linear",
         "zeroline": false
        },
        "yaxis": {
         "mirror": "allticks",
         "range": [
          -440,
          0
         ],
         "rangemode": "tozero",
         "showgrid": false,
         "showline": true,
         "showticklabels": true,
         "tickmode": "array",
         "ticks": "outside",
         "ticktext": [
          "35_recovery_reconstitution_...",
          "15_contingency_plan_conting...",
          "8_alternate_site_alternate ...",
          "21_telecommunications_telec...",
          "40_contaminated_corrective ...",
          "34_discoverable_vulnerabili...",
          "9_vulnerabilities_vulnerabi...",
          "0_cloud_criterion_cloud ser...",
          "19_transaction_configuratio...",
          "22_tamper_resistance_compon...",
          "24_assessments_red team exe...",
          "17_testing_coverage_penetra...",
          "20_passwords_penetration_pe...",
          "28_integrity_information in...",
          "25_detection_intrusion dete...",
          "10_configuration_inventory_...",
          "29_alerts_generated_alerts ...",
          "23_monitoring_impact analys...",
          "27_services_locations_infor...",
          "4_incident_incident respons...",
          "33_products_acquisition_com...",
          "38_ports protocols services...",
          "39_information processed_co...",
          "37_media_sanitization_digital",
          "12_wireless_wireless access...",
          "32_program_restrictions_acc...",
          "6_privileged_access_privile...",
          "36_access agreements_agreem...",
          "18_sa_security functions_sa...",
          "3_authentication_identity_a...",
          "16_personnel_individuals_ma...",
          "1_privacy_organization_proc...",
          "5_accounts_account_usage",
          "2_audit_audit records_records",
          "11_maintenance_maintenance ...",
          "13_physical_physical access...",
          "7_power_emergency_environme...",
          "41_memory_boundary protecti...",
          "31_shared resources_resourc...",
          "30_host_host based_based",
          "14_cryptographic_cryptograp...",
          "43_cryptographic_confidenti...",
          "26_encryption_flow_authenti...",
          "42_sessions_network_session"
         ],
         "tickvals": [
          -5,
          -15,
          -25,
          -35,
          -45,
          -55,
          -65,
          -75,
          -85,
          -95,
          -105,
          -115,
          -125,
          -135,
          -145,
          -155,
          -165,
          -175,
          -185,
          -195,
          -205,
          -215,
          -225,
          -235,
          -245,
          -255,
          -265,
          -275,
          -285,
          -295,
          -305,
          -315,
          -325,
          -335,
          -345,
          -355,
          -365,
          -375,
          -385,
          -395,
          -405,
          -415,
          -425,
          -435
         ],
         "type": "linear",
         "zeroline": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize hierarchy\n",
    "topic_model.visualize_hierarchy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Topics\n",
    "\n",
    "- In BERTopic, you can use .merge_topics to manually select and merge those topics. \n",
    "- Doing so will update their topic representation which in turn updates the entire model\n",
    "- You can also track the merges and other changes in topics and their mappings with the [BERTopic.topic_mapper_](https://maartengr.github.io/BERTopic/api/bertopic.html) class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge topics\n",
    "topics_to_merge = [[11, 13],  # perhaps we want to merge physical access and maintenance topics\n",
    "                   [6, 36]]  # perhaps we want to merge topics that seem to deal with \"access\"\"\n",
    "topic_model.merge_topics(docs, topics_to_merge)\n",
    "            \n",
    "# merging and updating topic model:\n",
    "topic_model.merge_topics(docs, topics_to_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see updated topics - these are just topic numbers for each of our documents\n",
    "# topic_model.topics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.6762305835749479,
          0.6762305835749479,
          0
         ],
         "xaxis": "x",
         "y": [
          -15,
          -15,
          -25,
          -25
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.6762305835749479,
          0.7335609370022939,
          0.7335609370022939,
          0
         ],
         "xaxis": "x",
         "y": [
          -20,
          -20,
          -35,
          -35
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.8233104210204211,
          0.8233104210204211,
          0.7335609370022939
         ],
         "xaxis": "x",
         "y": [
          -5,
          -5,
          -27.5,
          -27.5
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(255,65,54)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.7386530488314869,
          0.7386530488314869,
          0
         ],
         "xaxis": "x",
         "y": [
          -45,
          -45,
          -55,
          -55
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(35,205,205)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.42196412409566664,
          0.42196412409566664,
          0
         ],
         "xaxis": "x",
         "y": [
          -65,
          -65,
          -75,
          -75
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.7386530488314869,
          1.0610357535880648,
          1.0610357535880648,
          0.42196412409566664
         ],
         "xaxis": "x",
         "y": [
          -50,
          -50,
          -70,
          -70
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(133,20,75)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.621617011579036,
          0.621617011579036,
          0
         ],
         "xaxis": "x",
         "y": [
          -105,
          -105,
          -115,
          -115
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(133,20,75)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.621617011579036,
          0.7327176544760514,
          0.7327176544760514,
          0
         ],
         "xaxis": "x",
         "y": [
          -110,
          -110,
          -125,
          -125
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(133,20,75)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.7575594804432297,
          0.7575594804432297,
          0.7327176544760514
         ],
         "xaxis": "x",
         "y": [
          -95,
          -95,
          -117.5,
          -117.5
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(133,20,75)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.7575594804432297,
          0.8421956833532769,
          0.8421956833532769,
          0
         ],
         "xaxis": "x",
         "y": [
          -106.25,
          -106.25,
          -135,
          -135
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(133,20,75)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.906764872023437,
          0.906764872023437,
          0.8421956833532769
         ],
         "xaxis": "x",
         "y": [
          -85,
          -85,
          -120.625,
          -120.625
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(255,220,0)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.7118479466664378,
          0.7118479466664378,
          0
         ],
         "xaxis": "x",
         "y": [
          -145,
          -145,
          -155,
          -155
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.906764872023437,
          1.0303138552596198,
          1.0303138552596198,
          0.7118479466664378
         ],
         "xaxis": "x",
         "y": [
          -102.8125,
          -102.8125,
          -150,
          -150
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(40,35,35)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.821563699063259,
          0.821563699063259,
          0
         ],
         "xaxis": "x",
         "y": [
          -165,
          -165,
          -175,
          -175
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          1.0303138552596198,
          1.0537409943593887,
          1.0537409943593887,
          0.821563699063259
         ],
         "xaxis": "x",
         "y": [
          -126.40625,
          -126.40625,
          -170,
          -170
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.7489065021038308,
          0.7489065021038308,
          0
         ],
         "xaxis": "x",
         "y": [
          -185,
          -185,
          -195,
          -195
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.7489065021038308,
          0.7754523542489632,
          0.7754523542489632,
          0
         ],
         "xaxis": "x",
         "y": [
          -190,
          -190,
          -205,
          -205
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(255,65,54)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.7451642217073357,
          0.7451642217073357,
          0
         ],
         "xaxis": "x",
         "y": [
          -215,
          -215,
          -225,
          -225
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(35,205,205)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.8724437915719236,
          0.8724437915719236,
          0
         ],
         "xaxis": "x",
         "y": [
          -245,
          -245,
          -255,
          -255
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(35,205,205)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.9473183080245439,
          0.9473183080245439,
          0.8724437915719236
         ],
         "xaxis": "x",
         "y": [
          -235,
          -235,
          -250,
          -250
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.7451642217073357,
          1.0577856049508503,
          1.0577856049508503,
          0.9473183080245439
         ],
         "xaxis": "x",
         "y": [
          -220,
          -220,
          -242.5,
          -242.5
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.7754523542489632,
          1.0991862632863645,
          1.0991862632863645,
          1.0577856049508503
         ],
         "xaxis": "x",
         "y": [
          -197.5,
          -197.5,
          -231.25,
          -231.25
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          1.0537409943593887,
          1.1203175570990136,
          1.1203175570990136,
          1.0991862632863645
         ],
         "xaxis": "x",
         "y": [
          -148.203125,
          -148.203125,
          -214.375,
          -214.375
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.8628382744364191,
          0.8628382744364191,
          0
         ],
         "xaxis": "x",
         "y": [
          -265,
          -265,
          -275,
          -275
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(61,153,112)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.8628382744364191,
          0.9209938522286489,
          0.9209938522286489,
          0
         ],
         "xaxis": "x",
         "y": [
          -270,
          -270,
          -285,
          -285
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(255,65,54)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.7568010875621718,
          0.7568010875621718,
          0
         ],
         "xaxis": "x",
         "y": [
          -295,
          -295,
          -305,
          -305
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(255,65,54)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.7906912278372283,
          0.7906912278372283,
          0
         ],
         "xaxis": "x",
         "y": [
          -315,
          -315,
          -325,
          -325
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(255,65,54)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.7568010875621718,
          0.9332690909168819,
          0.9332690909168819,
          0.7906912278372283
         ],
         "xaxis": "x",
         "y": [
          -300,
          -300,
          -320,
          -320
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.9209938522286489,
          1.0078184346639312,
          1.0078184346639312,
          0.9332690909168819
         ],
         "xaxis": "x",
         "y": [
          -277.5,
          -277.5,
          -310,
          -310
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          1.1203175570990136,
          1.173561589938041,
          1.173561589938041,
          1.0078184346639312
         ],
         "xaxis": "x",
         "y": [
          -181.2890625,
          -181.2890625,
          -293.75,
          -293.75
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(35,205,205)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.8505413042878286,
          0.8505413042878286,
          0
         ],
         "xaxis": "x",
         "y": [
          -335,
          -335,
          -345,
          -345
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(35,205,205)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.7606670157534969,
          0.7606670157534969,
          0
         ],
         "xaxis": "x",
         "y": [
          -355,
          -355,
          -365,
          -365
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(35,205,205)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.8505413042878286,
          0.9786407979275903,
          0.9786407979275903,
          0.7606670157534969
         ],
         "xaxis": "x",
         "y": [
          -340,
          -340,
          -360,
          -360
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(133,20,75)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0,
          0.7543525006813789,
          0.7543525006813789,
          0
         ],
         "xaxis": "x",
         "y": [
          -375,
          -375,
          -385,
          -385
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(133,20,75)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.7543525006813789,
          0.8501840921513234,
          0.8501840921513234,
          0
         ],
         "xaxis": "x",
         "y": [
          -380,
          -380,
          -395,
          -395
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.9786407979275903,
          1.0765229813492698,
          1.0765229813492698,
          0.8501840921513234
         ],
         "xaxis": "x",
         "y": [
          -350,
          -350,
          -387.5,
          -387.5
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          1.173561589938041,
          1.244164564856564,
          1.244164564856564,
          1.0765229813492698
         ],
         "xaxis": "x",
         "y": [
          -237.51953125,
          -237.51953125,
          -368.75,
          -368.75
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          1.0610357535880648,
          1.2832365219308182,
          1.2832365219308182,
          1.244164564856564
         ],
         "xaxis": "x",
         "y": [
          -60,
          -60,
          -303.134765625,
          -303.134765625
         ],
         "yaxis": "y"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(0,116,217)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.8233104210204211,
          1.4123108946664293,
          1.4123108946664293,
          1.2832365219308182
         ],
         "xaxis": "x",
         "y": [
          -16.25,
          -16.25,
          -181.5673828125,
          -181.5673828125
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "autosize": false,
        "height": 800,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "hovermode": "closest",
        "plot_bgcolor": "#ECEFF1",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Hierarchical Clustering</b>",
         "x": 0.5,
         "xanchor": "center",
         "yanchor": "top"
        },
        "width": 1000,
        "xaxis": {
         "mirror": "allticks",
         "rangemode": "tozero",
         "showgrid": false,
         "showline": true,
         "showticklabels": true,
         "ticks": "outside",
         "type": "linear",
         "zeroline": false
        },
        "yaxis": {
         "mirror": "allticks",
         "range": [
          -400,
          0
         ],
         "rangemode": "tozero",
         "showgrid": false,
         "showline": true,
         "showticklabels": true,
         "tickmode": "array",
         "ticks": "outside",
         "ticktext": [
          "30_recovery_reconstitution_...",
          "14_contingency_plan_conting...",
          "10_alternate_site_alternate...",
          "15_telecommunications_telec...",
          "36_contaminated_corrective ...",
          "27_discoverable_vulnerabili...",
          "11_vulnerabilities_vulnerab...",
          "0_cloud_criterion_cloud ser...",
          "26_program_restrictions_acc...",
          "13_personnel_individuals_ma...",
          "5_accounts_account_usage",
          "1_privacy_organization_proc...",
          "6_privileged_access_privilege",
          "3_authentication_identity_a...",
          "8_physical_physical access_...",
          "9_power_emergency_environme...",
          "12_wireless_wireless access...",
          "25_media_sanitization_digital",
          "18_passwords_penetration_pe...",
          "20_testing_coverage_penetra...",
          "22_assessments_red team exe...",
          "17_tamper_resistance_compon...",
          "19_transaction_configuratio...",
          "29_products_acquisition_com...",
          "39_information processed_co...",
          "16_sa_security functions_sa...",
          "28_services_locations_infor...",
          "4_incident_incident respons...",
          "2_audit_audit records_records",
          "33_alerts_generated_alerts ...",
          "21_monitoring_impact analys...",
          "34_integrity_information in...",
          "24_detection_intrusion dete...",
          "37_sessions_network_session",
          "23_encryption_flow_authenti...",
          "35_cryptographic_confidenti...",
          "7_cryptographic_configurati...",
          "32_host_host based_based",
          "31_shared resources_resourc...",
          "38_memory_boundary protecti..."
         ],
         "tickvals": [
          -5,
          -15,
          -25,
          -35,
          -45,
          -55,
          -65,
          -75,
          -85,
          -95,
          -105,
          -115,
          -125,
          -135,
          -145,
          -155,
          -165,
          -175,
          -185,
          -195,
          -205,
          -215,
          -225,
          -235,
          -245,
          -255,
          -265,
          -275,
          -285,
          -295,
          -305,
          -315,
          -325,
          -335,
          -345,
          -355,
          -365,
          -375,
          -385,
          -395
         ],
         "type": "linear",
         "zeroline": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check updates\n",
    "topic_model.visualize_hierarchy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster  0:                                cloud                           criterion                       cloud service\n",
      "Cluster  1:                              privacy                        organization                          procedures\n",
      "Cluster  2:                                audit                       audit records                             records\n",
      "Cluster  3:                       authentication                            identity                      authenticators\n",
      "Cluster  4:                             incident                   incident response                            response\n",
      "Cluster  5:                             accounts                             account                               usage\n",
      "Cluster  6:                           privileged                              access                           privilege\n",
      "Cluster  7:                        cryptographic                       configuration                        cryptography\n",
      "Cluster  8:                             physical                     physical access                              access\n",
      "Cluster  9:                                power                           emergency                       environmental\n",
      "Cluster 10:                            alternate                                site                   alternate storage\n",
      "Cluster 11:                      vulnerabilities                       vulnerability                               cloud\n",
      "Cluster 12:                             wireless                     wireless access                    control wireless\n",
      "Cluster 13:                            personnel                         individuals                         maintenance\n",
      "Cluster 14:                          contingency                                plan                    contingency plan\n",
      "Cluster 15:                   telecommunications         telecommunications services                            services\n",
      "Cluster 16:                                   sa                  security functions                               sa sa\n",
      "Cluster 17:                               tamper                          resistance                          components\n",
      "Cluster 18:                            passwords                         penetration                 penetration testing\n",
      "Cluster 19:                          transaction                       configuration                            previous\n",
      "Cluster 20:                              testing                            coverage                 penetration testing\n",
      "Cluster 21:                           monitoring                     impact analyses                              impact\n",
      "Cluster 22:                          assessments                  red team exercises                      team exercises\n",
      "Cluster 23:                           encryption                                flow                        authenticity\n",
      "Cluster 24:                            detection                 intrusion detection                           intrusion\n",
      "Cluster 25:                                media                        sanitization                             digital\n",
      "Cluster 26:                              program                        restrictions                 access restrictions\n",
      "Cluster 27:                         discoverable                     vulnerabilities             vulnerabilities scanned\n",
      "Cluster 28:                             services                           locations                information security\n",
      "Cluster 29:                             products                         acquisition                   component service\n",
      "Cluster 30:                             recovery                      reconstitution                            critical\n",
      "Cluster 31:                     shared resources                           resources                               proxy\n",
      "Cluster 32:                                 host                          host based                               based\n",
      "Cluster 33:                               alerts                           generated                    alerts generated\n",
      "Cluster 34:                            integrity               information integrity                     integrity check\n",
      "Cluster 35:                        cryptographic           confidentiality integrity                     confidentiality\n",
      "Cluster 36:                         contaminated                  corrective actions                          corrective\n",
      "Cluster 37:                             sessions                             network                             session\n",
      "Cluster 38:                               memory                 boundary protection                            boundary\n",
      "Cluster 39:                information processed    components information processed                            location\n"
     ]
    }
   ],
   "source": [
    "# show updates differently\n",
    "for k, v in topic_model.get_topics().items():\n",
    "    if k != -1:\n",
    "        print(f'Cluster {k : >2}:  {v[0][0]: >35} {v[1][0]: >35} {v[2][0]: >35}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:00<00:00, 846.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "├─contingency_alternate_site_telecommunications_planning\n",
      "│    ├─■──recovery_reconstitution_critical_recovery point_recovery time ── Topic: 30\n",
      "│    └─alternate_contingency_site_telecommunications_planning\n",
      "│         ├─site_alternate_contingency_alternate storage_planning\n",
      "│         │    ├─■──contingency_plan_contingency plan_planning_plans ── Topic: 14\n",
      "│         │    └─■──alternate_site_alternate storage_storage_sites ── Topic: 10\n",
      "│         └─■──telecommunications_telecommunications services_services_telecommunications service_alternate ── Topic: 15\n",
      "└─security_information_cloud_service_organization\n",
      "     ├─cloud_criterion_cloud service_service_service provider\n",
      "     │    ├─discoverable_vulnerabilities_corrective actions_corrective_vulnerability\n",
      "     │    │    ├─■──contaminated_corrective actions_corrective_disclosure_reporting ── Topic: 36\n",
      "     │    │    └─■──discoverable_vulnerabilities_vulnerabilities scanned_scanned_vulnerability ── Topic: 27\n",
      "     │    └─cloud_criterion_cloud service_service_service provider\n",
      "     │         ├─■──vulnerabilities_vulnerability_cloud_vulnerability monitoring_cloud service ── Topic: 11\n",
      "     │         └─■──cloud_criterion_cloud service_service_service provider ── Topic: 0\n",
      "     └─organization_organization defined_defined_security_systems\n",
      "          ├─organization_organization defined_defined_security_systems\n",
      "          │    ├─organization_security_systems_organization defined_defined\n",
      "          │    │    ├─organization_security_systems_privacy_organization defined\n",
      "          │    │    │    ├─organization_security_privacy_systems_organization defined\n",
      "          │    │    │    │    ├─organization_privacy_security_systems_procedures\n",
      "          │    │    │    │    │    ├─■──program_restrictions_access restrictions_software_execution ── Topic: 26\n",
      "          │    │    │    │    │    └─organization_security_privacy_systems_security privacy\n",
      "          │    │    │    │    │         ├─organization_privacy_security_procedures_security privacy\n",
      "          │    │    │    │    │         │    ├─■──personnel_individuals_maintenance_terminated_access ── Topic: 13\n",
      "          │    │    │    │    │         │    └─organization_privacy_security_procedures_security privacy\n",
      "          │    │    │    │    │         │         ├─organization_privacy_procedures_security_security privacy\n",
      "          │    │    │    │    │         │         │    ├─■──accounts_account_usage_software_account management ── Topic: 5\n",
      "          │    │    │    │    │         │         │    └─■──privacy_organization_procedures_security_security privacy ── Topic: 1\n",
      "          │    │    │    │    │         │         └─■──privileged_access_privilege_functions_privileges ── Topic: 6\n",
      "          │    │    │    │    │         └─■──authentication_identity_authenticators_identification authentication_identification ── Topic: 3\n",
      "          │    │    │    │    └─physical_power_environmental_facility_physical environmental\n",
      "          │    │    │    │         ├─■──physical_physical access_access_facility_maintenance ── Topic: 8\n",
      "          │    │    │    │         └─■──power_emergency_environmental_rooms_physical environmental ── Topic: 9\n",
      "          │    │    │    └─wireless_sanitization_media_devices_storage devices\n",
      "          │    │    │         ├─■──wireless_wireless access_control wireless_access_networking ── Topic: 12\n",
      "          │    │    │         └─■──media_sanitization_digital_devices_storage devices ── Topic: 25\n",
      "          │    │    └─testing_penetration testing_penetration_sa_components\n",
      "          │    │         ├─testing_penetration testing_penetration_passwords_assessments\n",
      "          │    │         │    ├─testing_penetration_penetration testing_passwords_sanitization\n",
      "          │    │         │    │    ├─■──passwords_penetration_penetration testing_testing_sanitization ── Topic: 18\n",
      "          │    │         │    │    └─■──testing_coverage_penetration testing_penetration_environment ── Topic: 20\n",
      "          │    │         │    └─■──assessments_red team exercises_team exercises_red_red team ── Topic: 22\n",
      "          │    │         └─sa_functions_components_sa sa_tamper\n",
      "          │    │              ├─tamper_transaction_components_counterfeit_risk management family\n",
      "          │    │              │    ├─■──tamper_resistance_components_systems components_disposal ── Topic: 17\n",
      "          │    │              │    └─■──transaction_configuration_previous_recovery_transaction based ── Topic: 19\n",
      "          │    │              └─sa_functions_sa sa_security functions_pm\n",
      "          │    │                   ├─■──products_acquisition_component service_piv_acquisition acquisition ── Topic: 29\n",
      "          │    │                   └─sa_functions_sa sa_security functions_pm\n",
      "          │    │                        ├─■──information processed_components information processed_location_processed_components information ── Topic: 39\n",
      "          │    │                        └─■──sa_security functions_sa sa_functions_pm ── Topic: 16\n",
      "          │    └─audit_incident_response_audit records_records\n",
      "          │         ├─audit_incident_audit records_records_response\n",
      "          │         │    ├─incident_response_incident response_incident response incident_response incident\n",
      "          │         │    │    ├─■──services_locations_information security_acquisition_processing ── Topic: 28\n",
      "          │         │    │    └─■──incident_incident response_response_incident response incident_response incident ── Topic: 4\n",
      "          │         │    └─■──audit_audit records_records_audit record_record ── Topic: 2\n",
      "          │         └─alerts_integrity_information integrity_generated_monitoring\n",
      "          │              ├─alerts_generated_privacy_monitoring_alerts generated\n",
      "          │              │    ├─■──alerts_generated_alerts generated_alert_officers ── Topic: 33\n",
      "          │              │    └─■──monitoring_impact analyses_impact_changes_analyses ── Topic: 21\n",
      "          │              └─detection_integrity_information integrity_intrusion detection_intrusion\n",
      "          │                   ├─■──integrity_information integrity_integrity check_security relevant_firmware information ── Topic: 34\n",
      "          │                   └─■──detection_intrusion detection_intrusion_wide_spam protection ── Topic: 24\n",
      "          └─protection_cryptographic_mechanisms_information_sessions\n",
      "               ├─cryptographic_information_sessions_mechanisms_configuration\n",
      "               │    ├─sessions_session_encryption_flow_control\n",
      "               │    │    ├─■──sessions_network_session_number_account ── Topic: 37\n",
      "               │    │    └─■──encryption_flow_authenticity_sessions_container ── Topic: 23\n",
      "               │    └─cryptographic_configuration_mechanisms_cryptography_automated\n",
      "               │         ├─■──cryptographic_confidentiality integrity_confidentiality_cryptographic mechanisms_integrity ── Topic: 35\n",
      "               │         └─■──cryptographic_configuration_cryptography_automated_inventory ── Topic: 7\n",
      "               └─boundary protection_boundary_protection_host_host based\n",
      "                    ├─host_host based_protection_boundary protection_components\n",
      "                    │    ├─■──host_host based_based_boundary protection_boundary ── Topic: 32\n",
      "                    │    └─■──shared resources_resources_proxy_shared_proxy servers ── Topic: 31\n",
      "                    └─■──memory_boundary protection_boundary_failures_data execution ── Topic: 38\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# printing tree - shows higher order, less granular topics too\n",
    "hierarchical_topics = topic_model.hierarchical_topics(docs)\n",
    "tree = topic_model.get_topic_tree(hierarchical_topics)\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redo topic representations w/ OpenAI API\n",
    "> See [documentation](https://maartengr.github.io/BERTopic/api/representation/openai.html#bertopic.representation._openai.OpenAI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get your key\n",
    "def read_key_from_file(filename=\"../keys/key.txt\"):\n",
    "    with open(filename, \"r\") as file:\n",
    "        return file.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "OpenAI.__init__() got an unexpected keyword argument 'api_key'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbertopic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BERTopic\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# must manually add openai representation because the bertopic utility doesn't work\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_key_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# main loop - get the topic names from OpenAI\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: OpenAI.__init__() got an unexpected keyword argument 'api_key'"
     ]
    }
   ],
   "source": [
    "# generate topic names using OpenAI\n",
    "import openai\n",
    "from bertopic.representation import OpenAI\n",
    "from bertopic import BERTopic\n",
    "\n",
    "# must manually add openai representation because the bertopic utility doesn't work\n",
    "client = OpenAI(api_key=read_key_from_file())\n",
    "\n",
    "# main loop - get the topic names from OpenAI\n",
    "import time\n",
    "rows_to_append = []\n",
    "\n",
    "# client = openai.OpenAI(api_key=read_key_from_file())  # NOTE: this is the old and now defunct way of calling OPenAI\n",
    "\n",
    "for x, i in enumerate(topic_model.get_topics()):\n",
    "  # skip -1, outliers\n",
    "  if x == 0 and i == -1:\n",
    "        continue\n",
    "  completion = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages = [\n",
    "{\"role\": \"system\", \"content\": \"You are a helpful assistant, knowledgeable on data privacy and security standards and controls, that helps in topic modeling tasks.\"},\n",
    "{\"role\": \"user\", \"content\": f\"I have a topic that contains the following documents: {topic_model.get_representative_docs()[i]}.\"},\n",
    "{\"role\": \"user\", \"content\": f\"The topic is described by the following keyword-probability pairs: {topic_model.get_topics()[i]}.\"},\n",
    "{\"role\": \"user\", \"content\": \"\"\"Based on the information above, extract a short but highly descriptive topic label of at most 5 words. \n",
    " \n",
    "    Make sure it is in the following format:\n",
    "    \n",
    "    topic: <topic label>.\"\"\"},\n",
    "]\n",
    "  )\n",
    "\n",
    "  # Extract the topic label from the completion response\n",
    "  topic_label = completion.choices[0].message.content.split(\"topic: \")[1].strip()\n",
    "\n",
    "  rows_to_append.append({\n",
    "    \"topic_num\": i,\n",
    "    \"representative_docs\": topic_model.get_representative_docs()[i],  \n",
    "    \"top_words\": topic_model.get_topics()[i], \n",
    "    \"topic_label\": topic_label\n",
    "    })\n",
    "\n",
    "  print(f\"Appended topic {i}: {topic_label}\")\n",
    "\n",
    "  time.sleep(.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
